{"meta":{"title":"知行合一","subtitle":"stan","description":"啊咧咧啊咧咧啊咧啊咧咧~","author":"Light","url":"http://example.com","root":"/"},"pages":[{"title":"Java8","date":"2024-10-28T13:37:10.000Z","updated":"2024-12-01T14:27:24.113Z","comments":true,"path":"Java8/index.html","permalink":"http://example.com/Java8/index.html","excerpt":"","text":"Java基础 集合框架 Java并发 Mysql Redis 框架 计算机网络 JVM 中间件 操作系统 其它"},{"title":"algorithm","date":"2024-04-27T11:19:37.000Z","updated":"2024-07-30T08:12:55.914Z","comments":true,"path":"algorithm/index.html","permalink":"http://example.com/algorithm/index.html","excerpt":"","text":"二分查找的两种写法 二分查找仅适用于有序的数据集合（当然数组是最常见的 一、左闭右闭步骤如下： 初始化 代码如下： 双指针 对撞指针定义指的是两个指针 𝑙𝑒𝑓𝑡left、𝑟𝑖𝑔ℎ𝑡right 分别指向序列第一个元素和最后一个元素，然后 𝑙𝑒𝑓𝑡left 指针不断递增，𝑟𝑖𝑔ℎ𝑡right 不断递减，直到两个指针的值相撞（即 𝑙𝑒𝑓𝑡&#x3D;&#x3D;𝑟𝑖𝑔ℎ𝑡left&#x3D;&#x3D;right），或者满足其他要求的特殊条件为止。 模板1234567891011left, right = 0, len(nums) - 1while left &lt; right: if 满足要求的特殊条件: return 符合条件的值 elif 一定条件 1: left += 1 elif 一定条件 2: right -= 1return 没找到 或 找到对应值 适用范围对撞指针一般用来解决有序数组或者字符串问题： 查找有序数组中满足某些约束条件的一组元素问题：比如二分查找、数字之和等问题。 字符串反转问题：反转字符串、回文数、颠倒二进制等问题。 快慢指针定义指的是两个指针从同一侧开始遍历序列，且移动的步长一个快一个慢。移动快的指针被称为 「快指针（fast）」，移动慢的指针被称为「慢指针（slow）」。两个指针以不同速度、不同策略移动，直到快指针移动到数组尾端，或者两指针相交，或者满足其他特殊条件时为止。 模板1234567slow = 0fast = 1while 没有遍历完： if 满足要求的特殊条件: slow += 1 fast += 1return 合适的值 适用范围快慢指针一般用于处理数组中的移动、删除元素问题，或者链表中的判断是否有环、长度问题。 口诀搜索一个元素时，搜索区间两端闭。while 条件带等号，否则需要打补丁。if 相等就返回，其他的事甭操心。mid 必须加减一，因为区间两端闭。while结束就凉了，凄凄惨惨返 -1。 搜索左右边界时，搜索区间要阐明。 左闭右开最常见，其余逻辑便自明: while要用小于号，这样才能不漏掉。 if 相等别返回，利用 mid 锁边界。 mid 加一或减一?要看区间开或闭。 while结束不算完，因为你还没返回。 索引可能出边界，if 检查保平安。 二叉树前中后序遍历（递归）1234567891011121314151617181920212223242526272829//前序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; result.add(root.val);; //中间节点在前面 preorder(root.left, result); preorder(root.right, result);&#125;//中序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; preorder(root.left, result); result.add(root.val); //中间节点在中间 preorder(root.right, result);&#125;//后序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; preorder(root.left, result); preorder(root.right, result); result.add(root.val);; //中间节点在后面&#125; 前中后序遍历（迭代）12345678910111213141516171819202122232425262728293031323334353637383940414243//前序 public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return res; &#125; Deque&lt;TreeNode&gt; stack = new LinkedList&lt;TreeNode&gt;(); //显示声明一个栈 TreeNode node = root; while (!stack.isEmpty() || node != null) &#123; while (node != null) &#123; res.add(node.val); stack.push(node); node = node.left; &#125; node = stack.pop(); //可以让node重新返回上一个父节点 node = node.right; &#125; return res;&#125;//中序public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return res; &#125; Deque&lt;TreeNode&gt; stk = new LinkedList&lt;TreeNode&gt;(); while (root != null || !stk.isEmpty()) &#123; while (root != null) &#123; //找第一个左叶子节点，且该左叶子节点是入栈了的，所以下面要先出栈，再给结果赋值 stk.push(root); root = root.left; &#125; root = stk.pop(); res.add(root.val); root = root.right; &#125; return res;&#125;//后序"},{"title":"about","date":"2024-04-24T02:39:53.000Z","updated":"2024-04-26T12:54:38.247Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"双非研一在读"},{"title":"算法学习","date":"2024-04-27T11:25:24.000Z","updated":"2024-07-05T11:57:20.083Z","comments":true,"path":"algorithm/二分查找.html","permalink":"http://example.com/algorithm/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE.html","excerpt":"","text":"二分查找二分查找仅适用于有序的数据集合（当然数组是最常见的 二分查找的两种思路直接法12345678910111213141516int left = 0;int right = nums.length - 1;while(left &lt;= right)&#123; int mid = (left + right ) &gt;&gt; 1; //如果找到目标值，则直接范围中心位置 if (nums[mid] == target) return mid; //如果 nums[mid] 小于目标值，则在 [mid + 1, right] 中继续搜索 else if(nums[mid] &lt; target) left = mid + 1; //如果 nums[mid] 大于目标值，则在 [left, mid - 1] 中继续搜索 else right = mid - 1;&#125;//未搜索到元素，返回 -1return -1; 排除法12345678910111213int left = 0;int right = nums.length - 1;while(left &lt; right)&#123; int mid = (left + right ) &gt;&gt; 1; //如果 nums[mid] 小于目标值，排除掉不可能区间 [left, mid]，在 [mid + 1, right] 中继续搜索 else if(nums[mid] &lt; target) left = mid + 1; //如果 nums[mid] 大于目标值，目标元素可能在 [left, mid] 中，在 [left, mid] 中继续搜索 else if(nums[mid] &lt; target) right = mid; //未搜索到元素，返回 -1 return left if nums[left] == target else -1&#125;"},{"title":"categories","date":"2024-09-11T03:20:45.000Z","updated":"2024-09-11T03:21:12.040Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2024-10-03T15:39:20.336Z","updated":"2024-10-03T15:39:20.336Z","comments":true,"path":"css/custom.css","permalink":"http://example.com/css/custom.css","excerpt":"","text":"/* 侧边栏个人信息卡片动态渐变色 */ #aside-content > .card-widget.card-info { background: linear-gradient( -45deg, #e8d8b9, #eccec5, #a3e9eb, #bdbdf0, #eec1ea ); box-shadow: 0 0 5px rgb(66, 68, 68); position: relative; background-size: 400% 400%; -webkit-animation: Gradient 10s ease infinite; -moz-animation: Gradient 10s ease infinite; animation: Gradient 10s ease infinite !important; } @-webkit-keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } @-moz-keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } @keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } /* 黑夜模式适配 */ [data-theme=\"dark\"] #aside-content > .card-widget.card-info { background: #191919ee; } /* 个人信息Follow me按钮 */ #aside-content > .card-widget.card-info > #card-info-btn { background-color: #3eb8be; border-radius: 8px; }"},{"title":"标签","date":"2018-01-04T16:00:00.000Z","updated":"2024-09-11T10:03:52.716Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"更换主题","slug":"更换主题","date":"2025-01-21T08:30:26.000Z","updated":"2025-01-21T08:37:41.121Z","comments":true,"path":"2025/01/21/更换主题/","permalink":"http://example.com/2025/01/21/%E6%9B%B4%E6%8D%A2%E4%B8%BB%E9%A2%98/","excerpt":"","text":"一、查看前置条件以下是官方的前置条件： 这是我的hexo版本信息 这是node和npm版本信息 二、更新主题修改博客配置文件 1theme: volantis","categories":[],"tags":[]},{"title":"springcloud学习","slug":"springcloud学习","date":"2025-01-18T12:32:05.000Z","updated":"2025-01-20T02:48:00.003Z","comments":true,"path":"2025/01/18/springcloud学习/","permalink":"http://example.com/2025/01/18/springcloud%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"一、Docker1.基础命令2.数据卷容器内部的数据不好修改，因此数据卷应运而生，它就是一个虚拟目录，是联通宿主机目录和容器目录的中间桥梁。 数据卷命令： 注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中，数据卷会自动创建。 数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似： 1234# 挂载本地目录-v 本地目录:容器内目录# 挂载本地文件-v 本地文件:容器内文件 注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。 例如： 12-v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷-v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录 二、项目 导入项目 出现错误：docker: Error response from daemon: Get “https://registry-1.docker.io/v2/“: net&#x2F;http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers). 在这里解决了，修改了daemon.json就可以了，效果如下 接下来连接数据库，这里账号密码应该是数据库的而不是虚拟机的 接下来按照视频里面启动后端项目，有两个小插曲，一个是lombok版本问题，修改为了1.18.30，另一个是8080端口被占用了，直接在任务管理器里面杀死了 后面为item-service创建单独数据库的时候，发现连接不上去，后面解决了，是docker里面的mysql没有启动，设置自启动好像有点问题，后面再看看 设置docker开启自启动： 1systemctl enable docker 然后启动MySQL容器 12# docker start 容器名docker start mysql 然后就是拆分了商品服务和购物车服务","categories":[],"tags":[]},{"title":"分布式","slug":"八股/分布式","date":"2025-01-18T07:13:37.000Z","updated":"2025-01-18T09:06:32.531Z","comments":true,"path":"2025/01/18/八股/分布式/","permalink":"http://example.com/2025/01/18/%E5%85%AB%E8%82%A1/%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"分布式（distributed）是为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段，将一个业务拆分成不同的子业务，分布在不同的机器上执行。服务之间通过远程调用协同工作，对外提供服务。 一、分布式理论1、CAP原则在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这 3 个基本需求，最多只能同时满足其中的 2 个。 Consistency（一致性）： 指数据在多个副本之间能够保持一致的特性（严格的一致性） Availability（可用性）：指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据） Partition tolerance（分区容错性）：分布式系统出现网络分区的时候，仍然能够对外提供服务。 什么是网络分区？ 分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了， 整个网络就分成了几块区域，这就叫 网络分区。 2、为什么CAP不能同时满足首先，在分布式系统中，分区是必然存在的，因此P就必须要满足，否则就违背了分布式系统的初衷，在满足P的前提下，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。 因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。 另外，需要补充说明的一点是：如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。 Spring Cloud在CAP法则上主要满足的是AP法则，Dubbo和Zookeeper在CAP法则主要满足的是CP法则 ，Nacos 不仅支持 CP 也支持 AP 3、BASE理论BASE 是 Basically Available（基本可用）、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。 其核心思想时：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。 Basically Available（基本可用）：什么是基本可用呢？假设系统出现了不可预知的故障，但还是能用，只是相比较正常的系统而言，可能会有响应时间上的损失，或者功能上的降级（正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用）。 Soft-state（软状态）：什么是硬状态呢？要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态也称为弱状态，相比较硬状态而言，允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 Eventually Consistent（最终一致性）：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 二、分布式锁的实现 1、MYSQL实现 用数据库实现分布式锁比较简单，就是创建一张锁表，数据库对字段作唯一性约束。 加锁的时候，在锁表中增加一条记录即可；释放锁的时候删除记录就行。 如果有并发请求同时提交到数据库，数据库会保证只有一个请求能够得到锁。 这种属于数据库 IO 操作，效率不高，而且频繁操作会增大数据库的开销，因此这种方式在高并发、高性能的场景中用的不多。 2、Redis实现 Redis 执行命令是单线程的，Redis 实现分布式锁就是利用这个特性。 通过 setnx 和过期时间实现分布式锁。 当然，一般生产中都是使用 Redission 客户端，非常良好地封装了分布式锁的 api，而且支持 RedLock。 3、Zookeeper实现 三、分布式事务 四、分布式一致性算法","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"算法学习","slug":"算法学习","date":"2024-12-24T07:24:36.000Z","updated":"2024-12-24T09:14:22.111Z","comments":true,"path":"2024/12/24/算法学习/","permalink":"http://example.com/2024/12/24/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"图论","categories":[],"tags":[]},{"title":"黑马点评记录","slug":"黑马点评记录","date":"2024-12-18T14:28:12.000Z","updated":"2025-01-17T13:28:50.168Z","comments":true,"path":"2024/12/18/黑马点评记录/","permalink":"http://example.com/2024/12/18/%E9%BB%91%E9%A9%AC%E7%82%B9%E8%AF%84%E8%AE%B0%E5%BD%95/","excerpt":"","text":"一、登录redis启动命令：在finalsell中systemctl start redis 1、发送验证码12345678910111213141516171819/** * 发送验证码 * @param phone * @param session * @return */ public Result sendCode(String phone, HttpSession session) &#123; //1、校验手机号格式 if (RegexUtils.isPhoneInvalid(phone)) &#123; return Result.fail(&quot;手机号无效&quot;); &#125; //2、如果成功，生成6位的验证码 String code = RandomUtil.randomNumbers(6); //3、保存到session session.setAttribute(&quot;code&quot;, code); //4、发送验证码需要调第三方接口，暂不做，打印日志 log.info(&quot;验证码为：&#123;&#125;&quot;, code); return Result.ok(); &#125; 2、登录功能这里一开始忘了在createNewUser用mp的sava将新生成的user保存到数据库了，我说怎么半天不见数据库有新数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 登录 * @param loginForm * @param session * @return */ public Result login(LoginFormDTO loginForm, HttpSession session) &#123; //1、校验手机号是否合规 String phone = loginForm.getPhone(); if (RegexUtils.isPhoneInvalid(phone)) &#123; return Result.fail(&quot;手机号无效&quot;); &#125; //2、校验验证码是否有效 String code = loginForm.getCode(); Object cacheCode = session.getAttribute(&quot;code&quot;); if(cacheCode == null || !cacheCode.equals(code))&#123; //验证码无效 return Result.fail(&quot;验证码无效&quot;); &#125; //3、查询用户——此处使用MP User user = query().eq(&quot;phone&quot;, phone).one(); if(user == null)&#123; //user不存在，则创建一个新的user user = createNewUser(phone); &#125; //4、根据用户是否存在，最终都保存到session中 //BeanUtil.copyProperties(user, UserDTO.class)将user的信息复制到UserDTO并创建一个UserDTO对象返回 session.setAttribute(&quot;user&quot;, BeanUtil.copyProperties(user, UserDTO.class)); return Result.ok(); &#125; private User createNewUser(String phone) &#123; //1、创建用户 User user = new User(); user.setPhone(phone); user.setNickName(&quot;user_&quot; + RandomUtil.randomString(10)); //2、保存用户，用的MP save(user); return user; &#125; 3、登录校验拦截器现在有一个问题：对于其它业务（Controller），每个都要写登录逻辑岂不是很麻烦 答：引入拦截器，可以在所有Controller之前判断是否放行 又有一个问题：如何把拦截器拦截到的信息传给其它Controller呢？ 答：ThreadLocal，每个请求都是一个独立的线程，也可以避免并发问题的出现 12345678910111213141516171819202122232425262728293031323334353637public class LoginInterceptor implements HandlerInterceptor &#123; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //1、获取session HttpSession session = request.getSession(); //2、从session中获取user Object user = session.getAttribute(&quot;user&quot;); //3、判断user是否存在 if(user == null)&#123; return false; &#125; //否则就保存到当前线程 UserHolder.saveUser((UserDTO) user); return true; &#125; /** * 渲染之后，将保存的信息删除，避免内存泄露 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; //直接调用UserHolder UserHolder.removeUser(); &#125;&#125; 拦截器写好了还没有生效，需要配置 123456789101112131415@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()). excludePathPatterns( //排除不需要被拦截登录的路径 &quot;/shop/**&quot;, &quot;/voucher/**&quot;, &quot;shop-type/**&quot;, &quot;/upload/**&quot;, &quot;/blog/hot&quot;, &quot;/user/code&quot;, &quot;/user/login&quot;); &#125;&#125; 4 、Redis代替session解决session问题STAR法则 S（Situation ）：尽管现在是一个单体式的架构，但为了应对并发，肯定要布置多台tomcat服务器形成负载均衡的集群。这时就有问题了：因为多台tomcat不能共享空间，可能导致多次请求打到不同的tomcat服务器上，出现数据丢失问题 T（Task）：session的替代方案应满足以下需求： 数据共享 内存存储（因为session就是基于内存的，所以读写效率才会比较高） key-value结构 A（Action ）： 12//修改发送验证码，保存验证码到redis，并设置有效期防止堆积占用内存stringRedisTemplate.opsForValue().set(LOGIN_CODE_KEY + phone, code, LOGIN_CODE_TTL, TimeUnit.MINUTES); 接下来修改登录逻辑，在登录逻辑实现中修改代码如下： 1234567//2、校验验证码是否有效，从redis中取 String code = loginForm.getCode(); Object cacheCode = redisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone); if(cacheCode == null || !cacheCode.equals(code))&#123; //验证码无效 return Result.fail(&quot;验证码无效&quot;); &#125; 123456789101112131415//保存用户信息到redis中 //1、生成token作为key UUID token = UUID.randomUUID(true); //2、将user转为map存储 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO); //3、存储到redis redisTemplate.opsForHash().putAll(LOGIN_USER_KEY + token, userMap); //3、设置token有效期 redisTemplate.expire(LOGIN_USER_KEY + token, LOGIN_USER_TTL, TimeUnit.MINUTES); return Result.ok(token); 拦截器中代码也要修改，同时只要拦截到请求，说明用户还在活跃状态，就刷新token的有效期（不然可能会出现用户一直在使用但token有效期过了就要重新登录的错误） 5、双重拦截器解决非登录页面token刷新问题但是又有一个问题，因为我们第一个拦截器只拦截了需要登录的页面的请求。如果用户一直处于不需要登录的页面，是在活跃的，但这时token有效期过了再发请求可能就要重新登录，所以可以再加一个拦截器来拦截一切请求，只要来了请求就说明用户还在活跃，然后更新token有效期。 最终双重拦截器的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class RefreshTokenInterceptor implements HandlerInterceptor &#123; private StringRedisTemplate stringRedisTemplate; public RefreshTokenInterceptor(StringRedisTemplate stringRedisTemplate)&#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //1、获取token String token = request.getHeader(&quot;authorization&quot;); if (StrUtil.isBlank(token)) &#123; return true; &#125; //2、根据token从redis中获取用户 Map&lt;Object, Object&gt; userMap = stringRedisTemplate.opsForHash().entries(RedisConstants.LOGIN_USER_KEY + token); //3、判断user是否存在 if(userMap.isEmpty())&#123; return true; &#125; //4、将map转为dto UserDTO userDTO = BeanUtil.fillBeanWithMap(userMap, new UserDTO(), false); //保存到当前线程 UserHolder.saveUser(userDTO); return true; &#125; /** * 渲染之后，将保存的信息删除，避免内存泄露 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; //直接调用UserHolder UserHolder.removeUser(); &#125;&#125; 12345678910111213141516public class LoginInterceptor implements HandlerInterceptor &#123; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (UserHolder.getUser() == null) &#123; return false; &#125; return true; &#125;&#125; 同时需要在MvcConfig中更新配置，注意用order指定拦截器顺序 1234567891011121314151617181920@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Resource private StringRedisTemplate stringRedisTemplate; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()). excludePathPatterns( //排除不需要被拦截登录的路径 &quot;/shop/**&quot;, &quot;/voucher/**&quot;, &quot;/shop-type/**&quot;, &quot;/upload/**&quot;, &quot;/blog/hot&quot;, &quot;/user/code&quot;, &quot;/user/login&quot;).order(1); registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).addPathPatterns(&quot;/**&quot;).order(0); &#125;&#125; 二、商户查询缓存1、添加商铺缓存1234567891011121314151617181920212223242526272829@Servicepublic class ShopServiceImpl extends ServiceImpl&lt;ShopMapper, Shop&gt; implements IShopService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; //1、从redis中查，查到了直接返回 String shopJson = stringRedisTemplate.opsForValue().get(key); if(StrUtil.isNotBlank(shopJson))&#123; Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; //2、没有查到就去数据库查，如果数据库也没有，就返回 Shop shop = getById(id); if(shop == null) return Result.fail(&quot;商铺信息不存在&quot;); //3、如果数据库有，保存到redis便于下次查找，然后再返回 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop)); return Result.ok(shop); &#125;&#125; 2、练习：添加商铺类型缓存3、缓存更新策略issue1、采用什么缓存更新策略？ 内存淘汰 超时剔除 主动更新 说明 不用自己维护， 利用Redis的内存淘汰机制， 当内存不足时自动淘汰部分数据。 下次查询时更新缓存。 给缓存数据添加TTL时间， 到期后自动删除缓存。 下次查询时更新缓存。 编写业务逻辑， 在修改数据库的同时， 更新缓存。 一致性 差 一般 好 维护成本 无 低 高 业务场景 低一致性需求：使用内存淘汰机制，例如店铺类型的查询缓存（因为这个很长一段时间都不需要更新） 高一致性需求：主动更新，并以超时剔除作为兜底方案，例如店铺详情查询的缓存 ans1：本项目采用主动更新+超时剔除（兜底） 更新方案采用双写方案（Cache Aside Pattern）：人工编码方式，缓存调用者在更新完数据库后再去更新缓存。 issue2：在对缓存的更新上，对比删除缓存与更新缓存 更新缓存：每次更新数据库都需要更新缓存，无效写操作较多 删除缓存：更新数据库时让缓存失效，再次查询时更新缓存 ans2：所以我们采用直接删除缓存 issue3：是先操作缓存（先删除缓存，再更新数据库）还是先操作数据库（先更新数据库，再操作缓存）？ 对比如下： 先删除缓存，再更新数据库： 删除缓存的操作很快，但是更新数据库的操作相对较慢，如果此时有一个线程2刚好进来查询缓存，由于我们刚刚才删除缓存，所以线程2需要查询数据库，并写入缓存，但是我们更新数据库的操作还未完成，所以线程2查询到的数据是脏数据，出现线程安全问题 先更新数据库，再操作缓存 当线程1在查询缓存且未命中，此时线程1查询数据，查询完准备写入缓存时，由于没有加锁线程2乘虚而入，线程2在这期间对数据库进行了更新，此时线程1将旧数据返回了，出现了脏读，这个事件发生的概率很低，因为先是需要满足缓存未命中，且在写入缓存的那段事件内有一个线程进行更新操作，缓存的查询很快，这段空隙时间很小，所以出现脏读现象的概率也很低 这种方式的不足之处：存在脏读现象，但概率较小 ans3：虽然这二者都存在线程安全问题，但是相对来说，后者出现线程安全问题的概率相对较低，所以我们最终采用后者先操作数据库，再删除缓存的方案 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 根据id查询商铺数据（查询时，重建缓存） * * @param id * @return */@Overridepublic Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据 String shopJson = stringRedisTemplate.opsForValue().get(key); Shop shop = null; // 2、判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 2.1 缓存命中，直接返回店铺数据 shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 2.2 缓存未命中，从数据库中查询店铺数据 shop = this.getById(id); // 4、判断数据库是否存在店铺数据 if (Objects.isNull(shop)) &#123; // 4.1 数据库中不存在，返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 4.2 数据库中存在，重建缓存，并返回店铺数据 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop);&#125;/** * 更新商铺数据（更新时，更新数据库，删除缓存） * * @param shop * @return */@Transactional@Overridepublic Result updateShop(Shop shop) &#123; // 参数校验, 略 // 1、更新数据库中的店铺数据 boolean f = this.updateById(shop); if (!f)&#123; // 缓存更新失败，抛出异常，事务回滚 throw new RuntimeException(&quot;数据库更新失败&quot;); &#125; // 2、删除缓存 f = stringRedisTemplate.delete(CACHE_SHOP_KEY + shop.getId()); if (!f)&#123; // 缓存删除失败，抛出异常，事务回滚 throw new RuntimeException(&quot;缓存删除失败&quot;); &#125; return Result.ok();&#125; 4、缓存穿透概念：客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 解决方案： 缓存空对象 优点：实现简单，维护方便 缺点：额外的内存消耗，可能造成短期的不一致 布隆过滤 优点：内存占用较少，没有多余key 缺点：实现复杂，存在误判可能（有穿透的风险），无法删除数据 本文采用是缓存缓存空对象 12345678910111213141516171819202122232425262728@Overridepublic Result queryById(Long id) &#123; //先从Redis中查，这里的常量值是固定的前缀 + 店铺id String shopJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY + id); //如果不为空（查询到了），则转为Shop类型直接返回 if (StrUtil.isNotBlank(shopJson)) &#123; Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; //如果查询到的是空字符串，则说明是我们缓存的空数据 if (shopjson != null) &#123; return Result.fail(&quot;店铺不存在！！&quot;); &#125; //否则去数据库中查 Shop shop = getById(id); //查不到，则将空字符串写入Redis if (shop == null) &#123; //这里的常量值是2分钟 stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, &quot;&quot;, CACHE_NULL_TTL, TimeUnit.MINUTES); return Result.fail(&quot;店铺不存在！！&quot;); &#125; //查到了则转为json字符串 String jsonStr = JSONUtil.toJsonStr(shop); //并存入redis，设置TTL stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, jsonStr, CACHE_SHOP_TTL, TimeUnit.MINUTES); //最终把查询到的商户信息返回给前端 return Result.ok(shop);&#125; 5、缓存雪崩 概念：缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。 解决方案 给不同的Key的TTL添加随机值 利用Redis集群提高服务的可用性 给缓存业务添加降级限流策略，比如快速失败机制，让请求尽可能打不到数据库上 给业务添加多级缓存 这里采用方案1 6、缓存击穿 概念：缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。 解决方案 互斥锁（时间换空间）优点：内存占用小，一致性高，实现简单缺点：性能较低，容易出现死锁 逻辑过期（空间换时间）优点：性能高缺点：内存占用较大，容易出现脏读 两者相比较，互斥锁更加易于实现，但是容易发生死锁，且锁导致并行变成串行，导致系统性能下降，逻辑过期实现起来相较复杂，且需要耗费额外的内存，但是通过开启子线程重建缓存，使原来的同步阻塞变成异步，提高系统的响应速度，但是容易出现脏读 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//互斥锁解决方案/** * 根据id查询商铺数据 * * @param id * @return */ @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据，并判断缓存是否命中 Result result = getShopFromCache(key); if (Objects.nonNull(result)) &#123; // 缓存命中，直接返回 return result; &#125; try &#123; // 2、缓存未命中，需要重建缓存，判断能否能够获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); if (!isLock) &#123; // 2.1 获取锁失败，已有线程在重建缓存，则休眠重试 Thread.sleep(50); return queryById(id); &#125; // 2.2 获取锁成功，判断缓存是否重建，防止堆积的线程全部请求数据库（所以说双检是很有必要的） result = getShopFromCache(key); if (Objects.nonNull(result)) &#123; // 缓存命中，直接返回 return result; &#125; // 3、从数据库中查询店铺数据，并判断数据库是否存在店铺数据 Shop shop = this.getById(id); if (Objects.isNull(shop)) &#123; // 数据库中不存在，缓存空对象（解决缓存穿透），返回失败信息 stringRedisTemplate.opsForValue().set(key, &quot;&quot;, CACHE_NULL_TTL, TimeUnit.SECONDS); return Result.fail(&quot;店铺不存在&quot;); &#125; // 4、数据库中存在，重建缓存，响应数据 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop); &#125;catch (Exception e)&#123; throw new RuntimeException(&quot;发生异常&quot;); &#125; finally &#123; // 5、释放锁（释放锁一定要记得放在finally中，防止死锁） unlock(key); &#125; &#125; /** * 从缓存中获取店铺数据 * @param key * @return */ private Result getShopFromCache(String key) &#123; String shopJson = stringRedisTemplate.opsForValue().get(key); // 判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 缓存数据有值，说明缓存命中了，直接返回店铺数据 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 判断缓存中查询的数据是否是空字符串(isNotBlank把 null 和 空字符串 给排除了) if (Objects.nonNull(shopJson)) &#123; // 当前数据是空字符串，说明缓存也命中了（该数据是之前缓存的空对象），直接返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 缓存未命中（缓存数据既没有值，又不是空字符串） return null; &#125; /** * 获取锁 * * @param key * @return */ private boolean tryLock(String key) &#123; Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, 10, TimeUnit.SECONDS); // 拆箱要判空，防止NPE return BooleanUtil.isTrue(flag); &#125; /** * 释放锁 * * @param key */ private void unlock(String key) &#123; stringRedisTemplate.delete(key); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//逻辑过期实现/** * 缓存重建线程池 */ public static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10); /** * 根据id查询商铺数据 * * @param id * @return */ @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据，并判断缓存是否命中 String shopJson = stringRedisTemplate.opsForValue().get(key); if (StrUtil.isBlank(shopJson)) &#123; // 1.1 缓存未命中，直接返回失败信息 return Result.fail(&quot;店铺数据不存在&quot;); &#125; // 1.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期 RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class); // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段 JSONObject data = (JSONObject) redisData.getData(); Shop shop = JSONUtil.toBean(data, Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) &#123; // 当前缓存数据未过期，直接返回 return Result.ok(shop); &#125; // 2、缓存数据已过期，获取互斥锁，并且重建缓存 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); if (isLock) &#123; // 获取锁成功，开启一个子线程去重建缓存 CACHE_REBUILD_EXECUTOR.submit(() -&gt; &#123; try &#123; this.saveShopToCache(id, 20L); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; finally &#123; unlock(lockKey); &#125; &#125;); &#125; // 3、获取锁失败，再次查询缓存，判断缓存是否重建（这里双检是有必要的） shopJson = stringRedisTemplate.opsForValue().get(key); if (StrUtil.isBlank(shopJson)) &#123; // 3.1 缓存未命中，直接返回失败信息 return Result.fail(&quot;店铺数据不存在&quot;); &#125; // 3.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期 redisData = JSONUtil.toBean(shopJson, RedisData.class); // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段 data = (JSONObject) redisData.getData(); shop = JSONUtil.toBean(data, Shop.class); expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) &#123; // 当前缓存数据未过期，直接返回 return Result.ok(shop); &#125; // 4、返回过期数据 return Result.ok(shop); &#125; /** * 从缓存中获取店铺数据 * @param key * @return */ private Result getShopFromCache(String key) &#123; String shopJson = stringRedisTemplate.opsForValue().get(key); // 判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 缓存数据有值，说明缓存命中了，直接返回店铺数据 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 判断缓存中查询的数据是否是空字符串(isNotBlank把 null 和 空字符串 给排除了) if (Objects.nonNull(shopJson)) &#123; // 当前数据是空字符串，说明缓存也命中了（该数据是之前缓存的空对象），直接返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 缓存未命中（缓存数据既没有值，又不是空字符串） return null; &#125; /** * 将数据保存到缓存中 * * @param id 商铺id * @param expireSeconds 逻辑过期时间 */ public void saveShopToCache(Long id, Long expireSeconds) throws InterruptedException &#123; // 从数据库中查询店铺数据 Shop shop = this.getById(id); Thread.sleep(200); // 封装逻辑过期数据 RedisData redisData = new RedisData(); redisData.setData(shop); redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds)); // 将逻辑过期数据存入Redis中 stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData)); &#125; 小结为了解决数据一致性问题，我们可以选择适当的缓存更新策略： 以缓存主动更新（双写方案+删除缓存模式+先操作数据库后操作缓存+事务）为主，超时剔除为辅 查询时，先查询缓存，缓存命中直接返回，缓存未命中查询数据库并重建缓存，返回查询结果 更新时，先修改数据删除缓存，使用事务保证缓存和数据操作两者的原子性、 除了会遇到数据一致性问题意外，我们还会遇到缓存穿透、缓存雪崩、缓存击穿等问题 对于缓存穿透，我们采用了缓存空对象解决 对于缓存击穿，我们分别演示了互斥锁（setnx实现方式）和逻辑过期两种方式解决 三、优惠券秒杀1、全局唯一ID自增ID存在的问题 当用户抢购时，就会生成订单并保存到tb_voucher_order这张表中，而订单表如果使用数据库自增ID就存在一些问题： id的规律性太明显，容易出现信息的泄露，被不怀好意的人伪造请求 受单表数据量的限制，MySQL中表能够存储的数据有限，会出现分库分表的情况，id不能够一直自增 那么该如何解决呢？我们需要使用分布式ID（也可以叫全局唯一ID），分布式ID满足以下特点： 全局唯一性：分布式ID保证在整个分布式系统中唯一性，不会出现重复的标识符。这对于区分和追踪系统中的不同实体非常重要。 高可用性：分布式ID生成器通常被设计为高可用的组件，可以通过水平扩展、冗余备份或集群部署来确保服务的可用性。即使某个节点或组件发生故障，仍然能够正常生成唯一的ID标识符。 安全性：分布式ID生成器通常是独立于应用程序和业务逻辑的。它们被设计为一个单独的组件或服务，可以被各种应用程序和服务所共享和使用，使得各个应用程序之间的ID生成过程互不干扰。 高性能：分布式ID生成器通常要求在很短的时间内生成唯一的标识符。为了实现低延迟，设计者通常采用高效的算法和数据结构，以及优化的网络通信和存储策略。 递增性：分布式ID通常可以被设计成可按时间顺序排序，以便更容易对生成的ID进行索引、检索或排序操作。这对于一些场景，如日志记录和事件溯源等，非常重要。 1234567891011121314151617181920212223242526272829303132//生成分布式ID@Componentpublic class RedisIdWorker &#123; @Resource private StringRedisTemplate stringRedisTemplate; /** * 开始时间戳 */ private static final long BEGIN_TIMESTAMP = 1640995200; /** * 序列化位数 */ private static final int COUNT_BITS = 32; /** * 生成分布式ID * @param keyPrefix * @return */ public long nextId(String keyPrefix)&#123; // 1、生成时间戳 LocalDateTime now = LocalDateTime.now(); long nowSecond = now.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; // 2、生成序列号 // 以当天的时间戳为key，防止一直自增下去导致超时，这样每天的极限都是 2^&#123;31&#125; String date = now.format(DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)); Long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix + &quot;:&quot; + date); // 3、拼接并返回 return timestamp &lt;&lt; COUNT_BITS | count; &#125;&#125; 注意：测试类包括CountDownLatch的使用 1234567891011121314151617181920212223242526272829303132333435//测试类@SpringBootTestpublic class RedisIdWorkerTest &#123; @Resource private RedisIdWorker redisIdWorker; private ExecutorService es = Executors.newFixedThreadPool(500); /** * 测试分布式ID生成器的性能，以及可用性 */ @Test public void testNextId() throws InterruptedException &#123; // 使用CountDownLatch让线程同步等待 CountDownLatch latch = new CountDownLatch(300); // 创建线程任务 Runnable task = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; long id = redisIdWorker.nextId(&quot;order&quot;); System.out.println(&quot;id = &quot; + id); &#125; // 等待次数-1 latch.countDown(); &#125;; long begin = System.currentTimeMillis(); // 创建300个线程，每个线程创建100个id，总计生成3w个id for (int i = 0; i &lt; 300; i++) &#123; es.submit(task); &#125; // 线程阻塞，直到计数器归0时才全部唤醒所有线程 latch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;生成3w个id共耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 2、秒杀券下单功能首先添加秒杀券，tb_voucher保存的是普通优惠券，而tb_seckill_voucher保存的是秒杀券的信息，也就是说，秒杀券也是优惠券，只是秒杀券比优惠券有更多的一些信息。在这里踩了一个坑。就是设置秒杀券的end_time时，这个时间必须在你电脑当前时间之后，否则就会不显示！！ 然后是秒杀券的下单功能 12345678910111213141516171819202122232425262728293031323334@Transactional public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 5、秒杀券合法，则秒杀券抢购成功，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .setSql(&quot;stock = stock -1&quot;)); if (!flag)&#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 6、秒杀成功，创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); save(voucherOrder); // 返回订单id return Result.ok(orderId); &#125; 这里也踩了一个坑，就是执行了半天点击但发现优惠券并没有扣除，甚至controller处的写的打印信息都没有在控制台打印，原因好像跟访问路径有关系？？刚解决完就忘了。。鱼的记忆-_- 3、单体下一人多单超卖问题上一节我们通过分布式ID+事务成功完成了优惠券秒杀功能，并且在测试后发现逻辑跑通了，看上去已经成功的解决了秒杀优惠券功能。但是前面我们只是正常的测试，那如果换到高并发的场景下能否成功解决？现在就让我们使用 Jmeter 来进行压力测试看看吧！ jmeter设置 经过测试， 发现有超卖问题。为什么会产生超卖呢？ 线程1查询库存，发现库存充足，创建订单，然后准备对库存进行扣减，但此时线程2和线程3也进行查询，同样发现库存充足，然后线程1执行完扣减操作后，库存变为了0，线程2和线程3同样完成了库存扣减操作，最终导致库存变成了负数！这就是超卖问题的完整流程 那么我们该如何有效防止超卖问题的发生呢，以下提供几种常见的解决方案 超卖问题的常见解决方案： 悲观锁，认为线程安全问题一定会发生，因此操作数据库之前都需要先获取锁，确保线程串行执行。常见的悲观锁有：synchronized、lock 乐观锁，认为线程安全问题不一定发生，因此不加锁，只会在更新数据库的时候去判断有没有其它线程对数据进行修改，如果没有修改则认为是安全的，直接更新数据库中的数据即可，如果修改了则说明不安全，直接抛异常或者等待重试。常见的实现方式有：版本号法、CAS操作、乐观锁算法 悲观锁和乐观锁的比较 悲观锁比乐观锁的性能低：悲观锁需要先加锁再操作，而乐观锁不需要加锁，所以乐观锁通常具有更好的性能。 悲观锁比乐观锁的冲突处理能力低：悲观锁在冲突发生时直接阻塞其他线程，乐观锁则是在提交阶段检查冲突并进行重试。 悲观锁比乐观锁的并发度低：悲观锁存在锁粒度较大的问题，可能会限制并发性能；而乐观锁可以实现较高的并发度。 应用场景：两者都是互斥锁，悲观锁适合写入操作较多、冲突频繁的场景；乐观锁适合读取操作较多、冲突较少的场景。 拓展：CAS CAS（Compare and Swap）是一种并发编程中常用的原子操作，用于解决多线程环境下的数据竞争问题。它是乐观锁算法的一种实现方式。 CAS操作包含三个参数：内存地址V、旧的预期值A和新的值B。CAS的执行过程如下： 比较（Compare）：将内存地址V中的值与预期值A进行比较。 判断（Judgment）：如果相等，则说明当前值和预期值相等，表示没有发生其他线程的修改。 交换（Swap）：使用新的值B来更新内存地址V中的值。 CAS操作是一个原子操作，意味着在执行过程中不会被其他线程中断，保证了线程安全性。如果CAS操作失败（即当前值与预期值不相等），通常会进行重试，直到CAS操作成功为止。 CAS操作适用于精细粒度的并发控制，可以避免使用传统的加锁机制带来的性能开销和线程阻塞。然而，CAS操作也存在一些限制和注意事项： ABA问题：CAS操作无法感知到对象值从A变为B又变回A的情况，可能会导致数据不一致。为了解决ABA问题，可以引入版本号或标记位等机制。 自旋开销：当CAS操作失败时，需要不断地进行重试，会占用CPU资源。如果重试次数过多或者线程争用激烈，可能会引起性能问题。 并发性限制：如果多个线程同时对同一内存地址进行CAS操作，只有一个线程的CAS操作会成功，其他线程需要重试或放弃操作。 在Java中，提供了相关的CAS操作支持，如AtomicInteger、AtomicLong、AtomicReference等类，可以实现基于CAS操作的线程安全操作。 乐观锁解决一人多单超卖问题 CAS法类似与版本号法，但是不需要另外在添加一个 version 字段，而是直接使用库存替代版本号，线程1查询完库存后进行库存扣减操作，线程2在查询库存时，发现库存充足，也准备执行库存扣减操作，但是需要判断当前的库存是否是之前查询时的库存，结果发现库存数量发生了改变，这就说明数据库中的数据已经发生了修改，需要进行重试（或者直接抛异常中断） qps200，异常90%，吞吐量1652.9 这又是什么原因呢？这就是乐观锁的弊端，我们只要发现数据修改就直接终止操作了，我们只需要修改一下判断条件，即只要库存大于0就可以进行修改，而不是库存数据修改我们就终止操作 12345// 5、秒杀券合法，则秒杀券抢购成功，秒杀券库存数量减一boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); 执行完之后库存恰好为0，订单表中恰好是一百条 4、单体下一人一单问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Override @Transactional public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 3、判断当前用户是否是第一单 int count = this.count(new LambdaQueryWrapper&lt;VoucherOrder&gt;() .eq(VoucherOrder::getUserId, UserHolder.getUser().getId())); if (count &gt;= 1) &#123; // 当前用户不是第一单 return Result.fail(&quot;用户已购买&quot;); &#125; // 4、用户是第一单，可以下单，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); if (!flag) &#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 6、秒杀成功，创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); save(voucherOrder); // 返回订单id return Result.ok(orderId); &#125; 现在是不是可以成功完成了一人一单的要求呢？让我们来使用 Jmeter 测一下吧 通过测试，发现并没有达到我们想象中的目标，一个人只能购买一次，但是发现一个用户居然能够购买10次。这说明还是存在超卖问题！ 问题原因：出现这个问题的原因和前面库存为负数数的情况是一样的，线程1查询当前用户是否有订单，当前用户没有订单准备下单，此时线程2也查询当前用户是否有订单，由于线程1还没有完成下单操作，线程2同样发现当前用户未下单，也准备下单，这样明明一个用户只能下一单，结果下了两单，也就出现了超卖问题 解决方案：一般这种超卖问题可以使用下面两种常见的解决方案 悲观锁 乐观锁 悲观锁解决超卖问题 乐观锁需要判断数据是否修改，而当前是判断当前是否存在，所以无法像解决库存超卖一样使用CAS机制，但是可以使用版本号法，但是版本号法需要新增一个字段，所以这里为了方便，就直接演示使用悲观锁解决超卖问题 代码这里注意，seckillVocher上面的@Transactional要去掉，然后要加一个依赖，启动类上加上一个注解@EnableAspectJAutoProxy(exposeProxy = true) 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.21&lt;/version&gt; &lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Override public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 3、创建订单 Long userId = UserHolder.getUser().getId(); synchronized (userId.toString().intern()) &#123; // 创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效 IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(userId, voucherId); &#125; &#125; /** * 创建订单 * * @param userId * @param voucherId * @return */ @Transactional public Result createVoucherOrder(Long userId, Long voucherId) &#123;// synchronized (userId.toString().intern()) &#123; // 1、判断当前用户是否是第一单 int count = this.count(new LambdaQueryWrapper&lt;VoucherOrder&gt;() .eq(VoucherOrder::getUserId, userId)); if (count &gt;= 1) &#123; // 当前用户不是第一单 return Result.fail(&quot;用户已购买&quot;); &#125; // 2、用户是第一单，可以下单，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); if (!flag) &#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 3、创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); flag = this.save(voucherOrder); if (!flag) &#123; throw new RuntimeException(&quot;创建秒杀券订单失败&quot;); &#125; // 4、返回订单id return Result.ok(orderId); &#125; TODO这里代码的实现细节有点看不懂（以下内容看的别人的总结，这里回头再看看 锁的范围尽量小。synchronized尽量锁代码块，而不是方法，锁的范围越大性能越低 锁的对象一定要是一个不变的值。我们不能直接锁 Long 类型的 userId，每请求一次都会创建一个新的 userId 对象，synchronized 要锁不变的值，所以我们要将 Long 类型的 userId 通过 toString()方法转成 String 类型的 userId，toString()方法底层（可以点击去看源码）是直接 new 一个新的String对象，显然还是在变，所以我们要使用 intern() 方法从常量池中寻找与当前 字符串值一致的字符串对象，这就能够保障一个用户 发送多次请求，每次请求的 userId 都是不变的，从而能够完成锁的效果（并行变串行） 我们要锁住整个事务，而不是锁住事务内部的代码。如果我们锁住事务内部的代码会导致其它线程能够进入事务，当我们事务还未提交，锁一旦释放，仍然会存在超卖问题 Spring的@Transactional注解要想事务生效，必须使用动态代理。Service中一个方法中调用另一个方法，另一个方法使用了事务，此时会导致@Transactional失效，所以我们需要创建一个代理对象，使用代理对象来调用方法。 总结： 首先用全局唯一id代表优惠券的下单订单号。如果一个人可以买多单的情况下，在并发场景下，会出现超卖情况，此时用乐观锁的cas来实现防止超卖。然后是单体的一人一单，这里就是下单前需要验证当前用户是否已经下单了，确认是否存在，如果硬要用乐观锁，使用版本号法需要加一个字段，所以用的是悲观锁。但如果在集群环境下，由于锁依赖于jvm内部的监视器，如果是多台机器，每个机器内部的锁只能锁住自己这个进程的，所以要用分布式锁了。 四、分布式锁由于synchronized是本地锁，只能提供线程级别的同步，每个JVM中都有一把synchronized锁，不能跨 JVM 进行上锁，当一个线程进入被 synchronized 关键字修饰的方法或代码块时，它会尝试获取对象的内置锁（也称为监视器锁）。如果该锁没有被其他线程占用，则当前线程获得锁，可以继续执行代码；否则，当前线程将进入阻塞状态，直到获取到锁为止。而现在我们是创建了两个节点，也就意味着有两个JVM，所以synchronized会失效！从而出现超卖问题： 分布式锁的常见实现 基于关系数据库：可以利用数据库的事务特性和唯一索引来实现分布式锁。通过向数据库插入一条具有唯一约束的记录作为锁，其他进程在获取锁时会受到数据库的并发控制机制限制。 基于缓存（如Redis）：使用分布式缓存服务（如Redis）提供的原子操作来实现分布式锁。通过将锁信息存储在缓存中，其他进程可以通过检查缓存中的锁状态来判断是否可以获取锁。 基于ZooKeeper：ZooKeeper是一个分布式协调服务，可以用于实现分布式锁。通过创建临时有序节点，每个请求都会尝试创建一个唯一的节点，并检查自己是否是最小节点，如果是，则表示获取到了锁。 从性能角度（从高到低）： 缓存 &gt; Zookeeper &gt; 数据库 从可靠性角度（从高到低）： Zookeeper &gt; 缓存 &gt; 数据库 setnx指令的特点：setnx只能设置key不存在的值，值不存在设置成功，返回 1 ；值存在设置失败，返回 0 获取锁 12# 添加锁set [key] [value] ex [time] nx 释放锁 12# 释放锁（除了使用del手动释放，还可超时释放）del [key] 1、基于redis实现的分布式锁创建分布式锁 12345678910111213public interface ILock &#123; /** * 尝试获取锁 * @param timeoutSec 锁持有的时间，过期后自动释放 * @return true true代表获取锁成功，反之代表失败 */ boolean tryLock(long timeoutSec); /** * 释放锁 */ void unlock();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public class SimpleRedisLock implements ILock &#123; /** * RedisTemplate */ private StringRedisTemplate stringRedisTemplate; /** * 锁的名称 */ private String name; public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name) &#123; this.stringRedisTemplate = stringRedisTemplate; this.name = name; &#125; /** * 获取锁 * * @param timeoutSec 超时时间 * @return */ @Override public boolean tryLock(long timeoutSec) &#123; String id = Thread.currentThread().getId() + &quot;&quot;; // SET lock:name id EX timeoutSec NX Boolean result = stringRedisTemplate.opsForValue() .setIfAbsent(&quot;lock:&quot; + name, id, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(result); &#125; /** * 释放锁 */ @Override public void unlock() &#123; stringRedisTemplate.delete(&quot;lock:&quot; + name); &#125;&#125; 使用分布式锁：改造前面VoucherOrderServiceImpl中的代码，将之前使用sychronized锁的地方，改成我们自己实现的分布式锁： 1234567891011121314Long userId = UserHolder.getUser().getId(); SimpleRedisLock lock = new SimpleRedisLock(stringRedisTemplate, &quot;order:&quot; + userId); boolean isLock = lock.tryLock(1200); if (!isLock) &#123; // 索取锁失败，重试或者直接抛异常（这个业务是一人一单，所以直接返回失败信息） return Result.fail(&quot;一人只能下一单&quot;); &#125; try &#123; // 索取锁成功，创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效 IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(userId, voucherId); &#125; finally &#123; lock.unlock(); &#125; 然后用apifox发送两个请求 可以看到8081端口为false，8082端口为true 这里遇到了一个bug，就是打了断点但是变量那里看不到，根本就没有进入断点。最后发现是apifox发送的请求中，携带登录token的参数Authorization应该是放在header中，我一开始放在了params中 2、分布式锁优化1——解决释放不属于自己锁的问题 上一节，我们实现了一个简单的分布式锁，但是会存在一个问题：当线程1获取锁后，由于业务阻塞，线程1的锁超时释放了，这时候线程2趁虚而入拿到了锁，然后此时线程1业务完成了，然后把线程2刚刚获取的锁给释放了，这时候线程3又趁虚而入拿到了锁，这就导致又出现了超卖问题！（但是这个在小项目（并发数不高）中出现的概率比较低，在大型项目（并发数高）情况下是有一定概率的） 备注：我们可以把锁的有效期降低一点，这样就能够测试上面哪种情况了(●’◡’●) 如何解决呢？我们为分布式锁添加一个线程标识，在释放锁时判断当前锁是否是自己的锁，是自己的就直接释放，不是自己的就不释放锁，从而解决多个线程同时获得锁的情况导致出现超卖 3、分布式锁优化2——释放锁时的原子性问题。说到底也是锁超时释放的问题 在上一节中，我们通过给锁添加一个线程标识，并且在释放锁时添加一个判断，从而防止锁超时释放产生的超卖问题，一定程度上解决了超卖问题，但是仍有可能发生超卖问题（出现超卖概率更低了）：当线程1获取锁，执行完业务然后并且判断完当前锁是自己的锁时，但就在此时发生了阻塞，结果锁被超时释放了，线程2立马就趁虚而入了，获得锁执行业务，但就在此时线程1阻塞完成，由于已经判断过锁，已经确定锁是自己的锁了，于是直接就删除了锁，结果删的是线程2的锁，这就又导致线程3趁虚而入了，从而继续发生超卖问题 备注：我们可以在判断删除锁的那行代码上打一个断点，然后user1发送一个请求，获取锁，手动把锁删了，模拟锁超时释放，然后使用user2发送一个请求，成功获取锁，从而模拟上诉过程，检验超卖问题 PS：虽然这个情况发生的概率较低，但是根据墨菲定律，我们最好不要抱有侥幸心理，不然最终我们会在这个细微的问题上付诸沉重的代价！你可能还会想，判断锁和释放锁在同一个方法中，并且两者之间没有别的代码，为什么会发生阻塞呢？JVM的垃圾回收机制会导致短暂的阻塞（我个人感觉这种情况发生的概率真的不高，但是我也没有实际接触过真正的大型高并发项目，所以具体也只能靠揣摩） 那么我们该如何保障 判断锁 和 释放锁 这连段代码的原子性呢？答案是使用Lua脚本 4、Redisson经过优化1和优化2，我们实现的分布式锁已经达到生产可用级别了，但是还不够完善，比如： 分布式锁不可重入：不可重入是指同一线程不能重复获取同一把锁。比如，方法A中调用方法B，方法A需要获取分布式锁，方法B同样需要获取分布式锁，线程1进入方法A获取了一次锁，进入方法B又获取一次锁，由于锁不可重入，所以就会导致死锁 分布式锁不可重试：获取锁只尝试一次就返回false，没有重试机制，这会导致数据丢失，比如线程1获取锁，然后要将数据写入数据库，但是当前的锁被线程2占用了，线程1直接就结束了而不去重试，这就导致数据发生了丢失 分布式锁超时释放：超市释放机机制虽然一定程度避免了死锁发生的概率，但是如果业务执行耗时过长，期间锁就释放了，这样存在安全隐患。锁的有效期过短，容易出现业务没执行完就被释放，锁的有效期过长，容易出现死锁，所以这是一个大难题！ 我们可以设置一个较短的有效期，但是加上一个 心跳机制 和 自动续期：在锁被获取后，可以使用心跳机制并自动续期锁的持有时间。通过定期发送心跳请求，显示地告知其他线程或系统锁还在使用中，同时更新锁的过期时间。如果某个线程持有锁的时间超过了预设的有效时间，其他线程可以尝试重新获取锁。 主从一致性问题：如果Redis提供了主从集群，主从同步存在延迟，线程1获取了锁 我们如果想要更进一步优化分布式锁，当然是可以的，但是没必要，除非是迫不得已，我们完全可以直接使用已经造好的轮子，比如：Redisson。Redssion是一个十分成熟的Redis框架，功能也很多，比如：分布式锁和同步器、分布式对象、分布式集合、分布式服务，各种Redis实现分布式的解决方案。简而言之Redisson就是一个使用Redis解决分布式问题的方案的集合，当然它不仅仅是解决分布式相关问题，还包含其它的一些问题。 所以说分布式锁的究极优化就是使用别人造好的轮子🤣redisson分布式锁的实现使用 1）、引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.6&lt;/version&gt;&lt;/dependency&gt; 2）、配置Redisson客户端 1234567891011121314151617@Configurationpublic class RedissonConfig &#123; /** * 创建Redisson配置对象，然后交给IOC管理 * * @return */ @Bean public RedissonClient redissonClient() &#123; // 获取Redisson配置对象 Config config = new Config(); // 添加redis地址，这里添加的是单节点地址，也可以通过 config.userClusterServers()添加集群地址 config.useSingleServer().setAddress(&quot;redis://192.168.200.100:6379&quot;).setPassword(&quot;123321&quot;); // 获取RedisClient对象，并交给IOC进行管理 return Redisson.create(config); &#125;&#125; 温馨提示：此外还有一种引入方式，可以引入 redission 的 starter 依赖，然后在yml文件中配置Redisson，但是不推荐这种方式，因为他会替换掉 Spring官方 提供的这套对 Redisson 的配置 3）、修改一下使用锁的地方，其它的业务代码都不需要改 123//SimpleRedisLock lock = new SimpleRedisLock(stringRedisTemplate, &quot;order:&quot; + userId); RLock lock = redissonClient.getLock(&quot;lock:order:&quot; + userId); boolean isLock = lock.tryLock(); 五、MQ异步优化此时先测一下之前同步的方式性能如何 用一下测试代码生成1000个登录用户的token并保存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.hmdp;import cn.hutool.core.bean.BeanUtil;import cn.hutool.core.bean.copier.CopyOptions;import com.hmdp.dto.UserDTO;import com.hmdp.entity.User;import com.hmdp.service.IUserService;import org.junit.jupiter.api.Test;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.StringRedisTemplate;import javax.annotation.Resource;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.UUID;import java.util.concurrent.TimeUnit;import static com.hmdp.utils.RedisConstants.LOGIN_USER_KEY;import static com.hmdp.utils.RedisConstants.LOGIN_USER_TTL;@SpringBootTestpublic class yibuTest &#123; @Resource IUserService userService; @Resource private StringRedisTemplate stringRedisTemplate; @Test public void testGetAll() &#123; List&lt;User&gt; users = userService.list();// for(User user : users)&#123;// System.out.println(user);// &#125;// System.exit(0); users.forEach( user -&gt; &#123; // 7.1,随机生成token,作为登录令牌 String token = UUID.randomUUID().toString();// 7.2,将User对象转化为HashMap存储 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); File file = new File(&quot;D:\\\\code\\\\token.txt&quot;); FileOutputStream output = null; try &#123; output = new FileOutputStream(file, true); byte[] bytes = token.getBytes(); output.write(bytes); output.write(&quot;\\r\\n&quot;.getBytes()); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; finally &#123; try &#123; output.close(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125; Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO, new HashMap&lt;&gt;(), CopyOptions.create() .setIgnoreNullValue(true) .setFieldValueEditor((fieldName, fieldValue) -&gt; fieldValue.toString()));// 7.3,存储 String tokenKey = LOGIN_USER_KEY + token; stringRedisTemplate.opsForHash().putAll(tokenKey, userMap);// 7.4,设置token有效期 stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES); &#125; ); &#125;&#125; 更改优惠券数量为200，并清空订单表 注意优惠券的过期时间！！！！！ 执行完之后，库存扣减为0，订单表中正好200条订单 jmeter显示结果如下：还是比较慢的 第二次测试 第三次测试 1、优化思路之前的流程如下： 2、安装rabbitMQ已有centOS7,docker,finalshell 安装参考链接：rabbitMQ安装参考 安装Erlang 成功截图 rabbitmq启动成功 开启web管理功能 开启后，在本机访问虚拟机ip加端口号15672即可访问 然后是创建用户。因为在finalshell开启了rabbitmq后，就不能继续输入命令了。所以这里我是先在centos里面开启rabbitmq，然后再在finalshell输入创建用户的命令。执行后如下： 然后登录web管理页面： 3.实现异步处理的代码新增代码结构如下： 配置mq通信为主题模式 12345678910111213141516171819202122232425262728293031package com.hmdp.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.context.annotation.Bean;import org.springframework.amqp.core.TopicExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Configuration;// 这段代码用于配置 RabbitMQ 的话题模式，包括队列、交换机和绑定。下面是加上注释后的代码：@Configurationpublic class RabbitMQTopicConfig &#123; public static final String QUEUE = &quot;seckillQueue&quot;; // 队列名 public static final String EXCHANGE = &quot;seckillExchange&quot;; // 交换机名 public static final String ROUTINGKEY = &quot;seckill.lua.#&quot;; @Bean public Queue queue()&#123; return new Queue(QUEUE); &#125; @Bean public TopicExchange topicExchange()&#123; return new TopicExchange(EXCHANGE); &#125; @Bean public Binding binding()&#123; return BindingBuilder.bind(queue()).to(topicExchange()).with(ROUTINGKEY); &#125;&#125; 123456789101112131415161718192021222324252627package com.hmdp.rabbitmq;import com.hmdp.config.RabbitMQTopicConfig;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * 消息发送者 */@Slf4j@Servicepublic class MQSender &#123; @Autowired private RabbitTemplate rabbitTemplate; private static final String ROUTINGKEY = &quot;seckill.lua.message&quot;; /** * 发送秒杀信息 * @param msg */ public void sendSeckillMessage(String msg)&#123; log.info(&quot;发送消息&quot;+msg); rabbitTemplate.convertAndSend(RabbitMQTopicConfig.EXCHANGE,ROUTINGKEY,msg); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.hmdp.rabbitmq;import com.alibaba.fastjson.JSON;import com.hmdp.config.RabbitMQTopicConfig;import com.hmdp.entity.VoucherOrder;import com.hmdp.service.ISeckillVoucherService;import com.hmdp.service.IVoucherOrderService;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import javax.annotation.Resource;/** * 消息消费者 */@Slf4j@Servicepublic class MQReceiver &#123; @Resource IVoucherOrderService voucherOrderService; @Resource ISeckillVoucherService seckillVoucherService; /** * 接收秒杀信息并下单 * @param msg */ @Transactional @RabbitListener(queues = RabbitMQTopicConfig.QUEUE) public void receiveSeckillMessage(String msg)&#123; log.info(&quot;接收到消息: &quot;+msg); VoucherOrder voucherOrder = JSON.parseObject(msg, VoucherOrder.class); Long voucherId = voucherOrder.getVoucherId(); //5.一人一单 Long userId = voucherOrder.getUserId(); //5.1查询订单 int count = voucherOrderService.query().eq(&quot;user_id&quot;,userId).eq(&quot;voucher_id&quot;, voucherId).count(); //5.2判断是否存在 if(count&gt;0)&#123; //用户已经购买过了 log.error(&quot;该用户已购买过&quot;); return ; &#125; log.info(&quot;扣减库存&quot;); //6.扣减库存 boolean success = seckillVoucherService .update() .setSql(&quot;stock = stock-1&quot;) .eq(&quot;voucher_id&quot;, voucherId) .gt(&quot;stock&quot;,0)//cas乐观锁 .update(); if(!success)&#123; log.error(&quot;库存不足&quot;); return; &#125; //直接保存订单 voucherOrderService.save(voucherOrder); &#125;&#125; 注意这里需要手动向redis中添加库存键及数量，键名就是下面lua代码中stockKey的名字，这里voucherId为7，键名就是stock:7，这里也算一个bug，搞了有一阵子 12345678910111213141516171819202122232425262728-- 1.参数列表-- 1.1优惠卷idlocal voucherId = ARGV[1]-- 1.2用户idlocal userId = ARGV[2]-- 2.数据key-- 2.1库存keylocal stockKey = &#x27;stock:&#x27; .. voucherId-- 2.2订单keylocal orderKey = &#x27;order:&#x27; .. voucherId-- 3.脚本业务-- 3.1判断库存是否充足if(tonumber(redis.call(&#x27;get&#x27;,stockKey)) &lt;= 0)then -- 3.2 库存不足 返回1 return 1end--3.2判断用户是否下单if(redis.call(&#x27;sismember&#x27;,orderKey,userId) == 1) then -- 3.3存在,说明是重复下单 return 2end-- 3.4扣库存redis.call(&#x27;incrby&#x27;,stockKey,-1)-- 3.5下单并保存用户redis.call(&#x27;sadd&#x27;,orderKey,userId)return 0 下面是VoucherOrderServiceImpl的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class VoucherOrderServiceImpl extends ServiceImpl&lt;VoucherOrderMapper, VoucherOrder&gt; implements IVoucherOrderService &#123; @Resource private MQSender mqSender; @Resource private RedisIdWorker redisIdWorker; //private RateLimiter rateLimiter = RateLimiter.create(10); @Resource private StringRedisTemplate stringRedisTemplate; //@Resource //private RedissonClient redissonClient; //lua脚本 private static final DefaultRedisScript&lt;Long&gt; SECKILL_SCRIPT; static &#123; SECKILL_SCRIPT = new DefaultRedisScript&lt;&gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(&quot;seckill.lua&quot;)); SECKILL_SCRIPT.setResultType(Long.class); &#125; @Override public Result seckillVocher(Long voucherId) &#123; //1.执行lua脚本 Long userId = UserHolder.getUser().getId(); Long r = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); //2.判断结果为0 int result = r.intValue(); if (result != 0) &#123; //2.1不为0代表没有购买资格 return Result.fail(r == 1 ? &quot;库存不足&quot; : &quot;该用户重复下单&quot;); &#125; //2.2为0代表有购买资格,将下单信息保存到阻塞队列 //2.3创建订单 VoucherOrder voucherOrder = new VoucherOrder(); //2.4订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); //2.5用户id voucherOrder.setUserId(userId); //2.6代金卷id voucherOrder.setVoucherId(voucherId); //2.7将信息放入MQ中 mqSender.sendSeckillMessage(JSON.toJSONString(voucherOrder)); //2.7 返回订单id return Result.ok(orderId); &#125;&#125; 4.结果分析注意在用jmeter测试之前，先清除之前的数据，如下： 实验结果如下： 可以看到最小耗时2ms，最大耗时112ms，提高了将近20倍，平均耗时34ms，提高了将近30倍左右","categories":[],"tags":[]},{"title":"字节跳动-番茄小说面经","slug":"面经/字节跳动-番茄小说面经","date":"2024-12-14T03:17:09.000Z","updated":"2024-12-21T06:18:19.192Z","comments":true,"path":"2024/12/14/面经/字节跳动-番茄小说面经/","permalink":"http://example.com/2024/12/14/%E9%9D%A2%E7%BB%8F/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-%E7%95%AA%E8%8C%84%E5%B0%8F%E8%AF%B4%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"Q：java并发编程并发的是线程还是进程？A：线程，不过说的很紊乱，讲了很多没必要讲的东西 以下是gpt回答 解释： 线程 是程序中的一个执行单元，线程是轻量级的，它们共享进程的资源，如内存和文件句柄。在Java中，线程是通过实现 Runnable 接口或继承 Thread 类来创建的。 进程 是操作系统分配资源的最小单位，每个进程都有自己独立的内存空间。Java程序通常运行在一个进程中，而该进程内可能有多个线程。 并发的定义： 并发 指的是多个任务的执行在时间上有重叠，而不一定是同时进行。通过多线程并发执行，Java能够在多核处理器上高效地利用多个CPU核心，但并发本身并不等同于并行。并行是指多个任务在同一时刻执行。 总结： Java并发编程中，“并发”是指 多个线程 的执行。 如果涉及多个进程，通常称之为 多进程 编程，而不属于并发的范畴。 Q：进程和线程的区别A：一个进程可能就是会包含多个线程，线程可以理解为轻量级的进程，上下文切换这个开销一般是比较小的，线程可以共享这个进程的一些资源比如说内存空间（内存空间埋雷了） Q：那你觉得你对于他们的底层结构了解吗，比如说你刚才提到了共享内存那你共享的资源嘛对吧那你能说一下比如说我启动了一个那个进程然后那进程跟线程之间应该是如何去申请这个资源以及实现资源共享呢。后续又补充了一点，比如说创建一个进程然后这个资源我是怎么申请的以及线程去怎么去共享这些资源的。A：的一塌糊涂 Q：线程池的作用以及实现原理。A：复用线程，实现原理不会（其实就是线程池处理任务的流程，不知道是这个题目，背了八股也没用上😭😭😭😭 以下是gpt回答 线程池的实现原理 线程池的核心思想是任务提交-线程复用。以下是线程池的基本组成和工作原理： 1. 基本组成 任务队列（Task Queue）： 一个线程安全的队列，用于存储提交但尚未被执行的任务。 任务是实现了某种接口（如 Runnable 或 Callable）的对象。 工作线程（Worker Threads）： 线程池中实际执行任务的线程集合。线程池在初始化时会创建一定数量的线程，并在任务提交后复用这些线程执行任务。 线程管理器： 管理线程的生命周期，维护线程池中线程的数量。 根据配置动态增加或减少线程数（如扩展或缩减线程池大小）。 任务提交接口： 提供给用户用于提交任务的方法，比如 execute() 或 submit()。 任务调度器： 从任务队列中获取任务并分配给工作线程。 如果任务队列为空，工作线程会进入等待状态。 2. 线程池的工作流程 线程池初始化： 根据配置，线程池创建一定数量的工作线程，并处于等待任务的状态。 任务提交： 用户通过线程池的接口（如 execute() 或 submit()）提交任务，任务被添加到任务队列中。 任务调度： 线程池中的工作线程会从任务队列中取出任务进行执行。 如果所有工作线程都在忙，任务会在任务队列中排队等待。 任务执行： 工作线程执行完任务后，线程不会被销毁，而是返回线程池继续等待新的任务。 动态扩展（可选）： 如果任务队列过长且所有线程都在忙，线程池可以动态创建新的线程来处理任务（受最大线程数限制）。 线程回收： 如果线程池中某些线程长时间没有任务可执行，线程池可以销毁这些空闲线程以节省资源。 Q、如果没有锁机制的话在并发编程的场景会出现什么问题。A：数据的一致性可能出现问题（问我还有没有补充，我也没想到其它的了 以下是在网上搜的，并发编程需要加锁的时候，如果就不加会怎么样？ 数据不一致：多个线程同时访问和修改共享资源时，如果没有加锁，可能会导致数据竞争，即一个线程在读取数据的同时，另一个线程修改了数据，从而导致最终的数据状态与预期不符。例如，在多线程环境下，多个线程同时对同一个账户余额进行操作，如果不加锁，可能会出现余额被重复扣款或重复加款的情况。 竞态条件：竞态条件是指在多线程环境中，由于线程调度的不确定性，导致程序的行为依赖于不可预测的执行顺序。如果不加锁，可能会导致程序在某些情况下出现不可预期的行为，如死锁、饥饿等问题。 线程安全问题：在多线程编程中，多个线程可能会同时访问共享资源，这很容易导致数据的不一致性和竞态条件。如果不加锁，可能会导致线程安全问题，影响程序的正确性和稳定性。 死锁风险：死锁是指两个或多个线程互相等待对方释放资源，导致所有线程都无法继续执行。如果不加锁，可能会增加死锁的风险，尤其是在复杂的并发场景中。 难以调试：在多线程环境中，如果不加锁，可能会导致难以调试的问题。由于线程的执行顺序是不可预测的，错误可能在某些特定的执行路径下才会出现，这使得调试变得非常困难。 Q：项目：怎么实现优惠券的秒杀A：这个基本答得是那么回事，就是乐观锁的cas Q：什么叫乐观锁？为什么不用悲观锁？A：适用读多写少，然后说了一下cas的实现（感觉都没答到点子上😅😅）；用悲观锁就是影响性能，因为会频繁的更新数据 Q：select语句的执行过程A：（这个答得应该大差不差，唯一画蛇添足的一点就是把废弃的那个缓存器也答上了，又给后面埋雷了😅😅😅😅）连接器——语法器——优化器——执行器 Q：缓存的粒度是什么？或者说它是怎么缓存的，缓存的东西是什么A：直接说不清楚，缓存的应该是语句吧。然后问如果缓存了SELECT A = 1再来执行SELECT A = 1 AND B = 1能用到缓存吗？猜的能 以下来自gpt 存储常用或最近使用的数据和查询结果，提高了查询性能，减少了对底层存储的访问。 存储查询的完整结果集，下一次遇到相同的查询语句时，直接返回结果。 适用于简单的 SELECT 查询，尤其是少更新、多读取的场景。 默认情况下，SELECT A = 1 的缓存不能直接用于 SELECT A = 1 AND B = 1，因为两者查询条件和结果集不同。 Q：SELECT语句想做查询优化，从哪些方面去优化？A：答了索引，避免查询不必要的列，数据量过大时从分表三点，问还有补充没， 以下来自gpt 优化 SELECT 语句的方法包括： 从表结构设计入手，建立合理的索引，优化字段类型，必要时分表或分区。 改进查询语句，减少不必要的字段、行和表，避免复杂计算。 提高数据访问效率，利用缓存和分页优化减少查询开销。 分析查询执行计划，通过工具发现潜在问题并调整查询结构和索引。 Q：索引的底层结构是啥？A：说了B+树，然后问只有B+树么？还有其它结构吗，然后又回答了还有哈希 Q：从数据结构的角度来说，能影响B+树的查询性能的，是这个树的什么A：树高 以下来自gpt Q：我们怎么影响这个树的高度呢？通过哪些方式让这个树的高度更扁平一点？A：不知道，瞎几把答了 以下来自gpt 树高主要受以下因素影响： 节点扇出数（由节点大小和键值大小决定）。 数据分布是否均匀。 数据量和磁盘块的大小。 键值的大小和排序。 问答18min。手撕环节。差不多三分钟说了一下思路。撕了差不多20min才跑通测试用例， Q：题目：给中缀表达式转后缀表达式思路： 遇到操作数（数字或变量）：直接输出到结果中。 遇到左括号 (：直接压入操作符栈。 遇到右括号 )： 弹出栈顶的操作符并加入结果，直到遇到左括号（左括号本身不加入结果）。 遇到运算符（如 +, -, *, /）： 将栈顶优先级高于或等于当前操作符的运算符弹出并加入结果。 然后将当前操作符压栈。 遍历结束后：将栈中剩余的运算符依次弹出并加入结果。 算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 定义运算符优先级 private static final Map&lt;Character, Integer&gt; precedence = new HashMap&lt;&gt;(); static &#123; precedence.put(&#x27;+&#x27;, 1); precedence.put(&#x27;-&#x27;, 1); precedence.put(&#x27;*&#x27;, 2); precedence.put(&#x27;/&#x27;, 2); precedence.put(&#x27;(&#x27;, 0); // 左括号优先级最低 &#125; public static String infixToPostfix(String infix) &#123; // 栈：存储操作符 Stack&lt;Character&gt; operatorStack = new Stack&lt;&gt;(); // 结果字符串 StringBuilder postfix = new StringBuilder(); // 遍历表达式中的每个字符 for (int i = 0; i &lt; infix.length(); i++) &#123; char ch = infix.charAt(i); // 如果是操作数（字母或数字），直接加入结果 if (Character.isLetterOrDigit(ch)) &#123; postfix.append(ch); &#125; // 如果是左括号，压入栈 else if (ch == &#x27;(&#x27;) &#123; operatorStack.push(ch); &#125; // 如果是右括号，弹出运算符直到遇到左括号 else if (ch == &#x27;)&#x27;) &#123; while (!operatorStack.isEmpty() &amp;&amp; operatorStack.peek() != &#x27;(&#x27;) &#123; postfix.append(operatorStack.pop()); &#125; if (!operatorStack.isEmpty() &amp;&amp; operatorStack.peek() == &#x27;(&#x27;) &#123; operatorStack.pop(); // 弹出左括号 &#125; &#125; // 如果是运算符 else &#123; // 弹出栈顶优先级大于等于当前运算符的运算符 while (!operatorStack.isEmpty() &amp;&amp; precedence.get(operatorStack.peek()) &gt;= precedence.get(ch)) &#123; postfix.append(operatorStack.pop()); &#125; // 当前运算符压入栈 operatorStack.push(ch); &#125; &#125; // 遍历结束后，弹出栈中剩余的运算符 while (!operatorStack.isEmpty()) &#123; postfix.append(operatorStack.pop()); &#125; // 返回后缀表达式 return postfix.toString(); &#125;","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"中科星图面经","slug":"面经/中科星图面经","date":"2024-12-14T03:16:45.000Z","updated":"2024-12-14T03:18:32.994Z","comments":true,"path":"2024/12/14/面经/中科星图面经/","permalink":"http://example.com/2024/12/14/%E9%9D%A2%E7%BB%8F/%E4%B8%AD%E7%A7%91%E6%98%9F%E5%9B%BE%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"自我介绍 问实习，做了啥，遇到了啥问题，叽里咕噜扯了一通 问我熟悉什么框架，必须boot啊，然后让我讲一下，讲不好，扯到spring讲讲ioc和aop了 然后问我注解，是通过反射吧好像，忘了 然后反问，聊了一下工作时间，做什么（全栈），。。","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"hot100一句话思路","slug":"hot100一句话思路","date":"2024-12-13T13:33:20.000Z","updated":"2025-01-21T06:44:44.859Z","comments":true,"path":"2024/12/13/hot100一句话思路/","permalink":"http://example.com/2024/12/13/hot100%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%9D%E8%B7%AF/","excerpt":"","text":"一、哈希表1. 两数之和 思路：map（key存储元素值，value为索引）。遍历数组的过程中，判断map中是否有target - 当前元素，如果没有就把当前元素插入到map。 详细题解：1.两数之和 参考代码 1234567891011121314151617class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] ans = new int[2]; for (int i = 0; i &lt; nums.length; i++) &#123; if(map.containsKey(target - nums[i]))&#123; ans[0] = map.get(target - nums[i]); ans[1] = i; break; &#125; map.put(nums[i], i); &#125; return ans; &#125;&#125; 49. 字母异位词分组 思路：字母异位词转化为字符数组，经过排序再转为字符串，是相同的。利用这一点，使用map，key为经过排序后的字符串，value为当前异位词列表。最终将value值返回到一个列表中。 详细题解：49. 字母异位词分组 参考代码 1234567891011121314class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; HashMap&lt;String , List&lt;String&gt;&gt; map = new HashMap&lt;&gt;(); for (String str : strs) &#123; char[] array = str.toCharArray(); Arrays.sort(array); String key = new String(array); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;&gt;(map.values()); &#125;&#125; 128. 最长连续序列 思路：一个数字能不能作为序列的开始，取决于它前一个数字是否存在；一个数字能不能作为序列的结束，取决于它后一个数字是否不存在。借助此，我们可以用一个set来现把所有元素加入，然后直接遍历set集合来看 详细题解：128. 最长连续序列 参考代码 123456789101112131415161718class Solution &#123; public int longestConsecutive(int[] nums) &#123; HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); int ans = 0; for (int num : nums) &#123; set.add(num); &#125; for (int num : set) &#123; if(!set.contains(num - 1))&#123; int len = 1; while (set.contains(++num)) len++; ans = Math.max(ans, len); &#125; &#125; return ans; &#125;&#125; 二、双指针283. 移动零 思路：始终让慢指针指向零元素（如果不为0直接自增后跳出当前循环进入下一次循环），快指针去寻找不为零的元素，然后找到了就设置慢指针所指的元素为快指针所指的元素，再让慢指针自增 详细题解：283. 移动零 参考代码 123456789101112131415class Solution &#123; public void moveZeroes(int[] nums) &#123; int slow = 0, fast = 1; while (fast &lt; nums.length)&#123; if(nums[slow] == 0 &amp;&amp; nums[fast] != 0)&#123; nums[slow] = nums[fast]; nums[fast] = 0; slow++; &#125; if(nums[slow]!= 0) slow++; fast++; &#125; &#125;&#125; 11. 盛最多水的容器 思路：从两边向中间靠，每次计算此时的体积（高为左右线的较低者），然后较低的线那一边向中间靠拢 详细题解： 参考代码 123456789101112131415class Solution &#123; public int maxArea(int[] height) &#123; int low = 0; int high = height.length - 1; int ans = Integer.MIN_VALUE; while (low &lt;= high)&#123; ans = Math.max(ans, (high - low) * Math.min(height[low], height[high])); if(height[low] &lt; height[high]) low++; else high--; &#125; return ans; &#125;&#125; 15. 三数之和 思路：首先将数组排成有序。然后遍历数组，有两个退出条件：1.当前数字大于0，break；2.当前元素和前一个元素一样，continue（相当于对第一个元素的去重），然后在剩下元素中，从首尾向中间靠拢，如果满足条件了，再对左右指针所指元素去重 详细题解：15. 三数之和 参考代码： 12345678910111213141516171819202122232425262728class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i++) &#123; if(nums[i] &gt; 0) break; if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.length - 1; while (l &lt; r)&#123; int temp = nums[i] + nums[l] + nums[r]; if(temp &lt; 0) l++; else if (temp &gt; 0) &#123; r--; &#125;else &#123; ans.add(Arrays.asList(nums[i], nums[l], nums[r])); while (l &lt; r &amp;&amp; nums[l] == nums[l + 1]) l++; while (l &lt; r &amp;&amp; nums[r] == nums[r - 1]) r--; l++; r--; &#125; &#125; &#125; return ans; &#125;&#125; 42. 接雨水 思路：首位位置不装雨水，其余每个位置所装雨水 = min（左边柱子最大值，右边柱子最大值）- 当且柱子高。左右指针的更新类似11. 盛最多水的容器 这一题，每次移动较低的那根柱子 详细题解：42. 接雨水 参考代码： 1234567891011121314151617181920class Solution &#123; public int trap(int[] height) &#123; if(height.length &lt;= 2) return 0; int maxLeft = height[0]; int maxRight = height[height.length - 1]; int left = 0; int right = height.length - 1; int ans = 0; while (left &lt;= right)&#123; maxLeft = Math.max(maxLeft, height[left]); maxRight = Math.max(maxRight, height[right]); if(maxLeft &lt; maxRight) ans += maxLeft - height[left++]; else ans += maxRight - height[right--]; &#125; return ans; &#125;&#125; 三、滑动窗口3. 无重复字符的最长子串 思路：双指针之快慢指针。将快指针所遍历的字符加入set，当添加失败时（说明有重复字符），将慢指针向快指针收缩，直到此时快指针所指字符可以加入set，再继续移动快指针 详细题解：3. 无重复字符的最长子串 参考代码： 1234567891011121314151617class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int ans = 0; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); int begin = 0; for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); while (begin &lt; i &amp;&amp; set.contains(c))&#123; set.remove(s.charAt(begin)); begin++; &#125; set.add(c); ans = Math.max(ans, i - begin + 1); &#125; return ans; &#125;&#125; 438. 找到字符串中所有字母异位词 思路：快慢指针＋哈希（数组）。用数组哈希记录p每个字符出现的次数，快指针遍历s中的字符，每次让数组中对应字符的值减一，如果当前这个数组元素值小于0，说明出现了p中没有的字符，收缩慢指针同时恢复字符次数状态，直到慢指针赶上快指针的时候才能填补上这个差距。如果快慢指针的长度等于p的长度，可以将此时慢指针的坐标添加到结果 详细题解：438. 找到字符串中所有字母异位词 参考代码： 12345678910111213141516171819202122class Solution &#123; public List&lt;Integer&gt; findAnagrams(String s, String p) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int[] cnt = new int[26]; for (int i = 0; i &lt; p.length(); i++) &#123; cnt[p.charAt(i) - &#x27;a&#x27;]++; &#125; for (int r = 0, l = 0; r &lt; s.length(); r++) &#123; char c = s.charAt(r); cnt[c - &#x27;a&#x27;]--; while (l &lt;= r &amp;&amp; cnt[c - &#x27;a&#x27;] &lt; 0)&#123; //左指针右移 cnt[s.charAt(l) - &#x27;a&#x27;]++; l++; &#125; if(r - l + 1 == p.length()) ans.add(l); &#125; return ans; &#125;&#125; 四、字符串560. 和为 K 的子数组 思路：利用前缀和加上一个哈希表记录前缀和出现的次数，通过查找当前前缀和减去目标和k的值是否已经存在于哈希表中，快速统计满足条件的子数组个数。 详细题解：560. 和为 K 的子数组 参考代码： 12345678910111213141516class Solution &#123; public int subarraySum(int[] nums, int k) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); int ans = 0; int pre = 0; for (int i = 0; i &lt; nums.length; i++) &#123; pre += nums[i]; if(map.containsKey(pre - k))&#123; ans += map.get(pre - k); &#125; map.put(pre, map.getOrDefault(pre, 0) + 1); &#125; return ans; &#125;&#125; 239. 滑动窗口最大值（难） 思路：借助单调队列，来存储可能成为最大值的元素。具体而言，如果当前元素比队列末尾元素要小，就直接进入队列。这样队头就是最大的元素。注意：在窗口移动过程中，如果当前队头元素和即将被（窗口）移除的元素一样大，那队头元素也要出队。 详细题解：239. 滑动窗口最大值 参考代码： 12345678910111213141516171819202122232425class Solution &#123; public int[] maxSlidingWindow(int[] nums, int k) &#123; int[] ans = new int[nums.length - k + 1]; LinkedList&lt;Integer&gt; deque = new LinkedList&lt;&gt;(); //未形成窗口时 for (int i = 0; i &lt; k; i++) &#123; while (!deque.isEmpty() &amp;&amp; deque.peekLast() &lt; nums[i]) deque.removeLast(); deque.addLast(nums[i]); &#125; ans[0] = deque.peekFirst(); //形成窗口时 for (int i = k; i &lt; nums.length; i++) &#123; if(nums[i - k] == deque.peekFirst()) deque.removeFirst(); while (!deque.isEmpty() &amp;&amp; deque.peekLast() &lt; nums[i]) deque.removeLast(); deque.addLast(nums[i]); ans[i - k + 1] = deque.peekFirst(); &#125; return ans; &#125;&#125; 76. 最小覆盖子串在做这题之前，可以先试一下这题的“简单版”——438. 找到字符串中所有字母异位词 思路：和438类似，不过这题要维护一个变量，用于记录t中字符是否匹配完了 详细题解：这个是我在题解下面看的别人的 参考代码 12345678910111213141516171819202122232425262728class Solution &#123; public String minWindow(String s, String t) &#123; int[] cnt = new int[128]; int count = 0;//记录t中需要匹配的字符个数 for (int i = 0; i &lt; t.length(); i++) &#123; cnt[t.charAt(i) - &#x27;A&#x27;]++; count++; &#125; int start = -1, end = s.length(); for (int r = 0, l = 0; r &lt; s.length(); r++) &#123; char cur = s.charAt(r); if(--cnt[cur - &#x27;A&#x27;] &gt;= 0)//如果当前消除的是有效（t中的）字符 count--; while (l &lt;= r &amp;&amp; count == 0) &#123; //当前需要匹配的字符全部匹配完了 if(++cnt[s.charAt(l) - &#x27;A&#x27;] &gt; 0)&#123; //说明当前左指针指向的字符是有效字符 if(r - l &lt; end - start)&#123; //更新有效区间 end = r; start = l; &#125; count++; &#125; l++; &#125; &#125; return start == -1 ? &quot;&quot; : s.substring(start, end + 1); &#125;&#125; 五、普通数组53. 最大子数组和 思路：dp。dp[i]代表以下标i结尾的最大子数组和为dp[i]，所以我们要找的是： max (dp[i]), i ∈ {0, n - 1} 还要注意的是，状态转移方程dp[i] = max(dp[i-1]+nums[i]，nums[i]) 详细题解：53.最大子数组和 参考代码 1234567891011121314class Solution &#123; public int maxSubArray(int[] nums) &#123; int[] dp = new int[nums.length]; int pre = nums[0]; int ans = pre; for (int i = 1; i &lt; nums.length; i++) &#123; pre += nums[i]; pre = Math.max(nums[i], pre); ans = Math.max(ans, pre); &#125; return ans; &#125;&#125; 因为当前状态仅和上一个状态有关，因此也可以这样写： 12345678910class Solution &#123; public int maxSubArray(int[] nums) &#123; int pre = 0, maxAns = nums[0]; for (int x : nums) &#123; pre = Math.max(pre + x, x); //状态转移 maxAns = Math.max(maxAns, pre); &#125; return maxAns; &#125;&#125; 56. 合并区间 思路：用一个数组类型的列表来存储最终结果。遍历所给二维数组，如果当前数组的第一个元素&lt;&#x3D;列表中最后一个元素p（数组）的第二个元素，那就要对p的第二个数字进行更新。例如：[1,3], [2, 4] &#x3D;&gt; [1, 4] 详细题解：56.合并区间 参考代码： 1234567891011121314class Solution &#123; public int[][] merge(int[][] intervals) &#123; Arrays.sort(intervals, (p, q) -&gt; p[0] - q[0]); List&lt;int[]&gt; list = new ArrayList&lt;&gt;(); for (int[] interval : intervals) &#123; int m = list.size(); if(m &gt; 0 &amp;&amp; list.get(m - 1)[1] &gt;= interval[0]) list.get(m - 1)[1] = Math.max(interval[1], list.get(m - 1)[1]); else list.add(interval); &#125; return list.toArray(new int[list.size()][]); &#125;&#125; 189. 轮转数组 思路：先对整个数组逆置。再对前k个元素逆置。再对后n - k个元素逆置。注意先对k进行处理 详细题解：189.轮转数组 参考代码 1234567891011121314151617class Solution &#123; public void rotate(int[] nums, int k) &#123; int n = nums.length; k = k % n; reverse(nums, 0, n - 1); reverse(nums, 0, k - 1); reverse(nums, k, n - 1); &#125; private void reverse(int[] nums, int low, int high) &#123; while (low &lt;= high)&#123; int temp = nums[high]; nums[high--] = nums[low]; nums[low++] = temp; &#125; &#125;&#125; 238. 除自身以外数组的乘积 思路：一种简单的思路是，使用两个数组，一个数组存储每个元素左边元素的乘积，另一个数组存储每个元素右边元素的乘积。最后结果就是这两个数组对应位置相乘，就是每个元素除自身以外数组的乘积。但是可以省略记录右边元素乘积的这个数组，之间将其存储到结果数组中。见代码。 详细题解：238.除自身以外数组的乘积 参考代码 12345678910111213141516class Solution &#123; public int[] productExceptSelf(int[] nums) &#123; int n = nums.length; int[] ans = new int[n]; //记录左边元素的乘积 ans[0] = 1; for (int i = 1; i &lt; n; i++) &#123; ans[i] = ans[i - 1] * nums[i - 1]; &#125; int temp = 1; for (int i = n - 1; i &gt;= 0; i--)&#123; ans[i] = ans[i] * temp; temp *= nums[i]; &#125; return ans; &#125;&#125; 41. 缺失的第一个正数 （★★ 思路：数组内置哈希（置换法）——源自GPT 将正整数放到对应的位置上： 如果数组中存在数字 x，且 1≤x≤n（n 是数组长度），我们可以尝试将它放到索引 x−1 的位置上。 通过不断交换数字和它应该在的位置，将所有可能的正整数放到正确的位置。 遍历数组寻找缺失的最小正整数： 经过上述处理后，索引 i 应该存储 i+1。 如果某个位置 i不满足 nums[i]&#x3D;i+1，那么 i+1 就是缺失的最小正整数。 若所有位置都正确： 如果数组中所有位置都满足 nums[i]&#x3D;i+1，则缺失的最小正整数是 n+1（数组范围之外的第一个正整数）。 详细题解：41.缺失的第一个正数 参考代码： 123456789101112131415161718192021class Solution &#123; public int firstMissingPositive(int[] nums) &#123; int n = nums.length; int x = 0; for (int i = 0; i &lt; n; i++) &#123; x = nums[i]; while (x &gt; 0 &amp;&amp; x &lt;= n &amp;&amp; x != nums[x - 1])&#123; int temp = nums[x - 1]; nums[x - 1] = x; x = temp; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if(nums[i] != i + 1) return i + 1; &#125; return n + 1; &#125;&#125; 六、矩阵73. 矩阵置零 思路：1、扫描首行首列，标记首行首列是否要置零；2、扫描剩余元素（非首行首列的其余元素），如果某个元素为0，就将其首行对应行索引，首列对应列索引设置为0，方便后续对该行该列置零；3、扫描首行首列，如果有元素0，就将对应列&#x2F;行置零。4、最后根据第一步的标记位，对首行首列置零 详细题解：73.矩阵置零 参考代码： 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public void setZeroes(int[][] matrix) &#123; int m = matrix.length; int n = matrix[0].length; boolean b1 = false, b2 = false; //1、先扫描第一行第一列，记录第一行，第一列是否要置0 for (int i = 0; i &lt; n; i++) if(matrix[0][i] == 0) b1 = true; for (int i = 0; i &lt; m; i++) if(matrix[i][0] == 0) b2 = true; //2、扫描其余，如果有元素为0，将它最左方和最上方的元素置零 for (int i = 1; i &lt; m; i++) for (int j = 1; j &lt; n; j++) if(matrix[i][j] == 0)&#123; matrix[0][j] = 0; matrix[i][0] = 0; &#125; //3、按照首行首列所记录元素，如果为0将对应行列置为0 for (int i = 1; i &lt; n; i ++) if(matrix[0][i] == 0) for (int j = 1; j &lt; m; j++) matrix[j][i] = 0; for (int i = 1; i &lt; m; i++) if(matrix[i][0] == 0) Arrays.fill(matrix[i], 0); //4、根据第一步得到的结果对第一行列置零 if(b1) Arrays.fill(matrix[0], 0); if(b2) for (int j = 0; j &lt; m; j++) matrix[j][0] = 0; &#125;&#125; 54. 螺旋矩阵 思路：设置上下左右四个指针，按照→↓←↑的方向，每次到了最边界，就缩减边界。 详细题解： 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public List&lt;Integer&gt; spiralOrder(int[][] matrix) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int m = matrix.length; int n = matrix[0].length; int l = 0, r = n - 1; int s = 0, x = m - 1; int i = 0; while (i &lt; m * n)&#123; for (int j = l; j &lt;= r; j++)&#123; ans.add(matrix[s][j]); i++; if(i == m * n) return ans; &#125; s++; for (int j = s; j &lt;= x; j++)&#123; ans.add(matrix[j][r]); i++; if(i == m * n) return ans; &#125; r--; for (int j = r; j &gt;= l; j--)&#123; ans.add(matrix[x][j]); i++; if(i == m * n) return ans; &#125; x--; for (int j = x; j &gt;= s; j--)&#123; ans.add(matrix[j][l]); i++; if(i == m * n) return ans; &#125; l++; &#125; return ans; &#125;&#125; 48. 旋转图像 思路：先沿着主对角线交换元素，然后再对每一行进行逆置 详细题解： 参考代码 12345678910111213141516171819202122class Solution &#123; public void rotate(int[][] matrix) &#123; int m = matrix.length; int n = matrix[0].length; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int temp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = temp; &#125; &#125; for (int i = 0; i &lt; m; i++) &#123; int l = 0, r = n - 1; while (l &lt;= r)&#123; int temp = matrix[i][l]; matrix[i][l++] = matrix[i][r]; matrix[i][r--] = temp; &#125; &#125; &#125;&#125; 240. 搜索二维矩阵 II 思路：以第一行最后一个元素作为根节点，可将矩阵看作是一个BST。在不越界的前提下，如果元素比target大，往左找，否则，往下找 详细题解： 参考代码： 123456789101112131415161718192021class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; int m = matrix.length; int n = matrix[0].length; int i = 0; int j = n - 1; while (i &lt; m &amp;&amp; j &gt;=0)&#123; int temp = matrix[i][j]; if(target &gt; temp)&#123; //往下找 i++; &#125; else if (target &lt; temp) &#123; //往左找 j--; &#125;else return true; &#125; return false; &#125;&#125; 七、链表160. 相交链表 思路：如果两个链表相交，设相交部分为c，另外两个链表各自的部分分别为a、b。有a + c + b &#x3D; b + c + a，这就是说，当两个指针从各自链表开头走，走完链表再从对方链表的开头走，它们会在相交部分的起点相遇。这里的代码写法很妙，值得记忆一下。而如果两个链表不相交，核心是m + n &#x3D; n + m，这就是说，当两个指针各自走完自己的链表，再去走完对方的链表，此时两个指针均指向一个共同的“交点‘——null 详细题解：160.相交链表 参考代码 12345678910111213public class Solution &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; //两个指针分别走完各自的链表，再从对方的链表节点开始走，然后它俩相等的时候，就是相交节点 ListNode A = headA; ListNode B = headB; while (A != B)&#123; A = A == null ? headB : A.next; B = B == null ? headA : B.next; &#125; return A; &#125;&#125; 206. 反转链表最基础的操作，这题是后面好几题进阶链表反转的基础核心 思路：借用三个指针，pre，temp，cur，这题可以看着代码手动模拟一下 详细题解：206.反转链表 参考代码： 1234567891011121314class Solution &#123; public ListNode reverseList(ListNode head) &#123; ListNode pre = null; ListNode temp = pre; while (head != null)&#123; temp = head.next; head.next = pre; pre = head; head = temp; &#125; return pre; &#125;&#125; 234. 回文链表 （待最优 思路：这题一个简单的思路就是，把链表节点值存储到列表，然后首尾依次对比。不过这种不是空间最优，官解还有一个递归和快慢指针的解法，快慢指针的感觉很复杂。 详细题解： 参考代码： 1234567891011121314151617181920class Solution &#123; public boolean isPalindrome(ListNode head) &#123; ListNode cur = head; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while (cur != null)&#123; list.add(cur.val); cur = cur.next; &#125; int l = 0; int r = list.size() - 1; while (l &lt; r)&#123; if(list.get(l) != list.get(r)) return false; l++; r--; &#125; return true; &#125;&#125; 141. 环形链表 思路：快慢指针。如果有环，二者肯定能相遇 详细题解：141.环形链表 参考代码： 12345678910111213141516public class Solution &#123; public boolean hasCycle(ListNode head) &#123; if(head == null) return false; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; if(slow == fast) return true; &#125; return false; &#125;&#125; 142. 环形链表 II 思路：直接给结论，还是快慢指针，当二者相遇的时候，再创建一个指针从链表头节点开始走，同时慢指针也开始走，当这俩指针相遇的时候，就是环的入口。详细验证请看详细题解 详细题解：142.环形链表Ⅱ 参考代码： 123456789101112131415161718192021public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; if (slow == fast)&#123; //此时相遇了，让slow和头指针一起往后走 ListNode cur = head; while (cur != slow)&#123; cur = cur.next; slow = slow.next; &#125; return cur; &#125; &#125; return null; &#125;&#125; 21. 合并两个有序链表 思路：双指针，两两比较 详细题解：21.合并两个有序链表 参考代码： 12345678910111213141516171819class Solution &#123; public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; ListNode dummy = new ListNode(); ListNode cur = dummy; while (list1 != null &amp;&amp; list2 != null)&#123; if(list1.val &lt; list2.val)&#123; cur.next = list1; list1 = list1.next; &#125;else &#123; cur.next = list2; list2 = list2.next; &#125; cur = cur.next; &#125; cur.next = list1 == null ? list2 : list1; return dummy.next; &#125;&#125; ❤️类似题目：”两数相加“类型 21. 合并两个有序链表 67. 二进制求和 2. 两数相加 2. 两数相加 思路：通过创建新节点，同时需要一位来记录进位。新节点的值设置为(x + y + temp) % 10，进位temp更新为(x + y + temp) / 10。注意这个while循环的条件和获取当前两个节点值的三目运算符写法，这个在这种类型的题目中经常这样使用 详细题解： 参考代码： 12345678910111213141516171819202122232425class Solution &#123; public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; ListNode ans = new ListNode(); ListNode dummy = ans; int temp = 0; while (l1 != null || l2 != null)&#123; int x = l1 == null ? 0 : l1.val; int y = l2 == null ? 0 : l2.val; int cur = (x + y + temp) % 10; ans.next = new ListNode(cur); temp = (x + y + temp) / 10; //作为下一个节点要累加的值 if(l1 != null) l1 = l1.next; if(l2 != null) l2 = l2.next; ans = ans.next; &#125; if(temp == 1) ans.next = new ListNode(1); return dummy.next; &#125;&#125; 19. 删除链表的倒数第 N 个结点 思路：要删除这个节点，只需找到它前面的一个节点就可以了。快慢指针，快指针从哨兵节点开始，先走n+1步，此时快指针在要删除节点的前一个节点。此时快慢指针同时移动（慢指针也是从哨兵节点开始的），当快指针指向null，此时慢指针就正好指向要删除节点的前一个节点。 详细题解：19.删除链表的倒数第N个节点 参考代码： 1234567891011121314151617class Solution &#123; public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode slow = new ListNode(); slow.next = head; ListNode fast = slow, dummy = slow; for (int i = 0; i &lt;= n; i++) &#123; fast = fast.next; &#125; while (fast != null)&#123; slow = slow.next; fast = fast.next; &#125; slow.next = slow.next.next; return dummy.next; &#125;&#125; 24. 两两交换链表中的节点 思路：这题就是两个数交换的稍微复杂一点的版本。用temp指向要交换两个节点的前一个节点，head指向要交换两个节点的第一个节点 详细题解：24.两两交换链表中的节点 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041//这样写更直观class Solution &#123; public ListNode swapPairs(ListNode head) &#123; ListNode dummyHead = new ListNode(0); dummyHead.next = head; ListNode temp = dummyHead; //temp要始终位于要交换的两个节点之前的一个节点 //如果没有节点或只有一个节点，直接返回 while (temp.next != null &amp;&amp; temp.next.next != null)&#123; ListNode node1 = temp.next; ListNode node2 = temp.next.next; //开始交换这两个节点 temp.next = node2; //先让temp连向node2 node1.next = node2.next; //node2后面还连接着剩余的链表，要先把剩余的接上再调整node2和node1的关系 node2.next = node1; //此时让node2的后面连接node1，现在的关系就是temp——&gt;node2——&gt;node1了 //更新temp，不用更新node1和node2，下次进入循环会更新它俩 temp = node1; //假如后面还有两个节点要更换，比如node3和node4，那node3的前面节点此时就是现在的node1，所以要设置temp指向node1 &#125; //虚拟节点的后一个才是真正的头节点 return dummyHead.next; &#125;&#125;//简单写就是这样class Solution &#123; public ListNode swapPairs(ListNode head) &#123; ListNode dummy = new ListNode(); dummy.next = head; ListNode temp = dummy; while (head != null &amp;&amp; head.next != null)&#123; temp.next = head.next; head.next = head.next.next; temp.next.next = head; temp = head; head = head.next; &#125; return dummy.next; &#125;&#125; 25. K 个一组翻转链表这题还是有点难度的，在做这题之前，可以先理解这几题： 206.翻转链表 92.翻转链表Ⅱ 思路：先统计链表长度，然后每翻转一组，长度-k，直到不能翻转为止。再翻转每组时，要维护好这段链表和其前后的关系。这题和上面两题不同的是，要显式的为这k组链表的第一个节点来声明，以此来维护前后关系。这题最好还是手动模拟一两轮就知道是怎么回事了 详细题解：25.K个一组翻转链表 参考代码： 1234567891011121314151617181920212223242526272829303132class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; ListNode dummy = new ListNode(); dummy.next = head; ListNode cur = head; int count = 0; while (cur != null)&#123; cur = cur.next; count++; &#125; cur = head; ListNode node = dummy; ListNode pre = null; ListNode temp = pre; while (k &lt;= count)&#123; for (int i = 0; i &lt; k; i++) &#123; temp = cur.next; cur.next = pre; pre = cur; cur = temp; &#125; ListNode tail = node.next; node.next = pre; tail.next = cur; node = tail; count -= k; &#125; return dummy.next; &#125;&#125; 138. 随机链表的复制还有一个133. 克隆图 ，本质上和这题一样 思路：哈希表，先创建原链表每个节点和新链表每个节点的映射关系，然后再对新链表每个节点的next和random关系进行维护 详细题解：138.随机链表的复制 参考代码： 123456789101112131415161718class Solution &#123; public Node copyRandomList(Node head) &#123; HashMap&lt;Node, Node&gt; hashMap = new HashMap&lt;&gt;(); Node cur = head; while (cur != null)&#123; hashMap.put(cur, new Node(cur.val)); cur = cur.next; &#125; cur = head; while (cur != null)&#123; hashMap.get(cur).next = hashMap.get(cur.next); hashMap.get(cur).random = hashMap.get(cur.random); cur = cur.next; &#125; return hashMap.get(head); &#125;&#125; 148. 排序链表分治+递归，有点像归并排序（这个我暂时还没学习） 思路：将链表分成两段，这两段调用这个函数都排成有序的了，然后再对这两段链表做合并，类似21. 合并两个有序链表 详细题解：148.排序链表 参考代码： 123456789101112131415161718192021222324252627282930class Solution &#123; public ListNode sortList(ListNode head) &#123; if(head == null || head.next == null) return head; ListNode slow = head, fast = head.next; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; &#125; ListNode temp = slow.next; slow.next = null; ListNode left = sortList(head); ListNode right = sortList(temp); ListNode dummy = new ListNode(); ListNode cur = dummy; while (left != null &amp;&amp; right != null)&#123; if(left.val &lt; right.val)&#123; cur.next = left; left = left.next; &#125;else &#123; cur.next = right; right = right.next; &#125; cur = cur.next; &#125; cur.next = left == null ? right : left; return dummy.next; &#125;&#125; 23. 合并 K 个升序链表(难★) 思路：分治、归并 详细题解： 参考代码： 1234567891011121314151617181920212223242526272829class Solution &#123; public ListNode mergeKLists(ListNode[] lists) &#123; if(lists == null || lists.length == 0) return null; return merge(lists, 0, lists.length - 1); &#125; private ListNode merge(ListNode[] lists, int begin, int end) &#123; if(begin == end) return lists[begin]; int mid = begin + (end - begin)/2; ListNode left = merge(lists, begin, mid); ListNode right = merge(lists, mid + 1, end); return mergeList(left, right); &#125; //合并两个有序链表 private ListNode mergeList(ListNode a, ListNode b) &#123; if(a == null || b == null) return a == null ? b : a; if(a.val &lt; b.val)&#123; a.next = mergeList(a.next, b); return a; &#125;else &#123; b.next = mergeList(a, b.next); return b; &#125; &#125;&#125; 146. LRU 缓存(难)属于是完全不想写第二遍的题目 思路：抽书 双向循环链表（带哨兵节点）负责方便插入删除 哈希表负责O(1)复杂度来寻找元素 要写三个函数： 在双向链表中移除节点x 在链表头部添加一个节点x 确定当前链表中是否有节点x（通过哈希表对值为key的映射来判断 参考题解：灵茶山的题解 详细题解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class LRUCache &#123; //双向循环链表的节点结构 private static class Node&#123; int key,value; Node prev, next; Node(int key, int value)&#123; this.key = key; this.value = value; &#125; &#125; private final int capacity; private final Node dummy = new Node(0,0); //哨兵节点 //哈希表，用以保存值和节点的关系， private final HashMap&lt;Integer, Node&gt; keyToNode = new HashMap&lt;&gt;(); public LRUCache(int capacity) &#123; this.capacity = capacity; dummy.prev = dummy; dummy.next = dummy; &#125; public int get(int key) &#123; //如果哈希表不存在，返回-1 Node node = getNode(key); //如果哈希表存在，则返回该节点的值，同时该节点用了，要把它移动到链表头部，怎么移动呢，直接删除再添加到头部 return node == null ? -1: node.value; &#125; public void put(int key, int value) &#123; //如果哈希表有这个key，就把它移到链表头部，同时更新value Node node = getNode(key); if(node != null)&#123; //移动操作在getNode里面做过了，直接更新返回即可 node.value = value; return; &#125; //如果没有这个key，就新建一个节点，插入头部，同时插入哈希表 node = new Node(key, value); pushFront(node); keyToNode.put(key, node); if(keyToNode.size() &gt; capacity)&#123; //如果插入后大于容量，就要移除链表尾部的节点,同时在哈希表中也要移除 Node backNode = dummy.prev; //哨兵的前一个节点就是链表尾部节点 remove(backNode); keyToNode.remove(backNode.key); &#125; &#125; //get和put都需要确定哈希表中是否有key所对应的节点，因此可以抽象成一个函数 private Node getNode(int key)&#123; //不含这个key所对应的节点 if(!keyToNode.containsKey(key))&#123; return null; &#125; //含的话，不仅要返回这个节点，还要把它移动到链表头部，怎么移动呢，直接删除再添加到头部 Node node = keyToNode.get(key); remove(node); pushFront(node); return node; &#125; //删除一个节点 private void remove(Node x)&#123; x.next.prev = x.prev; x.prev.next = x.next; &#125; //在链表头部添加一个节点 private void pushFront(Node x)&#123; dummy.next.prev = x; x.next = dummy.next; x.prev = dummy; dummy.next = x; &#125;&#125; 八、二叉树94. 二叉树的中序遍历 思路：递归or迭代（栈）。这两种都要掌握。递归就不说了，说一下迭代的大致思路 维护一个栈，一直往最左边走，同时不断添加节点到栈，找到最左节点后加入结果，然后向右遍历，详细过程见代码，可手动模拟一下就清晰了 详细题解： 参考代码： 递归版 123456789101112131415class Solution &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; lnr(root); return ans; &#125; private void lnr(TreeNode root) &#123; if(root == null) return; lnr(root.left); ans.add(root.val); lnr(root.right); &#125;&#125; 迭代版 123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if(root == null) return ans; ArrayDeque&lt;TreeNode&gt; stack = new ArrayDeque&lt;&gt;(); while (root != null || !stack.isEmpty())&#123; while (root != null)&#123; stack.push(root); root = root.left; &#125; root = stack.pop(); ans.add(root.val); root = root.right; &#125; return ans; &#125;&#125; 104. 二叉树的最大深度 思路：二叉树的最大深度等于MAX(左子树最大深度，右子树最大深度)+1 详细题解：104.二叉树的最大深度 参考代码： 123456789class Solution &#123; public int maxDepth(TreeNode root) &#123; if(root == null) return 0; int left = maxDepth(root.left); int right = maxDepth(root.right); return Math.max(left, right) + 1; &#125;&#125; 226. 翻转二叉树 思路：类似在数组中交换两个元素。这题先交换两个左右子树，然后再递归的对左子树和右子树这样操作 详细题解：226.翻转二叉树 参考代码： 123456789101112class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; if(root == null) return null; TreeNode temp = root.left; root.left = root.right; root.right = temp; invertTree(root.left); invertTree(root.right); return root; &#125;&#125; 101. 对称二叉树 思路：左右子树要想对称，左子树的右节点——右子树的左节点；左子树的左节点——右子树的右节点 详细题解：101.对称二叉树 参考代码： 123456789101112131415161718class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; return isD(root.left, root.right); &#125; private boolean isD(TreeNode left, TreeNode right) &#123; if(left == null &amp;&amp; right == null) return true; else if (left != null &amp;&amp; right != null) &#123; if(left.val != right.val) return false; &#125;else return false; boolean b1 = isD(left.left, right.right); boolean b2 = isD(left.right, right.left); return b1 &amp;&amp; b2; &#125;&#125; 543. 二叉树的直径该题和124. 二叉树中的最大路径和 类似 思路：二叉树的直径 &#x3D; MAX(ans， 左子树+右子树)。这题特殊的是这个’链长’的写法。如果为空节点了，返回-1，左子树和右子树的链长在递归的基础上+1，可抵消这个-1，然后递归函数返回左右子树中较大的那个 详细题解：543.二叉树的直径 参考代码： 12345678910111213141516class Solution &#123; int ans = 0; public int diameterOfBinaryTree(TreeNode root) &#123; dfs(root); return ans; &#125; private int dfs(TreeNode root) &#123; if(root == null) return -1; int left = dfs(root.left) + 1; int right = dfs(root.right) + 1; ans = Math.max(ans, left + right); return Math.max(left, right); &#125;&#125; 102. 二叉树的层序遍历BFS，迭代（队列）。这个题也是基础，后续很多题都是在这个基础上改了一点点 思路：先把头节点入队列，每次弹出队列中的节点，并把该节点的左右节点入队列 详细题解：102.二叉树的层序遍历 参考代码： 1234567891011121314151617181920212223class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); if(root == null) return ans; ArrayDeque&lt;TreeNode&gt; deque = new ArrayDeque&lt;&gt;(); deque.offer(root); while (!deque.isEmpty())&#123; int size = deque.size(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; TreeNode remove = deque.remove(); path.add(remove.val); if(remove.left != null) deque.offer(remove.left); if(remove.right != null) deque.offer(remove.right); &#125; ans.add(path); &#125; return ans; &#125; &#125; ❤️二叉树BFS（队列）类题目 102. 二叉树的层序遍历 199. 二叉树的右视图 下面为150的题目 117. 填充每个节点的下一个右侧节点指针 II 173. 二叉搜索树迭代器 637. 二叉树的层平均值 103. 二叉树的锯齿形层序遍历 108. 将有序数组转换为二叉搜索树 思路：类似二分查找 详细题解：108.将有序数组转换为二叉搜索树 参考代码： 123456789101112131415class Solution &#123; public TreeNode sortedArrayToBST(int[] nums) &#123; return build(0, nums.length - 1, nums); &#125; private TreeNode build(int low, int high, int[] nums) &#123; if(low &gt; high) return null; int mid = low + (high - low) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = build(low, mid - 1, nums); root.right = build(mid + 1, high, nums); return root; &#125;&#125; ❤️BST题目汇总分治： 108. 将有序数组转换为二叉搜索树 、 二叉树性质（严格递增）： 98. 验证二叉搜索树 230. 二叉搜索树中第 K 小的元素 530. 二叉搜索树的最小绝对差 98. 验证二叉搜索树 思路：如果当前节点&lt;&#x3D;前一个节点，说明不满足BST性质。这题要特别注意节点值的范围，要用long型 详细题解：98.验证二叉搜索树 参考代码： 123456789101112131415class Solution &#123; long pre = Long.MIN_VALUE; public boolean isValidBST(TreeNode root) &#123; if(root == null) return true; if(!isValidBST(root.left)) return false; if(root.val &lt;= pre) return false; pre = root.val; if(!isValidBST(root.right)) return false; return true; &#125;&#125; 230. 二叉搜索树中第 K 小的元素 思路：中序遍历，初始化index &#x3D; 1 详细题解： 参考代码： 123456789101112131415161718class Solution &#123; int ans = Integer.MAX_VALUE; int index = 1; public int kthSmallest(TreeNode root, int k) &#123; dfs(root, k); return ans; &#125; private void dfs(TreeNode root, int k) &#123; if(root == null) return; dfs(root.left, k); if(index == k) ans = root.val; index++; dfs(root.right, k); &#125;&#125; 199. 二叉树的右视图 思路：层序遍历，到了最后一个节点就保存记录。 详细题解：199.二叉树的右视图 参考代码： 12345678910111213141516171819202122class Solution &#123; public List&lt;Integer&gt; rightSideView(TreeNode root) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); ArrayDeque&lt;TreeNode&gt; deque = new ArrayDeque&lt;&gt;(); if(root == null) return ans; deque.offer(root); while (!deque.isEmpty())&#123; int size = deque.size(); for (int i = 0; i &lt; size; i++) &#123; TreeNode node = deque.remove(); if(i == size - 1) ans.add(node.val); if(node.left != null) deque.offer(node.left); if(node.right != null) deque.offer(node.right); &#125; &#125; return ans; &#125;&#125; 114. 二叉树展开为链表 思路：不断地将左子树替换为root的右子树，并将之前的右子树拼到其新右子树（也就是之前的左子树）的最右节点之后，然后更新root 详细题解：114.二叉树展开为链表 参考代码： 1234567891011121314151617class Solution &#123; public void flatten(TreeNode root) &#123; while (root != null)&#123; if(root.left != null)&#123; TreeNode temp = root.left; TreeNode cur = temp; while (cur.right != null)&#123; cur = cur.right; &#125; cur.right = root.right; root.left = null; root.right = temp; &#125; root = root.right; &#125; &#125;&#125; 105. 从前序与中序遍历序列构造二叉树难倒是不难，就是繁琐，得慢慢模拟那个传入的值 类似的还有：106. 从中序与后序遍历序列构造二叉树 思路：借助哈希表和全局数组，前者存储中序遍历数组&lt;值，索引&gt;，后者赋值为前序遍历数组。通过哈希表得知当前节点值在中序遍历数组中的索引。这题最关键的是如何确定在左右子树中传递的值 详细题解：105.从前序与中序遍历序列构造二叉树 参考代码： 123456789101112131415161718192021class Solution &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] p ; public TreeNode buildTree(int[] preorder, int[] inorder) &#123; p = preorder; for (int i = 0; i &lt; inorder.length; i++) &#123; map.put(inorder[i], i); &#125; return build(0, preorder.length - 1, 0, inorder.length - 1); &#125; private TreeNode build(int pb, int pe, int ib, int ie) &#123; if(pb &lt; 0 || ib &lt; 0 || pb &gt; pe || ib &gt; pe) return null; int index = map.get(p[pb]); TreeNode root = new TreeNode(p[pb]); root.left = build(pb + 1, pb + index - ib, ib, index - 1); root.right = build(pb + index + 1 - ib, pe, index + 1, ie); return root; &#125;&#125; 后面几题都有点邪乎了。。 437. 路径总和 III （小难哈希表+前缀和，类似560. 和为 K 的子数组 思路：哈希表保存&lt;当前路径从根节点到当前节点的节点值之和，出现次数&gt;，如果想在当前路径找到一段路径之和为target，那么哈希表中必须有这样的元素，即当前节点值之和 - 该元素的key &#x3D; target。还有一些细节参考详细题解，这题核心思路就是这样，但还有一些繁琐的小细节，比如哈希表key的类型，状态恢复（因为题目要求只能是从父节点到子节点，也即是不能跨越父节点有两段子树参与） 详细题解：437.路径总和 III 参考代码： 1234567891011121314151617181920212223class Solution &#123; HashMap&lt;Long, Integer&gt; map = new HashMap&lt;&gt;(); int targrt; public int pathSum(TreeNode root, int targetSum) &#123; targrt =targetSum; map.put(0L, 1); return dfs(root, 0L); &#125; private int dfs(TreeNode root, long curSum) &#123; if(root == null) return 0; curSum += root.val; int ans = 0; ans += map.getOrDefault(curSum - targrt, 0); map.put(curSum, map.getOrDefault(curSum, 0) + 1); int left = dfs(root.left, curSum); int right = dfs(root.right, curSum); ans += left + right; map.put(curSum, map.get(curSum) - 1); return ans; &#125;&#125; 236. 二叉树的最近公共祖先 （思路有点懵懂 思路：这题可直接参考Krahets 的题解，他这个思路很清晰，代码我是参考的灵茶山艾府的，这个代码比较好写 详细题解： 参考代码： 1234567891011class Solution &#123; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if(root == null || p == root || q == root) return root; TreeNode l = lowestCommonAncestor(root.left, p, q); TreeNode r = lowestCommonAncestor(root.right, p, q); if(l != null &amp;&amp; r != null) return root; return l == null ? r : l; &#125;&#125; 124. 二叉树中的最大路径和 思路：递归函数返回当前节点及其左右子树较大值之和与0的比较，而ans要取当前节点和其左右子树之和与and的较大值 详细题解： 参考代码： 12345678910111213141516class Solution &#123; int ans = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) &#123; dfs(root); return ans; &#125; private int dfs(TreeNode root) &#123; if(root == null) return 0; int left = dfs(root.left); int right = dfs(root.right); ans = Math.max(ans, left + right + root.val); return Math.max(0, Math.max(left, right) + root.val); &#125;&#125; 九、图论 十、回溯回溯，主要就是套模板。我感觉最关键的就是两个要素： 回溯传递的参数 回溯退出的条件 46. 全排列 思路：可以用一个list来存储每组的元素。退出条件就是list.size() == nums.length，同时要能加入list的前提是list不含当前元素 详细题解： 参考代码： 1234567891011121314151617181920class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; backTracking(nums); return ans; &#125; private void backTracking(int[] nums) &#123; if(path.size() == nums.length) ans.add(new ArrayList&lt;&gt;(path)); for (int num : nums) &#123; if(!path.contains(num))&#123; path.add(num); backTracking(nums); path.remove(path.size() - 1); &#125; &#125; &#125;&#125; 78. 子集 思路：这题有点特殊的是，每个分组都要添加到结果，所以不用写退出条件了 详细题解： 参考代码： 1234567891011121314151617class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; backTracking(nums, 0); return ans; &#125; private void backTracking(int[] nums, int begin) &#123; ans.add(new ArrayList&lt;&gt;(path)); for (int i = begin; i &lt; nums.length; i++) &#123; path.add(nums[i]); backTracking(nums, i + 1); path.remove(path.size() - 1); &#125; &#125;&#125; 17. 电话号码的字母组合 思路：借助哈希表存储电话号码和字符串的映射关系，传入字符串即开始索引begin，退出条件为begin == digits.length() 详细题解：17.电话号码的字母组合 参考代码： 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); HashMap&lt;Character, String&gt; map = new HashMap&lt;&gt;(); StringBuilder sb = new StringBuilder(); public List&lt;String&gt; letterCombinations(String digits) &#123; if(digits.isEmpty()) return ans; map.put(&#x27;2&#x27;, &quot;abc&quot;); map.put(&#x27;3&#x27;, &quot;def&quot;); map.put(&#x27;4&#x27;, &quot;ghi&quot;); map.put(&#x27;5&#x27;, &quot;jkl&quot;); map.put(&#x27;6&#x27;, &quot;mno&quot;); map.put(&#x27;7&#x27;, &quot;pqrs&quot;); map.put(&#x27;8&#x27;, &quot;tuv&quot;); map.put(&#x27;9&#x27;, &quot;wxyz&quot;); backTracking(digits, 0); return ans; &#125; private void backTracking(String digits, int begin) &#123; if(begin == digits.length())&#123; ans.add(sb.toString()); return; &#125; char c = digits.charAt(begin); String curS = map.get(c); for (int i = 0; i &lt; curS.length(); i++) &#123; sb.append(curS.charAt(i)); backTracking(digits, begin + 1); sb.deleteCharAt(sb.length() - 1); &#125; &#125;&#125; 39. 组合总和 思路：传入数组开始索引begin，当前和cur，目标值，数组。结束条件是begin == candidates.length || cur == target，也有可能提前退出，那就是cur &gt; target 详细题解：39.组合总和 参考代码： 123456789101112131415161718192021222324class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; backTracking(0, 0, target, candidates); return ans; &#125; private void backTracking(int begin, int cur, int target, int[] candidates) &#123; if(begin == candidates.length || cur == target)&#123; ans.add(new ArrayList&lt;&gt;(path)); return; &#125; if(cur &gt; target) return; for (int i = begin; i &lt; candidates.length; i++) &#123; cur += candidates[i]; path.add(candidates[i]); backTracking(i, cur, target, candidates); path.remove(path.size() - 1); cur -= candidates[i]; &#125; &#125;&#125; 22. 括号生成 思路：传入当前左括号剩余left和右括号剩余right以及当前字符串cur。退出条件是left == 0 &amp;&amp; right == 0。还要一个提前退出条件，就是left &gt; right，此时无法组成合法的括号。这里回溯的写法形式也不太一样。 详细题解：22.括号生成 参考代码： 123456789101112131415161718192021class Solution &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); public List&lt;String&gt; generateParenthesis(int n) &#123; backTracking(n, n, &quot;&quot;); return ans; &#125; private void backTracking(int left, int right, String cur) &#123; if(left == 0 &amp;&amp; right == 0)&#123; ans.add(cur); return; &#125; if(left &gt; right) return; if(left &gt; 0)&#123; backTracking(left-1, right, cur + &quot;(&quot;); &#125; if(right &gt; 0) backTracking(left, right-1, cur + &quot;)&quot;); &#125;&#125; 79. 单词搜索 思路：DFS，从矩阵每个元素开始匹配，匹配了修改当前字符为&#96;.&#96;&#96;,表示已经用过，搜索完之后回溯为之前的字符 详细题解：79.单词搜索 参考代码： 1234567891011121314151617181920212223242526272829class Solution &#123; public boolean exist(char[][] board, String word) &#123; int m = board.length; int n = board[0].length; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if(dfs(i, j, board, word, 0)) return true; &#125; &#125; return false; &#125; private boolean dfs(int i, int j, char[][] board, String word, int k) &#123; if(i &lt; 0 || j &lt; 0 || i &gt;= board.length || j &gt;= board[0].length || word.charAt(k) != board[i][j]) return false; if(k == word.length() - 1) return true; char c = board[i][j]; board[i][j] = &#x27;.&#x27;; boolean ans = dfs(i + 1, j , board, word, k + 1)|| dfs(i - 1, j , board, word, k + 1) || dfs(i, j + 1, board, word, k + 1) || dfs(i, j - 1, board, word, k + 1); board[i][j] = c; return ans; &#125;&#125; 131. 分割回文串 思路：每个字符在回溯循环中往后匹配，需要写一个判断是否为回文串的函数，如果是就添加进中间结果集。回溯传入字符串和开始索引，退出条件为开始索引等于字符串长度 详细题解：131. 分割回文串 参考代码： 123456789101112131415161718192021222324252627282930313233class Solution &#123; List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;String&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; backTracking(s, 0); return ans; &#125; private void backTracking(String s, int begin) &#123; if(begin == s.length())&#123; ans.add(new ArrayList&lt;&gt;(path)); return; &#125; for (int i = begin; i &lt; s.length(); i++) &#123; if(isH(s, begin, i))&#123; String substring = s.substring(begin, i + 1); path.add(substring); backTracking(s, i + 1); path.remove(path.size() - 1); &#125; &#125; &#125; private boolean isH(String s, int l, int r) &#123; while (l &lt;= r)&#123; if(s.charAt(l) != s.charAt(r)) return false; l++; r--; &#125; return true; &#125;&#125; 51. N 皇后 思路：回溯函数传入棋盘数组和当前行索引，退出条件为当前行索引等于棋盘宽，回溯里面的循环是列循环。同上题一样，需要写一个函数来判断是否满足条件，判断当前字符是否可以作为Q。具体来说，就是判断当前行，列，主对角，副对角是否有其它Q。 详细题解：51. N 皇后 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123; List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;String&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; char[][] chars = new char[n][n]; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; chars[i][j] = &#x27;.&#x27;; &#125; &#125; backTracking(0, chars); return ans; &#125; private void backTracking(int row, char[][] chars) &#123; if(row == chars.length)&#123; ans.add(chars2List(chars)); return; &#125; for (int col = 0; col &lt; chars[0].length; col++) &#123; if(isT(row, col, chars))&#123; chars[row][col] = &#x27;Q&#x27;; backTracking(row + 1, chars); chars[row][col] = &#x27;.&#x27;; &#125; &#125; &#125; private List&lt;String&gt; chars2List(char[][] chars) &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; chars.length; i++) &#123; ans.add(new String(chars[i])); &#125; return ans; &#125; private boolean isT(int row, int col, char[][] chars) &#123; int m = chars.length; int n = chars[0].length; for (int i = 0; i &lt; m; i++) &#123; if(chars[i][col] == &#x27;Q&#x27;) return false; &#125; for (int i = 0; i &lt; n; i++) &#123; if(chars[row][i] == &#x27;Q&#x27;) return false; &#125; for (int i = row, j = col; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) if(chars[i][j] == &#x27;Q&#x27;) return false; for (int i = row, j = col; i &gt;= 0 &amp;&amp; j &lt; n; i--, j++) if(chars[i][j] == &#x27;Q&#x27;) return false; return true; &#125;&#125; 十一、二分查找35. 搜索插入位置 思路：二分查找找存在时的元素这没什么好说的，当元素不存在时，为什么返回low 就可以了呢，观察while退出条件，退出时，low &#x3D; high + 1 详细题解：35. 搜索插入位置 参考代码： 123456789101112131415class Solution &#123; public int searchInsert(int[] nums, int target) &#123; int low = 0, high = nums.length- 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] == target) return mid; else if (nums[mid] &gt; target) &#123; high = mid - 1; &#125;else low = mid + 1; &#125; return low; &#125;&#125; 74. 搜索二维矩阵 思路：将矩阵按行展开拼成一个一维数组，可以发现就是对这个数组来进行二分查找，每次得到的mid和行列有一个对应关系，row = mid / n, col = mid % n 详细题解： 参考代码： 12345678910111213141516171819class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; int m = matrix.length; int n = matrix[0].length; int low = 0, high = m * n - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; int row = mid / n; int col = mid % n; if(matrix[row][col] == target) return true; else if (matrix[row][col] &gt; target) &#123; high = mid - 1; &#125;else low = mid + 1; &#125; return false; &#125;&#125; 34. 在排序数组中查找元素的第一个和最后一个位置 思路：二分查找，如果找不到，那就正常套路，如果找到了，直接从当前位置向左右扩散，直到扩散的元素不等于target 详细题解：34. 在排序数组中查找元素的第一个和最后一个位置 参考代码： 12345678910111213141516171819class Solution &#123; public int[] searchRange(int[] nums, int target) &#123; int low = 0, high = nums.length - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] &gt; target) high = mid - 1; else if(nums[mid] &lt; target) low = mid + 1; else &#123; int l = mid, r = mid; while (l &gt;= 0 &amp;&amp; nums[l] == target) l--; while (r &lt; nums.length &amp;&amp; nums[r] == target) r++; return new int[]&#123;l + 1, r - 1&#125;; &#125; &#125; return new int[] &#123;-1, -1&#125;; &#125;&#125; 33. 搜索旋转排序数组 思路：这种数组是局部有序，全局无序，比如前半部分是有序的，后半部分也是有序的。我们做二分查找时，如果当前mid元素不等于target，那就判断当前元素是处于左边有序区间还是右边有序区间，然后再分别做区间缩减 详细题解：33. 搜索旋转排序数组 参考代码： 12345678910111213141516171819202122class Solution &#123; public int search(int[] nums, int target) &#123; int low = 0, high = nums.length - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] == target) return mid; else if (nums[mid] &lt; nums[high]) &#123; if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[high]) low = mid + 1; else high = mid - 1; &#125;else &#123; if(target &gt;= nums[low] &amp;&amp; target &lt; nums[mid]) high = mid - 1; else low = mid + 1; &#125; &#125; return -1; &#125;&#125; 153. 寻找旋转排序数组中的最小值 思路：同上题一样，这种旋转数组要分区间。如果是在左边区间，就将最小值和left比较，如果是在最右边，就将最小值和mid比较 详细题解：153. 寻找旋转排序数组中的最小值 参考代码： 123456789101112131415161718class Solution &#123; public int findMin(int[] nums) &#123; int low = 0, high = nums.length - 1; int ans = Integer.MAX_VALUE; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; int temp = nums[mid]; if(temp &lt; nums[high])&#123; ans = Math.min(ans, temp); high = mid - 1; &#125;else &#123; ans = Math.min(ans, nums[low]); low = mid + 1; &#125; &#125; return ans; &#125;&#125; 4. 寻找两个正序数组的中位数 （难） 思路： 详细题解： 参考代码： 1 十二、栈20. 有效的括号 思路：借助栈，如果是左括号直接入栈，右括号就根据栈顶元素来确定对右括号的策略 详细题解：20. 有效的括号 参考代码： 123456789101112131415161718192021222324class Solution &#123; public boolean isValid(String s) &#123; ArrayDeque&lt;Character&gt; stack = new ArrayDeque&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if(c == &#x27;[&#x27; || c == &#x27;(&#x27; || c == &#x27;&#123;&#x27;) stack.push(c); else &#123; if(stack.isEmpty()) return false; else if (c == &#x27;]&#x27; &amp;&amp; stack.peek() == &#x27;[&#x27;) &#123; stack.pop(); &#125;else if (c == &#x27;)&#x27; &amp;&amp; stack.peek() == &#x27;(&#x27;) &#123; stack.pop(); &#125;else if (c == &#x27;&#125;&#x27; &amp;&amp; stack.peek() == &#x27;&#123;&#x27;) &#123; stack.pop(); &#125;else return false; &#125; &#125; if (!stack.isEmpty()) return false; return true; &#125;&#125; 155. 最小栈 思路：另外创建一个只存储栈中最小元素的辅助栈，来模拟最小栈的操作 详细题解：155. 最小栈 参考代码： 12345678910111213141516171819202122232425262728class MinStack &#123; ArrayDeque&lt;Integer&gt; nums = new ArrayDeque&lt;&gt;(); ArrayDeque&lt;Integer&gt; minStack = new ArrayDeque&lt;&gt;(); public MinStack() &#123; nums = new ArrayDeque&lt;&gt;(); minStack = new ArrayDeque&lt;&gt;(); minStack.push(Integer.MAX_VALUE); &#125; public void push(int val) &#123; nums.push(val); minStack.push(Math.min(minStack.peek(), val)); &#125; public void pop() &#123; nums.pop(); minStack.pop(); &#125; public int top() &#123; return nums.peek(); &#125; public int getMin() &#123; return minStack.peek(); &#125;&#125; 394. 字符串解码 思路：双栈模拟，一个栈仅存数字，另一个栈仅存字符串。遍历s的字符，根据字符为数字、左括号、右括号、字符四种情况分类操作。详细可见代码及详细题解 详细题解：394. 字符串解码 参考代码： 1234567891011121314151617181920212223242526272829class Solution &#123; public String decodeString(String s) &#123; ArrayDeque&lt;Integer&gt; numStack = new ArrayDeque&lt;&gt;(); ArrayDeque&lt;String&gt; strStack = new ArrayDeque&lt;&gt;(); int num = 0; String curStr = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if(Character.isDigit(c))&#123; num = num * 10 + c - &#x27;0&#x27;; &#125; else if (c == &#x27;[&#x27;) &#123; numStack.push(num); strStack.push(curStr); num = 0; curStr = &quot;&quot;; &#125; else if (c == &#x27;]&#x27;) &#123; int loop = numStack.pop(); StringBuilder sb = new StringBuilder(strStack.pop()); for (int j = 0; j &lt; loop; j++) &#123; sb.append(curStr); &#125; curStr = sb.toString(); &#125;else curStr += c; &#125; return curStr; &#125;&#125; 739. 每日温度 （略微难单调栈，这题以及84. 柱状图中最大的矩形 都是单调栈，略微难想 思路： 详细题解： 参考代码： 1 84. 柱状图中最大的矩形 （略微难 思路： 详细题解： 参考代码： 1 十三、堆 十四、贪心算法121. 买卖股票的最佳时机 思路：记录今天及之前的最小值，然后更新可获得的最大利润 详细题解： 参考代码： 1234567891011class Solution &#123; public int maxProfit(int[] prices) &#123; int pre = Integer.MAX_VALUE; int ans = Integer.MIN_VALUE; for (int price : prices) &#123; pre = Math.min(pre, price); ans = Math.max(ans, price - pre); &#125; return ans; &#125;&#125; 55. 跳跃游戏 思路：对当前最大可跳跃步数做循环，同时维护更新最大步数，如果这个值超过了数组长度 - 1，说明可以到达最后一个元素 详细题解：55. 跳跃游戏 参考代码： 1234567891011class Solution &#123; public boolean canJump(int[] nums) &#123; int maxStep = 0; for (int i = 0; i &lt;= maxStep; i++) &#123; maxStep = Math.max(maxStep, i + nums[i]); if(maxStep &gt;= nums.length - 1) return true; &#125; return false; &#125;&#125; 45. 跳跃游戏 II 思路：遍历数组元素，不断维护更新可到达最远位置，如果到了最边界就更新边界同时ans++。这题要注意的是不必到达最后一个元素才判断，到达倒数第二个元素就可以了（详细看官方题解下对于这点说明 详细题解：45. 跳跃游戏 II 参考代码： 123456789101112131415class Solution &#123; public int jump(int[] nums) &#123; int ans = 0; int maxPosition = 0; int end = 0; for (int i = 0; i &lt; nums.length - 1; i++) &#123; maxPosition = Math.max(maxPosition, i + nums[i]); if(i == end)&#123; end = maxPosition; ans++; &#125; &#125; return ans; &#125;&#125; 763. 划分字母区间 思路：先记录每个字符的最远索引是在哪。然后定义begin和end来处理每个区间的长度。每次遍历不断更新end。如果到了end，则将当前区间长度添加进入ans，然后更新begin为end的下一个位置 详细题解：763. 划分字母区间 参考代码： 12345678910111213141516171819class Solution &#123; public List&lt;Integer&gt; partitionLabels(String s) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int[] maxP = new int[26]; for (int i = 0; i &lt; s.length(); i++) &#123; maxP[s.charAt(i) - &#x27;a&#x27;] = i; &#125; int end = 0, begin = 0; for (int i = 0; i &lt; s.length(); i++) &#123; end = Math.max(end, maxP[s.charAt(i) - &#x27;a&#x27;]); if(i == end)&#123; ans.add(end - begin + 1); begin = end + 1; &#125; &#125; return ans; &#125;&#125; 十五、动态规划70. 爬楼梯 思路：定义dp数组i为到达当前位置的方案，当前状态可由dp[i-1]或者dp [i-2]转移过来 详细题解： 参考代码： 123456789101112131415class Solution &#123; public int climbStairs(int n) &#123; int[] dp = new int[n + 1]; if(n == 1) return 1; if(n == 2) return 2; dp[1] = 1; dp[2] = 2; for (int i = 3; i &lt;= n; i++) &#123; dp[i] = dp[i - 1] + dp[i - 2]; &#125; return dp[n]; &#125;&#125; 118. 杨辉三角 思路：当前状态可由上一行的两个元素转移过来 详细题解： 参考代码： 1234567891011121314151617181920class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); ans.add(List.of(1)); if(numRows == 1) return ans; for (int i = 1; i &lt; numRows; i++) &#123; List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); path.add(1); if(i &gt; 1)&#123; for (int j = 0; j &lt; i - 1; j++) &#123; path.add(ans.get(i - 1).get(j) + ans.get(i - 1).get(j + 1)); &#125; &#125; path.add(1); ans.add(path); &#125; return ans; &#125;&#125; 198. 打家劫舍 思路：dp[i]为到当前i所能获得的最高金额，这个金额取决于前面一家(也就是i-1是否打劫了)，dp[i]=max(dp[i-1],dp [i-2]+nums [i]) 详细题解：198. 打家劫舍 参考代码： 1234567891011121314151617class Solution &#123; public int rob(int[] nums) &#123; int n = nums.length; int[] dp = new int[n]; if(n == 1) return nums[0]; if(n == 2) return Math.max(nums[0], nums[1]); dp[0] = nums[0]; dp[1] = Math.max(nums[0], nums[1]); for (int i = 2; i &lt; n; i++) &#123; dp[i] = Math.max(dp[i - 1], dp[i - 2] + nums[i]); &#125; return dp[n - 1]; &#125;&#125; 279. 完全平方数 思路： 详细题解： 参考代码： 1 322. 零钱兑换 思路：完全背包的组合问题，dp[i]表示组成金额i所需的最少硬币个数，怎么转移过来的呢，比如当前i，前提是硬币小于金额i，如果选取了此时的硬币，那就是dp[i - 硬币金额] + 1，这个1就是此时选的硬币，如果不选的话，那就是dp[i] 详细题解：322. 零钱兑换 参考代码： 123456789101112131415class Solution &#123; public int coinChange(int[] coins, int amount) &#123; int[] dp = new int[amount + 1]; Arrays.fill(dp, amount + 1); dp[0] = 0; for (int i = 0; i &lt;= amount; i++) &#123; for (int j = 0; j &lt; coins.length; j++) &#123; if(i &gt;= coins[j]) dp[i] = Math.min(dp[i], dp[i - coins[j]] + 1); &#125; &#125; return dp[amount] &gt; amount ? -1 : dp[amount]; &#125;&#125; 139. 单词拆分 思路：完全背包的排列问题，dp[i]代表以前i个字符是否能由数组里面的字符串组成，可以先把数组里面的字符串存到set里面，对于j &lt; i，如果dp[j]为true，且从j到i的字符串在set里面有，那就说明dp[i]也为true 详细题解：139. 单词拆分 参考代码： 1234567891011121314151617class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; HashSet&lt;String&gt; set = new HashSet&lt;&gt;(); for (String string : wordDict) &#123; set.add(string); &#125; boolean[] dp = new boolean[s.length() + 1]; dp[0] = true; for (int i = 0; i &lt;= s.length(); i++) &#123; for (int j = 0; j &lt; i; j++) &#123; if(dp[j] &amp;&amp; set.contains(s.substring(j, i))) dp[i] = true; &#125; &#125; return dp[s.length()]; &#125;&#125; 十六、多维动态规划 十七、技巧136. 只出现一次的数字 思路：数字与， 任何数和 0 做异或运算，结果仍然是原来的数，即 a⊕0=a。 任何数和其自身做异或运算，结果是 0，即 a⊕a=0。 异或运算满足交换律和结合律，即 a⊕b⊕a=b⊕a⊕a=b⊕(a⊕a)=b⊕0=b。 根据以上三条性质，可对数组中所有数字进行与运算，最终得到的结果就是只出现一次的数字 详细题解： 参考代码： 1234567891011class Solution &#123; public int singleNumber(int[] nums) &#123; if(nums.length == 1) return nums[0]; int k = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; k = k ^ nums[i]; &#125; return k; &#125;&#125; 169. 多数元素 思路：摩尔投票，维护一个vote代表当前投票数，先假设众数就是当前遍历的数字，然后继续遍历，如果当前数与众数相同，vote+1，反之则减1，如果vote为0就设置众数为当前数，最终返回众数即是答案 详细题解：169. 多数元素 参考代码： 12345678910111213141516class Solution &#123; public int majorityElement(int[] nums) &#123; int ans = 0; int vote = 0; for (int num : nums) &#123; if(vote == 0)&#123; ans = num; &#125; if(num == ans) vote++; else vote--; &#125; return ans; &#125;&#125; 75. 颜色分类“荷兰国旗”问题，详细题解可参照 思路：三指针，因为要将数据分成三部分，有一个指针c用于遍历数组，a指针分隔0，1；b指针分隔1，2，退出条件为 c &gt; b，然后根据c当前元素做出不同的操作 c当前元素为0，那么就交换a和c所指的元素，同时a，c右移 当前元素为1，那么a，b线都不动，让c右移 当前元素为2，那交换a和b所指的元素，但c不能右移，因为交换过来的可能是0， 如果右移了但a没有同步移动，就会出错，所以c要停留，到下次知道这个c所指的元素是什么再做判断 详细题解：75.颜色分类 参考代码： 123456789101112131415161718class Solution &#123; public void sortColors(int[] nums) &#123; int a = 0, c = 0, b = nums.length - 1; while (c &lt;= b)&#123; if(nums[c] == 0)&#123; int temp = nums[c]; nums[c++] = nums[a]; nums[a++] = temp; &#125; else if (nums[c] == 1) &#123; c++; &#125;else &#123; int temp = nums[b]; nums[b--] = nums[c]; nums[c] = temp; &#125; &#125; &#125;&#125; 31. 下一个排列 （思路 思路：从后往前找到第一个不满足递增的元素a，然后从这个元素后面找到一个比它大一点的元素b，让它俩交换，最后让元素b后面的所有元素用双指针两两交换，成为从前往后是递增的 详细题解：31. 下一个排列 参考代码： 1234567891011121314151617181920212223class Solution &#123; public void nextPermutation(int[] nums) &#123; int i = nums.length - 2; while (i &gt;= 0 &amp;&amp; nums[i] &gt;= nums[i + 1]) i--; if(i &gt;= 0)&#123; int j = nums.length - 1; while (j &gt; i &amp;&amp; nums[j] &lt;= nums[i]) j--; int temp = nums[j]; nums[j] = nums[i]; nums[i] = temp; &#125; int low = i + 1; int high = nums.length - 1; while (low &lt;= high)&#123; int temp = nums[low]; nums[low++] = nums[high]; nums[high--] = temp; &#125; &#125;&#125; 287. 寻找重复数 思路：龟兔赛跑算法，类似链表环问题，让元素映射到链表节点上，通过快慢指针，第一步先找到环，当两个指针相遇后，将其中一个指针移回起点，并以相同速度前进，直到两个指针再次相遇。再次相遇的点即为环的起点，也就是重复的数字。 详细题解：使用 Floyd 的循环检测算法 将数组映射为链表： 由于 nums 中的值范围是 [1, n]，我们可以将每个数字视为链表的下标。 例如，nums[i] 指向下标 nums[nums[i]]。 重复的数字会导致形成环。 检测环的起点： 使用两个指针：一个慢指针（slow）和一个快指针（fast）。 slow 每次移动一步，fast 每次移动两步。 如果存在环，slow 和 fast 最终会相遇。 找到环的起点（重复数字）： 当两个指针相遇后，将其中一个指针移回起点，并以相同速度前进，直到两个指针再次相遇。 再次相遇的点即为环的起点，也就是重复的数字。 参考代码： 123456789101112131415class Solution &#123; public int findDuplicate(int[] nums) &#123; int slow = nums[0], fast = nums[0]; do &#123; slow = nums[slow]; fast = nums[nums[fast]]; &#125; while (slow != fast); slow = nums[0]; while (slow != fast) &#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/tags/LeetCode/"}]},{"title":"其它","slug":"八股/其它","date":"2024-11-28T12:57:13.000Z","updated":"2024-11-28T13:46:19.521Z","comments":true,"path":"2024/11/28/八股/其它/","permalink":"http://example.com/2024/11/28/%E5%85%AB%E8%82%A1/%E5%85%B6%E5%AE%83/","excerpt":"","text":"设计模式分类： 创建型模式——单例模式，工厂模式 结构型模式 行为型模式 一、单例模式Java 中的单例模式（Singleton Pattern）是一种常用的设计模式，旨在确保一个类只有一个实例，并提供一个全局的访问点。单例模式通常用于管理全局共享资源，例如数据库连接池、日志对象等。 常见写法如下： 1、 懒汉式（线程不安全） 饿汉式在类加载时就创建实例，因此线程安全，不会出现多次创建实例的问题。缺点是即使不需要该实例，类也会被加载。 1234567891011public class Singleton &#123; private static final Singleton instance = new Singleton(); private Singleton() &#123; // 防止外部直接实例化 &#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 2、 懒汉式（线程不安全） 在这种方式中，单例对象是在首次使用时被创建的。但由于没有同步处理，多个线程同时访问时可能会创建多个实例。 1234567891011121314public class Singleton &#123; private static Singleton instance; private Singleton() &#123; // 防止外部直接实例化 &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); // 不安全，多个线程可能同时进入 &#125; return instance; &#125;&#125; 3、 懒汉式（线程安全） 通过 synchronized 关键字来保证多线程下的安全性，但性能较差，因为每次调用 getInstance() 时都会进行同步。 1234567891011121314public class Singleton &#123; private static Singleton instance; private Singleton() &#123; // 防止外部直接实例化 &#125; public synchronized static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 4、双重锁检查（DCL） 双重检查锁定是一种优化的懒汉式实现，它结合了懒加载和线程安全的优点，只有在实例为空时才会进入同步块，从而减少了锁的竞争。 懒加载 （lazy loading）：使⽤的时候再创建对象 123456789101112131415161718public class Singleton &#123; private static volatile Singleton instance; private Singleton() &#123; // 防止外部直接实例化 &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 5、枚举单例 枚举单例是实现单例模式的最佳方式之一。它由 JVM 保证线程安全和单例，并且防止反序列化创建新的对象。 1234567public enum Singleton &#123; INSTANCE; public void someMethod() &#123; // 实现方法 &#125;&#125; 总结 懒汉式（线程不安全）：适用于多线程环境下，但不安全。 懒汉式（线程安全）：通过 synchronized 确保线程安全，但性能较差。 饿汉式：类加载时即创建实例，线程安全，但缺乏灵活性。 双重锁检查：性能较好，推荐使用。 枚举单例：推荐使用，简洁且线程安全。 二、工厂模式Java 中的 工厂模式（Factory Pattern）是一种创建型设计模式，旨在通过定义一个接口来创建对象，但让子类决定实例化哪个类。工厂模式可以帮助减少客户端与具体产品类之间的耦合，提高代码的灵活性和扩展性。 1、简单工厂模式 简单工厂模式通过一个工厂类来根据提供的信息生成不同类型的对象。它不需要暴露创建对象的具体逻辑，只暴露一个工厂方法供客户端调用。 结构： 工厂类：负责创建实例。 产品接口：定义产品的公共接口。 具体产品：实现产品接口的具体类。 12345678910111213141516171819202122232425262728293031323334353637383940414243// 产品接口public interface Product &#123; void use();&#125;// 具体产品Apublic class ConcreteProductA implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品A&quot;); &#125;&#125;// 具体产品Bpublic class ConcreteProductB implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品B&quot;); &#125;&#125;// 简单工厂类public class SimpleFactory &#123; public static Product createProduct(String type) &#123; if (&quot;A&quot;.equals(type)) &#123; return new ConcreteProductA(); &#125; else if (&quot;B&quot;.equals(type)) &#123; return new ConcreteProductB(); &#125; throw new IllegalArgumentException(&quot;未知产品类型&quot;); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Product productA = SimpleFactory.createProduct(&quot;A&quot;); productA.use(); // 输出: 使用产品A Product productB = SimpleFactory.createProduct(&quot;B&quot;); productB.use(); // 输出: 使用产品B &#125;&#125; 优缺点： 优点：客户端只需要知道工厂类和产品接口，无需关心具体实现。 缺点：工厂类一旦增加新的产品，需修改工厂类代码，违反开闭原则。 2、工厂方法模式 工厂方法模式通过在抽象类中定义一个工厂方法，让子类去实现这个方法，从而决定创建哪种产品。这种模式通过继承和多态来让子类决定创建的产品类型，避免了修改工厂类。 结构： 抽象工厂：声明工厂方法。 具体工厂：实现工厂方法，负责创建具体产品。 产品接口：定义产品的公共接口。 具体产品：实现产品接口的具体类. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 产品接口public interface Product &#123; void use();&#125;// 具体产品Apublic class ConcreteProductA implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品A&quot;); &#125;&#125;// 具体产品Bpublic class ConcreteProductB implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品B&quot;); &#125;&#125;// 抽象工厂public abstract class Creator &#123; public abstract Product factoryMethod();&#125;// 具体工厂Apublic class ConcreteCreatorA extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductA(); &#125;&#125;// 具体工厂Bpublic class ConcreteCreatorB extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductB(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Creator creatorA = new ConcreteCreatorA(); Product productA = creatorA.factoryMethod(); productA.use(); // 输出: 使用产品A Creator creatorB = new ConcreteCreatorB(); Product productB = creatorB.factoryMethod(); productB.use(); // 输出: 使用产品B &#125;&#125; 优缺点： 优点：遵循了开闭原则，可以通过扩展子类来增加新产品，不需要修改原有代码。 缺点：需要创建大量的具体工厂类，如果产品种类过多，工厂类会急剧增加。 3、抽象工厂模式 三、观察者模式四、装饰器模式五、责任链模式LinuxGit场景一、秒杀系统设计什么是秒杀 通俗一点讲就是网络商家为促销等目的组织的网上限时抢购活动 业务特点 高并发：秒杀的特点就是这样时间极短、 瞬间用户量大。 库存量少：一般秒杀活动商品量很少，这就导致了只有极少量用户能成功购买到。 业务简单：流程比较简单，一般都是下订单、扣库存、支付订单 恶意请求，数据库压力大 解决方案 前端：页面资源静态化，按钮控制，使用答题校验码可以防止秒杀器的干扰，让更多用户有机会抢到 nginx：校验恶意请求，转发请求，负载均衡；动静分离，不走tomcat获取静态资源；gzip压缩，减少静态文件传输的体积，节省带宽，提高渲染速度 业务层：集群，多台机器处理，提高并发能力 redis：集群保证高可用，持久化数据；分布式锁（悲观锁）；缓存热点数据（库存） mq：削峰限流，MQ堆积订单，保护订单处理层的负载，Consumer根据自己的消费能力来取Task，实际上下游的压力就可控了。重点做好路由层和MQ的安全 数据库：读写分离，拆分事务提高并发度 秒杀系统设计小结 秒杀系统就是一个“三高”系统，即高并发、高性能和高可用的分布式系统 秒杀设计原则：前台请求尽量少，后台数据尽量少，调用链路尽量短，尽量不要有单点 秒杀高并发方法：访问拦截、分流、动静分离 秒杀数据方法：减库存策略、热点、异步、限流降级 访问拦截主要思路：通过CDN和缓存技术，尽量把访问拦截在离用户更近的层，尽可能地过滤掉无效请求。 分流主要思路：通过分布式集群技术，多台机器处理，提高并发能力。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"集合","slug":"八股/集合","date":"2024-11-24T09:11:53.000Z","updated":"2024-12-06T14:32:33.696Z","comments":true,"path":"2024/11/24/八股/集合/","permalink":"http://example.com/2024/11/24/%E5%85%AB%E8%82%A1/%E9%9B%86%E5%90%88/","excerpt":"","text":"1.1、List1.1.1、为什么数组索引从0开始呢？从1开始不行吗？ key：寻址公式，数组会根据索引获取元素，计算公式：数组首地址+索引*存储数据类型的大小 如果从1开始，就要多执行一次减法操作，对于CPU来说要多执行一次指令，降低性能 1.1.2、ArrayList和Array的区别？1.1.3、ArrayList可以添加null值吗？1.1.4、ArrayList和LinkedList的区别？ 底层数据结构：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 多数情况下，ArrayList更利于查找，LinkedList更利于增删 占用空间：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。 是否支持随机访问 1.1.5、ArrayList的扩容机制了解吗？所以在插入时候，会先检查是否需要扩容，如果当前容量+1超过数组长度，就会进行扩容。 ArrayList的扩容是创建一个1.5倍的新数组，然后把原数组的值拷贝过去。 在扩容和复制的过程中，如果检测到有其他线程正在修改ArrayList，可能会抛出ConcurrentModificationException。 1.1.5、ArrayList的底层实现原理？主要前3点 ArrayList底层是用动态的数组实现的 ArrayList初始容量为0，当第一次添加数据的时候才会初始化容量为10 ArrayList在进行扩容的时候是原来容量的1.5倍，每次扩容都需要拷贝数组 ArrayList在添加数据的时候 确保数组已使用长度(size）加1之后足够存下一个数据 计算数组的容量，如果当前数组已使用长度+1后的大于当前的数组长度，则调用grow方法扩容（原来的1.5倍) 确保新增的数据有地方存储之后，则将新元素添加到位于size的位置上。 返回添加成功布尔值。 1.1.6、 为什么ArrayList不是线程安全的，具体来说是哪里不安全？在高并发添加数据下，ArrayList会暴露三个问题; 部分值为null（我们并没有add null进去） 索引越界异常 size与我们add的数量不符 如何产生的： 部分值为nul1:当线程1走到了扩容那里发现当前size是9，而数组容量是10，所以不用扩容，这时候cpu让出执行权，线程2也进来了，发现size是9，而数组容量是10，所以不用扩容，这时候线程1继续执行，将数组下标索引为9的位置set值了，还没有来得及执行size++，这时候线程2也来执行了，又把数组下标索引为9的位置set了一遍，这时候两个先后进行size++，导致下标索引10的地方就为null了。 索引越界异常:线程1走到扩容那里发现当前size是9，数组容量是10不用扩容，cpu让出执行权，线程2也发现不用扩容，这时候数组的容量就是10，而线程1set完之后size++，这时候线程2再进来size就是10，数组的大小只有10，而你要设置下标索引为10的就会越界(数组的下标索引从0开始); size与我们add的数量不符:这个基本上每次都会发生，这个理解起来也很简单，因为size++本身就不是原子操作，可以分为三步:获取size的值，将size的值加1，将新的size值覆盖掉原来的，线程1和线程2拿到一样的size值加完了同时覆盖，就会导致一次没有加上，所以肯定不会与我们add的数量保持一致的; 1.1.7、ArrayList list&#x3D;new ArrayList(10)中的list扩容几次？该语句只是声明和实例了一个ArrayList，指定了容量为10，未扩容 1.1.8、CopyOnWriteArrayList了解多少？CopyOnWriteArrayList就是线程安全版本的ArrayList。 它的名字叫CopyOnWrite——写时复制，已经明示了它的原理。 CopyOnWriteArrayList采用了一种读写分离的并发策略。CopyOnWriteArrayList容器允许并发读，读操作是无锁的，性能较高。至于写操作，比如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。 1.1.8、数组和Lis之间的转换 数组转List ，使用JDK中java.util.Arrays工具类的asList方法List转数组， 使用List的toArray方法。无参toArray方法返回Object数组，传入初始化长度的数组对象，返回该对象数组 1.2、Set1.2.1、List和Set的区别？ List：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。 List 支持for循环，也就是通过下标来遍历，也可以用迭代器 Set：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性 。set只能用迭代器，因为他无序，无法用下标来取得想要的值。 3、Map3.1、HashMap怎么处理Hash冲突 链接法：使用链表或其他数据结构来存储冲突的键值对，将它们链接在同一个哈希桶中。 开放寻址法:在哈希表中找到另一个可用的位置来存储冲突的键值对，而不是存储在链表中。常见的开放寻址方法包括线性探测、二次探测和双重散列。 再哈希法(Rehashing):当发生冲突时，使用另一个哈希函数再次计算键的哈希值，直到找到一个空位来存储键值对。 1.3.1、说一下HashMap的实现原理 JDK1.8及以后底层结构为: 数组+链表+红黑树，之前只有数组加链表 当我们往Hashmap中添加（put）元素时，利用key的hashCode计算出当前对象的元素在数组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。(1)如果key相同，则覆盖原始值；(2)如果key不同（出现冲突），则将当前的放入链表或红黑树中 jdk1.8。当链表长度大于阈值(默认为8) 时并且数组长度达到64时，将链表转化为红黑树，以减少搜索时间，从 O(n)降低到 O(log n)。扩容resize()时，红黑树拆分成的树的结点数小于等于临界值6个，则退化成链表 1.3.2、HashMap的put方法的具体流程？ 根据key值计算哈希值（调用了hash方法），得到插入的数组索引 判断tab是否为空或者长度为0，如果是则进行扩容操作。 否则就判断该索引处是否为空，如果为空就直接插入 如果不为空 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value 判断table[i]是否为treeNode，也就是table[i]是否是红黑树，如果是红黑树，则直接在树中插入键值对遍历table[i]]， 否则就遍历链表，如果key存在就直接覆盖，否则就在链表尾部插入，再判断链表长度是否大于8，如果大于8就转为红黑树 插入成功后，判断实际存在的键值对数量size是否超过了最大容量threshold(数组长度*0.75【负载因子】)，如果超过，进行扩容 1.3.3、讲一讲HashMap的扩容机制 第1步是对哈希表长度的扩展（2倍） 第2步是将旧哈希表中的数据放到新的哈希表中。 因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置 ，要么是在原位置再移动2次幂的位置。 我们在扩充HashMap的时候，不需要重新计算hash， 只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变， 是1的话索引变成“原索引+旧容量（oldCapacity）” 。既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，可以均匀的把之前的冲突的节点分散到新的bucket了 1.3.4、HashMap的寻址算法这个问题和3.5，3.6结合着理解 传入key的哈希码是经过两次哈希计算的（hash算法里面又有一个hashCode（））,目的是减少碰撞 (n - 1) &amp; hash 确定元素存放在哪个桶（数组节点）中，也就是得到索引，n是数组大小 12345static final int hash(Object key) &#123; int h; // 传入key的hashcode的高16位和低16位进行异或操作 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 1.3.5、HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？ 哈希值与数组大小范围不匹配；hashCode()方法返回的是int整数类型，范围远超HashMap的容量范围 解决方法：3.4中的2和3 1.3.6、HashMap 的长度（容量capacity）为什么是2的幂次方？ 不用重新计算hash，元素的位置要么是在原位置 ，要么是在原位置再移动2次幂的位置。 只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变， 是1的话索引变成“原索引+旧容量（oldCapacity）”，省去了重新计算hash值的时间 由于新增的1bit是0还是1可以认为是随机的，可以均匀的把之前的冲突的节点分散到新的bucket了 1.3.7、HashMap在1.7的多线程死循环问题（HashMap在多线程下可能会出现的问题？ 问题：在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。 解决：为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 HashMap，因为多线程下使用 HashMap 还是会存在数据覆盖的问题。并发环境下，推荐使用concurrentHashMap 多线程同时执行 put 操作，如果计算出来的索引位置是相同的 ，那会造成前一个 key 被后一个 key 覆盖， 从而导致元素的丢失。此问题在JDK 1.7和 JDK 1.8 中都存在。 1.3.8、ConcurrentHashMap的底层原理 jdk1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap采用Segment + HashEntry的方式进行实现 ，一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，Segment 包含HashEntry 数组，每个 HashEntry 是一个链表结构的元素， 该类包含两个静态内部类 HashEntry 和 Segment ；前者用来封装映射表的键值对，后者用来充当锁的角色； Segment（分段锁） 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。 jdk1.8 jdk1.7因为底层采用的是数组加链表的结构，在在数据比较多的情况下访问是很慢的，因为要遍历整个链表。而 JDK 1.8 则使用了数组 + 链表&#x2F;红黑树的方式优化。JDK 1.8 ConcurrentHashMap 主要通过 volatile + CAS 或者 synchronized 来实现的线程安全的。 添加元素时首先会判断容器是否为空： 如果为空则使用 volatile 加 CAS 来初始化 如果容器不为空，则根据存储的元素计算该位置是否为空。 如果根据存储的元素计算结果为空，则利用 CAS 设置该节点； 如果根据存储的元素计算结果不为空，则使用 synchronized ，然后，遍历桶中的数据，并替换或新增节点到桶中， 最后再判断是否需要转为红黑树 ConcurrentHashMap通过对头结点加锁来保证线程安全的 ，发生冲突和加锁的频率降低了，并发操作的性能就提高了。 而且红黑树的结构在数据量比较大的时候，查询性能也会比之前有很大的提升 1.3.9、分段锁怎么加锁的在 ConcurrentHashMap 中，对于插入、更新、删除等操作，需要先定位到具体的 Segment，然后再在该Segment 上加锁，而不是像传统的 HashMap 一样对整个数据结构加锁。这样可以使得不同 Segment 之间的操作并行进行，提高了并发性能。 1.3.10、ConcurrentHashMap用了悲观锁还是乐观锁?ConcurrentHashMap 的实现原理悲观锁和乐观锁都有用到。添加元素时首先会判断容器是否为空 如果为空则使用 volatile 加 CAS （乐观锁） 来初始化。 如果容器不为空，则根据存储的元素计算该位置是否为空。 如果根据存储的元素计算结果为空，则利用 CAS（乐观锁） 设置该节点； 如果根据存储的元素计算结果不为空，则使用 synchronized（悲观锁） ，然后，遍历桶中的数据， 并替换或新增节点到桶中， 最后再判断是否需要转为红黑树 JDK 7 中的 ConcurrentHashMap 的实现原理？ ①、put 流程 ConcurrentHashMap 的 put 流程和 HashMap 非常类似，只不过是先定位到具体的 Segment，然后通过 ReentrantLock 去操作而已。 计算 hash，定位到 segment，segment 如果是空就先初始化； 使用 ReentrantLock 加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定能获取到锁； 遍历 HashEntry，key 相同就直接替换，不存在就插入。 释放锁。 ②、get 流程 get 也很简单，通过 hash(key) 定位到 segment，再遍历链表定位到具体的元素上，需要注意的是 value 是 volatile 的，所以 get 是不需要加锁的。 JDK 8 中的 ConcurrentHashMap 的实现原理？ JDK 8 中的 ConcurrentHashMap 取消了 Segment 分段锁，采用 CAS + synchronized 来保证并发安全性，整个容器只分为一个 Segment，即 table 数组。 Node 和 JDK 7 一样，使用 volatile 关键字，保证多线程操作时，变量的可见性。 ConcurrentHashMap 实现线程安全的关键点在于 put 流程。 ①、put 流程 第一步，计算 hash，遍历 node 数组，如果 node 是空的话，就通过 CAS+自旋的方式初始化。 第二步，如果当前数组位置是空，直接通过 CAS 自旋写入数据。 第三步，如果 hash==MOVED，说明需要扩容。 第四步，如果都不满足，就使用 synchronized 写入数据，和 HashMap 一样，key 的 hash 一样就覆盖，反之使用拉链法解决哈希冲突，当链表长度超过 8 就转换成红黑树。 1.3.11、HashMap 和 ConcurrentHashMap 的区别 线程安全：ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护 ，而HashMap没有锁机制，不是线程安全的 HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。 1.3.12、HashTable的底层原理Hashtable的底层数据结构是数组加上链表 HashTable是线程安全的，它采用的是全表锁。它使用 synchronized 来保证线程安全，效率非常低下。 1.3.13、ConcurrentHashMap 和 Hashtable 的区别？ 底层数据结构 jdk7之前的ConcurrentHashMap底层采用的是分段的数组+链表实现，jdk8之后采用的是数组+链表&#x2F;红黑树; HashTable采用的是数组+链表，数组是主体，链表是解决hash冲突存在的。 实现线程安全的方式 idk8以前，ConcurrentHashMap采用分段锁，对整个数组进行了分段分割，每一把锁只锁容器里的一部分数据，多线程访问不同数据段里的数据，就不会存在锁竞争，提高了并发访问;idk8以后，直接采用数组+链表&#x2F;红黑树，并发控制使用CAS和synchronized操作，更加提高了速度。 HashTable:使用 synchronized 来保证线程安全，效率非常低下 ，当一个线程访问同步方法另一个线程也访问的时候，就会陷入阻塞或者轮询的状态。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"http://example.com/tags/JavaSE/"}]},{"title":"中间件","slug":"八股/中间件","date":"2024-11-24T05:10:08.000Z","updated":"2024-12-12T09:23:57.588Z","comments":true,"path":"2024/11/24/八股/中间件/","permalink":"http://example.com/2024/11/24/%E5%85%AB%E8%82%A1/%E4%B8%AD%E9%97%B4%E4%BB%B6/","excerpt":"","text":"1、MQ的作用 解耦：生产者将消息放入队列，消费者从队列中取出消息，这样一来，生产者和消费者之间就不需要直接通信，生产者只管生产消息，消费者只管消费消息，这样就实现了解耦。 异步：系统可以将那些耗时的任务放在消息队列中异步处理，从而快速响应用户的请求。比如说，用户下单后，系统可以先返回一个下单成功的消息，然后将订单信息放入消息队列中，后台系统再去处理订单信息。 削峰：削峰填谷是一种常见的技术手段，用于应对系统高并发请求的瞬时流量高峰，通过消息队列，可以将瞬时的高峰流量转化为持续的低流量，从而保护系统不会因为瞬时的高流量而崩溃。 2、几种MQ的对比ActiveMQ 的社区算是比较成熟，但是较目前来说，ActiveMQ 的性能比较差，而且版本迭代很慢，不推荐使用，已经被淘汰了。 RabbitMQ 在吞吐量方面虽然稍逊于 Kafka、RocketMQ 和 Pulsar，但是由于它基于 Erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 Erlang 开发，所以国内很少有公司有实力做 Erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这几种消息队列中，RabbitMQ 或许是你的首选。 RocketMQ 和 Pulsar 支持强一致性，对消息一致性要求比较高的场景可以使用。 RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。 Kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 Kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。Kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka(大吞吐量才会去使用) 追求消息低延迟：RabbitMQ、Kafka 3、MQ的工作模式 简单模式：一对一模式，一个生产者、一个消费者，一个队列，生产者发送消息，消费者消费消息 工作队列模式：一对多模式，一个生产者，多个消费者，一个队列，每个消费者从队列中获取唯一的消息。适用于资源密集型任务， 单个消费者处理不过来，需要多个消费者进行处理的场景。 发布订阅模式： 多了一个 Exchange 角色，而且过程略有变化： 生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） 消费者，消息的接收者，会一直等待消息到来 消息队列，接收消息、缓存消息 交换机一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange与消息队列的绑定模式： Fanout（广播模式）：将消息交给所有绑定到交换机的队列，当发送一条消息到fanout交换器上时，它会把消息投放到所有附加在此交换器上的队列 Direct（路由模式）：消息发送者通过指定不同的路由键将消息发送到交换机，交换机根据路由键将消息发送到对应的队列。 Topic（主题模式）：消息发送者通过指定主题(可以使用通配符)将消息发送到交换机，交换机根据主题将消息发送到对应的队列。 4、AMQP协议模型 Broker：代表着一个中间件应用，负责接收消息生产者的消息，然后将消息发送至消息接受者或者其他的broker。 Channel：代表着producer、consumer和broker之间的逻辑连接，一个Connection可以包含多个Channel。Channel使得基同一连接的不同进程之间与broker之间的交互相互隔离，不干扰。而不需要重新建立连接，channel在发生协议错误的时候会被关闭。 Exchange：这是所有被发送的消息首先到达的目的地，Exchange负责根据路由规则将消息路由到不同的目的地。路由规则包括下面几种：direct（point-to-point）、topic（publish-subscribe）和fanout（multicast）。 Queue：这是消息到达的最终目的地，到达queue的消息是已经准备好被消费的消息，一个消息可以被exchange copy发送至多个queue。 Binding：这是queue和exchange之间的虚拟连接，使得消息从哪个exchange路由到Queue。routing key可以通过binding和exchange routing规则关联。 5、延迟队列？rabbitmq怎么实现延迟队列？延迟队列指的是存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。 RabbitMQ 本身是没有延迟队列的，要实现延迟消息，一般有两种方式： 通过 RabbitMQ 本身队列的特性来实现，需要使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。 在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang&#x2F;OPT 18.0 及以上。 也就是说，AMQP 协议以及 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过 TTL 和 DLX 模拟出延迟队列的功能。 6、死信队列消息在一个队列中变成死信 (dead message) 之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX（Dead-Letter-Exchange），绑定 DLX 的队列就称之为死信队列。死信队列是用来处理无法被正常消费或处理的消息的特殊队列。 导致的死信的几种原因： 1.消息被拒绝(Rejected):当消费者拒绝消费消息或者消息超过消费者的最大重试次数时，消息会被发送到死信队列。2.消息过期(Expired):如果消息在一定时间内没有被消费者处理，即超过了消息的过期时间，该消息也会被发送到死信队列。3.队列达到最大长度(Queue Length Limit):当队列达到了定义的最大长度限制，新的消息无法进入队列，会将旧的消息发送到死信队列。 7、如何保证消息的可靠性（防止数据丢失）？丢失的情况：消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。 生产者到 RabbitMQ：事务机制和 Confirm 机制，推荐：可以通过生产者启用Confirm 机制，在消息成功发送给RabbitMQ后接收确认回执，确保消息已被正确接收。 注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。 RabbitMQ 自身：持久化、集群、普通模式、镜像模式。 持久化： Exchange 设置为持久化 。 Queue 设置为持久化 。 消息在发送时设置为持久化模式，即 deliveryMode=2 RabbitMQ 到消费者：手动消息确认：消费者在处理完消息后，需要显式地发送一个 ACK 确认信号给 RabbitMQ，RabbitMQ 才会从内存（和磁盘，如果是持久化消息的话）中移除消息。这样可以确保消息在处理过程中不会因为消费者进程挂掉而丢失 8、如何避免消息堆积？ 优化消费者代码，提高消费能力。减少消费时间 消息TTL：可以为消息设置生存时间（TTL），即消息在队列中停留的最大时间。超过TTL的消息将被自动丢弃或死信 队列长度限制：可以通过策略或队列参数设置队列的最大长度。当队列达到最大长度时，RabbitMQ会根据策略丢弃或死信队列的前端消息 增加消费者数量（Horizontal Scaling）：当消费者处理速度跟不上生产者发送消息的速度时，可以通过增加更多的消费者实例来并行处理消息，从而提升总体处理能力 使用死信队列（Dead Letter Queue, DLQ）：对于无法立即处理或处理失败的消息，可以配置死信交换器和队列，当消息达到一定重试次数或者超过一定期限未被成功ACK时，消息将被转发到死信队列中，后续可以单独处理这部分消息，避免阻塞正常的消息流 9、如何防止消息重复消费（保证消费幂等性）?RabbitMQ消息重复消费问题通常是由以下原因导致的:1.生产者用于发送消息失败后的重试，导致又发送了一次重复的消息2.消费者应用程序在处理消息时发生了错误，导致消息确认(ack)没有发送给RabbitMQ，从而导致RabbitMQ将消息重新分发给其他消费者进行消费。3.网络问题或消费者应用程序重启时，RabbitMQ无法收到消息确认，也会导致消息重新分发。 为了解决消息重复消费问题(保证消费幂等性)，可以采取以下措施: 使用消息唯一ID（幂等性）：确保消息的处理是幂等的，即无论同一条消息被消费多少次，结果都是相同的。每个消息用一个唯一标识来区分，消费前先判断标识有没有被消费过，若已消费过，则直接ACK 消息确认:消费者应及时地发送消息确认(ack)给RabbitMQ，表示已经成功处理了消息。这样RabbitMQ就不会将消息重新分发给其他消费者。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}]},{"title":"实习日记","slug":"实习日记","date":"2024-11-06T12:32:56.000Z","updated":"2024-11-06T12:38:46.389Z","comments":true,"path":"2024/11/06/实习日记/","permalink":"http://example.com/2024/11/06/%E5%AE%9E%E4%B9%A0%E6%97%A5%E8%AE%B0/","excerpt":"","text":"今天2024-11-06是我实习的第四个星期，终于算是有点产出了😭😭😭😭激动的心，颤抖的手，吭吭哧哧终于给做出来了，虽然只是很简单的一个页面和查询接口，我记得研发云好像是10.29才登上去的，哎，之前连前端三件套都没系统学过的我，更别提vue了，现在快速用vue做出来界面，也慢慢熟悉了中间是怎么交互的，最难的环节感觉就是前后端联调了，主要还是前端vue不太熟悉 11.4：完成前端页面的修改美化，基本符合设计原型 11.5：想着怎么测试接口的，上午一直在搞swagger，发现直接前后端联调即可，下午就一直在搞，也没搞好 11.6：前后端联调失败，有很多小错误，比如自动装配的注解忘了加，下午联通了但查询不到数据，跟state这个字段有关好像，涉及到字符串查询的时候用单引号，总之感觉莫名其妙的错误但又莫名其妙的好了；然后又是时间的问题，Cause: java.lang.IllegalArgumentException: invalid comparison: java.util.Date and java.lang.String。发现mybatis的if对时间判断时只要判断null就行了，不用判断空。然后又发现后端查到的数据不能显示在前端的表格上，发现是表格的列名要和返回的数据VO字段对应。。","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"实习","slug":"实习","permalink":"http://example.com/tags/%E5%AE%9E%E4%B9%A0/"}]},{"title":"wireshark抓包学习","slug":"技术类/wireshark抓包学习","date":"2024-10-30T12:40:35.000Z","updated":"2024-10-30T13:13:26.804Z","comments":true,"path":"2024/10/30/技术类/wireshark抓包学习/","permalink":"http://example.com/2024/10/30/%E6%8A%80%E6%9C%AF%E7%B1%BB/wireshark%E6%8A%93%E5%8C%85%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"过滤规则按IP过滤 想看源ip为xx的包：ip.src == xx 想看目标ip为xx的包：ip.dst == xx 想看源或者目标ip为xx的包：ip.addr == xx 按MAC地址过滤 想看源mac为xx的包：eth.src == xx 想看目标mac为xx的包：eth.dst == xx 想看源或者目标mac为xx的包：eth.addr == xx 按端口过滤 想看源端口为4694的包：tcp.srcport == 4694 想看目标端口为4694的包：eth.dstport == 4694 过滤tcp端口为4694的包：tcp.port == 4694 按协议类型过滤 arp dhcp https 规则组会 and 想看dhcp包且只想看某台电脑的dhcp包 or ！非","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"OS","slug":"八股/OS","date":"2024-10-28T12:30:49.000Z","updated":"2025-01-20T08:30:01.280Z","comments":true,"path":"2024/10/28/八股/OS/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/OS/","excerpt":"","text":"一、进程管理1.进程1.1.进程的状态 **创建状态(new)**：进程正在被创建，尚未到就绪状态。 **就绪状态(ready)**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 **运行状态(running)**：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 **阻塞状态(waiting)**：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 **结束状态(terminated)**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行 1.2.什么是PCB？PCB（Process Control Block） 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB。 PCB 是进程存在的唯一标识 ，包含以下信息： 进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中， 以便进程重新执行时，能从断点处继续执行。 1.3.进程上下文切换上下文切换是操作系统在多任务处理环境中，将 CPU 从一个进程切换到另一个进程的过程。通过让多个进程共享 CPU 资源，使系统能够并发执行多个任务。 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源， 还包括了内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候， 我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中 1.4.进程间的通信方式 管道（匿名管道）：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 命名管道：允许无亲缘关系的进程通信，通过在文件系统中创建一个特殊类型的文件来实现。 缺点：管道的效率低，不适合进程间频繁地交换数据。 信号：用于通知接收进程某个事件已经发生； 消息队列：消息队列是保存在内核中的消息链表，按照消息的类型进行消息传递，具有较高的可靠性和稳定性。 缺点：消息体有一个最大长度的限制，不适合比较大的数据传输；存在用户态与内核态之间的数据拷贝开销。 共享内存：允许两个或多个进程共享一个给定的内存区，一个进程写⼊的东西，其他进程⻢上就能看到。 共享内存是最快的进程间通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。缺点：当多进程竞争同一个共享资源时，会造成数据错乱的问题。 信号量：它本质上是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。 用来控制对共享资源的访问数量。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 套接字socket：不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信， 可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式， 一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。 1.5.进程调度算法 1.先来先服务 从就绪队列中选择一个最先进入该队列的进程为之分配资源 然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。 当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 可能会导致较短的进程等待较长进程执行完成，从而产生“饥饿”现象 2.短作业优先 优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。 对长作业不利，很容易造成一种极端现象。 3.时间片轮转 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。 如果进程在时间片结束时还没有完成，它将被放回队列的末尾。 公平的 4.优先级调度 这种调度方式中，每个进程都被分配一个优先级。CPU 首先分配给优先级最高的进程。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 可能会导致低优先级的进程永远不会运行。 5.多级反馈队列 既能使高优先级的作业得到响应又能使短作业（进程）迅速完成 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程， 转而去运行优先级高的队列； 工作流程： 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定 的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较 高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完， 可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了， 所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 2.线程2.1.进程和线程的区别 进程：进程是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。 进程是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。 线程：线程是进程内的一个执行单元，线程共享进程的内存空间，包括堆和全局变量。线程之间通信更加高效，因为它们可以直接读写共享内存。 线程的上下文切换开销较小，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。 然而，由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。 协程：协程是一种用户态的轻量级线程，其调度完全由用户程序控制，而不需要内核的参与。协 程拥有自己的寄存器上下文和栈，但与其他协程共享堆内存。协程的切换开销非常小，因为只需要保存 和恢复协程的上下文，而无需进行内核级的上下文切换。这使得协程在处理大量并发任务时具有非常高 的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其编程模型更为复 杂。 2.2.线程间的通信方式（线程间的同步方式） 互斥锁：只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 读写锁：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。 读写锁的工作原理是：当「写锁」没有被线程持有时，多个线程 能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景， 所以多个线程同时持有读锁也不会破坏共享资源的数据。但是，一旦「写锁」被线程持有后，读线程的 获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。所以说，写锁是独占锁，因 为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线 程同时持有。知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 通常信号量表示资源的数量 对应的变量是一个整型（sem）变量。 还有两个原子操作的系统调用函数来控制信号量的。分别是：P 操作：将 sem 减 1，相减 后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem &lt;&#x3D; 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞； 2.3.线程上下文切换得看线程是不是属于同⼀个进程： 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样； 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 所以，线程的上下⽂切换相⽐进程，开销要⼩很多。 二、锁","categories":[],"tags":[]},{"title":"计算机网络","slug":"八股/计算机网络","date":"2024-10-28T12:30:41.000Z","updated":"2024-12-11T13:37:55.101Z","comments":true,"path":"2024/10/28/八股/计算机网络/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"计算机网路层次结构OSI参考模型 应用层，负责给应用程序提供统一的接口; 表示层，负责把数据转换成兼容另一个系统能识别的格式 会话层，负责建立、管理和终止表示层实体之间的通信会话， 传输层，负责端到端的数据传输 网络层，负责数据的路由、转发、分片; 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址; 物理层，负责在物理网络中传输数据帧; TCP&#x2F;IP模型 应用层 主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输 传输层 处理主机到主机的通信（TCP、UDP） 网络层 寻址和路由数据包(IP 协议)——（转发与路由 ） 链路层 通过网络的物理电线、电缆或无线信道移动比特 1、HTTPHTTP、HTTPS、CDN、DNS、FTP 都是应用层协议 1、键入网址到浏览器显示期间发生了什么？（重要 在浏览器中输入指定网页的 URL。 浏览器通过 DNS 协议，获取域名对应的 IP 地址。 浏览器根据 IP 地址和端口号，向目标服务器发起一个 TCP 连接请求。 浏览器在 TCP 连接上，向服务器发送一个 HTTP 请求报文，请求获取网页的内容。 服务器收到 HTTP 请求报文后，处理请求，并返回 HTTP 响应报文给浏览器。 浏览器收到 HTTP 响应报文后，解析响应体中的 HTML 代码，渲染网页的结构和样式，同时根据 HTML 中的其他资源的 URL（如图片、CSS、JS 等），再次发起 HTTP 请求，获取这些资源的内容，直到网页完全加载显示。 解析URL：确定要访问Web 服务器和文件名 DNS解析：查询服务器域名对应的 IP 地址（这里可以有个问题：域名解析的工作流程） 获取MAC地址：当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，（传输层TCP）因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。（网络层IP）网络层会将本机地址作为源地址，获取的IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相结合，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。 建立TCP连接：主机将使用目标IP地址和目标MAC地址发送一个TCP SYN包，请求建立一个TCP连接然后交给路由器转发，等路由器转到目标服务器后，服务器回复一个SYN-ACK包，确认连接请求。然后，主机发送一个ACK包，确认已收到服务器的确认，然后TCP连接建立完成。 HTTPS 的 TLS 四次握手:如果使用的是 HTTPS 协议，在通信前还存在 TLS 的四次握手。 发送HTTP请求:连接建立后，浏览器会向服务器发送HTTP请求。请求中包含了用户需要获取的资源的信息，例如网页的URL、请求方法(GET、POST等)等。 服务器处理请求并返回响应:服务器收到请求后，会根据请求的内容进行相应的处理。例如，如果是请求网页，服务器会读取相应的网页文件，并生成HTTP响应。 1、HTTP常用的状态码 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 400 Bad Request：发送的 HTTP 请求存在问题。比如请求参数不合法、请求方法错误。 404 Not Found：你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 [502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 504 Gateway Time-out:作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器收到 举一个例子，假设 nginx 是代理服务器，收到客户端的请求后，将请求转发到后端服务器(tomcat 等)。 当nginx收到了无效的响应时，就返回502。 当nginx超过自己配置的超时时间，还没有收到请求时，就返回504错误。 2、GET和POST（重要 语义（主要区别）：GET 通常用于获取或查询资源，而 POST 通常用于创建或修改资源。 幂等：GET 请求是幂等的，即多次重复执行不会改变资源的状态，而 POST 请求是不幂等的，即每次执行可能会产生不同的结果或影响资源的状态。 格式：GET 请求的参数通常放在 URL 中，形成查询字符串（querystring），而 POST 请求的参数通常放在请求体（body）中，可以有多种编码格式，如 application&#x2F;x-www-form-urlencoded、multipart&#x2F;form-data、application&#x2F;json 等。GET 请求的 URL 长度受到浏览器和服务器的限制，而 POST 请求的 body 大小则没有明确的限制。不过，实际上 GET 请求也可以用 body 传输数据，只是并不推荐这样做，因为这样可能会导致一些兼容性或者语义上的问题。 缓存：由于 GET 请求是幂等的，它可以被浏览器或其他中间节点（如代理、网关）缓存起来，以提高性能和效率。而 POST 请求则不适合被缓存，因为它可能有副作用，每次执行可能需要实时的响应。 安全性：GET 请求和 POST 请求如果使用 HTTP 协议的话，那都不安全，因为 HTTP 协议本身是明文传输的，必须使用 HTTPS 协议来加密传输数据。另外，GET 请求相比 POST 请求更容易泄露敏感数据，因为 GET 请求的参数通常放在 URL 中。 3、HTTP长连接HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。 由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。 这样实在太累人了，一次连接只能请求一次资源。能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接?当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP请求&#x2F;应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。 HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 4、HTTP默认端口http 是 80，https 默认是 443。 5、HTTP为什么不安全HTTP 由于是明文传输，所以安全上存在以下三个风险: 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，!比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL&#x2F;TLS 协议，可以很好的解决了上述的风险: 信息加密:交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制:无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书:证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。 6、HTTP和HTTPS的区别（重要区别主要有以下四点: HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。 端口号，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 HTTPS 协议需要向 CA(证书权威机构)申请数字证书，来保证服务器的身份是可信的。 7、HTTPS四次握手8、HTTPS如何防范中间人攻击9、HTTP1.1和2.0的区别11、cookie，session，token的区别常见的用户身份验证和状态管理工具，用于维持状态信息（比如登录状态 cookie 存储在客户端（浏览器） 登录成功后，服务器返回用户名给前端，前端把用户名保存到浏览器的cookie。这样后续浏览器再访问后端都会自动带上cookie，从而维持状态信息。 可能存在的问题： 用户可以自己修改cookie里面存储的用户名，不安全 cookie的大小有限制 还可能会被用户禁用cookie session 保存在服务端（通常配合cookie使用） 登录信息传到服务端之后，服务器会在session中存储当前登录信息，并在响应头中把这个唯一的sessionId返回给前端（用的set-cookie），前端收到set-cookie后就会把这个唯一的sessionId存到cookie中，以后的每次请求都会把这个cookie发给后端 可能存在的问题： 占用服务器资源 依然需要依赖cookie 跨域限制（集群模式下，前端的每次请求通过负载均衡可能会发到不同的服务器上，比如第一次发到A服务器上登录成功后，第二次发到B服务器上会判定你未登录） token Token 是一种授权凭证，通常由服务器生成，用于客户端在后续请求中标识身份和权限。 登录成功后，后端生成一个jwt令牌，并在响应头中包含token（jwt）。前端后续访问后端，在请求头中设置属性Authorization值为token，后端收到后解密token，检查signature后放行。 2、DNS1、作用DNS（Domain Name System）域名管理系统，是当用户使用浏览器访问网址之后，使用的第一个重要协议。DNS 要解决的是域名和 IP 地址的映射问题。 DNS扮演着重要的角色，使得人们可以通过易记的域名访问互联网资源，而无需记住复杂的IP地址。 在一台电脑上，可能存在浏览器 DNS 缓存，操作系统 DNS 缓存，路由器 DNS 缓存。如果以上缓存都查询不到，那么 DNS 就闪亮登场了。 DNS默认端口号：53 2、域名解析的流程 客户端先访问本地DNS服务器（假如网址是www.server.com 没找到就（由本地DNS服务器）访问根DNS服务器（.），根DNS返回给本地DNS服务器要找的网址的顶级域DNS服务器（com) （本地DNS服务器）访问顶级域服务器（com），顶级域服务器返回给本地DNS服务器要找的网址的权威DNS服务器（server.com） （本地DNS服务器）访问权威DNS服务器（server.com），权威DNS服务器返回给本地DNS服务器要找IP地址 是不是每次解析域名都要经过那么多的步骤呢？ （了解，反正就是知道会先看缓存有没有就行 浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地DNS 服务器」。 3、TCP与UDP1、TCP和UDP的区别 连接：TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接，即刻传输数据。 服务对象：TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 可靠性：TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议 拥塞控制、流量控制：TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，UDP是尽最大努力交付 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 传输方式：TCP 面向字节流传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 2、TCP三次握手四次挥手 第三次握手是可以携带数据的（如果携带数据就消耗一个序号，不携带的话就不消耗），前两次握手是不可以携带数据的 为什么是三次握手？不是两次、四次？ 三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销， 能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。 不使用「两次握手」和「四次握手」的原因： 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费。（湖科大：防止已经失效的连接请求又传送到服务器，因而导致错误 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 6.3.2、为什么四次挥手之后要等2MSL? 被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文 ，而主动关闭方进入了关闭状态，就会导致被动关闭方无法进入关闭状态 - 6.5、GET和POST的区别最简回答:GET用于从服务器获取数据，将数据附加在URL上发送，对数据长度有限制;POST用于向服务器提交数据，将数据放在请求体中发送，数据长度没有限制。 6.6、HTTP和HTTPS的区别6.7、常见的HTTP响应状态码 6.8、HTTPS怎么加密的1、cookie、session、token的区别","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"JVM","slug":"八股/JVM","date":"2024-10-28T12:29:13.000Z","updated":"2024-12-16T03:13:04.029Z","comments":true,"path":"2024/10/28/八股/JVM/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/JVM/","excerpt":"","text":"1、引言1.1、JVM的特性最重要的特性还是跨平台，以下是其它特性 ①、垃圾回收：JVM 可以自动管理内存，通过垃圾回收机制（Garbage Collection）释放不再使用的对象所占用的内存。 ②、JIT：JVM 包含一个即时编译器（JIT Compiler），它在运行时将热点代码缓存到 codeCache 中，下次执行的时候不用再一行一行解释，而是直接执行缓存后的机器码，执行效率会提高很多。 ③、多语言支持：任何可以通过 Java 编译的语言，比如说 Groovy、Kotlin、Scala 等，都可以在 JVM 上运行。 2、内存管理2.1、JVM的内存区域JVM 的内存区域，有时叫 JVM 的内存结构，有时也叫 JVM 运行时数据区 主要包括 程序计数器（Program Counter Register） Java 虚拟机栈（Java Virtual Machine Stacks） 本地方法栈（Native Method Stack） 堆（Heap） 方法区（Method Area）其中 线程私有的：程序计数器，虚拟机栈，本地方法栈 线程共享的：堆，方法区，直接内存 (也即本地内存) 下面依次介绍这些区域： 程序计数器 程序计数器（Program Counter Register）也被称为 PC 寄存器，是一块较小的内存空间。 线程私有的，每个线程一份，内部保存的字节码的行号。用于记录正在执行的字节码指令的地址。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 从上面的介绍中我们知道了程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 Java堆 堆（heap）是 JVM 中最大的一块内存区域，被所有线程共享，在 JVM 启动时创建，主要用来存储对象的。 从内存回收的角度来看，由于垃圾收集器大部分都是基于分代收集理论设计的，所以堆也会被划分为新生代、老年代、Eden空间、From Survivor空间、To Survivor空间等。 简单介绍一下JIT和逃逸分析： 常见的编译型语言如 C++，通常会把代码直接编译成 CPU 所能理解的机器码来运行。而 Java 为了实现“一次编译，处处运行”的特性，把编译的过程分成两部分，首先它会先由 javac 编译成通用的中间形式——字节码，然后再由解释器逐条将字节码解释为机器码来执行。所以在性能上，Java 可能会干不过 C++ 这类编译型语言。 为了优化 Java 的性能 ，JVM 在解释器之外引入了 JIT 编译器：当程序运行时，解释器首先发挥作用，代码可以直接执行。随着时间推移，即时编译器逐渐发挥作用，把越来越多的代码编译优化成本地代码，来获取更高的执行效率。解释器这时可以作为编译运行的降级手段，在一些不可靠的编译优化出现问题时，再切换回解释执行，保证程序可以正常运行。 逃逸分析（Escape Analysis）是一种编译器优化技术，用于判断对象的作用域和生命周期。如果编译器确定一个对象不会逃逸出方法或线程的范围，它可以选择在栈上分配这个对象，而不是在堆上。这样做可以减少垃圾回收的压力，并提高性能。 堆最容易出现OOM问题： OutOfMemoryError: GC Overhead Limit Exceeded：当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生该错误。 java.lang.OutOfMemoryError: Java heap space：假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发该错误。和本机的物理内存无关，和我们配置的虚拟机内存大小有关！ 虚拟机栈 Java 虚拟机栈（JVM 栈）中是一个个栈帧，每个栈帧对应一个被调用的方法。当线程执行一个方法时，会创建一个对应的栈帧，并将栈帧压入栈中。当方法执行完毕后，将栈帧从栈中移除。 栈帧：用于存储局部变量表、操作数栈、动态链接、方法出口等信息 垃圾回收是否涉及栈内存? 垃圾回收主要指就是堆内存，当栈帧弹栈以后，内存就会释放 栈内存分配越大越好吗?未必，默认的栈内存通常为1024k，栈过大会导致线程数变少 方法内的局部变量是否线程安全?如果方法内局部变量没有逃离方法的作用范围，它是线程安全的 如果是局部变量引用了对象（传入有参数），并逃离方法的作用范围（有返回值），需要考虑线程安全 什么情况下会导致栈内存溢出? 栈帧过多导致栈内存溢出，典型问题:递归调用栈帧过大导致栈内存溢出 堆栈的区别是什么? 堆属于线程共享的内存区域，几乎所有的对象都在堆上分配，生命周期不由单个方法调用所决定，可以在方法调用结束后继续存在，直到不再被任何变量引用，然后被垃圾收集器回收。 栈属于线程私有的内存区域，主要存储局部变量、方法参数、对象引用等，通常随着方法调用的结束而自动释放，不需要垃圾收集器处理。 方法区 方法区并不真实存在，属于 Java 虚拟机规范中的一个逻辑概念，用于存储已被 JVM 加载的类信息、常量、静态变量、即时编译器编译后的代码缓存等。 在 HotSpot 虚拟机中，方法区的实现称为永久代（PermGen），但在 Java 8 及之后的版本中，已经被元空间（Metaspace）所替代。 永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。 每个JVM 只有一个方法区，它是一个共享的资源。 本地方法栈 与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； 在本地方法栈中，主要存放了 native 方法的局部变量、动态链接和方法出口等信息。当一个 Java 程序调用一个 native 方法时，JVM 会切换到本地方法栈来执行这个方法。 直接内存（不属于JVM的内存结构 操作系统划分的一块用于NIO（new io）的数据缓冲区，可以提高读写性能，不属于JVM的内存结构，不受JVM内存回收管理 2.2、JDK1.6、1.7、1.8内存区域的变化主要体现在方法区的实现： JDK1.6 使用永久代实现方法区： JDK1.7 时发生了一些变化，将字符串常量池、静态变量，存放在堆上 在 JDK1.8 时彻底干掉了永久代，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。 6.2.3、对象创建的过程 类加载检查：虚拟机遇到一条 new 指令时， 首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用， 并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。 如果没有，那必须先执行相应的类加载过程。 分配内存：在类加载检查通过后，接下来虚拟机将为新生对象分配内存。 对象所需的内存大小在类加载完成后便可确定， ，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。 初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用， 程序能访问到这些字段的数据类型所对应的零值。 进行必要设置，比如对象头：初始化零值完成之后，虚拟机要对对象进行必要的设置， 例如这个对象是哪个类的实例、如何才能找到类的元数据信息、 对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行 init 方法：在上面工作都完成之后，从虚拟机的视角来看， 一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始——构造函数， 即class文件中的方法还没有执行，所有的字段都还为零， 对象需要的其他资源和状态信息还没有按照预定的意图构造好。 所以一般来说，执行 new 指令之后会接着执行方法， 把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全被构造出来。 6.2.4、什么是指针碰撞？空闲列表？类加载完成后，接着会在Java堆中划分一块内存分配给对象。内存分配根据Java堆是否规整，有两种方式： 指针碰撞：假设堆内存是一个连续的空间，分为两个部分，一部分是已经被使用的内存，另一部分是未被使用的内存。 在分配内存时，Java 虚拟机维护一个指针，指向下一个可用的内存地址，每次分配内存时，只需要将指针向后移动（碰撞）一段距离，然后将这段内存分配给对象实例即可。 空闲列表：JVM 维护一个列表，记录堆中所有未占用的内存块，每个空间块都记录了大小和地址信息。 当有新的对象请求内存时，JVM 会遍历空闲列表，寻找足够大的空间来存放新对象。 分配后，如果选中的空闲块未被完全利用，剩余的部分会作为一个新的空闲块加入到空闲列表中。 选择哪种分配方式是由 Java 堆是否规整来决定的，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。、 指针碰撞适用于管理简单、碎片化较少的内存区域（如年轻代），而空闲列表适用于内存碎片化较严重或对象大小差异较大的场景（如老年代）。 6.2.5、JVM 里 new 对象时，堆会发生抢占吗？JVM 是怎么设计来保证线程安全的？会，对象的创建在虚拟机中是一个非常频繁的行为，哪怕只是修改一个指针所指向的位置，在并发情况下也是不安全的，可能出现正在给对象 A 分配内存，指针还没来得及修改，对象 B 又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案： 对分配内存空间的动作进行同步处理（采用 CAS + 失败重试来保障更新操作的原子性）； 每个线程在 Java 堆中预先分配一小块内存，也就是本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），要分配内存的线程，先在本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。 6.2.6、内存溢出和内存泄露内存溢出（Out of Memory，俗称 OOM）和内存泄漏（Memory Leak）是两个不同的概念，但它们都与内存管理有关。 ①、内存溢出：是指当程序请求分配内存时，由于没有足够的内存空间满足其需求，从而触发的错误。在 Java 中，这种情况会抛出 OutOfMemoryError。 内存溢出可能是由于内存泄漏导致的，也可能是因为程序一次性尝试分配大量内存，内存直接就干崩溃了导致的。 ②、内存泄漏：是指程序在使用完内存后，未能释放已分配的内存空间，导致这部分内存无法再被使用。随着时间的推移，内存泄漏会导致可用内存逐渐减少，最终可能导致内存溢出。 在 Java 中，内存泄漏通常发生在长期存活的对象持有短期存活对象的引用，而长期存活的对象又没有及时释放对短期存活对象的引用，从而导致短期存活对象无法被回收。 用一个比较有味道的比喻来形容就是，内存溢出是排队去蹲坑，发现没坑了；内存泄漏，就是有人占着茅坑不拉屎，占着茅坑不拉屎的多了可能会导致坑位不够用。 6.2.7、对象的几种引用四种，分别是强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）。 强引用是 Java 中最常见的引用类型。使用 new 关键字赋值的引用就是强引用，发生 gc 的时候不会被回收。 软引用是一种相对较弱的引用类型，可以通过 SoftReference 类实现。 有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用可以通过 WeakReference 类实现。有用但不是必须的对象，在下一次GC时会被回收。 虚引用可以通过 PhantomReference 类实现。虚引用对象在任何时候都可能被回收。主要用于跟踪对象被垃圾回收的状态，可以用于管理直接内存。 虚引用的用途是在 gc 时返回一个通知。 6.2.8、Java 堆的内存分区了解吗？ Java 堆被划分为新生代（Young Generation）和老年代（Old Generation）两个区域。 新生代又被划分为 Eden 空间和两个 Survivor 空间（From 和 To）。 Eden 空间：大多数新创建的对象会被分配到 Eden 空间中。当 Eden 区填满时，会触发一次轻量级的垃圾回收（Minor GC），清除不再使用的对象。 Survivor 空间：每次 Minor GC 后，仍然存活的对象会从 Eden 区或 From 区复制到 To 区。From 和 To 区交替使用。 对象在新生代中经历多次 GC 后，如果仍然存活，会被移动到老年代。 6.2.9、新生代的区域划分？ 新生代的垃圾收集主要采用标记-复制算法，因为新生代的存活对象比较少，每次复制少量的存活对象效率比较高。 基于这种算法，虚拟机将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次分配内存只使用 Eden 和其中一块 Survivor。发生垃圾收集时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后直接清理掉 Eden 和已用过的那块 Survivor 空间。默认 Eden 和 Survivor 的大小比例是 8∶1。 6.2.9、对象什么时候进入老年代？对象通常会先在年轻代中分配，然后随着时间的推移和垃圾收集的处理，某些对象会进入到老年代中。 ①、长期存活的对象将进入老年代 对象在年轻代中存活足够长的时间（即经过足够多的垃圾回收周期）后，会晋升到老年代。 每次 GC 未被回收的对象，其年龄会增加。当对象的年龄超过一个特定阈值（默认通常是 15），它就会被移动到老年代。这个年龄阈值可以通过 JVM 参数-XX:MaxTenuringThreshold来设置。 ②、大对象直接进入老年代 为了避免在年轻代中频繁复制大对象，JVM 提供了一种策略，允许大对象直接在老年代中分配。 这些是所谓的“大对象”，其大小超过了预设的阈值（由 JVM 参数-XX:PretenureSizeThreshold控制）。直接在老年代分配可以减少在年轻代和老年代之间的数据复制。 ③、动态对象年龄判定 除了固定的年龄阈值，还会根据各个年龄段对象的存活大小和内存空间等因素动态调整对象的晋升策略。 比如说，在 Survivor 空间中相同年龄的所有对象大小总和大于 Survivor 空间的一半，那么年龄大于或等于该年龄的对象就可以直接进入老年代。 2.2、类加载器2.2.1、什么是类加载器，类加载器有哪些?类加载器的主要作用就是加载 Java 类的字节码（ .class 文件）到 JVM 中 启动类加载器(Bootstrap ClassLoader)：用来加载java核心类库，无法被java程序直接引用。 扩展类加载器(extensions class loader)：它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。 系统类加载器（system class loader）：负责加载用户类路径（ClassPath）上的指定类库 ，是我们平时编写Java程序时默认使用的类加载器。 它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 用户自定义类加载器：开发者可以根据需求定制类的加载方式 ，通过继承 java.lang.ClassLoader类的方式实现。 2.2.2、什么是双亲委派机制？为什么采用双亲委派机制双亲委派机制是指类加载器在加载类时，首先不会自己去尝试加载这个类 ，而是将加载请求委托给父类加载器，只有当父类加载器无法加载时，才自己尝试加载。从而确保类的加载安全和防止类的重复加载。 保证类的唯一性 ：通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。 保证安全性： 为了安全，保证类库API不会被修改 2.2.3、类加载器加载的过程？ 1.加载：通过类的全限定名获取字节码文件，并将其转换为方法区内的运行时数据结构。2.验证：对字节码进行校验，确保符合Java虚拟机规范。3.准备：为类的静态变量分配内存，并设置默认初始值。4.解析：将符号引用转换为直接引用，即将类、方法、字段等解析为具体的内存地址。5.初始化：执行类的初始化代码，包括静态变量赋值和静态代码块的执行。 拓展一下： JVM 判定两个 Java 类是否相同的具体规则：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。 只有两者都相同的情况，才认为两个类是相同的。 6.3、垃圾收集6.3.1、如何判断对象仍然存活？（对象什么时候可以被垃圾器回收判断一个对象是否存活，也就等同于判断一个对象是否可以被回收。 如果一个或多个对象没有任何的引用指向它了，那么这个对象现在就是垃圾，如果定位了垃圾，则有可能会被垃圾回收器回收。 通常有两种方式：引用计数算法（reference counting）和可达性分析算法。 引用计数法 每个对象有一个引用计数器，记录引用它的次数。当计数器为零时，对象可以被回收。 但无法解决循环引用问题。例如，两个对象互相引用，但不再被其他对象引用，它们的引用计数都不为零，因此不会被回收。 可达性分析算法 通过一组名为 “GC Roots” 的根对象，进行递归扫描。那些无法从根对象到达的对象是不可达的，可以被回收；反之，是可达的，不会被回收。 6.3.2、finalize()方法了解吗？有什么作用？用一个不太贴切的比喻，垃圾回收就是古代的秋后问斩，finalize()就是刀下留人，在人犯被处决之前，还要做最后一次审计，青天大老爷看看有没有什么冤情，需不需要刀下留人。 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行 finalize()方法。如果对象在在 finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己 （this 关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它就”逃过一劫“；但是如果没有抓住这个机会，那么对象就真的要被回收了。 6.3.3、垃圾收集算法 标记-清除算法： 标记-清除算法分为“标记”和“清除”两个阶段，首先通过可达性分析，标记出所有需要回收的对象， 然后统一回收所有被标记的对象。 缺点：一个是效率问题，标记和清除的过程效率都不高 ；另一个就是，清除结束后会造成大量的碎片空间。 有可能会造成在申请大块内存的时候因为没有足够的连续空间导致再次 GC。 复制算法：为了解决碎片空间的问题，出现了“复制算法”。 它把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将当前使用的区域的可回收的对象进行回收。 缺点：因为每次在申请内存时，都只能使用一半的内存空间。内存利用率严重不足。 标记-整理算法： 复制算法在 GC 之后存活对象较少的情况下效率比较高，但如果存活对象比较多时， 会执行较多的复制操作，效率就会下降。 标记-整理算法的“标记”过程与“标记-清除算法”的标记过程一致，但标记之后不会直接清理。 而是将所有存活对象都移动到内存的一端。移动结束后直接清理掉剩余部分。 分代回收算法： 分代收集是将内存划分成了新生代和老年代。分配的依据是对象的生存周期，或者说经历过的 GC 次数。 对象创建时，一般在新生代申请内存，当经历一次 GC 之后如果对还存活，那么对象的年龄 +1。 对象创建时，一般在新生代申请内存，当经历一次 GC 之后如果对还存活，那么对象的年龄 +1。 新生代通常使用复制算法，老年代使用标记-清除或标记-整理算法。 6.3.4、Minor GC&#x2F;Young GC、Major GC&#x2F;Old GC、Mixed GC、Full GC 都是什么意思？ Minor GC 也称为 Young GC，是指发生在年轻代（Young Generation）的垃圾收集。年轻代包含 Eden 区以及两个 Survivor 区。 触发条件：当Eden区空间不足时，JVM会触发一次Minor GC， 将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代（Old Generation）。 Major GC 也称为 Old GC，主要指的是发生在老年代的垃圾收集。CMS 收集器的特有行为。 触发条件：当老年代空间不足时，或者系统检测到年轻代对象晋升到老年代的速度过快 ，可能会触发Major GC。 Mixed GC 是 G1 垃圾收集器特有的一种 GC 类型，它在一次 GC 中同时清理年轻代和部分老年代。 Full GC 是最彻底的垃圾收集，涉及整个 Java 堆和方法区（或元空间）。它是最耗时的 GC，通常在 JVM 压力很大时发生。 直接调用System.gc()或Runtime.getRuntime().gc()方法时， 虽然不能保证立即执行，但JVM会尝试执行Full GC。 Minor GC（新生代垃圾回收）时，如果存活的对象无法全部放入老年代 ，或者老年代空间不足以容纳存活的对象， 则会触发Full GC，对整个堆内存进行回收。 6.3.5、知道哪些垃圾收集器？2.3.3、简述分代回收器怎么工作的？（分代收集算法）分代回收器有两个分区：老生代和新生代，新生代和老生代空间占比是1：2 新生代使用的是复制算法，新生代里有 3 个分区：Eden（一den）、To 、From ，它们的默认占比是 8:1:1，它的执行流程如下： 把 Eden + From 存活的对象放入 To 区； 清空 Eden 和 From 分区； From 和 To 分区交换，From 变 To ，To 变 From 。 每次在 From 到 To 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。 老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。 2.3.4、说一下JVM有哪些垃圾回收器？ 串行垃圾收集器:Serial Gc、Serial Old GC 并行垃圾收集器:Parallel Old GC、ParNew GC CMS(并发)垃圾收集器:CMS GC，作用在老年代 G1垃圾收集器，作用在新生代和老年代 2.3.5、详细说一下G1垃圾收集器","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"Redis","slug":"八股/Redis","date":"2024-10-28T12:14:56.000Z","updated":"2025-01-10T12:51:22.803Z","comments":true,"path":"2024/10/28/八股/Redis/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/Redis/","excerpt":"","text":"1、Redis为什么快？ （内存操作）完全基于内存，绝大部分请求是纯粹的内存操作，非常快速 （单线程，省去线程切换、锁竞争的开销）采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗; 使用多路 I&#x2F;O 复用模型，非阻塞 IO； 2、Redis可以用来做什么？ 缓存 排行榜 分布式计数器 分布式锁 消息队列 延时队列 分布式 token 限流 0、3种常用的缓存读写策略 1、Cache Aside Pattern （旁路缓存模式，双写模式） 这是最常见的缓存使用模式，缓存和数据库分开管理，应用程序负责协调两者。 写： 先更新数据库 然后直接删除缓存 写数据的过程中，可以先删除 cache ，后更新 db 么？ 不行的！因为这样可能会造成 数据库（db）和缓存（Cache）数据不一致的问题。 比如： 线程A删除了缓存，但还没来得及更新db 线程B未读到缓存，然后从db种读取了旧数据，并写入缓存 线程A更新db，但缓存仍是旧数据 结果就是缓存和db出现了数据不一致的问题 读： 从 cache 中读取数据，读取到就直接返回 cache 中读取不到的话，就从 db 中读取数据返回 再把数据放到 cache 中。 缺点： 首次请求数据一定不在 cache 的问题 解决方法：可以将热点数据可以提前放入 cache 中。 写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。 解决方法： 数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁&#x2F;分布式锁来保证更新 cache 的时候不存在线程安全问题。 可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。 2、Read&#x2F;Write Through Pattern（读写穿透，直写缓存模式 ） 在此模式下，所有写操作都会先更新缓存，然后再同步更新数据库。 写： 先查缓存，缓存中不存在，直接更新缓存 缓存中存在，先更新缓存，然后由缓存服务再更新db 读： 从 cache 中读取数据，读取到就直接返回 。 读取不到的话，先从 db 加载，写入到 cache 后返回响应。 3、Write behind Pattern（异步缓存写入） 写操作只更新缓存，不立即同步到数据库，而是延迟批量更新数据库。 Write Behind Pattern 和 Read&#x2F;Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。 但是，两个又有很大的不同：Read&#x2F;Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。 很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。 这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。 Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。 比较 特性 Cache Aside Write Through Write Back 读性能 高 高 高 写性能 中 低 高 一致性 中 高 低 实现复杂度 中 中 高 适用场景： Cache Aside 适合读操作频繁、写操作较少且数据一致性要求高的场景，例如用户信息、商品详情查询等。 Write Through 适合读写操作都频繁且数据一致性要求较高的场景，例如金融交易系统。 Write Back 适合写操作频繁、对一致性要求不高且容忍一定延迟的场景，例如日志系统、计数统计等。 热数据&#x2F;冷数据 热数据（Hot Data） 定义：热数据是指访问频率非常高的数据，通常是系统中经常被查询、更新或操作的数据。 特性： 访问频繁：短时间内被大量用户反复请求。 时效性强：通常对实时性有较高要求。 缓存优先级高：热数据通常被存储在高性能的存储系统（如缓存）中，以加快访问速度。 例子： 电商系统中某个爆款商品的详情页数据。 热门社交媒体帖子或评论。 游戏中实时的玩家排名信息。 使用场景： 将热数据存储在快速存取的缓存系统（如 Redis、Memcached）中，降低数据库访问压力，提高性能。 冷数据（Cold Data） 定义：冷数据是指访问频率较低的数据，通常是历史数据、归档数据或不再被频繁使用的数据。 特性： 访问较少：仅在特定情况下或较长时间间隔后被请求。 存储优先级低：适合存储在较便宜的存储介质（如磁盘或分布式存储系统）上。 时效性要求低：大部分冷数据不需要实时处理。 例子： 已完成的订单记录。 几年前的社交媒体帖子。 数据分析中需要的历史日志文件。 使用场景： 将冷数据存储在低成本的存储系统（如 Amazon S3、HDFS）中，以降低存储成本。 根据需要通过离线计算或批处理的方式使用冷数据。 1、数据类型1.1、Redis有哪些数据类型？常用的使用场景 String：存储单个值，适用于缓存和键值存储，常用命令:SET用于设置值，GET用于获取值。 分布式锁、分布式Session、值缓存、浏览数、分库分表主键序列号 List：有序、可重复的字符串集合，适用于消息队列和发布&#x2F;订阅系统，常用命令:LPUSH用于从列表左侧添加元素，LRANGE用于获取指定范围的元素。 分布式Duque、消息队列、Push式信息流 Set：无序、不可重复的字符串集合，适用于标签系统和好友关系等，常用命令:SADD用于向集合添加成员，SMEMBERS用于获取集合所有成员。 点赞、抽奖、集合运算 Hash：包含键值对的无序散列表，适用于存储对象、缓存和计数器，常用命令:HSET用于设置字段值，HGETALL用于获取散列的所有字段和值。 购物车、对象存储 Zset：也就是Sorted Set，有序的字符串集合，每个成员关联一个分数，适用于排行榜和按分数范围获取成员，常用命令:ZADD用于添加成员及其分数，ZRANGE用于获取指定范围的成员， 热搜、最近播放 2、持久化什么是持久化？ 大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了做数据同步（比如 Redis 集群的主从节点通过 RDB 文件同步数据）。 Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制: 2.1、RDBRDB：是Redis DataBase缩写快照 因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时 ，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。 为了解决这个问题，Redis 增加了 RDB 快照。 RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据， RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。 Redis 提供了两个命令来生成 RDB 快照文件： save:同步保存操作，会阻塞 Redis 主进程； bgsave:fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。 2.2、AOFAOF持久化(即Append Only File持久化)，Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里， 然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。 AOF为什么是在执行完写命令才将该命令记录到AOF日志？ 避免额外的检查开销，AOF 记录日志不会对命令进行语法检查； 在命令执行完之后再记录，不会阻塞当前的命令执行。 潜在风险 如果刚执行完命令 Redis 就宕机会导致对应的修改丢失； 可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的，也就是说这两个操作是同步的 如果在将日志内容写入到硬盘时，服务器的硬盘的 I&#x2F;O 压力太大，就会导致写硬盘的速度很慢， 进而阻塞住了，也就会导致后续的命令无法执行。 AOF执行流程 AOF持久化策略 AOF重写 两种方式对比 AOF 优点：首先，AOF提供了更好的数据安全性，因为它默认每接收到一个写命令就会追加到文件末尾。 即使Redis服务器宕机，也只会丢失最后一次写入前的数据。 缺点：因为记录了每一个写操作，所以AOF文件通常比RDB文件更大，消耗更多的磁盘空间。 简答：RDB是Redis的快照持久化方式，通过周期性的快照将数据保存到硬盘，占用更少的磁盘空间和 CPU资源，适用于数据备份和恢复，但可能存在数据丢失的风险。AOF 是追加日志持久化方式，将每个写操作以追加的方式记录到日志文件中，确保了更高的数据完整性和持久性，但相对于RDB 消耗更多的磁盘空间和写入性能，适用于数据持久化和灾难恢复，且可以通过配置实现不同的同步频率。 3、过期键的删除策略3.1、Redis过期键的删除策略？ 定时过期（CPU不友好，内存友好）：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期（CPU友好，内存不友好）：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 定期过期（前两种的折中）：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 3.2、Redis key的过期时间和永久有效分别怎么设置？expire命令和persist命令 3.3、过期数据如何处理？ 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 4、内存淘汰MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？ redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 4.1、Redis的内存淘汰策略都有哪些？Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。 全局的键空间选择性移除 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 设置过期时间的键空间选择性移除 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，挑选将要过期的数据淘汰。 5、缓存异常5.1、缓存穿透​ 缓存和数据库中都没有用户要访问的数据，当有大量这样的请求到来时，数据库的压力骤增 ，造成数据库短时间内承受大量请求而崩掉。 解决方案： 非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在， 如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 缓存空值或者默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据， 在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值， 返回给应用，而不会继续查询数据库。 布隆过滤器：我们可以在写入数据库数据时，使用布隆过滤器做个标记， 然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在， 如果不存在，就不用通过查询数据库来判断数据是否存在。即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行 5.2、缓存击穿如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取， 直接访问数据库，数据库很容易就被高并发的请求冲垮 解决方案： 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求， 要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 不给热点数据设置过期时间，由后台异步更新缓存， 或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间； 5.3、缓存雪崩当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求， 都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增， 严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃， 解决方案： 设置合理的缓存失效时间:针对不同的业务需求，设置不同的缓存失效时间，避免缓存同时失效，引发雪崩效应。 设置缓存锁:在缓存失效时，设置一个短暂的锁定时间，只允许一个请求查询数据库并刷新缓存，其他请求等待锁释放后再读取缓存。 6、高可用6.1、主从复制为了应对并发能力问题，可以搭建主从集群，实现读写分离，Redis大多都是读多写少的场景 多台服务器要保存同一份数据，这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？ Redis 提供了主从复制模式，来避免上述的问题。 当是写操作，在主服务器上进行，然后将这个操作同步给从服务器，当是读操作，就分发给从服务器。 第一次同步——全量同步 如何确定主从关系？比如想让服务器B变成服务器A的从服务器 12# 服务器 B 执行这条命令replicaof &lt;服务器 A 的 IP 地址&gt; &lt;服务器 A 的 Redis 端口号&gt; 在介绍第一次同步的过程之前，需要先介绍两个参数 从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。 psync 命令包含两个参数 ，可以判断从服务器是否第一次来同步数据 Replicationld：简称replid，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。 从服务器会继承主服务器的replid offset：偏移量，表示复制的进度，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。 如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。 全量同步的流程如下： slave节点请求增量同步 master节点判断replid，发现不一致，拒绝增量同步，执行全量同步 master将执行 bgsave 命令（异步，不会阻塞主线程）生成RDB，发送RDB到slave。 slave清空本地数据，加载master的RDB master将生成RDB期间、发送RBD期间的命令记录在repl_baklog，并持续将log中的命令发送给slave slave执行接收到的命令，保持与master之间的同步 至此，主从服务器的第一次同步的工作就完成了。 断开后的同步——增量同步 从节点断开后重启，采用增量同步 slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave repl_baklog大小有上限，是一个环形区域，写满后会覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。 因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该设置repl_backlog_buffer 缓冲区尽可能的大一些， 减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。 6.2、哨兵（Sentinel）机制 为什么要有哨兵机制？ 主节点如果要是挂了，就没办法接收写操作了 哨兵的三个作用？ 监控：Sentinel会不断检查您的master和slave是否按预期工作 自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主 通知：Sentinel充当Redis客户端（比如RedisTemplate）的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端 如何判断节点是否故障？ Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令 主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。 客观下线：若超过指定数量(quorum)的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。 选出新的主节点的规则？ 首先要把网络状态不好的从节点给过滤掉，首先把已经下线的从节点过滤掉 。然后对所有从节点进行三轮考察：优先级、复制进度、ID 号。 优先级最高的从节点胜出 节点的offset值（反映了复制进度）越大说明数据越新，优先级越高 slave节点的运行id大小，越小优先级越高。 故障转移的过程？ 选出一个新的主节点 让旧主节点的从节点成为新主节点的从节点，开始从新的主节点同步数据 将新主节点的IP地址和信息，通知给客户端 继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点 TODO 如何从 Sentinel 集群中选择出 Leader ？（由哪个哨兵进行主从故障转移） 脑裂Sentinel 可以防止脑裂吗？（在小林”主从复制是怎么实现的“那里最后有提到脑裂，可结合gpt看看） 6.3、分片集群（Cluster ） 为什么需要 Redis Cluster？解决了什么问题？有什么优势？ 主从解决了高并发（读）问题，但存在高可用问题，哨兵解决了高可用问题。但还有两个问题没有解决： 海量数据存储问题 高并发写的问题 使用分片集群可以解决上述问题，分片集群特征： 集群中有多个主节点，每个主节点保存不同数据 每个主节点都可以有多个从节点 主节点之间通过ping监测彼此健康状态 客户端请求可以访问集群任意节点，最终都会被转发到正确节点 Redis Cluster 是如何分片的？ 为什么 Redis Cluster 的哈希槽是 16384 个? 如何确定给定 key 的应该分布到哪个哈希槽中？ Redis Cluster 支持重新分配哈希槽吗？ Redis Cluster 扩容缩容期间可以提供服务吗？ Redis Cluster 中的节点是怎么进行通信的？","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Mysql","slug":"八股/Mysql","date":"2024-10-28T12:14:46.000Z","updated":"2025-01-02T09:45:56.440Z","comments":true,"path":"2024/10/28/八股/Mysql/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/Mysql/","excerpt":"","text":"1、基础知识1.1、MySQL存储引擎MyISAM与InnoDB区别如果没有特别的需求，使用默认的Innodb即可 1、是否支持行级锁 MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。 2、是否支持事务 MyISAM 不提供事务支持。 InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。 3、是否支持外键 MyISAM 不支持，而 InnoDB 支持。 外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，我们是不建议在实际生产项目中使用外键的，在业务代码中进行约束即可！ 4、是否支持数据库异常崩溃后的安全恢复 MyISAM 不支持，而 InnoDB 支持。 使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。 5、是否支持 MVCC MyISAM 不支持，而 InnoDB 支持。 讲真，这个对比有点废话，毕竟 MyISAM 连行级锁都不支持。MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。 1.2、执行一条SQL请求的过程是什么？ Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。 存储引擎：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。 MySQL 服务器的连接器开始处理这个请求，主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作 分析器开始对 SQL 语句进行解析，检查语句是否符合 SQL 语法规则，确保引用的数据库、表和列都存在，并处理 SQL 语句中的名称解析和权限验证。 优化器负责确定 SQL 语句的执行计划，这包括选择使用哪些索引，以及决定表之间的连接顺序等。优化器会尝试找出最高效的方式来执行查询。 执行器首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。 ps：如果是一条查询语句，略有一点不同： 执行更新的时候肯定要记录日志啦，这就会引入日志模块了 ，MySQL 自带的日志模块是 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志） 先查询到数据，不会走查询缓存，因为更新语句会导致与该表相关的查询缓存失效。 然后拿到查询的语句，进行修改，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中， 同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。 更新完成。 1.3、三大范式 第一范式：要求数据库表的每一列都是不可分割的原子数据项。 第二范式：在 1NF 的基础上，要求数据库表中的每一列都和主键直接相关，而不能只与主键的某一部分相关（主要针对联合主键）。 比如说在一个订单表中，可能会存在订单编号和商品编号，设计出来的表可能是这样的。 这个订单表中就存在冗余数据，比如说商品名称、单位、商品价格等，应该将其拆分为订单表、订单商品关联表、商品表。 这个订单表中就存在冗余数据，比如说商品名称、单位、商品价格等，应该将其拆分为订单表、订单商品关联表、商品表。 第三范式：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖），第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 1.4、表连接 内连接：返回两个表中有匹配关系的行 。相当于取交集 外连接：仅返回两个表中匹配的行，还返回左表、右表或两者中未匹配的行。 左连接：以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN 右连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN 交叉连接（得到笛卡尔积）：返回第一个表中的每一行与第二个表中的每一行的组合，这种类型的连接通常用于生成笛卡尔积。 1.5、in和exit的区别1.6、NULL和&#39;&#39;的区别？也可以这样问：为什么 MySQL 不建议使用 NULL 作为列默认值？ NULL 代表一个不确定的值,就算是两个 NULL,它俩也不一定相等。例如，SELECT NULL=NULL的结果为 false，但是在我们使用DISTINCT,GROUP BY,ORDER BY时,NULL又被认为是相等的。 &#39;&#39;的长度是 0，是不占用空间的，而NULL 是需要占用空间的。 NULL 会影响聚合函数的结果。例如，SUM、AVG、MIN、MAX 等聚合函数会忽略 NULL 值。 COUNT 的处理方式取决于参数的类型。如果参数是 *(COUNT(*))，则会统计所有的记录数，包括 NULL 值；如果参数是某个字段名(COUNT(列名))，则会忽略 NULL 值，只统计非空值的个数。 查询 NULL 值时，必须使用 IS NULL 或 IS NOT NULLl 来判断，而不能使用 &#x3D;、!&#x3D;、 &lt;、&gt; 之类的比较运算符。而&#39;&#39;是可以使用这些比较运算符的。 2、索引对于这样一张表 它的索引结构如下所示（其中叶子节点是双链表连接） 2.1、索引的种类 从数据结构角度 B数索引：MySQL 里默认和最常用的索引类型。只有叶子节点存储 value，非叶子节点只有指针和 key。 Hash索引：类似键值对的形式，一次即可定位。 从物理存储角度 聚簇索引和非聚簇索引的区别在于索引和数据行的存储方式。聚簇索引将索引和数据行存储在一起，而非聚簇索引将索引和数据行分开存储。 聚簇索引：聚簇索引是一种索引组织方式，它将索引和数据行存储在一起，即数据行按照索引的顺序存储在磁盘上。聚簇索引的叶子节点保存的是完整的数据行，因此不需要进行额外的查找操作就可以获取到所需的数据。InnoDB 中的主键索引就属于聚簇索引。 非聚簇索引：它将索引和数据行分开存储，即索引保存了指向数据行的指针（通常是行的物理地址或主键值）。非聚簇索引的叶子节点保存的是指向数据行的引用，当查询需要获取数据时，首先根据索引查找到相应的行指针，然后再通过行指针获取数据行。 MyISAM 存储引擎的索引通常是非聚簇索引。 回表查询是什么？ 在使用索引进行查询时，当需要访问表中未包含在索引中的其他列时，MySQL需要根据索引中的键值回到表中检索相应的行数据。这个过程就称为回表查询。 对于非聚簇索引，一定会回表查询吗？ 不一定。试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。 这种情况就称之为索引覆盖。 从逻辑角度 主键索引：数据列不允许重复，不允许为NULL，一个表只能有一个主键。 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。关键字UNIQUE 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 普通索引：基本的索引类型，没有唯一性的限制，允许为NULL值。 可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建联合索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一联合索引 在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引： 如果有主键，默认会使用主键作为聚簇索引的索引键（key）； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）； 其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。 主键索引的 B+Tree 和二级索引的 B+Tree 区别如下： 主键索引的 B+Tree 的叶子节点存放的是实际数据， 所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 二级索引的查找过程 将前面的商品表中的 product_no （商品编码）字段设置为二级索引， 那么二级索引的 B+Tree 如下图 其中非叶子的 key 值是 product_no（图中橙色部分）， 叶子节点存储的数据是主键值（图中绿色部分）。 如果我用 product_no 二级索引查询商品，如下查询语句： 1select * from product where product_no = &#x27;0002&#x27;; 会先检二级索引中的 B+Tree 的索引值(商品编码，product no)找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据。 不过，当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到， 这时就不用再查主键索引查，比如下面这条查询语句： 1select id from product where product_no = &#x27;0002&#x27;; 这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」 ，也就是只需要查一个 B+Tree 就能找到数据。 2.2、索引底层原理MySQL的索引底层结构是 B+树。 B+树是一种平衡多路搜索树，具有以下特点: 所有关键字保存在叶子节点，并且叶子节点之间通过链表连接，形成一个有序的叶子节点序列。 非叶子节点只存储索引字段的值和子节点的指针，不保存实际的数据。这样可以使得一个节点可以存储更多的关键字，减少了树的高度，加快搜索速度。 叶子节点包含所有索引字段的值和指向对应数据的指针。 在 B+树索引中，每个节点的大小是固定的，与磁盘页的大小相当。节点的大小通常是数据库页的大小例如16KB或 32KB。每个节点可以存储多个关键字和指针。叶子节点的关键字是有序的，且通过链表连接在一起。 索引查询快的原因有以下几点: 路径长度短:B+树具有平衡性，所有叶子节点的深度相同，因此在查询过程中只需要沿着树的高度进行几次磁盘 &#x2F;&#x2F;O 操作，所以查询速度较快。 顺序访问优势:B+树的叶子节点之间使用链表连接，并且叶子节点的关键字是有序的，因此对于范围查询操作，可以通过顺序扫描叶子节点来获取有序的数据结果，提高查询速度。 最小化磁盘I&#x2F;0 操作:B+树具有较高的填充因子，每个磁盘页上存储的关键字数量较多，能够减少磁盘 I&#x2F;0 操作的次数，提高查询效率。 综上所述，B+树的平衡性、有序的叶子节点、顺序访问以及最小化的磁盘!&#x2F;0 操作是使得索引查询快速的关键因素。通过 B+ 树的数据结构和索引的建立，可以大幅度减少磁盘访问次数，提高数据库查询的效率。 简答：索引底层原理使用了 B+树数据结构，它是一种平衡树，能快速定位和检索数据。B+树的叶子节点存储实际数据，中间节点存储索引，通过减少磁盘I&#x2F;O来提高查询效率;索引按照值的大小顺序排列，使得范围查询效率更高。 2.3、为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？（TODO要设计一个适合 MySQL 索引的数据结构，至少满足以下要求： 能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作； 要能高效地查询某一个记录，也要能高效地执行范围查找； 1、B+Tree vs B Tree 在B+树中，数据都存储在叶子节点上，而非叶子节点只存储索引信息；而B树的非叶子节点既存储索引信息也存储部分数据。 另外，B+Tree 叶子节点采用的是双链表连接，适合 MSQL 中常见的基于范围的顺序查找，而B树无法做到这一点。 B+树的查找性能更稳定，每次查找都需要查找到叶子节点;而B树的查找可能会在非叶子节点找到数据，性能相对不稳定。 B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B树更「矮胖」，查询底层节点的磁盘 &#x2F;O次数会更少。 B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 &#x2F;0 操作，范围查询效率不如 B+ 树。 2、B+Tree vs 二叉树 普通二叉树存在退化的情况，如果它退化成链表，就相当于全表扫描。 2.4、最左匹配原则？MySQL联合索引遵循最左前缀匹配原则，即最左优先，查询的时候会优先匹配最左边的索引。例如当我们在 (a,b,c)三个字段上创建联合索引时，实际上是创建了三个索引，分别是(a)、(a,b).(a,b,c)。 mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。 如果查询条件包含(a,c)，也会用到索引，相当于用到了(a)索引。 比如，将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name) ，它的B+树示意图如下： 可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product no 字段比较，在 product no 相同的情况下再按 name 字段比较。 也就是说，联合索引查询的 B+Tree 是先按 product no 进行排序，然后再 product no 相同的情况再按name 字段排序。 再比如建立（a，b）的索引，它的索引示意图如下： 可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8）， 而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。 因此，直接执行where b = 2这种查询条件没有办法利用联合索引的， 利用索引的前提是索引里的 key 是有序的。 只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候， b 的值为（7，8），这时就是有序的，这个有序状态是局部的， 因此，执行where a = 2 and b = 7是 a 和 b 字段能用到联合索引的 接下来说几个范围查询的经典例子 1、select * from t_table where a &gt; 1 and b &#x3D; 2 。 由于联合索引(二级索引)是先按照a字段的值排序的，所以符合a&gt;1条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合a&gt;1条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合a&gt;1条件位置，所以a字段可以在联合索引的 B+Tree 中进行索引查询。 但是在符合 a &gt; 1 条件的二级索引记录的范围里，b 字段的值是无序的。 比如前面图的联合索引的 B+ Tree 里， 下面这三条记录的 a 字段的值都符合 a &gt; 1 查询条件， 而 b 字段的值是无序的： a 字段值为 5 的记录，该记录的 b 字段值为 8； a 字段值为 6 的记录，该记录的 b 字段值为 10； a 字段值为 7 的记录，该记录的 b 字段值为 5； 因此，这条查询语句只有 a 字段用到了联合索引进行索引查询，联合索引的最左匹配原则在遇到 a 字段的范围查询（ &gt;）后就停止匹配了 而 b 字段并没有使用到联合索引。 2、select * from t_table where a &gt;&#x3D; 1 and b &#x3D; 2 在符合 a&gt;&#x3D; 1 条件的二级索引记录的范围里，b 字段的值是「无序」的， 但是对于符合 a &#x3D; 1 的二级索引记录的范围里，b 字段的值是「有序」的 （因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下 ，再按照 b 字段的值进行排序）。 当二级索引记录的 a 字段值为 1 时，可以通过 b &#x3D; 2 条件减少需要扫描的二级索引记录范围 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 3、SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b &#x3D; 2 在 MySQL 中，BETWEEN 包含了 value1 和 value2 边界值， 类似于 &gt;&#x3D; and &#x3D;&lt;。 因此 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 4、SELECT * FROM t_user WHERE name like ‘j%’ and age &#x3D; 22 对于符合 name &#x3D; j 的二级索引记录的范围里，age字段的值是「有序」的 ，（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序）。 也就是说，从符合 name = &#39;j&#39; and age = 22 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描 。 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 综上所述，联合索引的最左匹配原则，在遇到范围查询（如 &gt;、&lt;）的时候，就会停止匹配，** **也就是范围查询的字段可以用到联合索引，** **但是在范围查询字段的后面的字段无法用到联合索引。** **注意，对于 &gt;&#x3D;、&lt;&#x3D;、BETWEEN、like 前缀匹配的范围查询， 并不会停止匹配 2.5、索引下推对于联合索引（a, b） ，在执行 select * from table where a &gt; 1 and b &#x3D; 2只有 a 字段能用到索引 ，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后 ，还需要判断其他条件是否满足（看 b 是否等于 2）， 那是在联合索引里判断？还是回主键索引去判断呢？ MySQL 5.6 引入的索引下推优化 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断 直接过滤掉不满足条件的记录，减少回表次数。 当你的查询语句的执行计划里，出现了 Extra 为 Using index condition 那么说明使用了索引下推的优化。 2.6、索引失效有哪些？ 当我们使用左或者左右模糊匹配的时候， 也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 不知道从哪个索引值开始比较，于是就只能通过全表扫描的方式来查询。 当我们在查询条件中对索引列使用函数，就会导致索引失效。因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。因为索引保存的是索引字段的原始值，而不是id +1表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。 当我们在查询条件中对索引列进行隐式类型转换操作 ，背后可能也做了函数运算 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配 ，否则就会导致索引失效。 在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列， 那么索引会失效。 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的， 2.7、count(*) 和 count(1) 有什么区别？哪个性能最好？ count() 是什么？ 该函数作用是统计符合查询条件的记录中， 函数指定的参数不为 NULL 的记录有多少个。 2.8、索引创建的原则（了解1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 2）较频繁作为查询条件的字段才去创建索引 3）更新频繁字段不适合创建索引 4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低) 5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 6）定义有外键的数据列一定要建立索引。 7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。 8）对于定义为text、image和bit的数据类型的列不要建立索引。 2.9、索引的缺点占用存储空间： 每个索引都会占用额外的磁盘空间，尤其在数据量很大的情况下，存储需求会显著增加。 影响写操作性能： 插入、更新、删除时，MySQL需要维护所有相关索引。这会导致写操作变慢，特别是在频繁更新的表中。 复杂的索引选择： 如果索引过多，优化器在执行查询时需要花费额外时间决定使用哪个索引，这可能导致优化器选择不当。 增加维护成本： 开发和维护人员需要理解和管理这些索引，可能导致复杂性增加。 因此，对于写操作多于读操作的场景，尽量减少索引数量。 2.10、主键索引为什么最好设置为自增的如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置， 不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。 因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时， 就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入， 甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。 页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。 举个例子，假设某个数据页中的数据是1、3、5、9，且数据页满了，现在准备插入一个数据7，则需要把数据页分割为两个数据页: 出现页分裂时，需要将一个页的记录移动到另外一个页，性能会受到影响， 同时页空间的利用率下降，造成存储空间的浪费。 而如果记录是顺序插入的，例如插入数据11，则只需开辟新的数据页，也就不会发生页分裂： 3、事务事务是逻辑上的一组操作，要么都执行，要么都不执行。 3.1、事务的ACID特性以及怎么实现的（★ 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不会丢失。 只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 3.2、脏读、幻读、不可重复读（★ 脏读（读到其他事务未提交的数据； 如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。 某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读（前后读取的数据不一致； 在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。 在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新了原有的数据。 幻读（前后读取的记录数量不一致 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。 严重性排序：脏读 &gt; 不可重复读 &gt; 幻读 3.3、事务的隔离级别（★隔离水平高低排序如下：串行化 &gt; 可重复读 &gt; 读已提交 &gt; 读未提交 读未提交：指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交：指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； 在各个隔离级别下： 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象； 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象； 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象； 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。 MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。 3.4、隔离级别的实现原理MySQL 的事务隔离级别主要依赖 锁机制 和 MVCC 实现。 读已提交和可重复读通过 MVCC 机制中的 ReadView 来实现。 读已提交：每次读取数据前都生成一个 ReadView，保证每次读操作都是最新的数据。 可重复读：只在第一次读操作时生成一个 ReadView，后续读操作都使用这个 ReadView，保证事务内读取的数据是一致的。 串行化是通过锁来实现的：事务在读操作时，必须先加表级共享锁，直到事务结束才释放；事务在写操作时，必须先加表级排他锁，直到事务结束才释放。 以下了解即可 (1) 锁机制 共享锁（S 锁）：允许多个事务并发读取同一数据，但阻止写入。 排他锁（X 锁）：阻止其他事务读取或写入。 隔离级别越高，锁的粒度和范围越大。 3.5、MVCC 基本概念 当前读 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如:select .. lockin share mode(共享锁)，select.... for update、update、insert、delete(排他锁)都是一种当前读。 快照读 简单的select(不加锁)就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。 RC读已提交：每次select，都生成一个快照读。 RR可重复读：开启事务后第一个select语句才是快照读的地方 串行化：快照读退化为当前读 MVCC 全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，快照读为MVSOL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undolog、readView。 实现过程： 读取时，根据当前事务的版本号和数据的创建&#x2F;删除版本号，判断该数据是否可见。 写入时，生成新的版本，旧版本通过 Undo Log 保留。 三个字段 TRX_ID: 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID。 ROLL_PTR：回滚指针，指向这条记录的上一个版本，用于配合undolog，指向上一个版本 ROW_ID:隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段。 undolog readview ReadView(读视图)是 快照读 SOL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务(未提交的)id。 四个核心字段： m_ids：当前活跃的事务ID集合。在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表， 注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id：在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务， 也就是 m_ids 的最小值。 max_trx_id：预分配事务ID，当前最大事务ID+1（因为事务ID是自增的）。也就是创建 Read View 时当前数据库中应该给下一个事务的 id 值 creator_trx_id:：创建该 Read View 的事务的事务 id。 4、锁当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。 就像酒店的房间，如果大家随意进出，就会出现多人抢夺同一个房间的情况，而在房间上装上锁，申请到钥匙的人才可以入住并且将房间锁起来，其他人只有等他使用完毕才可以再次使用。 4.1、表级锁和行级锁（锁粒度不同行级锁 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 4.2、共享锁和排他锁从锁的类别上来讲，有共享锁和排他锁。 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 5、三大日志（★Redo log(重做日志)：是 Innodb 存储引擎层生成的日志，用于保证事务的持久性，它在事务提交前将数据写入磁盘，以防止数据丢失。主要用于掉电等故障恢复； Undo log(回滚日志)：是 Innodb 存储引擎层生成的日志， 用于事务的回滚操作，它记录了事务对数据的修改，以便在事务回滚时进行数据恢复。保证事务的原子性，主要用于事务回滚和 MVCC。 Bin log(二进制日志)：是 Server 层生成的日志， 记录了数据库的所有修改操作，包括对数据的增删改操作，主要用于数据备份和主从复制； 5.1、Undo logundo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图: 每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时， 要把回滚时需要的信息都记录到 undo log 里 。在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。 在插入一条记录时，要把这条记录的主键值记下来， 回滚时只需要把这个主键值对应的记录删掉就好了； 在删除一条记录时，要把这条记录中的内容都记下来， 回滚时再把由这些内容组成的记录插入到表中就好了； 在更新一条记录时，要把被更新的列的旧值记下来， 这样之后回滚时再把这些列更新为旧值就好了。 TODO另外，undo log 还有一个作用， 通过 ReadView + undo log 实现 MVCC（多版本并发控制）。 因此，undo log 两大作用： 实现事务回滚，保障事务的原子性。 实现 MVCC（多版本并发控制）关键因素之一。 5.2、Redo Log重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。 该日志文件由两部分组成:重做日志缓冲(redolog buffer)以及重做日志文件(redolog file),前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中,用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用。 为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候， InnoDB 引擎就会先更新内存（同时标记为脏页）， 然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。 后续，InnoDB 引擎会在适当的时候， 由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术。 WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上， 而是先写日志，然后在合适的时间再写到磁盘上。 过程如下图： 顺序写vs随机写 redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？ 写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写， 而写入数据需要先找到写入位置，然后才写到磁盘， 所以磁盘操作是随机写。 磁盘的「顺序写 」比「随机写」 高效的多， 因此 redo log 写入磁盘的开销更小。 至此，为什么需要 redo log 这个问题我们有两个答案： 实现事务的持久性，让 MySQL 有 崩溃恢复 的能力， 能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失； 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。 产生的 redo log 是直接写入磁盘的吗？ 不是的。实际上，执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;0操作，而且磁盘的运行速度远慢于内存。所以，redo log也有自己的缓存– redo log buffer，每当产生一条 redo log 时，会先写入到 redo logbuffer，后续在持久化到磁盘如下图: redo log buffer 默认大小 16 MB，可以通过 innodb_log_Buffer_size 参数动态的调整大小， 增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。 redo log和undo log的区别 这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于： redo log 记录了此次事务「修改后」的数据状态，记录的是更新之后的值， 主要用于事务崩溃恢复，保证事务的持久性。 undo log 记录了此次事务「修改前」的数据状态，记录的是更新之前的值， 主要用于事务回滚，保证事务的原子性。 事务提交之前发生了崩溃(这里的崩溃不是宕机崩溃，而是事务执行错误，mysql 还是正常运行的)，重启后会通过 undo log 回滚事务。 事务提交之后发生了崩溃（这里的崩溃是宕机崩溃），重启后会通过 redo log 恢复事务，如下图： 5.2.1、redolog刷盘时机 5.3、binlogbinog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT和 SHOW 操作。 作用： 灾难时的数据恢复; MySQ4的主从复制。 binlog 有3种格式类型 分别是 STATEMENT(默认格式)、ROW、 MIXED，区别如下: 指定statement，记录的内容是SQL语句原文，比如执行一条update T set update_time=now() where id=1，记录的内容如下。 同步数据时，会执行记录的SQL语句，但是有个问题，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。 为了解决这种问题，我们需要指定为row，记录的内容不再是简单的SQL语句了，还包含操作的具体数据，记录内容如下。 但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量update 语句，更新多少行数据就会产生多少条记录，使 binog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已; 所以就有了一种折中的方案，指定为mixed，记录的内容是前两者的混合。 MySQL 会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式。 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况， 理论上只要记录在 binlog 上的数据，都可以恢复， 所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。 两阶段提交 事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑， 可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。 先写 redo log 直接提交，然后写 binlog， 假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据， 但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了， 由于没有 redo log，本机是无法恢复这一条记录的， 但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。 可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态， 就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据， binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。 两阶段提交的过程在一条更新语句的执行过程那里 6、SQL优化6.1、MySQL 慢查询的排除与优化? 慢查询日志:在 MySQL中，可以启用慢查询日志功能来记录执行时间超过设定阈值的查询。通过分析这些日志，可以找到执行时间较长的SQL语句。 使用 EXPLAIN分析:对慢SQL语句使用 MySQL的EXPLAIN命令，可以分析查询的执行计划。这有助于了解 MySQL是如何处理你的查询的，包括是否使用了索引、是否进行了全表扫描等。 查询了过多不需要的数据:有时候，查询语句可能会返回比实际需要更多的数据，这会导致查询变慢。例如，使用 SELECT*从多个表中进行关联查询时，可能会取出所有列的数据，但实际上可能只需要其中的一部分列。这种情况下，可以优化SQL语句，只选择需要的列。 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。 6.2、explain执行计划如果一条sql执行很慢的话，我们通常会使用mysql自动的执行计划explain来去查看这条sql的执行情况， 比如在这里面可以通过key和key_len检查是否命中了索引，如果本身已经添加了索引，也可以判断索引是否有失效的情况， 第二个，可以通过type字段查看sq!是否有进一步的优化空间，是否存在全索引扫描或全盘扫描， 第三个可以通过extra建议来判断，是否出现了回表的情况，如果出现了可以尝试添加索引或修改返回字段来修复 key 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。 key_length 索引长度 extra 的信息非常丰富，常见的有： Using index：表示只利用了索引。 Using where：表示使用了 WHERE 过滤。 Using temporary ：表示使用了临时表来存储中间结果。 type(非常重要，可以看到有没有走索引) 访问类型 性能从最优到最差分别为：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL。 system，表只有一行，一般是系统表，往往不需要进行磁盘 IO，速度非常快 const、eq_ref、ref：这些类型表示 MySQL 可以使用索引来查找单个行，其中 const 是最优的，表示查询最多返回一行。 range：只检索给定范围的行，使用索引来检索。在where语句中使用 bettween...and、&lt;、&gt;、&lt;=、in 等条件查询 type 都是 range。 index：遍历索引树读取。 ALL：全表扫描，效率最低。 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。说明：1） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2） ref 指的是使用普通的索引（normal index）。3） range 对索引进行范围检索。反例：explain表的结果，type&#x3D;index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫 6.3、给你张表，发现查询速度很慢，你有那些解决方案 分析查询语句：使用EXPLAIN命令分析SQL执行计划，找出慢查询的原因 ，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改。 创建或优化索引： 根据查询条件创建合适的索引 避免索引失效： 不符合最左匹配原则 查询优化：避免使用SELECT *，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段； 优化数据库表：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，减轻单个表的查询压力。 使用缓存技术： 引入缓存层，如Redis，存储热点数据和频繁查询的结果， 6.4、主键使用自增ID还是UUID？推荐使用自增ID，不要使用UUID。 因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。 总之，在数据量大一些的情况下，用自增主键性能会好一些。 6.5、分库分表 分库 垂直分库：按业务划分，把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。 比如将数据库中的用户表、订单表和商品表分别单独拆分为用户数据库、订单数据库和商品数据库。 水平分库：同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。 分库有个读扩散问题：见B站视频原神那一集（TODO） 分表 垂直分表：简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 优点：可以使得行数据变小，在查询时减少读取的Block数，减少I&#x2F;O次数。 水平分表：是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。 水平分表的分片算法 哈希分片：根据分片键（一般是主键）对分的表数量取模得到的值，确定该行数据分到哪个表 范围分片：特定范围区间的分片键都分配到同一个表中 7、架构7.1、主从复制 原理 MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。 流程如下： MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务， 更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。 从库会创建一个专门的 I&#x2F;O 线程，连接主库的 log dump 线程， 来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里， 再返回给主库“复制成功”的响应。 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志， 然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。 在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库， 这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。 7.2、读写分离读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。 这样的话，就能够小幅提升写性能，大幅提升读性能。 一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。 如何实现读写分离？ 代理方式 我们可以在应用和数据中间加了一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。 提供类似功能的中间件有 MySQL Router（官方， MySQL Proxy 的替代方案）、Atlas（基于 MySQL Proxy）、MaxScale、MyCat。 组件方式 7.3、主从延迟读写分离对于提升数据库的并发非常有效，但是，同时也会引来一个问题：主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 主从同步延迟 。 主从延迟出现的原因 MySQL 主从同步延时是指从库的数据落后于主库的数据，这种情况可能由以下两个原因造成： 从库 I&#x2F;O 线程接收 binlog 的速度跟不上主库写入 binlog 的速度，导致从库 relay log 的数据滞后于主库 binlog 的数据； 从库 SQL 线程执行 relay log 的速度跟不上从库 I&#x2F;O 线程接收 binlog 的速度，导致从库的数据滞后于从库 relay log 的数据。 与主从同步有关的时间点主要有 3 个： 主库执行完一个事务，写入 binlog，将这个时刻记为 T1； 从库 I&#x2F;O 线程接收到 binlog 并写入 relay log 的时刻记为 T2； 从库 SQL 线程读取 relay log 同步数据本地的时刻记为 T3。 结合我们上面讲到的主从复制原理，可以得出： T2 和 T1 的差值反映了从库 I&#x2F;O 线程的性能和网络传输的效率，这个差值越小说明从库 I&#x2F;O 线程的性能和网络传输效率越高。 T3 和 T2 的差值反映了从库 SQL 线程执行的速度，这个差值越小，说明从库 SQL 线程执行速度越快。 如果我们的业务场景无法容忍主从同步延迟的话，应该如何避免呢（注意：我这里说的是避免而不是减少延迟）？ 强制走主库方案：既然你从库的数据过期了，那我就直接从主库读取嘛！这种方案虽然会增加主库的压力，但是，实现起来比较简单 8、内存8.1、BufferPool虽然说 MySQL的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的。 要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。 为此，Innodb 存储引擎设计了一个缓冲池(Buffer Pool)来提高数据库的读写性能。 有了缓冲池后: 当读取数据时，如果数据存在于 Bufer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"框架","slug":"八股/框架","date":"2024-10-28T12:14:40.000Z","updated":"2024-11-30T03:54:40.804Z","comments":true,"path":"2024/10/28/八股/框架/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/%E6%A1%86%E6%9E%B6/","excerpt":"","text":"Spring1、Spring用到哪些设计模式 工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例； 单例模式：Bean默认为单例模式。 代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术； 模板模式：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。 观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。 2、Spring的基本特性 IoC容器 AOP 事务管理 ：Spring提供了一致的事务管理接口，支持声明式和编程式事务。 开发者可以轻松地进行事务管理，而无需关心具体的事务API。 MVC框架： Spring MVC是一个基于Servlet API构建的Web框架， 采用了模型-视图-控制器（MVC）架构。 一、IOC1、IOCIOC(lnversion Of Controll，控制反转)是一种设计思想，就是将原本在程序中手动创建对象的控制权，交由给Spring框架来管理。 IOC 负责创建对象，管理对象（通过依赖注入（DI），装配对象，配置对象，并且管理这些对象的整个生命周期。 IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。 Spring 中的 IoC 的实现原理就是工厂模式加反射机制。 依赖注入：依赖注入和控制反转恰恰相反，它是一种具体的编码技巧。我们不通过 new 的方式在类内部创建依赖类的对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递(或注入)给类来使用。 2、什么是Spring Bean？简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。 我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。 3、Spring注入Bean（依赖注入）的方式？注入Bean的注解有@Autowired,@Resource,@Inject 依赖注入 (Dependency Injection, DI) 的常见方式： 构造函数注入：通过类的构造函数来注入依赖项。 Setter 注入：通过类的 Setter 方法来注入依赖项。 Field（字段） 注入：直接在类的字段上使用注解（如 @Autowired 或 @Resource）来注入依赖项。 123456789101112131415161718192021222324252627282930313233343536371、构造函数注入@Servicepublic class UserService &#123; private final UserRepository userRepository; public UserService(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; //...&#125;2、Setter注入@Servicepublic class UserService &#123; private UserRepository userRepository; // 在 Spring 4.3 及以后的版本，特定情况下 @Autowired 可以省略不写 @Autowired public void setUserRepository(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; //...&#125;3、字段注入@Servicepublic class UserService &#123; @Autowired private UserRepository userRepository; //...&#125; 构造器注入：推荐使用的方式，适用于所有必需的依赖项，确保依赖项在对象创建时已被注入。构造函数注入适合处理必需的依赖项 Setter 注入：适用于可选的依赖项，灵活性较高，但不如构造器注入安全。 Setter 注入 则更适合可选的依赖项，这些依赖项可以有默认值或在对象生命周期中动态设置。 字段注入：最简洁的方式，适用于小项目或快速开发，但不推荐用于大规模项目，因其可维护性差。 4、Bean的作用域重点关注前两种 singleton : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。 prototype : 每次获取都会创建一个新的 bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。 request （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。 session （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。 application&#x2F;global-session （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。 websocket （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。 5、Bean是线程安全的吗？Spring 框架中的 Bean 是否线程安全，取决于其作用域和状态。 我们这里以最常用的两种作用域 prototype 和 singleton 为例介绍。几乎所有场景的 Bean 作用域都是使用默认的 singleton ，重点关注 singleton 作用域即可。 prototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。singleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。 有状态 Bean 示例： 12345678910111213// 定义了一个购物车类，其中包含一个保存用户的购物车里商品的 List@Componentpublic class ShoppingCart &#123; private List&lt;String&gt; items = new ArrayList&lt;&gt;(); public void addItem(String item) &#123; items.add(item); &#125; public List&lt;String&gt; getItems() &#123; return items; &#125;&#125; 不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。 对于有状态单例 Bean 的线程安全问题，常见的三种解决办法是： 避免可变成员变量: 尽量设计 Bean 为无状态。 使用ThreadLocal: 将可变成员变量保存在 ThreadLocal 中，确保线程独立。 使用同步机制: 利用 synchronized 或 ReentrantLock 来进行同步控制，确保线程安全。 ​ 6、spring bean 的生命周期 概括： 实例化（Instantiation） 属性赋值（Populate） 初始化（Initialization） 销毁（Destruction） 实例化：实例化一个 bean 对象；Bean 容器首先会找到配置文件中的 Bean 定义，然后使用 Java 反射 API 来创建 Bean 的实例。 属性赋值：为 Bean 设置相关属性和依赖，例如@Autowired 等注解注入的对象、@Value 注入的值、setter方法或构造函数注入依赖和值、@Resource注入的各种资源。 初始化：第 3~7 步，步骤较多，其中第 5、6 步为初始化操作，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，该阶段结束，才能被用户使用； Aware BeanNameAware：注入当前 bean 对应 beanName； BeanClassLoaderAware：注入加载当前 bean 的 ClassLoader； BeanFactoryAware：注入 当前BeanFactory容器 的引用。 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入 Bean 的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果 Bean 实现了 BeanFactoryAware 接口，调用 setBeanFactory()方法，传入 BeanFactory对象的实例。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果 Bean 实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法。 销毁：第 8~10步，第8步不是真正意义上的销毁（还没使用呢），而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 bean 时再执行相应的方法。 如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的 Bean 销毁方法。 记忆： 整体上可以简单分为四步：实例化 —&gt; 属性赋值 —&gt; 初始化 —&gt; 销毁。 初始化这一步涉及到的步骤比较多，包含 Aware 接口的依赖注入、BeanPostProcessor 在初始化前后的处理以及 InitializingBean 和 init-method 的初始化操作。 销毁这一步会注册相关销毁回调接口，最后通过DisposableBean 和 destory-method 进行销毁。 7、如果让你设计一个SpringIoc，你觉得会从哪些方面考虑这个设计？ Bean的生命周期管理:需要设计Bean的创建、初始化、销毁等生命周期管理机制，可以考虑使用工厂模式和单例模式来实现。 依赖注入:需要实现依赖注入的功能，包括属性注入、构造函数注入、方法注入等，可以考虑使用反射机制和XML配置文件来实现。 Bean的作用域:需要支持多种Bean作用域，比如单例、原型、会话、请求等，可以考虑使用Map来存诸不同作用域的Bean实例。 AOP功能的支持:需要支持AOP功能，可以考虑使用动态代理机制和切面编程来实现。 异常处理:需要考虑异常处理机制，包括Bean创建异常、依赖注入异常等，可以考虑使用try-catch机制来处理异常。 配置文件加载:需要支持从不同的配置文件中加载Bean的相关信息，可以考虑使用XML、注解或者Java配置类来实现。 8、@Resource和@Autowired 的区别都是用来自动装配的，都可以放在属性的字段上 @Autowired通过 byType的方式实现，而且必须要求这个对象存在! @Resource 默认通过 byName的方式实现，如果找不到名字，则通过 byType实现!如果两个都找不到的情况下，就报错 二、AOPAOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 SpringAOP的实现原理： Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理 Spring AOP 和 AspectJ AOP 有什么区别？ Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单， 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。 术语： 术语 含义 目标(Target) 被通知的对象 代理(Proxy) 向目标对象应用通知之后创建的代理对象 连接点(JoinPoint) 目标对象的所属类中，定义的所有方法均为连接点 切入点(Pointcut) 被切面拦截 &#x2F; 增强的连接点（切入点一定是连接点，连接点不一定是切入点） 通知(Advice) 增强的逻辑 &#x2F; 代码，也即拦截到目标对象的连接点之后要做的事情 切面(Aspect) 切入点(Pointcut)+通知(Advice) Weaving(织入) 将通知应用到目标对象，进而生成代理对象的过程动作 通知分类： Before（前置通知）：通知方法在目标方法调用之前执行 After （后置通知）：通知方法在目标方法返回或异常后执行 AfterReturning（返回通知）：通知方法会在目标方法返回后调用 AfterThrowing（异常通知）：通知方法会在目标方法抛出异常后调用 Around （环绕通知）：通知方法会将目标方法封装起来 SpringAOP织入时期 三、spring循环依赖循环依赖是指 Bean 对象循环引用，是两个或多个 Bean 之间相互持有对方的引用，例如 CircularDependencyA → CircularDependencyB → CircularDependencyA。 1234567891011@Componentpublic class CircularDependencyA &#123; @Autowired private CircularDependencyB circB;&#125;@Componentpublic class CircularDependencyB &#123; @Autowired private CircularDependencyA circA;&#125; Spring 框架通过使用三级缓存来解决这个问题，确保即使在循环依赖的情况下也能正确创建 Bean。 一级缓存（singletonObjects）：存放最终形态的 Bean（已经实例化、属性填充、初始化），单例池，为“Spring 的单例属性”⽽⽣。一般情况我们获取 Bean 都是从这里获取的，但是并不是所有的 Bean 都在单例池里面，例如原型 Bean 就不在里面。 二级缓存（earlySingletonObjects）：存放过渡 Bean（半成品，尚未属性填充），也就是三级缓存中ObjectFactory产生的对象，与三级缓存配合使用的，可以防止 AOP 的情况下，每次调用ObjectFactory#getObject()都是会产生新的代理对象的。 三级缓存（singletonFactories）：存放ObjectFactory，ObjectFactory的getObject()方法（最终调用的是getEarlyBeanReference()方法）可以生成原始 Bean 对象或者代理对象（如果 Bean 被 AOP 切面代理）。三级缓存只会对单例 Bean 生效。 Spring 创建 Bean 的流程： 先去 一级缓存 singletonObjects 中获取，存在就返回； 如果不存在或者对象正在创建中，于是去 二级缓存 earlySingletonObjects 中获取； 如果还没有获取到，就去 三级缓存 singletonFactories 中获取，通过执行 ObjectFacotry 的 getObject() 就可以获取该对象，获取成功之后，从三级缓存移除，并将该对象加入到二级缓存中。 举例 12345678class A &#123; // 使用了 B private B b;&#125;class B &#123; // 使用了 A private A a;&#125; 当 Spring 创建 A 之后，发现 A 依赖了 B ，又去创建 B，B 依赖了 A ，又去创建 A； 在 B 创建 A 的时候，那么此时 A 就发生了循环依赖，由于 A 此时还没有初始化完成，因此在 一二级缓存 中肯定没有 A； 那么此时就去三级缓存中调用 getObject() 方法去获取 A 的 前期暴露的对象 ，也就是调用上边加入的 getEarlyBeanReference() 方法，生成一个 A 的 前期暴露对象； 然后就将这个 ObjectFactory 从三级缓存中移除，并且将前期暴露对象放入到二级缓存中，那么 B 就将这个前期暴露对象注入到依赖，来支持循环依赖。 只用两级缓存够吗？ 在没有 AOP 的情况下，确实可以只使用一级和三级缓存来解决循环依赖问题。但是，当涉及到 AOP 时，二级缓存就显得非常重要了，因为它确保了即使在 Bean 的创建过程中有多次对早期引用的请求，也始终只返回同一个代理对象，从而避免了同一个 Bean 有多个代理对象的问题。 总结一下 Spring 如何解决三级缓存： 在三级缓存这一块，主要记一下 Spring 是如何支持循环依赖的即可，也就是如果发生循环依赖的话，就去 三级缓存 singletonFactories 中拿到三级缓存中存储的 ObjectFactory 并调用它的 getObject() 方法来获取这个循环依赖对象的前期暴露对象（虽然还没初始化完成，但是可以拿到该对象在堆中的存储地址了），并且将这个前期暴露对象放到二级缓存中，这样在循环依赖时，就不会重复初始化了！ 不过，这种机制也有一些缺点，比如增加了内存开销（需要维护三级缓存，也就是三个 Map），降低了性能（需要进行多次检查和转换）。并且，还有少部分情况是不支持循环依赖的，比如非单例的 bean 和@Async注解的 bean 无法支持循环依赖。 四、事务1、Spring中如何管理事务编程式事务：在代码中硬编码(在分布式系统中推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，事务范围过大会出现事务未提交导致超时，因此事务要比锁的粒度更小。 声明式事务：在 XML 配置文件中配置或者直接基于注解（单体应用或者简单业务系统推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 声明式事务管理更加简洁，适合大多数情况；而编程式事务管理则提供了更高的灵活性，适用于更复杂的场景。选择合适的事务管理方式，可以有效地保证数据的一致性和完整性。 2、事务怎么开启在 Spring Boot 中开启事务非常简单，只需在服务层的方法上添加@Transactional注解即可。 3、spring的事务什么情况下会失效Spring中如何配置一个类加载一个类不加载 @Autowire和@Resource区别 AOP使用的什么动态代理，AOP动态代理的具体实现过程，详细说明 spring的AOP是什么？谈谈你的理解？这个和aspectj有什么区别吗？你有写过那些切面？ SpringMVCMVC全名是Model View Controller，是模型(model)一视图(view)一控制器(controller)的缩写，一种软件设计典范，用一种业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑。 1、核心组件 DispatcherServlet：核心的中央处理器，负责接收请求、分发，并给予客户端响应。 HandlerMapping：处理器映射器，根据 URL 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。 HandlerAdapter：处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler； Handler：请求处理器，处理实际请求的处理器。 ViewResolver：视图解析器，根据 Handler 返回的逻辑视图 &#x2F; 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端 2、工作原理 客户端（浏览器）发送请求， DispatcherServlet拦截请求。 DispatcherServlet 根据请求信息调用 HandlerMapping 。HandlerMapping 根据 URL 去匹配查找能处理的 Handler（也就是我们平常说的 Controller 控制器） ，并会将请求涉及到的拦截器和 Handler 一起封装。 DispatcherServlet 调用 HandlerAdapter适配器执行 Handler 。 Handler 完成对用户请求的处理后，会返回一个 ModelAndView 对象给DispatcherServlet，ModelAndView 顾名思义，包含了数据模型以及相应的视图的信息。Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispaterServlet 把返回的 Model 传给 View（视图渲染）。 把 View 返回给请求者（浏览器） Mybatis1、Mybatis里的 # 和 $ 的区别？ Mybatis 在处理 #{} 时，会创建预编译的 SQL 语句，将 SQL 中的 #{} 替换为 ? 号，在执行 SQL 时会为预编译 SQL 中的占位符（?）赋值，预编译的 SQL 语句执行效率高，并且可以防止SQL 注入 Mybatis 在处理 ${} 时，只是创建普通的 SQL 语句，然后在执行 SQL 语句时 MyBatis 将参数直接拼入到 SQL 里，不能防止 SQL 注入 sql注入： 假设有一个简单的登录表单，其后端验证用户名和密码的SQL查询如下： sql 1SELECT * FROM users WHERE username = &#x27;输入的用户名&#x27; AND password = &#x27;输入的密码&#x27; 如果攻击者在用户名字段输入： 1&#x27; OR &#x27;1&#x27;=&#x27;1 那么完整的SQL查询将变为： sql 1SELECT * FROM users WHERE username = &#x27;&#x27; OR &#x27;1&#x27;=&#x27;1&#x27; AND password = &#x27;输入的密码&#x27; 由于&#39;1&#39;=&#39;1&#39;始终为真，这个查询将返回数据库中所有用户的记录，导致数据泄露。 2、 MybatisPlus和Mybatis的区别？3、MyBatis运用了哪些常见的设计模式？4、ResultType 和 ResultMap 的区别 如果数据库结果集中的列名和要封装实体的属性名完全一致的话用 resultType 属性。 如果数据库结果集中的列名和要封装实体的属性名有不一致的情况用 resultMap 属 性，通过。resultMap 手动建立对象关系映射，resultMap 要配置一下表和类的–对应关系，所以说就算你的字段名和你的实体类的属性名不一样也没关系，都会给你映射出来 SpringBoot1、why springboot 简化开发:Spring Boot通过提供一系列的开箱即用的组件和自动配置，简化了项目的配置和开发过程，开发人员可以更专注于业务逻辑的实现，而不需要花费过多时间在繁琐的配置上。 快速启动:Spring Boot提供了快速的应用程序启动方式，可通过内嵌的Tomcat、Jetty或Undertow等容器快速启动应用程序，无需额外的部署步骤，方便快捷。 自动化配置:Spring Boot通过自动配置功能，根据项目中的依赖关系和约定俗成的规则来配置应用程序，减少了配置的复杂性，使开发者更容易实现应用的最佳实践。 2、spring VS spring boot Spring Boot 提供了自动化配置，大大简化了项目的配置过程。通过约定优于配置的原则，很多常用的配置可以自动完成，开发者可以专注于业务逻辑的实现。 Spring Boot 提供了快速的项目启动器，通过引入不同的 Starter，可以快速集成常用的框架和库(如数据库、消息队列、Web 开发等)，极大地提高了开发效率。 Spring Boot 默认集成了多种内嵌服务器(如Tomcat、Jetty、Undertow)，无需额外配置，即可将应用打包成可执行的 JAR 文件，方便部署和运行。 3、springboot怎么实现约定大于配置的 自动化配置：Spring Boot根据项目的依赖和环境自动配置应用程序， 无需手动配置大量的XML或Java配置文件。 例如，如果项目引入了Spring Web MVC依赖， Spring Boot会自动配置一个基本的Web应用程序上下文。 起步依赖：Spring Boot提供了一系列起步依赖，这些依赖包含了常用的框架和功能， 可以帮助开发者快速搭建项目。 4、Springboot自动装配5、说几个启动器？写过SpringBoot starter吗SpringCloud了解SpringCloud吗，说一下他和SpringBoot的区别 微服务组件 负载均衡有哪些算法？ 如何实现一直均衡给一个用户？ 熔断降级（了解）","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Spring, SSM","slug":"Spring-SSM","permalink":"http://example.com/tags/Spring-SSM/"}]},{"title":"JUC","slug":"八股/JUC","date":"2024-10-28T12:14:32.000Z","updated":"2024-12-20T02:13:18.397Z","comments":true,"path":"2024/10/28/八股/JUC/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/JUC/","excerpt":"","text":"1、线程基础1、线程和进程的区别？ 进程 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 线程 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。 与进程不同的是同类的多个线程共享进程的堆和方法区资源， 但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间做切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。 2、并行与并发有什么区别？ 并发：两个及两个以上的作业在同一 时间段 内执行。 并行：两个及两个以上的作业在同一 时刻 执行。 3、创建线程的方式有哪些？(四种） 继承 Thread 类 定义一个Thread类的子类，重写run方法； 创建自定义的线程子类对象 调用子类实例的star()方法来启动线程 1234567891011121314151617public class MyThread extends Thread &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; run()方法正在执行...&quot;); &#125;&#125;public class TheadTest &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread(); myThread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行结束&quot;); &#125;&#125; 实现 Runnable 接口 定义Runnable接口实现类MyRunnable，并重写run()方法 创建MyRunnable实例myRunnable，以myRunnable作为target创建Thead对象，该Thread对象才是真正的线程对象 调用线程对象的start()方法 123456789101112131415161718public class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;); &#125;&#125;public class RunnableTest &#123; public static void main(String[] args) &#123; MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); &#125;&#125; 实现 Callable 接口 创建实现Callable接口的类myCallable 以myCallable为参数创建FutureTask对象 将FutureTask作为参数创建Thread对象 调用线程对象的start()方法 12345678910111213141516171819202122232425262728public class MyCallable implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; System.out.println(Thread.currentThread().getName() + &quot; call()方法执行中...&quot;); return 1; &#125;&#125;public class CallableTest &#123; public static void main(String[] args) &#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new MyCallable()); Thread thread = new Thread(futureTask); thread.start(); try &#123; Thread.sleep(1000); System.out.println(&quot;返回结果 &quot; + futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); &#125;&#125; 使用 Executors 工具类创建线程池 Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 主要有newFixedThreadPool，newCachedThreadPool，newSingleThreadExecutor，newScheduledThreadPool，后续详细介绍这四种线程池 4、runnable 和 callable 有什么区别？ Runnable 接口run方法没有返回值 Callable接口call方法有返回值，需要FutureTask获取结果 Callable接口的call()方法允许抛出异常;而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛 5、run()和 start()有什么区别? start():用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。 start方法只能被调用一次。run():封装了要被线程执行的代码，可以被调用多次。 6、线程包括哪些状态？状态之间是如何变化的？状态：新建(NEW)、可运行(RUNNABLE)、阻塞(BLOCKED)、等待(WAITING)、时间等待(TIMED_WALTING)、终止(TERMINATED) 变化： 创建线程对象是新建状态 调用了start()方法转变为可执行状态线 程获取到了CPU的执行权，执行结束是终止状态 在可执行状态的过程中，如果没有获取CPU的执行权，可能会切换其他状态 如果没有获取锁(synchronized或lock)进入阻塞状态，获得锁再切换为可执行状态 如果线程调用了wait()方法进入等待状态，其他线程调用notify()唤醒后可切换为可执行状态 如果线程调用了sleep(50)方法，进入计时等待状态，到时间后可切换为可执行状态 7、notify（）和notifyAll（）的区别？notifyAll() 会唤醒所有的线程，notify() 只会唤醒一个线程。 8、Java中sleep和wait方法有什么不同？ 两者都可以暂停线程的执行 不同点在于： 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。 sleep() 不释放锁；wait() 释放锁。 wait() 方法被调用后，线程不会自动苏醒， 需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。 sleep()方法执行完成后，线程会自动苏醒 ，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 用途不同：Wait 通常被用于线程间交互&#x2F;通信，sleep 通常被用于暂停执行。 8、如何停止一个正在运行的线程？ 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止 使用stop方法强行终止(不推荐，方法已作废) 使用interrupt方法中断线程 打断阻塞的线程(sleep，wait，join)的线程，线程会抛出InteruptedException异常 打断正常的线程，可以根据打断状态来标记是否退出线程 9、线程&#x2F;进程之间的通信方式线程 线程之间的通信由于共享同一个进程的内存空间，可以通过共享数据或同步机制实现。以下是主要的通信方式： 共享变量：多个线程通过共享变量直接读写数据。比如说 volatile 和 synchronized 关键字。 **使用 wait() 和 notify()**，例如，生产者-消费者模式中，生产者生产数据，消费者消费数据，通过 wait() 和 notify() 方法可以实现生产和消费的协调。 ReentrantLock 和条件变量：*使用 ReentrantLock 提供的 Condition 对象进行线程通信。 进程 进程之间由于没有共享内存，通信需要依赖操作系统提供的 IPC（Inter-Process Communication）机制。 管道（Pipe）：单向通信，适用于父子进程间。 信号（Signal）：进程之间通过信号传递简单的通知或控制信息。 消息队列：内核维护的消息队列，支持消息的发送和接收，适合多进程通信。 套接字（Socket）：通过网络通信协议实现跨主机的通信，也可以用于本地进程通信。 **信号量(Semaphores)**：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 共享内存(Shared memory)：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。 这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 10、导致并发程序出现问题的根本原因是说什么？（Java程序中怎么保证多线程的执行安全）并发编程三要素是什么？在 Java 程序中怎么保证多线程的运行安全？ 原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。 可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（synchronized,volatile） 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 出现线程安全问题的原因： 线程切换带来的原子性问题 缓存导致的可见性问题 编译优化带来的有序性问题 解决办法： JDK Atomic开头的原子类、synchronized、LOCK，可以解决原子性问题 synchronized、volatile、LOCK，可以解决可见性问题 Happens-Before 规则可以解决有序性问题 11、死锁产生的条件是什么？ 产生死锁的四个必要条件 互斥条件：所谓互斥就是进程在某一时间内独占资源。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：进程已获得资源，在末使用完之前，不能强行剥夺。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 产生死锁的情况 1.互斥锁顺序问题:如果多个线程按不同的顺序获取锁，并且互相依赖对方释放的锁，就有可能导致死锁。2.资源竞争问题:当多个线程同时竞争有限的资源，例如共享的数据库连接、文件等，在资源分配不当的情况下，可能导致死锁。 如何检测死锁 ​ 使用jstack命令或者使用 VisuaIVM 解决死锁的办法 解决死锁可采取以下方法: 避免死锁的发生，通过破坏死锁产生的四个必要条件之一来预防; 破坏请求与保持条件：一次性申请所有的资源。 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 检测死锁，使用算法检测出是否存在死锁，并采取相应的措施解除死锁; 恢复死锁，即进行资源的强制抢占或进行回滚操作，将进程回退到安全状态以解除死锁。 12、可以直接调用Thread的run方法吗？new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结：调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。 13、同步&#x2F;异步 同步：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。 异步：调用在发出之后，不用等待返回结果，该调用直接返回。 2、voliatle 保证线程间的可见性 确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 禁止指令重排序 如果我们将变量声明为 volatile ，在对这个变量进行读写操作的时候，会通过插入特定的 内存屏障 的方式来禁止指令重排序。以下供理解： 简单说就是JVM为了对代码进行优化提高性能会在不影响结果的情况下把代码执行顺序改变，但多线程就可能会出现结果不对的问题然后volatile原理就是加了一些屏障，使屏障后的代码一定不会比屏障前的代码先执行，从而实现有序性 3、乐观锁和悲观锁 悲观锁 悲观锁:认为自己在使用数据的时候一定有别的线程来修改数据，在获取数据的时候会先加锁，确保数据不会被别的线程修改。 锁实现:关键字synchronized、接口Lock的实现类 适用场景:写操作较多，先加锁可以保证写操作时数据正确 乐观锁 乐观锁:认为自己使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据 锁实现1:CAS算法，CAS即 Compare And swap，是一种更新的原子操作 V：要更新的变量值(Var) E：预期值(Expected) N：拟写入的新值(New) 当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。 ActomicInteger类的原子自增是通过CAS自选实现。 锁实现 2:版本号控制:数据表中加上版本号字段 version，表示数据被修改的次数。当数据被修改时这个字段值会加1，当更新数据时，同时比较版本号，若当前版本号和更新前获取的版本号一致， 则更新成功，否则失败。 适用场景:读操作较多，不加锁的特点能够使其读操作的性能大幅提升 3.2.6、CAS存在的缺点（问题） ABA问题 ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。 循环时间开销大 自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。 只能保证一个共享变量的原子性 只对一个共享变量操作可以保证原子性，但是多个则不行,多个可以通过AtomicReference来处理或者使用锁synchronized实现。 3、synchronized3.2.1、synchronized关键字的底层原理（★在 Java 中，synchronized 关键字是用来控制线程同步的，就是在多线程的环境下，控制 synchronized 代码段不被多个线程同时执行。synchronized 可以修饰类、方法、变量。 使用synchronized之后，编译之后在同步的代码块前后加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题, 执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1。此时其他竞争锁的线程则会进入等待队列中。执行monitorexit指令时则会把计数器-1，当计数器值为0时则锁释放，处于等待队列中的线程再继续竞争锁。 synchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态这种转换非常消耗性能。 3.2.2、synchronized可重入的原理重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。 3.2.3、什么是自旋很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 3.2.4、多线程中 synchronized 锁升级的原理是什么？无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁 偏向锁：第一次使用需要CAS操作，后续再获取该锁只要线程id一样（是同一个线程）就无需再用CAS操作 轻量级锁：每次都需要CAS操作 synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。 锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。 Java中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被一个线程持有、不同线程交替持有锁、多线程竞争锁三种情况。 重量级锁 底层使用的Monitor实现，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高性能比较低。 轻量级锁 线程加锁的时间是错开的(也就是没有竞争)，可以使用轻量级锁来优化。轻量级修改了对象头的锁标志，相对重量级锁性能提升很多。每次修改都是CAS操作，保证原子性 偏向锁 一段很长的时间内都只被一个线程使用锁，可以使用了偏向锁，在第一次获得锁时会有一个CAS操作，之后该线程再获取锁，只需要判断mark word中是否是自己的线程id即可，而不是开销相对较大的CAS命令 3.2.5、synchronized 和 volatile 的区别是什么？​ synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！ volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。 volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。 volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。 volatile不能完全保证在多线程下的线程安全 3.2.8、synchronized和Lock有什么区别？ 首先synchronized是Java内置关键字，在JVM层面，Lock是个Java类； synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。 4、ReentrantLockReentrantLock 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。 但提供了比 synchronized 更细粒度的锁控制，支持公平锁、可中断锁、尝试获取锁等功能。 适用场景： 当需要更复杂的锁控制、当线程需要中断时、当锁的获取需要超时限制时， 1、公平锁和非公平锁公平锁 : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。 非公平锁：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。 2、synchronized 和 ReentrantLock 的区别是什么？、 两者都是可重入锁 可重入锁 也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。 synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API synchronized 是JM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。 ReentrantLock比sychronized 增加了一些高级功能 ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。 synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。 3、可中断锁和不可中断锁有什么区别?可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。 不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。 5、ThreadLocal1、是什么ThreadLocal是线程本地变量，在多线程并发执行过程中，为保证多个线程对变量的安全访问，可以将变量放到ThreadLocal类型的对象中，使变量在每个线程中都有独立值，线程之间互不影响，相互隔离，提高了线程安全性 2、原理ThreadLocal底层使用ThreadLocalMap存储数据，它是一个哈希表，每个线程都有一个相关联的ThreadLocalMap。ThreadLocalMap的key是ThreadLocal实例，对应的value是需要存储的值 key：ThreadLocal value：需要存储的值 3、内存泄露问题使用线程池时，线程池中的线程会被重复使用。ThreadLocalMap是Thread中的一个属性，因此，ThreadLocalMap的生命周期与Thread一致。map中Entry对象的key被设置成弱引用，会被垃圾回收器回收，但是value不会被回收（ value 是强引用 ），从而造成内存泄漏。解决办法就是使用完之后调用remove()。 6、线程池作用：管理和复用线程，提高程序的性能和资源利用率，控制线程数量，避免系统过载 降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度：当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程复用原理：线程池对 Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程循环检查是否还有任务等待被执行，如果有则直接去执行这个任务，也就是调用任务的 run 方法，相当于把每个任务的 run() 方法串联了起来，所以线程数量并不增加。 1、线程池的核心参数（线程池的执行原理） corePoolSize：线程池核心线程数量 maximumPoolSize：线程池中最多可容纳的线程数量。 keepAliveTime ：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间 unit ：keepAliveTime的单位 workQueue：线程池所使用的缓冲队列，被提交但尚未被执行的任务 threadFactory：线程工厂，用于创建线程 handler：拒绝策略，线程池任务队列超过 maxinumPoolSize 之后的拒绝策略 流程 2、线程池的拒绝策略预置的有四种策略 AbortPolicy(默认方式，直接抛出一个任务被线程池拒绝的异常。 CallerRunsPolicy：由线程池的调用者所在的线程去执行被拒绝的任务 DiscardPolicy(不做任何处理，静默拒绝提交的任务。 DiscardOldestPolicy(丢弃最早被添加到队列的任务，然后尝试重新提交新任务) 如果希望快速失败并将异常传递给调用者，则选择AbortPolicy。如果希望尽可能保证任务的执行而不堆积在队列中，则选择CallerRunsPolicy。如果对任务的丢失情况不敏感，则选择 DiscardPolicy。而如果希望尽可能保留最新的任务而不是旧日的任务，则选择DiscardOldestPolicy。 3、线程池的大小如何设定？N是CPU核心数，设置corePoolSize的大小为： CPU密集型任务：N+1。这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N(CPU 核心数)+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。 I&#x2F;O密集型任务：2N。这种任务应用起来，系统会用大部分的时间来处理 I&#x2F;O 交互，而线程在处理 I&#x2F;0 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I&#x2F;O密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。 4、为什么不推荐使用Executors创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 各个方法的弊端： （加粗的也是创建线程池的四种方式，分别是创建固定大小的线程池，创建一个单线程的线程池，创建可缓存的线程池，创建一个无限大小的线程池） newFixedThreadPool 和 newSingleThreadExecutor: 程池的任务队列使用的是无界队列 LinkedBlockingQueue，可以无限地接受任务。这可能会导致 内存溢出（OOM） 的情况，特别是在任务提交过多且任务处理速度跟不上时。 newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 ThreaPoolExecutor创建线程池方式只有一种，就是走它的构造函数，参数自己指定 四种线程池： FixedThreadPool ：固定大小的线程池 如果当前运行的线程数小于 corePoolSize， 如果再来新任务的话，就创建新的线程来执行任务； 当前运行的线程数等于 corePoolSize 后， 如果再来新任务的话，会将任务加入 LinkedBlockingQueue； 线程池中的线程执行完 手头的任务后，会在循环中反复从 LinkedBlockingQueue 中获取任务来执行； SingleThreadExecutor： 是只有一个线程的线程池 如果当前运行的线程数少于 corePoolSize，则创建一个新的线程执行任务； 当前线程池中有一个运行的线程后，将任务加入 LinkedBlockingQueue 线程执行完当前的任务后，会在循环中反复从LinkedBlockingQueue 中获取任务来执行 CachedThreadPool：根据需要创建新线程的线程池 CachedThreadPool 的corePoolSize 被设置为空（0），maximumPoolSize被设置为 Integer.MAX.VALUE， 即它是无界的，这也就意味着如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时， CachedThreadPool 会不断创建新的线程。极端情况下，这样会导致耗尽 cpu 和内存资源。 ScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 核心线程数固定，但任务队列为无界队列（DelayedWorkQueue）。 7、什么是AQS？AQS，全称是 AbstractQueuedSynchronizer，中文意思是抽象队列同步器。AQS 就是一个抽象类，主要用来构建锁和同步器。 AQS 的思想是，如果被请求的共享资源空闲，则当前线程能够成功获取资源；否则，它将进入一个等待队列，当有其他线程释放资源时，系统会挑选等待队列中的一个线程，赋予其资源。 是多线程中的队列同步器。是一种锁机制，它是做为一个基础框架使用的，像ReentrantLock、Semaphore都是基于AQS实现的 AQS内部维护了一个先进先出的双向队列，队列中存储的排队的线程在AQS内部还有一个 int 属性state，这个state就相当于是一个资源，默认是0(无锁状态)，如果队列中的有一个线程修改成功了state为1，则当前线程就相等于获取了资源 在对state修改的时候使用的cas操作，保证多个线程修改的情况下原子性 以 ReentrantLock 为例，state 初始值为 0，表示未锁定状态。A 线程 lock() 时，会调用 tryAcquire() 独占该锁并将 state+1 。此后，其他线程再 tryAcquire() 时就会失败，直到 A 线程 unlock() 到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 state 是能回到零态的。 再以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后countDown() 一次，state 会 CAS(Compare and Swap) 减 1。等到所有子线程都执行完后(即 state=0 )，会 unpark() 主调用线程，然后主调用线程就会从 await() 函数返回，继续后余动作。 1、semaphore有什么用？synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，而Semaphore(信号量)可以用来控制同时访问特定资源的线程数量。 Semaphore 的使用简单，我们这里假设有 N(N&gt;5) 个线程来获取 Semaphore 中的共享资源，下面的代码表示同一时刻 N 个线程中只有 5 个线程能获取到共享资源，其他线程都会阻塞，只有获取到共享资源的线程才能执行。等到有线程释放了共享资源，其他阻塞的线程才能获取到。 Semaphore 通常用于那些资源有明确访问数量限制的场景比如限流（仅限于单机模式，实际项目中推荐使用 Redis +Lua 来做限流）。 2、semaphore的原理Semaphore 是共享锁的一种实现，它默认构造 AQS 的 state 值为 permits，你可以将 permits 的值理解为许可证的数量，只有拿到许可证的线程才能执行。 调用semaphore.acquire() ，线程尝试获取许可证，如果 state &gt;= 0 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 state 的值 state=state-1。如果 state&lt;0 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程。 调用semaphore.release(); ，线程尝试释放许可证，并使用 CAS 操作去修改 state 的值 state=state+1。释放许可证成功之后，同时会唤醒同步队列中的一个线程。 被唤醒的线程会重新尝试去修改 state 的值 state=state-1 ，如果 state&gt;=0 则获取令牌成功，否则重新进入阻塞队列，挂起线程。 3、CountDownLatch有什么用？CountDownLatch 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。 CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。 4、CountDownLatch的原理是什么CountDownLatch 是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。 当线程使用 countDown() 方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state,直至 state 为 0 。 当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。 直到count 个线程调用了countDown()使 state 值被减为 0，或者调用await()的线程被中断，该线程才会从阻塞中被唤醒，await() 方法之后的语句得到执行。 5、用过CountDownLatch吗？什么场景下用的测试分布式ID生成速度的时候用过 1234567891011121314151617181920212223242526272829303132333435//测试类@SpringBootTestpublic class RedisIdWorkerTest &#123; @Resource private RedisIdWorker redisIdWorker; private ExecutorService es = Executors.newFixedThreadPool(500); /** * 测试分布式ID生成器的性能，以及可用性 */ @Test public void testNextId() throws InterruptedException &#123; // 使用CountDownLatch让线程同步等待 CountDownLatch latch = new CountDownLatch(300); // 创建线程任务 Runnable task = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; long id = redisIdWorker.nextId(&quot;order&quot;); System.out.println(&quot;id = &quot; + id); &#125; // 等待次数-1 latch.countDown(); &#125;; long begin = System.currentTimeMillis(); // 创建300个线程，每个线程创建100个id，总计生成3w个id for (int i = 0; i &lt; 300; i++) &#123; es.submit(task); &#125; // 线程阻塞，直到计数器归0时才全部唤醒所有线程 latch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;生成3w个id共耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125;","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://example.com/tags/JUC/"}]},{"title":"白骡头条","slug":"白骡头条","date":"2024-10-23T12:08:21.000Z","updated":"2024-10-27T13:37:11.080Z","comments":true,"path":"2024/10/23/白骡头条/","permalink":"http://example.com/2024/10/23/%E7%99%BD%E9%AA%A1%E5%A4%B4%E6%9D%A1/","excerpt":"","text":"写在前面虽然目前正在实习，但也可以逐步开始微服务的相关学习了，所以这个项目，我的学习目标是： 吃透该项目，在看完视频教程后独立完成相应需求开发 不求速度，求质量，这个项目时间还是比较充裕的 学会该项目涉及技术栈的日常基础使用 10-23 day01nacos环境搭建1、配置虚拟镜像 更改虚拟机子网地址 图上写错了，是选择vm8，然后更改子网IP 更改虚拟机设置-网络适配器-改为vm8-net模式 视频里面用的是finalshell连接的虚拟机，我这里用的是xShell，注意建立连接，如果按照视频里面192.168.200.130建立连接的话，需要先看看虚拟机里面的IP地址，然后可以更改为192.168.200.130才能连接成功 按照如下更改好之后，再回到图2重新打开一下开关就可以更新IP地址了 今天先到这。。。要用docker安装nacos，，我docker还没安装，费劲。。。。 10-24 day02docker安装发现centos根本连不了网，不知道哪里出了问题 虚拟主机网络的三种模式区别直接用上个图这里来说 仅主机模式 虚拟机仅可以与主机进行通信 桥接模式 宿主机和虚拟机,都是由局域网路由(DHCP)进行IP的分配 宿主机和本地的虚拟机之间可以进行通信 局域网内其他机器也可以与虚拟机进行通信 缺点：虚拟机会占用大量的IP,局域网内如果机器太多,或者虚拟机太多,那么会出现大量的IP冲突 通俗的说：虚拟机就相当于一台真实的机器，如果虚拟机数量多的话，会占用局域网内的IP，可能会造成局域网内的IP冲突 NAT模式 宿主机和其他机器的IP由局域网路由进行IP的分配,虚拟机的IP通过VMnet8虚拟交换机进行分配 宿主机和本地的虚拟机之间可以进行通信 不会占用宿主机所在路由IP,不会造成IP冲突 通俗的说：宿主机再内置一个局域网，里面是这些虚拟机，这些虚拟机就不会占用现实局域网的IP了，虚拟机也可以与外网通信，唯一的方式就是借助宿主机，别人访问不到你的虚拟机。缺点：无法与外界的虚拟机通信 10-27 day03 哎哟，费了半天劲把centos的网络问题解决了，结果安装docker又废了半天劲，参考了这篇，才算解决好docker的安装问题，然后nacos又安装拉不下来了，好像是要配置阿里的镜像加速源，结果也没用，，，就是图上这个问题 报错：Error response from daemon: Get “https://registry-1.docker.io/v2/“: net&#x2F;http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) 哎哟无语了。。。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"项目","slug":"项目","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"杂谈","slug":"杂谈","date":"2024-10-20T02:25:39.000Z","updated":"2024-10-20T02:39:06.660Z","comments":true,"path":"2024/10/20/杂谈/","permalink":"http://example.com/2024/10/20/%E6%9D%82%E8%B0%88/","excerpt":"","text":"以下内容从网上看到的记录一下 感觉“不舒服”的地方要远离，相信自己的直觉 不要随便说不吉利的话，也不要随便骂人，甚至是诅咒别人，不管在网上还是现实。语言是很有能量的东西，不要给自己制造负能量 家里，尤其是卧室最好不要摆放人形玩偶 勿以善小而不为，勿以恶小而为之 家中的植物尽量避免蕨类和藤曼类的植物，以阔叶类植物为佳 未完待续…","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"杂谈记录","slug":"杂谈记录","permalink":"http://example.com/tags/%E6%9D%82%E8%B0%88%E8%AE%B0%E5%BD%95/"}]},{"title":"歌单迁移","slug":"歌单迁移","date":"2024-10-17T14:15:39.000Z","updated":"2024-10-17T14:19:50.382Z","comments":true,"path":"2024/10/17/歌单迁移/","permalink":"http://example.com/2024/10/17/%E6%AD%8C%E5%8D%95%E8%BF%81%E7%A7%BB/","excerpt":"","text":"迁移网易云&#x2F;QQ音乐歌单 至 Apple&#x2F;Youtube&#x2F;Spotify Music一、源音乐文件导出Go-Music官网：https://music.unmeta.cn/ Go-Music 可以把网易云或者QQ音乐平台上面的歌单，以文本的形式导出。 二、迁移Tunemymusic 官网：https://www.tunemymusic.com/zh-CN/transfer 按步骤操作即可，需注意的是免费版一次最多迁移500首歌曲 参考文献：https://coderschool.cn/3791.html","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"http://example.com/tags/%E9%9F%B3%E4%B9%90/"}]},{"title":"前端了解","slug":"技术类/前端了解","date":"2024-10-17T12:29:34.000Z","updated":"2024-10-17T12:33:49.110Z","comments":true,"path":"2024/10/17/技术类/前端了解/","permalink":"http://example.com/2024/10/17/%E6%8A%80%E6%9C%AF%E7%B1%BB/%E5%89%8D%E7%AB%AF%E4%BA%86%E8%A7%A3/","excerpt":"","text":"vscode安装插件HTML css support live server：在浏览器中实时预览页面的变化 auto rename tag：修改HTML标签的时候同步修改另一个标签 一、HTML标签单标签用于没有内容的元素，双标签用于有内容的元素 快速生成HTML初始结构：在vocode中！+tab键 标题标签 h1-6分别对应1-6级标题 文本标签 p段落标签 b字体加粗，i斜体，u下划线，s删除线 ul——li无序标签 ol——li有序列表 1 HTML属性 语法 &lt;开始标签 属性名&#x3D;“属性值”&gt; 属性名不区分大小写，但属性值区分 适用大多数HTML元素的属性 class：为 HTML元素定义一个或多个类名(类名从样式文件引入) id：定义元素唯一的 id style：规定元素的行内样式 二、HTML区块-块元素与行内元素块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。 块级元素通常会从新行开始，并占据整行的宽度，因此它们会在页面上呈现为一块独立的内容块。 可以包含其他块级元素和行内元素。 常见的块级元素包括div&gt;，&lt;p&gt;，&lt;h1&gt;到&lt;h6&gt;,,‘等 行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接强调文本等。 行内元素通常在同一行内呈现，不会独占一行。 它们只占据其内容所需的宽度，而不是整行的宽度。 行内元素不能包含块级元素，但可以包含其他行内元素。 常见的行内元素包括span&gt;，&lt;img&gt;，&lt;br&gt;，&lt;input&gt;等, 三、HTML表单form span标签等于label CSS","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"影视点评","slug":"影视点评","date":"2024-10-10T13:36:25.000Z","updated":"2025-01-17T14:10:11.210Z","comments":true,"path":"2024/10/10/影视点评/","permalink":"http://example.com/2024/10/10/%E5%BD%B1%E8%A7%86%E7%82%B9%E8%AF%84/","excerpt":"","text":"电视剧 人民的名义：9分 都挺好：8.5分 征服：9分 破冰行动：8.5分 狂飙：9分 马大帅1：8.5分 武林外传：10分 富贵：9.5分 我是余欢水：8分（有点高开低走 沉默的真相：9分 隐秘的角落：9分 漫长的季节：9.分 地下交通站-第一季：10分 三国演义：10分 少帅：9分 大宅门：9.5分！ 边水往事：7.5分（高开低走 权力的游戏-综评：9分 黑袍纠察队-综评：8.5分 韦恩：看的时间太长有点忘了，暂给8分 闯关东：9.5分！ 我是大哥大：10分！ 大染坊：9分 电影 让子弹飞：10分！ 异次元骇客：10分！","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"影视","slug":"影视","permalink":"http://example.com/tags/%E5%BD%B1%E8%A7%86/"}]},{"title":"MybatisPlus学习","slug":"技术类/MybatisPlus学习","date":"2024-10-09T14:49:21.000Z","updated":"2024-10-16T14:07:36.979Z","comments":true,"path":"2024/10/09/技术类/MybatisPlus学习/","permalink":"http://example.com/2024/10/09/%E6%8A%80%E6%9C%AF%E7%B1%BB/MybatisPlus%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"一、快速入门1.1、使用1、引入依赖 注意：引入了MP的依赖，就不用引Mybatis的依赖了，这个依赖已经包含了Mybatis的 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt; &lt;/dependency&gt; 2、定义Mapper 自定义的Mapper继承MybatisPlus提供的BaseMapper接口（要制定实体类的类型） 3、在实体类上添加注解声明表信息 4、在application.yml中根据需要添加配置 1.2、常见注解MyBatisPlus通过扫描实体类，并基于反射获取实体类信息作为数据库表信息 约定： 类名驼峰转下划线作为表名 名为id的字段作为主键 变量名驼峰转下划线作为表的字段名 如果实体和表的对应关系不符合以上约定，就要用注解来配置了 @TableName：用来指定表名 @TableId：用来指定表中的主键字段信息 @TableField：用来指定表中的普通字段信息 对于@TableId，IdType枚举： AUTO:数据库自增长 INPUT:通过set方法自行输入 ASSIGN_ID:分配ID，接口ldentifierGenerator的方法nextld来生成id 使用@TableField的常见场景： 成员变量名与数据库字段名不一致 成员变量名以is开头，且是布尔值 成员变量名与数据库关键字冲突 成员变量不是数据库字段 二、核心功能2.1、条件构造器MyBatisPlus支持各种复杂的where条件，可以满足日常开发的所有需求。 第一步：构建查询条件 第二步：操作（查询更新等） 推荐还是用lambda的模式 QueryWrapper和LambdaQueryWrapper通常用来构建selectdelete、update的where条件部分UpdateWrapper和LambdaUpdateWrapper通常只有在set语句比较特殊才使用尽量使用LambdaQueryWrapper和LambdaUpdateWrapper避免硬编码 2.2、自定义SQLMP擅长where条件的构建，因此我们可以利用MyBatisPlus的Wrapper来构建复杂的Where条件，然后自己定义SQL语句中剩下的部分。 基于Wrapper构建where条件 在mapper方法参数中用Param注解声明wrapper变量名称，必须是ew 自定义SQL，并使用Wrapper条件 2.3、Service接口2.3.1、IService接口的基本使用 MP的Service接口使用流程是怎样的? 自定义Service接口继承IService接口 自定义Service实现类，实现自定义接口并继承Servicelmpl类","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MybatisPlus","slug":"MybatisPlus","permalink":"http://example.com/tags/MybatisPlus/"}]},{"title":"广州南北科技面经","slug":"面经/广州南北科技面经","date":"2024-10-09T13:23:30.000Z","updated":"2024-10-10T04:17:23.667Z","comments":true,"path":"2024/10/09/面经/广州南北科技面经/","permalink":"http://example.com/2024/10/09/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E5%8D%97%E5%8C%97%E7%A7%91%E6%8A%80%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"广州小厂，面试问的问题感觉很奇怪，总共聊了半小时 聊了好长时间本科的毕业设计和现在的研究方向 ArrayList的底层实现，扩容机制； 然后问扩容，Arraylist正在add元素的时候，新数组和旧数组怎么处理（不是往新数组里面拷贝旧数组的元素吗 HashMap链表的扩容机制，链表里面是values，values是怎么存储的； 答：得到在数组中的索引，如果该处节点是链表，会在链表中遍历有没有相同的key，如果有就更新value，没有就在链表末尾插入，最后判断链表长度是否达到阈值（8，这个阈值忘了，直接说的阈值），是的话就转化为红黑树，增加查找效率 问了下平时用什么开发工具 很大的表，用Select count去统计表的条数，发现特别慢，怎么优化 不会，一开始没听清楚瞎答了索引，然后又说什么select count（1），，自己都有点想笑哈哈哈 很大的表，发现不管干啥都慢，有什么办法优化 不会，想到了分库分表，没看这个八股， 然后又问分（区）表策略，没了解 后面就聊到我的本科毕业设计了 然后又问springboot怎么实现‘约定大于配置’的，不会 redis怎么实现分布式锁 setnx命令 又说看我这边是用了lua脚本，直接说的没学过，就是跟着视频用的 最后反问环节","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"广州泰豪软件面经","slug":"面经/广州泰豪软件面经","date":"2024-10-09T13:15:47.000Z","updated":"2024-10-10T04:22:16.023Z","comments":true,"path":"2024/10/09/面经/广州泰豪软件面经/","permalink":"http://example.com/2024/10/09/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E6%B3%B0%E8%B1%AA%E8%BD%AF%E4%BB%B6%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"用时差不多正好半小时，面的是泰豪软件（广州），面试官人感觉不错。第一次面试感觉没有想象中的那么紧张，八股和项目都问了一点。 上来自我介绍 八股： private，default，protected，public的区别； &amp;和&amp;&amp;的区别； final关键字； break，continue，return； 单列集合，List和Set有什么区别； CopyOnWriteArrayList； 多线程同步有哪几种方式（就回答了synchronized和lock）； 常用的线程池有哪几种（一开始想说那个英文方法名，磕巴了半天没说出来还，最后直接用中文说了）； 线程之间是怎么传递数据的（没回答好，没准备这个八股）； 创建线程有几种方式； 项目： 除了MySQL还了解过其它数据库吗（本科的时候学过Oracle，没了）； 设计redis的缓存更新策略的时候，考虑哪些因素（1、过期时间，2、先更新数据库，再删除缓存，更新缓存。不知道 回答的对不对）； 怎么解决缓存击穿和缓存穿透的（介绍了一下这俩是什么，然后回答的，缓存击穿答得不是很详细，有点混乱了）； 后面就是聊天了 问了意向城市， 然后学习和做项目的时候有没有碰到什么问题，是怎么解决的 对前端有了解吗，vue，如果有这方面的学习愿不愿意了解一下 问了下如果通过最快什么时候能到岗 个人职业规划 反问环节，问了几个。最后面试官介绍了一下他们公司业务什么的","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"RabbitMQ学习","slug":"技术类/RabbitMQ","date":"2024-10-09T08:39:20.000Z","updated":"2024-10-10T04:05:45.174Z","comments":true,"path":"2024/10/09/技术类/RabbitMQ/","permalink":"http://example.com/2024/10/09/%E6%8A%80%E6%9C%AF%E7%B1%BB/RabbitMQ/","excerpt":"","text":"1、消息队列有啥用？ 异步处理 系统可以将那些耗时的任务放在消息队列中异步处理，从而快速响应用户的请求。比如说，用户下单后，系统可以先返回一个下单成功的消息，然后将订单信息放入消息队列中，后台系统再去处理订单信息。 削峰限流 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 降低系统耦合性 生产者将消息放入队列，消费者从队列中取出消息，这样一来，生产者和消费者之间就不需要直接通信，生产者只管生产消息，消费者只管消费消息，这样就实现了解耦。 2、常见的MQ产品 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka(大吞吐量才会去使用) 追求消息低延迟：RabbitMQ、Kafka 3、 RabbitMQ 工作模式 简单模式： 特点:使用单个生产者将消息发送到单个消费者。 应用场景:适用于简单的任务分发，消息的顺序不重要 工作队列模式： 特点:多个生产者将消息发送到一个或多个消费者。 应用场景:适用于任务分发，提高系统的并发处理能力。 发布订阅模式： 多了一个 Exchange 角色，而且过程略有变化： 生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） 消费者，消息的接收者，会一直等待消息到来 消息队列，接收消息、缓存消息 交换机一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange与消息队列的绑定模式： 3.1、广播模式（fanout） ​ 将消息交给所有绑定到交换机的队列 3.2、路由模式（定向模式，Direct ） ​ 把消息交给符合指定routing key 的队列，如果路由键完全匹配的话，消息才会被投放到相应的队列 3.3、主题模式（Topic） ​ 通配符，把消息交给符合routing pattern（路由模式） 的队列，设置模糊的绑定方式，“*”操作符将“.”视为分隔符，匹配单个字 符；“#”操作符没有分块的概念，它将任意“.”均视为关键字的匹配部分，能够匹配多个字符 4、rabbitmq如何保证消息的可靠性? 生产端(Producer)的可靠性保证措施: 发布者确认(Publisher Confirms):生产者可以通过启用发布者确认机制，在消息成功发送给RabbitMQ后接收确认回执，确保消息已被正确接收。 服务端(Broker)的可靠性保证措施:持久化(Durability): 队列和交换机可设置为持久化，使其在RabbitMQ重新启动后不会丢失 持久化消息:被标记为持久化的消息，会写入磁盘，确保消息在服务器故障时不会丢失。 消费端(Consumer)的可靠性保证措施:手动消息确认(Manual Message Acknowedgement):消费者在处理完消息后，发送确认回执给RabbitMQ，告知消息已被成功处理，RabbitMQ可以删除该消息。 5、rabbitmq如何避免消息堆积?1.去优化消费者代码，提高消费能力。减少消费时间 2.可以给消费设置年龄（生命周期），如果超时就丢弃掉。可以不让消息大量堆积在消息队列中 3.可以设置队列的最大长度：如果超过了，就无法接收消息到队列中。 6、MQ如何保证顺序消费RabbitMQ的queue本身就是队列，是可以保证消息的顺序投递的。 但是消息的顺序消费则是另一回事了，所谓的“顺序消费”意味着是否顺序达到目的地，比如：数据库。 看看以下场景： 一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1&#x2F;data2&#x2F;data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1&#x2F;data3。这不明显乱了。 产生多个consumer去消费一个queue，极有可能是因为：消息消费太慢，所以盲目让多个consumer同时来消费，而忽略了消息消费顺序性。 在某些情况下，消息是需要保证顺序性的，如果上图中的data1, data2, data3 分别意味着对某条数据的增改删，但是如果乱序以后就变成了：删改增。 解决方案： 将原来的一个queue拆分成多个queue，每个queue都有一个自己的consumer。该种方案的核心是生产者在投递消息的时候根据业务数据关键值(例如订单ID哈希值对订单队列数取模)来将需要保证先后顺序的同一类数据(同一个订单的数据)发送到同一个queue当中。 7、MQ如何消息不丢失，持久化 消息持久化 ACK确认机制（项目中使用）：ACK确认机制是消费者从队列中收到消息，进行业务逻辑的处理，在这一过程中如果消费者出现服务器异常、网络不稳定等，都不会有ACK应答，这时候RabbitMQ就认为这条消息没有正常消费成功，就会将消息重新放回队列中。直到消费者发送ACK应答，这条消息才会从队列中消费掉。使用：需要手动开启配置，yaml文件 publisher-confirm-type: correlated # 开启确认机制回调 必须配置这个才会确认回调 ​ publisher-returns: true # 开启return机制回调 设置集群镜像模式 消息补偿机制 消息持久化解决： 消息中心收到生产者的消息后，先将消息存储在本地数据文件，内存数据库或者远程数据库，再试图把消息发送给消费者，发送成功则讲消息从存储中删除，如失败则继续尝试发送消息中心启动时，先会检查指定的存储位置，如有未成功发送的消息，则会把消息发送出去 Exchange 设置持久化：基于代码的，参数设为true Queue 设置持久化 Message持久化发送：发送消息设置发送模式deliveryMode&#x3D;2，代表持久化消息 8、 死信队列是什么 DLX，全称为 Dead-Letter-Exchange ，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。 产生死信的情况： 消息被拒绝(Reiected)：当消费者拒绝消费消息或者消息超过消费者的最大重试次数时，消息会被发送到死信队列。 消息过期(Expired))：如果消息在一定时间内没有被消费者处理，即超过了消息的过期时间，该消息也会被发送到死信队列。 队列达到最大长度(Queue Length Limit)：当队列达到了定义的最大长度限制，新的消息无法进入队列，会将旧的消息发送到死信队列。 9、RabbitMQ消息重复消费问题（保证幂等性）RabbitMQ消息重复消费问题通常是由以下原因导致的: 生产者用于发送消息失败后的重试，导致又发送了一次重复的消息 消费者应用程序在处理消息时发生了错误，导致消息确认(ack)没有发送给RabbitMQ，从而导致RabbitMQ将消息重新分发给其他消费者进行消费。 网络问题或消费者应用程序重启时，RabbitMQ无法收到消息确认，也会导致消息重新分发。 为了解决消息重复消费问题(保证消费幂等性)，可以采取以下措施: 生产端: 生产消息时，为每个消息设置唯一的消息ID(可以使用雪花算法生成唯一ID)。 消费端: 加锁：消费者在处理消息之前，使用redis(更好的是使用Redisson框架，可以自动锁续期)的set命令添加nx选项设置分布式锁，key为消息id，值是任意值。如果设置分布式锁失败，则忽略重复消息，拒绝处理。如果设置分布式锁成功，则处理业务。 消息确认：消费者应及时地发送消息确认(ack)给RabbitMQ，表示已经成功处理了消息。这样RabbitMQ就不会将消息重新分发给其他消费者。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"从设备来理解计算机网络","slug":"技术类/从设备来理解计算机网络","date":"2024-10-03T12:17:15.000Z","updated":"2024-10-10T04:22:43.405Z","comments":true,"path":"2024/10/03/技术类/从设备来理解计算机网络/","permalink":"http://example.com/2024/10/03/%E6%8A%80%E6%9C%AF%E7%B1%BB/%E4%BB%8E%E8%AE%BE%E5%A4%87%E6%9D%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"一、Hub集线器（物理层）广播消息，由设备自己判断该消息是否发送给自己的 但如果两个设备同时发送电平信号，会导致消息杂糅起来，导致想接收的设备解析不了 CSMA&#x2F;CD协议：载波监听在发送消息之前先检测有无设备正在发送消息 缺点： 只能有一个设备同时发送数据 需要广播消息，占用带宽 二、SW交换机（数据链路层）交换机可记录标识：（设备）Mac地址和（交换机）端口的映射 对HUB的改进 所以这种方式不需要将消息广播 而且交换机采用的是全双工，就是可以边发边收，而集线器是半双工的，不能同时收发消息 交换机可以桥接交换机，就是可以通过某个端口向另一个交换机的设备发送消息 缺点： 可以在局域网内使用，在大规模网络中就有点乏力了，要找到设备需要不停的广播（一开始交换机中未记录对应映射的时候），可能会造成泛洪 三、路由器（网关）（网络层）多个网络之间的通信 这里提出IP地址：一是标识网络，二是标识设备。 IP地址是一个抽象的地址，真正传输的时候还是需要mac地址（真实地址） 所以在同一个网络内传输时 先根据目标IP地址得到其mac地址，ARP协议 就可以进行传输了","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"广州亿迅科技面经","slug":"面经/广州亿迅科技面经","date":"2024-09-29T10:43:20.000Z","updated":"2024-10-10T04:31:36.029Z","comments":true,"path":"2024/09/29/面经/广州亿迅科技面经/","permalink":"http://example.com/2024/09/29/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E4%BA%BF%E8%BF%85%E7%A7%91%E6%8A%80%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"全程大概半小时左右，都不是严格的问答，比较开放式的，感觉跟报菜名似的，全是八股项目几乎没问 聊到一些集合类，把List，Map，Set都介绍了一下，以及对应的使用场景 ArrayList和LinkedList的区别 ArrayList的扩容机制 HashMap简单说了一下，都没涉及到put流程 I&#x2F;O，不熟 项目中怎么用的乐观锁悲观锁 网络编程，Socket，不熟 NIO&#x2F;BIO，不熟 序列化和反序列化，怎么让一部分数据不被序列化，第二个忘了 Spring的IOC和AOP sql的全称，忘了。。-_-|| 然后问的视图，存储过程，都没背。。 索引简单答了一下底层数据结构 表之间的连接 JDBC，没看， String，StringBuffer，StringBulder &#x3D;&#x3D;和equals 后续10.8 OC","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"Spring面试常问题目","slug":"技术类/Spring面试常问题目","date":"2024-09-26T03:09:46.000Z","updated":"2024-10-10T04:06:18.686Z","comments":true,"path":"2024/09/26/技术类/Spring面试常问题目/","permalink":"http://example.com/2024/09/26/%E6%8A%80%E6%9C%AF%E7%B1%BB/Spring%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%97%AE%E9%A2%98%E7%9B%AE/","excerpt":"","text":"一、Spring spring用到哪些设计模式（从源码方面详细说说） AOP动态代理的具体实现过程，详细说明 Spring的基本特性（说了一下IOC和AOP，循环依赖问题说的不好，没提到第三层缓存） spring的装配原理（没讲出来） spring框架中有用过哪些功能？ 答：ioc + di + aop IOC是怎么实现的，AOP使用的什么动态代理 Springboot自动装配 .Spring中如何配置一个类加载一个类不加载 用过哪些注解 @Autowire和@Resource区别 spring的AOP是什么？谈谈你的理解？这个和aspectj有什么区别吗？你有写过那些切面？ 说一下spring spring bean 的生命周期 二、SpringBoot springboot启动流程（面试前看了牛客其他同学的面经，但是没答出来tomcat启动） tomcat如何接收http请求（咋接收，不是拿参数接收的？） springboot是怎么执行的 请求到SpringBoot具体处理函数的流程 三、SpringMVC 怎么理解MVC框架 Springmvc的关键技术 拦截器的具体过程和应用 springMVC知道吗？MVC的原理，分别指什么？ 四、SpringColoud SpringCloud 的整体架构 spring cloud你用过哪些常用的组件？分别有什么优势？ 说一下springcloud 四、Mybatis mybatis怎么实现效率的提升，给出几种方法 Mybatis使用方式 mybatis返回一个list如何封装成一个object对象（没讲出来） 五、git git命令，mr代码冲突怎么解决， 使用过 git 吗，有使用 git 创建过分支吗？ 六、Linux 使用过 linux 吗？使用什么命令找出错误的运行日志。 查看linux物理机文件，搜索某个关键词 linux常用命令。 linux抓包（不了解）","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Mysql学习","slug":"技术类/Mysql学习","date":"2024-09-11T10:40:44.000Z","updated":"2024-10-10T01:58:25.099Z","comments":true,"path":"2024/09/11/技术类/Mysql学习/","permalink":"http://example.com/2024/09/11/%E6%8A%80%E6%9C%AF%E7%B1%BB/Mysql%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"SQL语句DDL（Data Definition Language）数据定义语言，用来定义数据库对象(数据库，表，字段) 数据库操作12345678910#查询所有数据库SHOW DATABASES; #查询当前数据库SELECT DATABASE; #创建CREATE DATABASE [IF NOT EXISTS] 数据库名 [DEFAULT CHARSET 字符集] [COLLATE 排序规则]; #删除DROP DATABASE[IF EXISTS] 数据库名;#使用USE 数据库名； 表操作123456789101112131415161718192021222324252627282930#查询当前数据库所有表SHOW TABLES;#查询表结构DESC 表名；#查看指定表的建表语句；SHOW CREATE 表名；#创建表CREATE TABLE 表名（ 字段1 字段1类型 [COMMENT 字段1注释(用单引号括起来)]， 字段2 字段2类型 [COMMENT 字段2注释]， 字段3 字段3类型 [COMMENT 字段3注释]， ... 字段n 字段n类型 [COMMENT 字段n注释])[COMMENT 表注释];#添加字段ALTER TABLE 表名 ADD 字段名 类型（长度）[COMMENT 注释][约束];#修改数据类型ALTER TABLE 表名 MODIFY 字段名 新数据类型（长度）;#修改字段名和数据类型ALTER TABLE 表名 CHANGE 旧字段名 新字段名 新类型（长度）[COMMENT 注释][约束];#删除字段ALTER TABLE 表名 DROP 字段名;#删除表DROP TABLE[IF EXISTS] 表名;#删除指定表，并重新创建该表TRUNCATE TABLE 表名； DML（Data Manipulation Language）数据操作语言，用来对数据库表中的数据进行增删改 123456789101112131415161718#添加数据#1、给指定字段添加数据INSERT INTO 表名（字段名1，字段名2，...） VALUES(值1，值2，...);#2、给全部字段添加数据INSERT INTO 表名 VALUES(值1，值2，...);#3、批量添加数据INSERT INTO 表名（字段名1，字段名2，...） VALUES(值1，值2，...),(值1，值2，...),(值1，值2，...);INSERT INTO 表名 VALUES (值1，值2，...),(值1，值2，...),(值1，值2，...);#字符串和日期型数据应该包含在引号中，插入的数据大小应该在字段的规定范围内，括号要加#修改数据UPDATE 表名 SET 字段名1=值1，字段名2=值2,...[WHERE 条件];#修改语句的条件可以有，也可以没有，如果没有，则会修改整张表的所有数据#删除数据DELETE FROM 表名 [WHERE 条件];#条件可以有也可以没有，如果没有则会删除整张表的所有数据#DELETE不能删除某一个字段的值（可以用UPDATE) DQL（Data Query Language）数据查询语言，用来查询数据库中表的记录 基本查询12345678#基本查询#1、查询多个字段SELECT 字段1，字段2，字段3，...FROM 表名；SELECT * FROM 表名；#2、设置别名SELECT 字段1[AS 别名1],字段2[AS 别名2] ...FROM 表名；#3、去掉重复记录SELECT DISTINCT 字段列表 FROM 表名； 条件查询123#条件查询#1、语法SELECT 字段列表 FROM 表名 WHERE 条件列表； 条件查询的条件列表 比较运算符 功能 ＞，＞&#x3D;，&lt;，&lt;&#x3D;，&#x3D;，&lt;&gt;或!&#x3D; 最后一个是不等于 BETWEEND..AND… 在某个范围之内（含最小，最大值）前面可以加一个字段 IN(…) 在in之后的列表中的值，多选一 LIKE 占位符 模糊匹配（_匹配单个字符，%匹配任意个字符），占位符用单引号括起来 IS NULL 是NULL 逻辑运算符 功能 AND 或 &amp;&amp; 并且（同时成立） OR 或 || 或者（任一成立） NOT 或 ！ 非，不是 分组查询聚合函数将一列数据作为整体，进行纵向计算 函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 12#语法SELECT 聚合函数（字段列表） FROM 表名； 分组查询12#语法SELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件]； 这里where和having的区别 执行时机不同：where是分组前进行过滤，having是对分组后的数据进行过滤 判断条件不同：where不能对聚合函数判断（即不能使用聚合函数），having可以 执行顺序：where &gt; 聚合函数 &gt; having 分组之后，查询的字段一般为聚合函数和分组字段，查询其它字段无意义 排序查询12#语法SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2; 排序方式 ASC ：升序（默认） DESC：降序 注意：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段排序 分页查询12#语法SELECT 字段列表 FROM 表名 LIMIT 起始索引，查询记录数； 注意： 起始索引从0开始，起始索引&#x3D;（查询页码-1）*每页记录数 如果查询的是第一页数据，起始索引可以省略，直接简写为limit 10。 DQL的执行顺序编写顺序如下： 1234567891011121314SELECT #----第四步 字段列表FROM #----第一步 表名列表WHERE #----第二步 条件列表GROUP BY #----第三步 分组字段列表HAVING 分组后条件列表ORDER BY #----第五步 排序字段列表LIMIT #----第六步 分页参数 DCL（Data Control Language）数据控制语言，用来创建数据库用户、控制数据库的访问权限 管理用户123456789101112#查询用户USE mysql;SELECT * FROM user;#创建用户CREATE USER &#x27;用户名&#x27;@&#x27;主机名‘ IDENTIFIED BY &#x27;密码&#x27;；#修改用户密码ALTER USER &#x27;用户名&#x27;@&#x27;主机名’ IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;；#删除用户DROP USER &#x27;用户名&#x27;@&#x27;主机名’； 权限控制 权限 说明 ALL,ALL PRIVILEGES 所有权限 SELECT 查询数据 INSERT 插入数据 UPDATE 修改数据 DELETE 删除数据 ALTER 修改表 DROP 删除数据库&#x2F;表&#x2F;视图 CREATE 创建数据库&#x2F;表 12345678#查询权限SHOW GRANTS FOR &#x27;用户名&#x27;@‘主机名’；#授予权限GRANT 权限列表 ON 数据库.表名 TO &#x27;用户名&#x27;@‘主机名’；#撤销权限REVOKE 权限列表 ON 数据库.表名 FROM &#x27;用户名&#x27;@‘主机名’； 多个权限之间，用逗号分隔 授权时，数据库名和表名可以用*进行通配 函数字符串函数 函数 功能 CONCAT(S1,S2,…Sn) 将S1,S2,..SN拼接为一个字符串 LOWER(str) 转小写 UPPER(str) 转大写 LPAD(str,n,pad) 左填充，用pad对str的左边进行填充，达到n个字符串长度 RPAD(str,n,pad) 右填充，用pad对str的右边进行填充，达到n个字符串长度 TRIM(str) 去掉字符串头部和尾部的空格 SUBSTRING(str,start,len) 返回str从start起len个长度的字符串 数值函数 函数 功能 CEIL(x) 向上取整 FLOOR(x) 向下取整 MOD(x,y) 返回x&#x2F;y的模 RAND() 返回0~1的随机数 ROUND(x,y) 求参数x的四舍五入的值，保留y位小数 日期函数 函数 功能 CURDATE() 返回当前日期 CURTIME() 返回当前时间 NOW() 返回当前日期和时间 YEAR(date) 获取指定date的年份 MONTH(date) 获取指定date的月份 DAY(date) 获取指定date的日期 DATE_ADD(date,INTERVAL expr type) 返回一个日期&#x2F;时间值加上一个时间间隔expr后的时间值 DATEDIFF(date1,date2) 返回起始时间date1和结束时间date2之间的天数 流程函数可以在SQL语句中实现条件筛选，从而提高语句的效率 函数 功能 IF(value,t,f) 如果value为true，返回t，否则返回f IFNULL(value1,value2) 如果value不为空，返回value1，否则返回value2 CASE WHEN [val1] THEN [res1]…ELSE [default] END 如果val1为true，返回res1，否则返回默认值 CASE [expr] WHEN [val1] THEN [res1]…ELSE [default] END 如果expr的值等于val1，返回res1，否则返回默认值 约束约束是作用于表中字段上的规则，用于限制存储在表中的数据 约束 功能 关键字 非空约束 NOT NULL 唯一约束 UNIQUE 主键约束 主键是一行数据的唯一标识，要求非空且唯一 PRIMARY KEY 默认约束 保存数据时，如果未指定该字段的值，采用默认值 DEFAULT 检查约束 保证字段值满足某一个条件 CHECK 外键约束 用来让两张表的数据之间建立联系，保持数据的一致性和完整性 FOREIGN KEY 1234567891011#语法一、创建的时候指定外键约束CREATE TABLE 表名（ 字段名 数据类型 ... [CONSTRAINT] [外键名称] FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名));#语法二、对于已创建的表来修改外键约束ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名);#删除外键ALTER TABLE 表名 DROP FOREIGN KEY 外键名称； 删除&#x2F;更新行为 行为 说明 NO ACTION &#x2F; RESTRICT 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新。(默认情况) CASCADE 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有，则也删除&#x2F;更新外键在子表中的记录。 SET NULL 当在父表中删除对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为nu(这就要求该外键允许取nul) 12#语法，只需在后面加上更新和删除的方式ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名) ON UPDATE CASCADE ON DELETE CASCADE; 多表查询多表关系 一对多（多对一） 多对多 一对一 内连接查询两张表的交集部分 12345#隐式内连接SELECT 字段列表 FROM 表1，表2 WHERE 条件...；#显式内连接 （和隐式没有区别，仅是写法的不同而已）[INNER 可有可无SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件...； 外连接左外连接和右外连接左：查询左表的所有数据和左右表交集部分的数据 右：查询右表的所有数据和左右表交集部分的数据 12345#语法------左 [OUTER可有可无SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件...;#语法------右SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件...; 右外可改成左外。左外会写就行 自连接12#语法SELECE 字段列表 FROM 表A 别名A JOIN 表A 表名B ON 条件...; 自连接查询，可以是内连接也可以是外连接 联合查询对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集 1234#语法SELECT 字段列表 FROM 表A ...UNION [ALL] #带ALL不会对查询结果去重SELECT 字段列表 FROM 表B ...; 使用条件：两个语句的字段列表（数量&#x2F;类型）要保持一致 子查询SQL语句中嵌套SELECT语句，称为嵌套查询，又称子查询。子查询要用（）括起来 子查询外部的语句可以是INSERT&#x2F;UPADTE&#x2F;DELETE&#x2F;SELECT 中的任何一个 标量子查询子查询结果为单个值 常用的操作符：&#x3D;，&lt;&gt;,&gt;,&gt;&#x3D;,&lt;,&lt;&#x3D; 列子查询子查询结果是一列 常用的操作符：IN , NOT IN , ANY(满足子查询列表的一个即可) , SOME(与ANY同等) ,ALL(必须全部满足) 行子查询子查询结果是一行 常用的操作符： &#x3D; ，&lt;&gt; , IN , NOT IN 表子查询子查询结果是多行多列 常用的操作符： IN 事务事务 是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 事务操作12345#开启事务START TRANSATION#提交/回滚事务COMMIT / ROLLBACK; *事务四大特性ACID 原子性（Atomicity） ：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency） ：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 *脏读、不可重复读、幻读 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 例子:小明读取到小红提交的100数据.但是小红异常回滚了数据,100变成了90,这个时候小明还是100,但实际是90(脏读) 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 例子:小明多次读取A数据,小红在小明读取数据时,每次读取都修改了数据并提交,小明多次读到的数据不一致 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 例子:小明修改了A,B数据,小红同时又插入了一条C数据,小明会感觉自己明明数据都改了,突然多出来一条,以为出现了幻觉自己漏了一条 *事务的隔离级别 隔离级别 脏读 不可重复读 幻读 Read uncommitted 有 有 有 Read committed 无 有 有 Repeatable Read（Mysql的默认级别） 无 无 有 Serializable 无 无 无 级别越高，安全性越高，执行效率越低 12345#查看事务隔离级别SELECE @@TRANSATION_ISOLATION;#设置事务隔离级别SET [SESSION|GLOBAL] TRANSATION ISOLATION LEVEL &#123;级别&#125; 引擎存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。 MySQL存储引擎MyISAM与InnoDB区别 Innodb引擎：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。 MyIASM引擎(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。 存储引擎选择如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。 索引索引介绍索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。 索引的优缺点优点 使用索引可以大大加快数据的检索速度 缺点 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增&#x2F;改&#x2F;删的执行效率； 空间方面：索引需要占物理空间。 索引结构索引分类从数据结构角度 树索引 Hash索引 从物理存储角度 聚集索引 聚簇索引是一种索引组织方式，它将索引和数据行存储在一起，即数据行按照索引的顺序存储在磁盘上。 聚簇索引的叶子节点保存的是完整的数据行，因此不需要进行额外的查找操作就可以获取到所需的数据。 InnoDB 存储引擎的主键索引就是一个聚簇索引，如果表没有显式地定义主键，InnoDB 会选择一个唯一的非空索引作为聚簇索引。 非聚集索引 非聚簇索引是一种索引组织方式，它将索引和数据行分开存储，即索引保存了指向数据行的指针（通常是行的物理地址或主键值）。 非聚簇索引的叶子节点保存的是指向数据行的引用，当查询需要获取数据时，首先根据索引查找到相应的行指针，然后再通过行指针获取数据行。 在MySQL中，MyISAM 存储引擎的索引通常是非聚簇索引。 总的来说，聚簇索引和非聚簇索引的区别在于索引和数据行的存储方式。聚簇索引将索引和数据行存储在一起，而非聚簇索引将索引和数据行分开存储。 对于非聚簇索引，一定会回表查询吗？ 答：不一定。试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。 这种情况就称之为索引覆盖。 索引覆盖：如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后只写必要的查询字段，以增加索引覆盖的几率。 这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。 从逻辑角度 普通索引：基本的索引类型，没有唯一性的限制，允许为NULL值。 可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引 主键索引：数据列不允许重复，不允许为NULL，一个表只能有一个主键。 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引 索引语法SQL性能分析SQL优化插入数据load指令一次插入大批量数据 主键优化 满足业务需求的情况下，尽量降低主键的长度 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键 尽量不要使用UUID做主键或者是其它自然主键，如身份证号 业务操作时，避免对主键的修改 order by 优化group by优化","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"}]},{"title":"java八股","slug":"八股/java八股","date":"2024-09-11T04:35:44.000Z","updated":"2024-12-06T14:01:33.797Z","comments":true,"path":"2024/09/11/八股/java八股/","permalink":"http://example.com/2024/09/11/%E5%85%AB%E8%82%A1/java%E5%85%AB%E8%82%A1/","excerpt":"","text":"一、基础1、概述1.1、Java 语言有哪些特点？ 跨平台 内存管理（垃圾回收） 生态 面向对象（封装，继承，多态）； 1.2、JVM、JDK 和 JRE 有什么区别？ JVM：Java Virtual Machine，Java 虚拟机，Java 程序运行在 Java 虚拟机上。针对不同系统的实现（Windows，Linux，macOS）不同的 JVM，因此 Java 语言可以实现跨平台。 JRE：Java 运⾏时环境。它是运⾏已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，Java 命令和其他的⼀些基础构件。但是，它不能⽤于创建新程序。 JDK: Java Development Kit，它是功能⻬全的 Java SDK。它拥有 JRE 所拥有的⼀切，还有编译器（javac）和⼯具（如 javadoc 和 jdb）。它能够创建和编译程序。 1.3、什么是字节码？采用字节码的好处是什么?所谓的字节码，就是 Java 程序经过编译之类产生的.class 文件，字节码能够被虚拟机识别，从而实现 Java 程序的跨平台性。 Java 程序从源代码到运行主要有三步： 编译：将我们的代码（.java）编译成虚拟机可以识别理解的字节码(.class) 解释：虚拟机执行 Java 字节码，将字节码翻译成机器能识别的机器码 执行：对应的机器执行二进制机器码 1.4、Java 源码从编译到执行，发生了什么? 编译：编译器 (javac) 将 .java 文件编译为 .class 字节码文件。 加载：类加载器 (ClassLoader) 在运行时将 .class 文件加载到 JVM 的内存中。 链接：链接器将各类加载的代码整合在一起，为后续运行做准备。 执行：Java 虚拟机 (JVM) 执行字节码。 关键组件： 方法区 (Method Area)： 存储类信息、常量、静态变量等。 堆 (Heap)： 存储对象实例。 栈 (Stack)： 存储方法调用的局部变量和操作数。 程序计数器 (PC)： 跟踪当前执行的字节码指令。 过程： 字节码解释器： 将字节码逐条翻译为机器码并执行。 解释执行速度较慢。 即时编译器 (JIT Compiler)： 热点代码（高频执行的代码）会被编译为机器码，提高性能。 JIT 编译优化包括内联、逃逸分析等。 回收：在程序运行期间，JVM 自动管理内存，通过垃圾回收 (Garbage Collection) 清理不再使用的对象，避免内存泄漏。 1234567891011121314源代码 (.java) ↓ 编译器 (javac) ↓字节码 (.class) ↓ 类加载器 (ClassLoader) ↓ 验证、准备、解析 ↓ JVM 执行字节码 ↓ 垃圾回收与退出 2、基础语法2.1、Java 有哪些数据类型？ 数值型 整数类型（byte、int、short、long）(占字节分别是 1、2、4、8) 浮点类型（float、double）(占字节分别是 4、8) 字符型（char）（占字节2） 布尔型（boolean）（占字节1） 注意：浮点数的默认类型为double（如果需要声明一个常量为float型，则必须要在末尾加上f或F），比如float f&#x3D;3.4 就不对，3.4 是双精度数，转为float会有精度损失 2.2、什么是自动拆箱&#x2F;封箱？ 装箱：将基本类型用它们对应的引用类型包装起来；引用是 Integer 类型，&#x3D; 右侧是 int 基本类型时，会进行自动装箱，调用的其实是 Integer.valueOf()方法，它会调用 IntegerCache。 拆箱：将包装类型转换为基本数据类型； 3、面向对象3.1、面向对象有哪些特性 封装 封装把⼀个对象的属性私有化，同时提供⼀些可以被外界访问的属性的⽅法。 继承 继承是使⽤已存在的类的定义作为基础创建新的类，新类的定义可以增加新的属性或新的方法，也可以继承父类的属性和方法。通过继承可以很方便地进行代码复用。 注意： ⼦类拥有⽗类对象所有的属性和⽅法（包括私有属性和私有⽅法），但是⽗类中的私有属性和⽅法⼦类是⽆法访问，只是拥有。 ⼦类可以拥有⾃⼰属性和⽅法，即⼦类可以对⽗类进⾏扩展。 ⼦类可以⽤⾃⼰的⽅式实现⽗类的⽅法。 多态 所谓多态就是指程序中定义的引⽤变量所指向的具体类型和通过该引⽤变量发出的⽅法调⽤在编程时并不确定，⽽是在程序运⾏期间才确定，即⼀个引⽤变量到底会指向哪个类的实例对象，该引⽤变量发出的⽅法调⽤到底是哪个类中实现的⽅法，必须在由程序运⾏期间才能决定。 同一个接口，使用不同的实例而执行不同操作 父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。 多态性可以分为编译时多态（重载）和运行时多态（重写）。 在 Java 中有两种形式可以实现多态：继承（多个⼦类对同⼀⽅法的重写）和接⼝（实现接⼝并覆盖接⼝中同⼀⽅法）。 3.2、重载（overload）和重写（override）的区别？方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载； 重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。 方法重载的规则： 方法名一致，参数列表中参数的顺序，类型，个数不同。 重载与方法的返回值无关，存在于父类和子类，同类中。 可以抛出不同的异常，可以有不同修饰符。 3.4、面向对象五大原则（了解） 单一职责原则SRP(Single Responsibility Principle)类的功能要单一，不能包罗万象，跟杂货铺似的。 开放封闭原则OCP(Open－Close Principle)一个模块对于拓展是开放的，对于修改是封闭的，想要增加功能热烈欢迎，想要修改，哼，一万个不乐意。 里式替换原则LSP(the Liskov Substitution Principle LSP)子类可以替换父类出现在父类能够出现的任何地方。比如你能代表你爸去你姥姥家干活。哈哈~~ 依赖倒置原则DIP(the Dependency Inversion Principle DIP)高层次的模块不应该依赖于低层次的模块，他们都应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。就是你出国要说你是中国人，而不能说你是哪个村子的。比如说中国人是抽象的，下面有具体的xx省，xx市，xx县。你要依赖的抽象是中国人，而不是你是xx村的。 接口分离原则ISP(the Interface Segregation Principle ISP)设计时采用多个与特定客户类有关的接口比采用一个通用的接口要好。就比如一个手机拥有打电话，看视频，玩游戏等功能，把这几个功能拆分成不同的接口，比在一个接口里要好的多。 3.3、访问修饰符 public、private、protected、以及不写（默认）时的区别？ default (即默认，什么也不写）: 在同一包内可见，不使用任何修饰符。可以修饰在类、接口、变量、方法。 private : 在同一类内可见。可以修饰变量、方法。注意：不能修饰类（外部类） public : 对所有类可见。可以修饰类、接口、变量、方法 protected : 对同一包内的类和所有子类可见。可以修饰变量、方法。注意：不能修饰类（外部类）。 3.4、抽象类(abstract class)和接口(interface)有什么区别？两者的特点： 抽象类用于描述类的共同特性和行为，可以有成员变量、构造方法和具体方法。适用于有明显继承关系的场景。 接口用于定义行为规范，可以多实现 。适用于定义类的能力或功能。 两者的区别： 3.5、成员变量与局部变量的区别有哪些？ 作用域 成员变量：针对整个类有效。 局部变量：只在某个范围内有效。(一般指的就是方法,语句体内) 存储位置 成员变量：随着对象的创建而存在，随着对象的消失而消失，存储在堆内存中。 局部变量：在方法被调用，或者语句被执行的时候存在，存储在栈内存中。当方法调用完，或者语句结束后，就自动释放。 生命周期 成员变量：随着对象的创建而存在，随着对象的消失而消失 局部变量：当方法调用完，或者语句结束后，就自动释放。 初始值 成员变量：有默认初始值。 局部变量：没有默认初始值，使用前必须赋值。 3.6、静态变量和实例变量的区别？静态方法、实例方法呢？静态变量: 是被 static 修饰符修饰的变量，也称为类变量，它属于类，不属于类的任何一个对象，一个类不管创建多少个对象，静态变量在内存中有且仅有一个副本。 实例变量: 必须依存于某一实例，需要先创建对象然后通过对象才能访问到它。静态变量可以实现让多个对象共享内存。 3.7、&#x3D;&#x3D;和 equals 的区别？&#x3D;&#x3D; : 它的作⽤是判断两个对象的地址是不是相等。即，判断两个对象是不是同⼀个对象(基本数据类型 &#x3D;&#x3D; 比较的是值，引⽤数据类型 &#x3D;&#x3D; 比较的是内存地址)。 equals() : 它的作⽤也是判断两个对象是否相等。但是这个“相等”一般也分两种情况： 默认情况：类没有覆盖 equals() ⽅法。则通过 equals() 比较该类的两个对象时，等价于通过“ &#x3D;&#x3D; ”比较这两个对象，还是相当于比较内存地址。 自定义情况：类覆盖了 equals() ⽅法。我们平时覆盖的 equals()方法一般是比较两个对象的内容是否相同，自定义了一个相等的标准，也就是两个对象的值是否相等。 3.8 hashCode和equals为什么重写 quals 时必须重写 hashCode ⽅法？ 如果两个对象相等，则 hashcode ⼀定也是相同的。两个对象相等，对两个对象分别调⽤ equals⽅法都返回 true。反之，两个对象有相同的 hashcode 值，它们也不⼀定是相等的 。因此，equals ⽅法被覆盖过，则 hashCode ⽅法也必须被覆盖。如果重写了 equals()方法而没有重写 hashCode()方法，那么被认为相等的对象可能会有不同的哈希码，从而导致无法在 HashMap 中正确处理这些对象。 为什么两个对象有相同的 hashcode值，它们也不⼀定是相等的？ 因为可能会碰撞， hashCode() 所使⽤的散列算法也许刚好会让多个对象传回相同的散列值。越糟糕的散列算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode ）。 3.9、final关键字 被final修饰的类不可以被继承 被final修饰的方法不可以被重写 被final修饰的变量不可以被改变，被final修饰不可变的是变量的引用，而不是引用指向的内容，引用指向的内容是可以改变的 3.8、深拷贝和浅拷贝? 浅拷贝：浅拷贝会创建一个新对象，但这个新对象的属性（字段）和原对象的属性完全相同。如果属性是基本数据类型，拷贝的是基本数据类型的值；如果属性是引用类型，拷贝的是引用地址，因此新旧对象共享同一个引用对象。 深拷贝：深拷贝也会创建一个新对象，但会递归地复制所有的引用对象，确保新对象和原对象完全独立。新对象与原对象的任何更改都不会相互影响。 4、StringString不是基本数据类型，是引用数据类型 4.1、String、StringBuilder、StringBuffer String：操作少量的数据 StringBuilder：单线程操作字符串缓冲区下操作大量数据 StringBuffer：多线程操作字符串缓冲区下操作大量数据 4.2、String str1 &#x3D; new String(“abc”) 和 String str2 &#x3D; “abc” 的区别？直接使用双引号为字符串变量赋值时，Java 首先会检查字符串常量池中是否已经存在相同内容的字符串。 如果存在，Java 就会让新的变量引用池中的那个字符串；如果不存在，它会创建一个新的字符串，放入池中，并让变量引用它。 使用 new String(&quot;abc&quot;) 的方式创建字符串时，实际分为两步： 第一步，先检查字符串字面量 “abc” 是否在字符串常量池中，如果没有则创建一个；如果已经存在，则引用它。 第二步，在堆中再创建一个新的字符串对象，并将其初始化为字符串常量池中 “abc” 的一个副本。 也就是说 123456String s1 = &quot;沉默王二&quot;;String s2 = &quot;沉默王二&quot;;String s3 = new String(&quot;沉默王二&quot;);System.out.println(s1 == s2); // 输出 true，因为 s1 和 s2 引用的是字符串常量池中同一个对象。System.out.println(s1 == s3); // 输出 false，因为 s3 是通过 new 关键字显式创建的，指向堆上不同的对象。 String s &#x3D; new String(“abc”)创建了几个对象？ 字符串常量池中如果之前已经有一个，则不再创建新的，直接引用；如果没有，则创建一个。 堆中肯定有一个，因为只要使用了 new 关键字，肯定会在堆中创建一个。 4.3、如何保证 String 不可变？(为什么String是不可变的)第一，String 类内部使用一个私有的字符数组来存储字符串数据。这个字符数组在创建字符串时被初始化，之后不允许被改变。 第二，String 类没有提供任何可以修改其内容的公共方法， 第三，String 类本身被声明为 final，这意味着它不能被继承。这防止了子类可能通过添加修改方法来改变字符串内容的可能性。 5、Integer5.1、Integer a&#x3D; 127，Integer b &#x3D; 127；Integer c&#x3D; 128，Integer d &#x3D; 128；相等吗?a 和 b 相等，c 和 d 不相等。 这个问题涉及到 Java 的自动装箱机制以及Integer类的缓存机制。 a和b是相等的。这是因为 Java 在自动装箱过程中，会使用Integer.valueOf()方法来创建Integer对象。 Integer.valueOf()方法会针对数值在-128 到 127 之间的Integer对象使用缓存。因此，a和b实际上引用了常量池中相同的Integer对象。 c和d不相等。这是因为 128 超出了Integer缓存的范围(-128 到 127)。 因此，自动装箱过程会为c和d创建两个不同的Integer对象，它们有不同的引用地址。 6、异常处理 Throwable 是 Java 语言中所有错误和异常的基类。它有两个主要的子类：Error 和 Exception，这两个类分别代表了 Java 异常处理体系中的两个分支。 Error 类代表那些严重的错误，这类错误通常是程序无法处理的。比如，OutOfMemoryError 表示内存不足，StackOverflowError 表示栈溢出。这些错误通常与 JVM 的运行状态有关，一旦发生，应用程序通常无法恢复。 Exception 类代表程序可以处理的异常。它分为两大类：编译时异常（Checked Exception）和运行时异常（Runtime Exception）。 ①、编译时异常（Checked Exception）：这类异常在编译时必须被显式处理（捕获或声明抛出）。 如果方法可能抛出某种编译时异常，但没有捕获它（try-catch）或没有在方法声明中用 throws 子句声明它，那么编译将不会通过。例如：IOException、SQLException 等。 ②、运行时异常（Runtime Exception）：这类异常在运行时抛出，它们都是 RuntimeException 的子类。对于运行时异常，Java 编译器不要求必须处理它们（即不需要捕获也不需要声明抛出）。 运行时异常通常是由程序逻辑错误导致的，如 NullPointerException、IndexOutOfBoundsException 等。 6.1、异常的处理方式①、遇到异常时可以不处理，直接通过throw 和 throws 抛出异常，交给上层调用者处理。 throws 关键字用于声明可能会抛出的异常，而 throw 关键字用于抛出异常。 123public void test() throws Exception &#123; throw new Exception(&quot;抛出异常&quot;);&#125; ②、使用 try-catch 捕获异常，处理异常。 6.2、BIO、NIO、AIO的区别BIO（Blocking I&#x2F;O）：采用阻塞式 I&#x2F;O 模型，线程在执行 I&#x2F;O 操作时被阻塞，无法处理其他任务，适用于连接数较少的场景。 NIO（New I&#x2F;O 或 Non-blocking I&#x2F;O）：采用非阻塞 I&#x2F;O 模型，线程在等待 I&#x2F;O 时可执行其他任务，通过 Selector 监控多个 Channel 上的事件，适用于连接数多但连接时间短的场景。 AIO（Asynchronous I&#x2F;O）：使用异步 I&#x2F;O 模型，线程发起 I&#x2F;O 请求后立即返回，当 I&#x2F;O 操作完成时通过回调函数通知线程，适用于连接数多且连接时间长的场景。 7、序列化7.1、什么是序列化，什么是反序列化？序列化（Serialization）是指将对象转换为字节流的过程，以便能够将该对象保存到文件、数据库，或者进行网络传输。 反序列化（Deserialization）就是将字节流转换回对象的过程，以便构建原始对象。 Serializable 接口有什么用？ Serializable接口用于标记一个类可以被序列化。 12345public class Person implements Serializable &#123; private String name; private int age; // 省略 getter 和 setter 方法&#125; serialVersionUID 有什么用？ serialVersionUID 是 Java 序列化机制中用于标识类版本的唯一标识符。它的作用是确保在序列化和反序列化过程中，类的版本是兼容的。 所以serialVersionUlD就是起验证作用 Java 序列化不包含静态变量吗？ 是的，序列化机制只会保存对象的状态，而静态变量属于类的状态，不属于对象的状态。 如果有些变量不想序列化，怎么办？ 可以使用transient关键字修饰不想序列化的变量。 12345public class Person implements Serializable &#123; private String name; private transient int age; // 省略 getter 和 setter 方法&#125; 序列化的过程 Java序列化关键类和接口：ObjectOutputStream 用于序列化，ObjectInputStream用于反序列化。类必须实现Serializable接口才能被序列化。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}],"categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"},{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"},{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"},{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/tags/LeetCode/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"},{"name":"JavaSE","slug":"JavaSE","permalink":"http://example.com/tags/JavaSE/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"},{"name":"实习","slug":"实习","permalink":"http://example.com/tags/%E5%AE%9E%E4%B9%A0/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"Spring, SSM","slug":"Spring-SSM","permalink":"http://example.com/tags/Spring-SSM/"},{"name":"JUC","slug":"JUC","permalink":"http://example.com/tags/JUC/"},{"name":"项目","slug":"项目","permalink":"http://example.com/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"杂谈记录","slug":"杂谈记录","permalink":"http://example.com/tags/%E6%9D%82%E8%B0%88%E8%AE%B0%E5%BD%95/"},{"name":"音乐","slug":"音乐","permalink":"http://example.com/tags/%E9%9F%B3%E4%B9%90/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"影视","slug":"影视","permalink":"http://example.com/tags/%E5%BD%B1%E8%A7%86/"},{"name":"MybatisPlus","slug":"MybatisPlus","permalink":"http://example.com/tags/MybatisPlus/"},{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"面试","slug":"面试","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95/"},{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}