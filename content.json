{"meta":{"title":"light","subtitle":"stan","description":"啊咧咧啊咧咧啊咧啊咧咧~","author":"Light","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2024-04-24T02:39:53.000Z","updated":"2024-04-26T12:54:38.247Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"双非研一在读"},{"title":"categories","date":"2024-09-11T03:20:45.000Z","updated":"2024-09-11T03:21:12.040Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"Java8","date":"2024-10-28T13:37:10.000Z","updated":"2025-03-11T13:46:15.722Z","comments":true,"path":"Java8/index.html","permalink":"http://example.com/Java8/index.html","excerpt":"","text":"Java基础 集合框架 Java并发 Mysql Redis 框架 计算机网络 JVM 中间件 操作系统 其它"},{"title":"所有标签","date":"2025-01-31T08:58:37.808Z","updated":"2025-01-31T08:58:37.808Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"algorithm","date":"2024-04-27T11:19:37.000Z","updated":"2024-07-30T08:12:55.914Z","comments":true,"path":"algorithm/index.html","permalink":"http://example.com/algorithm/index.html","excerpt":"","text":"二分查找的两种写法 二分查找仅适用于有序的数据集合（当然数组是最常见的 一、左闭右闭步骤如下： 初始化 代码如下： 双指针 对撞指针定义指的是两个指针 𝑙𝑒𝑓𝑡left、𝑟𝑖𝑔ℎ𝑡right 分别指向序列第一个元素和最后一个元素，然后 𝑙𝑒𝑓𝑡left 指针不断递增，𝑟𝑖𝑔ℎ𝑡right 不断递减，直到两个指针的值相撞（即 𝑙𝑒𝑓𝑡&#x3D;&#x3D;𝑟𝑖𝑔ℎ𝑡left&#x3D;&#x3D;right），或者满足其他要求的特殊条件为止。 模板1234567891011left, right = 0, len(nums) - 1while left &lt; right: if 满足要求的特殊条件: return 符合条件的值 elif 一定条件 1: left += 1 elif 一定条件 2: right -= 1return 没找到 或 找到对应值 适用范围对撞指针一般用来解决有序数组或者字符串问题： 查找有序数组中满足某些约束条件的一组元素问题：比如二分查找、数字之和等问题。 字符串反转问题：反转字符串、回文数、颠倒二进制等问题。 快慢指针定义指的是两个指针从同一侧开始遍历序列，且移动的步长一个快一个慢。移动快的指针被称为 「快指针（fast）」，移动慢的指针被称为「慢指针（slow）」。两个指针以不同速度、不同策略移动，直到快指针移动到数组尾端，或者两指针相交，或者满足其他特殊条件时为止。 模板1234567slow = 0fast = 1while 没有遍历完： if 满足要求的特殊条件: slow += 1 fast += 1return 合适的值 适用范围快慢指针一般用于处理数组中的移动、删除元素问题，或者链表中的判断是否有环、长度问题。 口诀搜索一个元素时，搜索区间两端闭。while 条件带等号，否则需要打补丁。if 相等就返回，其他的事甭操心。mid 必须加减一，因为区间两端闭。while结束就凉了，凄凄惨惨返 -1。 搜索左右边界时，搜索区间要阐明。 左闭右开最常见，其余逻辑便自明: while要用小于号，这样才能不漏掉。 if 相等别返回，利用 mid 锁边界。 mid 加一或减一?要看区间开或闭。 while结束不算完，因为你还没返回。 索引可能出边界，if 检查保平安。 二叉树前中后序遍历（递归）1234567891011121314151617181920212223242526272829//前序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; result.add(root.val);; //中间节点在前面 preorder(root.left, result); preorder(root.right, result);&#125;//中序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; preorder(root.left, result); result.add(root.val); //中间节点在中间 preorder(root.right, result);&#125;//后序public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123; if (root == null) &#123; return; &#125; preorder(root.left, result); preorder(root.right, result); result.add(root.val);; //中间节点在后面&#125; 前中后序遍历（迭代）12345678910111213141516171819202122232425262728293031323334353637383940414243//前序 public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return res; &#125; Deque&lt;TreeNode&gt; stack = new LinkedList&lt;TreeNode&gt;(); //显示声明一个栈 TreeNode node = root; while (!stack.isEmpty() || node != null) &#123; while (node != null) &#123; res.add(node.val); stack.push(node); node = node.left; &#125; node = stack.pop(); //可以让node重新返回上一个父节点 node = node.right; &#125; return res;&#125;//中序public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return res; &#125; Deque&lt;TreeNode&gt; stk = new LinkedList&lt;TreeNode&gt;(); while (root != null || !stk.isEmpty()) &#123; while (root != null) &#123; //找第一个左叶子节点，且该左叶子节点是入栈了的，所以下面要先出栈，再给结果赋值 stk.push(root); root = root.left; &#125; root = stk.pop(); res.add(root.val); root = root.right; &#125; return res;&#125;//后序"},{"title":"","date":"2024-10-03T15:39:20.336Z","updated":"2024-10-03T15:39:20.336Z","comments":true,"path":"css/custom.css","permalink":"http://example.com/css/custom.css","excerpt":"","text":"/* 侧边栏个人信息卡片动态渐变色 */ #aside-content > .card-widget.card-info { background: linear-gradient( -45deg, #e8d8b9, #eccec5, #a3e9eb, #bdbdf0, #eec1ea ); box-shadow: 0 0 5px rgb(66, 68, 68); position: relative; background-size: 400% 400%; -webkit-animation: Gradient 10s ease infinite; -moz-animation: Gradient 10s ease infinite; animation: Gradient 10s ease infinite !important; } @-webkit-keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } @-moz-keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } @keyframes Gradient { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } } /* 黑夜模式适配 */ [data-theme=\"dark\"] #aside-content > .card-widget.card-info { background: #191919ee; } /* 个人信息Follow me按钮 */ #aside-content > .card-widget.card-info > #card-info-btn { background-color: #3eb8be; border-radius: 8px; }"},{"title":"算法学习","date":"2024-04-27T11:25:24.000Z","updated":"2024-07-05T11:57:20.083Z","comments":true,"path":"algorithm/二分查找.html","permalink":"http://example.com/algorithm/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE.html","excerpt":"","text":"二分查找二分查找仅适用于有序的数据集合（当然数组是最常见的 二分查找的两种思路直接法12345678910111213141516int left = 0;int right = nums.length - 1;while(left &lt;= right)&#123; int mid = (left + right ) &gt;&gt; 1; //如果找到目标值，则直接范围中心位置 if (nums[mid] == target) return mid; //如果 nums[mid] 小于目标值，则在 [mid + 1, right] 中继续搜索 else if(nums[mid] &lt; target) left = mid + 1; //如果 nums[mid] 大于目标值，则在 [left, mid - 1] 中继续搜索 else right = mid - 1;&#125;//未搜索到元素，返回 -1return -1; 排除法12345678910111213int left = 0;int right = nums.length - 1;while(left &lt; right)&#123; int mid = (left + right ) &gt;&gt; 1; //如果 nums[mid] 小于目标值，排除掉不可能区间 [left, mid]，在 [mid + 1, right] 中继续搜索 else if(nums[mid] &lt; target) left = mid + 1; //如果 nums[mid] 大于目标值，目标元素可能在 [left, mid] 中，在 [left, mid] 中继续搜索 else if(nums[mid] &lt; target) right = mid; //未搜索到元素，返回 -1 return left if nums[left] == target else -1&#125;"},{"title":"我的朋友们","date":"2025-02-01T04:37:52.996Z","updated":"2025-02-01T04:37:52.996Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"}],"posts":[{"title":"神之天平","slug":"生活/神之天平","date":"2025-05-20T08:03:27.000Z","updated":"2025-05-20T09:11:10.118Z","comments":true,"path":"2025/05/20/生活/神之天平/","permalink":"http://example.com/2025/05/20/%E7%94%9F%E6%B4%BB/%E7%A5%9E%E4%B9%8B%E5%A4%A9%E5%B9%B3/","excerpt":"记录steam上第一款通关的单机游戏","text":"记录steam上第一款通关的单机游戏 毫无疑问，与我而言，这是一款神作，无论从剧情、美术、音乐、玩法多方面评价，我都认为它值得“神作”二字。 （哎，好多年没写过作文了，现在反倒有点不知道该怎么记录了） 剧情那就先从上面说的剧情说起吧，就像最后嘉隆说的那句“没想到和你一起始于那间小屋的旅行……最终抵达的终点居然是这种地方啊”，确实，很佩服作者的构思，从剑与魔法的远古时代，一直打到未来的科幻世界，再到造物主的世界俯瞰这万物众生。谁能想到，最初的起点只是一个木屋，一人一鸟呢（哈哈感觉嘉隆更像真女主~） 整个剧情围绕天平展开，以女主为线索，最后真相居然是一切都是天平之神阿斯特赖亚的计划，然后使男主破坏造物主的遗志——清除现有星球然后重新开始。其实看到这里也可以看到一点宗教的意味，类似Bible中洪水清除一切。 总得来说，真是一部宏大的史诗呢，如果有一天能动画化就好了😄不过男主在游戏中一句台词都没有，很难想象动画化的男主要怎么处理。 这款游戏，结合了热血，羁绊，冒险，爱情等元素，可以说是非常传统的日式rpg了，但也是非常合我的胃口哈哈，可能也和我小时候受龙珠熏陶的原因有关吧 剧情方面暂时记录到这里，下面说一下美术方面 美术听说作者最初做出来的美术不是现在这样，然后是后面哪个又给优化的，而且有些观点认为这个游戏的画风太复古了，我倒觉得这并不是缺点，反而是优点，而且也没有特别复古吧哈哈。 里面人物建模，包括武器啊，护甲，盾牌等，设计的都非常好看，还有背景的处理，也非常的得当，每次在一个场景，看着背景那些建筑啊什么的，仿佛真的就处于这个世界一样，而背景中那些房屋中正是实实在在生活在这里的人，总之一个好的美术背景，虽然是2d的情况下，也能让玩家有一种沉浸的感觉。 对了，其中BOSS的美术，真的是各有特色，无可挑剔，每次看到BOSS都让人眼前一亮又一亮 音乐如果说好的背景已经能让玩家光是看着就已经沉浸在其中的世界了，而一个恰当的音乐无疑是注入了灵魂的一击。 这款游戏的音乐无论在什么场景下都配得恰到好处，或平静，或诙谐，或严肃，或神圣，或紧张，或科幻。总之就是未见其面，先闻其声，声音和画面的结合达到了一种完美的地步。 玩法从玩法上来说，天平系统，晶体技能系统，还有装备系统，这些组合起来，就让这个游戏即使本质是个刷刷刷的游戏，但也给玩家带来了不少的乐趣，而且可以自定义难度。不过由于我现在时间有限，但又想快速的体验一下剧情，在一周目最终BOSS那里，因为要连打好几个败了还要重新打，另一方面也可能是刷的不够，打不过去就有点折磨了，所以直接上了科技然后速通二周目了，后续如果还有时间的话可能会再重新打一遍然后争取全成就吧。 结语 非常好的游戏，治好了我的电子ed，往前，往后，估计都很难有这么对我口味的游戏了，不过就是带着记忆再刷一遍可能所带来的震撼感和乐趣就会少一点吧~","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"game","slug":"game","permalink":"http://example.com/tags/game/"}]},{"title":"Docker学习","slug":"技术类/Docker学习","date":"2025-05-14T03:25:46.000Z","updated":"2025-05-14T04:15:29.772Z","comments":true,"path":"2025/05/14/技术类/Docker学习/","permalink":"http://example.com/2025/05/14/%E6%8A%80%E6%9C%AF%E7%B1%BB/Docker%E5%AD%A6%E4%B9%A0/","excerpt":"本文记录学习Docker的一些历程，主要是一些术语和命令","text":"本文记录学习Docker的一些历程，主要是一些术语和命令 1.为什么引入Docker？程序运行在操作系统的用户空间，而不同的操作系统安装了不同的依赖库和配置，操作系统、依赖库、配置共同组成了环境，环境不同，程序就可能运行不了。 而将程序和环境一起打包，就可以避免上述问题，Docker就是这样一款软件，可以将程序和环境一起打包，而程序由于只运行在操作系统的用户空间，所以打包时只需打包用户空间部分。这就组成了镜像 镜像和容器的关系类似面向对象中类和对象的关系 dockerfile：就像一份TODOlist，列出了要做哪些事情。一个文本文件，包含构建镜像的指令（如安装软件、复制文件等）。 镜像仓库：存储镜像的服务器，如 Docker Hub（官方仓库）或私有仓库（如 Harbor）。 容器：镜像的运行实例，是一个轻量级的隔离进程环境。 容器可以启动、停止、删除，且每个容器相互隔离。 Docker compose：用于定义和运行多容器（包括执行顺序等）应用的工具，通过 docker-compose.yml 文件配置服务、网络和卷。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"好文分享","slug":"生活/好文分享","date":"2025-05-13T10:26:14.000Z","updated":"2025-05-30T06:44:28.042Z","comments":true,"path":"2025/05/13/生活/好文分享/","permalink":"http://example.com/2025/05/13/%E7%94%9F%E6%B4%BB/%E5%A5%BD%E6%96%87%E5%88%86%E4%BA%AB/","excerpt":"记录一些看到的很好的文章","text":"记录一些看到的很好的文章","categories":[],"tags":[]},{"title":"面试问题复盘总结","slug":"面经/面试问题复盘总结","date":"2025-04-23T13:51:46.000Z","updated":"2025-04-23T15:40:52.193Z","comments":true,"path":"2025/04/23/面经/面试问题复盘总结/","permalink":"http://example.com/2025/04/23/%E9%9D%A2%E7%BB%8F/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E5%A4%8D%E7%9B%98%E6%80%BB%E7%BB%93/","excerpt":"复盘记录面试中的问题","text":"复盘记录面试中的问题 1.Java基础 面相对象三大特征 封装：将对象的属性隐藏在对象内部，不允许外部对象直接访问对象的内部信息，但可以提供一些方法来操作对象的属性。 继承：在已经有的类基础上创建新的类，新的类可以继承父类的属性和方法，也可以进行扩展（方法和属性） 多态：同一操作作用于不同的对象产生不同的行为。具体就是“父类引用指向子类对象”，如果子类重写了父类的方法，那么实际执行的是子类的方法，否则执行的是父类的方法 重载和重写的区别 重载：同一个类中，两个方法的方法名相同，但方法列表不同（参数类型，个数，顺序不同） 哪些场景用到重载？（没答好🌟 重写：子类可以对继承的父类方法进行重写，就是方法名相同，参数列表也相同，但内部逻辑可以进行修改。 Java数据类型🌟 8个。（切记String不是基本数据类型，是引用类型） 数值型（6个） ​ 整数型：byte，short，int，long（分别占1，2，4，8字节）； ​ 浮点型：float，double（占4，8字节） 字符型（1个） char（占2字节） 布尔型（1个）boolean（占1字节） Java中的引用类型🌟 强引用：将一个对象赋值给引用变量，这个引用变量就是一个强引用。使用new关键字赋值的引用（变量）就是强引用。强引用在发生gc时也不会被回收，除非判断该对象不可达，变成了垃圾才会回收。 软引用：通过 SoftReference 类实现。 有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：通过 WeakReference 类实现。他的强度比软引用更低一点， 有用但不是必须的对象，在下一次GC时会被回收，而不管内存是否足够。 虚引用：虚引用对象在任何时候都可能被回收。主要用于跟踪对象被垃圾回收的状态，在 gc 时返回一个通知。 2.jvm3.juc4.框架 Spring的原理 依赖注入的原理 4.redis5.网络6.os","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"腾讯云智测开面经","slug":"面经/武汉腾讯云智测开面经","date":"2025-04-17T14:10:32.000Z","updated":"2025-04-17T15:54:04.128Z","comments":true,"path":"2025/04/17/面经/武汉腾讯云智测开面经/","permalink":"http://example.com/2025/04/17/%E9%9D%A2%E7%BB%8F/%E6%AD%A6%E6%B1%89%E8%85%BE%E8%AE%AF%E4%BA%91%E6%99%BA%E6%B5%8B%E5%BC%80%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"1 自我介绍（提到了平时会记录一些自己的学习过程和遇到的bug，然后面试官问有没有一些bug可以聊一下的，我瞬间傻了，因为记录的bug很少，且确实没什么印象了，随便说了一些然后面试官问这种bug写到博客里面是干啥用的，，，刚开局水晶就裂条缝。。） 然后问了一点之前实习 八股 面相对象三大特征 重载和重写的区别 然后又问哪些场景会用到重载（不会） Java数据类型（浮点型两个忘了答了，给String答上去了，哎，没想好就开始答了！！！） Java中的引用类型（一时也没转过弯来，强软弱虚那四个） springboot的源码有没有看过，spring的原理什么的（答的是通过一个map对bean进行管理）。依赖注入的原理（在运行时可以通过反射获得对象的信息进行一个注入） 怎么去理解进程和线程，它们之间的一个差异是什么（这段我的评价是语无伦次，语言能力太差，没组织好语言）一个进程里面可以包含线程，协程吗？（可以），线程里面可以包含进程吗（不能），线程里面可以包含协程吗？（可以） 封包解包的流程 怎么去理解MySQL的事务，它有哪些特点（持久性答的磕磕绊绊，一致性更是一塌糊涂） 举例哪些场景要开启一个事务，如果不开启事务会造成什么样的影响（一个人去取钱，但是由于系统原因数据库没有存储更新的数据，钱却被取走了。然后实在想不出来例子了，他给了一个场景） 用户a和b取同一个账户的钱，取之前要查询余额，这个过程用不用加事务（不用，因为不涉及数据库内容的修改），这时有个c用户往这个账户存了100块钱，如果没有事务，a用户看到的钱是多少呢？（答的是可能会看到c转账之前的余额）问怎么分析的（我说了要看查询的时机，然后又问有没有其他的因素，我说要看c用户这个操作有没有成功执行，问还有呢？说不下去了），然后又换了一个话题，如果把查询和插入都加上事务，会造成什么结果，有什么问题，影响（反问了一个特别蠢的问题，问这俩操作是不是同一个事务，然后面试官说查询和新增可能是同一个接口，查询和新增不可能是一个接口…然后还把问题给忘了。。。又问了一遍，然后还是没想出来），面试官估计到这就判给我“判死刑”了，然后说那我们问一些基础的吧 MySQL的一些语句（连表查询，排序，分组，组合查询（这个想了一会才想起来是union）） Redis数据类型有哪些 写了一个Java代码，要运行起来经历几个过程（经历哪些程序，才能跑起来）提示可以从Java的运行原理解决这个问题，然后我答了类加载的过程。。。。 jvm运行时数据区 最后一个是测试相关的问题，小程序可以输入三个参数，代表三条边（看录音的时候才发现好像提了个“长度”），返回结果会显示这是不是一个三角形，以及是个什么样的三角形，针对这个小程序去设计一个测试场景， 答三条边是相连的且不平行，某个边和另一个边相连且是终点相交，然后是什么样的三角形可以根据三角形的性质去判断 岗位和地点了解吗（安全测开，武汉） 没了。然后光速挂","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"美云智数面经","slug":"面经/佛山美云智数面经","date":"2025-04-10T09:24:19.000Z","updated":"2025-04-17T14:10:41.343Z","comments":true,"path":"2025/04/10/面经/佛山美云智数面经/","permalink":"http://example.com/2025/04/10/%E9%9D%A2%E7%BB%8F/%E4%BD%9B%E5%B1%B1%E7%BE%8E%E4%BA%91%E6%99%BA%E6%95%B0%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"1 自我介绍 然后问了一些上段实习的大致情况 springboot的一些特性（答的感觉不是特别好，就说了ioc，aop和事务管理） springboot的自动配置（不会，没看。。） bean的生命周期（答的也不太熟悉） 切面的作用，实现（实现没答好） sql注入 讲一下我了解的微服务组件 sql优化的一些手段或方法 Redis的数据类型及使用场景 分布式锁（详细介绍了自己实现的，然后顺带讲了一点Redisson） 然后问了一下用的ai工具 20多分钟结束 下午就oc了","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"Java基础补漏","slug":"Java基础补漏","date":"2025-04-08T02:19:12.000Z","updated":"2025-04-08T03:17:50.333Z","comments":true,"path":"2025/04/08/Java基础补漏/","permalink":"http://example.com/2025/04/08/Java%E5%9F%BA%E7%A1%80%E8%A1%A5%E6%BC%8F/","excerpt":"","text":"这里是对Java基础一些遗漏或者不太熟悉的知识点回顾 1.内部类内部类：写在一个类里面的类就叫做内部类 什么时候用到内部类? B类表示的事物是A类的一部分，且B单独存在没有意义，比如：汽车的发动，ArrayList的迭代器，人的心脏等等 前三种内部类了解即可，匿名内部类重点掌握 1.成员内部类写在成员位置的（即类中，方法外），属于外部类的成员。 12345678public class Car&#123; //外部类 String carName; int carAge; class Engine&#123; //内部类 String engineName; int engineAge; &#125;&#125; 成员内部类要关注： 成员内部类的代码如何写？ 如何创建成员内部类的对象？ 成员内部类如何获取外部类的成员变量(重名的）？ 创建内部类的对象： 在外部类编写方法，对外提供内部类的对象 直接创建：格式——&gt;外部类名.内部类名 对象名 = 外部类对象.内部类对象; 成员内部类获取外部类的成员变量： 外部类.this.变量名 一个题目 1234567891011121314151617181920public class Outer &#123; private int a = 10; class Inner&#123; private int a = 20; public void show()&#123; int a = 30; System.out.println(Outer.this.a); //想输出10 System.out.println(this.a); //想输出20 System.out.println(a); //想输出30 &#125; &#125; public static void main(String[] args) &#123; Outer.Inner inner = new Outer().new Inner(); inner.show(); &#125;&#125; 2.静态内部类是成员内部类的一种特殊情况，当成员内部类用static修饰时，就是静态内部类 静态内部类只能访问外部类中的静态变量和静态方法，如果想要访问非静态的需要创建对象 创建内部类对象的格式： 外部类名.内部类名 对象名 = new 外部类名.内部类名（） 调用非静态方法的格式： 先创建对象，再对象调用 调用静态方法： 外部类名.内部类名.方法名() 3.局部内部类没啥用，了解一下即可 将内部类定义在方法里面就叫做局部内部类，类似于方法里面的局部变量。 外界是无法直接使用，需要在方法内部创建对象并使用。 该类可以直接访问外部类的成员，也可以访问方法内的局部变量， 4.匿名内部类本质就是隐藏了名字的内部类 格式： 123new 类名或接口名()&#123; //1.继承/实现.这里是指&#123;&#125;是一个没有名字的类，它继承&#x27;类名&#x27; 或实现&#x27;接口名&#x27; 2.方法重写； 3.创建对象 重写方法;&#125;; 使用场景，如果实现类只要使用一次，就可以用匿名内部类简化代码。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"http://example.com/tags/JavaSE/"}]},{"title":"详解IO多路复用","slug":"详解IO多路复用","date":"2025-04-03T13:11:17.000Z","updated":"2025-04-07T06:56:21.853Z","comments":true,"path":"2025/04/03/详解IO多路复用/","permalink":"http://example.com/2025/04/03/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","excerpt":"本文以IO多路复用为核心，详细地介绍了从Socket模型——&gt;TCP连接——&gt;IO模型——&gt;IO多路复用——&gt;Redis线程模型，一文尽量讲解清楚。","text":"本文以IO多路复用为核心，详细地介绍了从Socket模型——&gt;TCP连接——&gt;IO模型——&gt;IO多路复用——&gt;Redis线程模型，一文尽量讲解清楚。 本文内容主要来自小林coding&#x2F;黑马 1.最基本的Socket模型要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，Socket是进程通信的一种方式，其特殊在可以跨主机通信 Socket中文译插口，类似这客户端和服务端搞了一个插口，然后中间连个线就可以通信了。 创建Socket时可以指定网络协议IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。UDP的Socket编程相对简单，这里以TCP的为例。 1.TCP建立的过程服务端要先启动，然后等待客户端来建立连接。 服务端首先调用 socket() 函数，指定网络协议和传输协议，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口 绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序 绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们； 绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，对应 TCP 状态图中的 listen ，服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。 客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： TCP 半连接队列，这个队列都是没有完成三次握手的连接 TCP 全连接队列，这个队列都是完成了三次握手的连接 当 TCP 全连接队列不为空后，服务端的 accept() 函数， 就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序 ，后续数据传输都用这个 Socket。 注意，监听的 Socket 和真正用来传数据的 Socket 是两个： 一个叫作监听 Socket； 一个叫作已连接 Socket； 2.如何服务更多的用户？前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 &#x2F;0 时，或者 读写操作发生阻塞时，其他客户端是无法与服务端连接的。 所以现在要对这个IO模型改进，以支持更多的客户端。 这里引入一个问题，服务器单机最多能连接多少客户端？ TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口。 服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。 因此服务器的本地 IP 和端口是固定的， 于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的， 所以最大 TCP 连接数 &#x3D; 客户端 IP 数×客户端端口数。 对于 IPv4，客户端的 IP 数最多为 2 的 32 次方， 客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方。 但是实际上连接不了那么多，受到两个方面的限制： 文件描述符，Socket 实际上是一个文件，也就会对应一个文件描述符。 在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024， 不过我们可以通过 ulimit 增大文件描述符的数目； 系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的； 3.IO多路复用为每个请求分配一个进程&#x2F;线程的方式不合适，因此引入 I&#x2F;O 多路复用技术，它只使用一个进程来维护多个 Socket 。 一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内， 这样 1 秒内就可以处理上千个请求，把时间拉长来看， 多个请求复用了一个进程，这就是多路复用。这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用， 进程可以通过一个系统调用函数从内核中获取多个事件。 select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时， 先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接， 然后在用户态中再处理这些连接对应的请求即可。 4.select&#x2F;poll1.selectselect 实现多路复用的方式是，将已连接的 Socket（一个Socket连接对应一个文件描述符fd） 都放到一个文件描述符集合（fd_set），然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写，返回给用户空间的是就绪的事件个数，接着再把整个文件描述符集合拷贝回用户态里（实际上是覆盖原来的fd_set），然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里， 一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合， 所支持的文件描述符的个数是有限制的，默认最大值为 1024 缺点： 两次拷贝：先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 需要遍历才能得知就绪的fd 可传入的fd数量有限制 2.poll流程基本和select类似 唯一不同的是，在传入fd的数量上有了突破，用户空间传入的是可自定义大小的pollfd数组，然后传入内核空间后，用链表形式组织。所以说fd的数量理论上是没有限制的（但实际受限于查询效率的问题，不可能没有限制的）。但仍然没有解决select的问题，拷贝，遍历。 3.epoll 执行流程 epoll_create()创建epoll实例，返回对应的句柄epfd。具体而言，这个实例包括一个红黑树和一个链表。红黑树用于记录要监听的fd，每个节点就是一个fd。而链表用于记录就绪的fd epoll_ctl()将要监听的fd添加到红黑树中，当这个fd就绪的时候，内核通过回调函数将该fd添加到链表中 epoll_wait()等待fd就绪，调用该方法会在用户空间创建一个数组，用于接受就绪的fd 改进点 红黑树结构增加效率：基于红黑树保存要监听的fd，增删改查效率高 减少重复拷贝：每个fd只需要一次epoll_ctl()添加到红黑树，无需重复拷贝fd到内核空间（相对于select和poll） 无需遍历就能得到就绪fd：内核将就绪的fd拷贝到用户空间的数组中，用户空间无需再次遍历，可以直接得到就绪的fd 4.epoll的ET和LT模式epoll事件的通知机制有两种模式，分别是： 水平触发（levelTrrigered， LT）：当有fd就绪时，会重复通知多次，直至数据被处理完。是epoll的默认模式 边缘触发（edgeTrrigered， ET）：当有fd就绪时，仅通知一次，如果数据没有被处理完就会丢失 LT模式的缺点： 频繁调用epoll_wait()会产生很多开销 可能会产生“惊群”现象，比如当前剩余没有被处理的数据仅仅一两个线程就能解决，但在这种模式下会唤醒所有线程处理数据，也就是会产生不必要的唤醒 ET模式如何保证数据可以被处理完毕？ 采用非阻塞IO一次性把就绪fd处理完。不能采用阻塞IO，如果采用阻塞IO在处理完就绪的fd后会阻塞等待未就绪的fd到就绪的状态，而非阻塞IO在处理完就绪的fd后就会返回错误，代表就绪的fd已经处理完了，剩下的都是未就绪的fd了。 手动把未处理完的fd添加到epoll实例中。（类似手动挡的LT） 前置了解：在拷贝就绪fd到用户空间时，会在就绪链表中移除拷贝的fd，同时会检查当前通知模式时ET还是LT，如果是ET，会永久的移除拷贝的fd，如果是LT，则会检查就绪fd数据有没有被处理完毕，如果没有，会重新把移除的fd添加到链表中。 我们可以调用epoll_ctl()手动将未处理完的fd添加到epoll实例上，完了之后红黑树检测到fd就绪，就会重新给这些就绪的fd添加到链表上。 5.Redis网络模型","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"}]},{"title":"腾讯面经","slug":"面经/腾讯面经","date":"2025-03-31T05:24:23.000Z","updated":"2025-03-31T05:50:39.748Z","comments":true,"path":"2025/03/31/面经/腾讯面经/","permalink":"http://example.com/2025/03/31/%E9%9D%A2%E7%BB%8F/%E8%85%BE%E8%AE%AF%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"d 这是第二次面腾讯，之前面的wxg的企业微信后台开发，太没有体验了。就给了三道题，然后面试官人就没了，最后也就做出来一道，直接就结束面试了。。。 3.21-wxg-企业微信1.（mid），给一个含有n个数的数组，然后有一个魔法值（初始为0），依次遍历数组，魔法值可以选择加当前数或者减当前数，加对应UP，减对应DOWN，最后要求魔法值的绝对值最小，还要输出对应的操作（UP，DOWN这些）用的dp通过0.2，实在没思路了这题 2.背包变种（easy），唯一和背包不同的是背包里面物品的重量不能有重复的 3.子序列计数（hard）给n个这样的序列，比如[2,5]对应的是数组{2,3,4,5}，[1,3]对应的{1,2,3}，然后问n个序列的可能的子序列总共有多少思路是对n个数组求全排列，不过这个和全排列不一样的是，子序列的长度只能为2，没做出来 3.31-S线-腾讯HR与管理线自我介绍 实习遇到的最大的挑战 （由于做的都是crud，就介绍了一下，然后后续没有展开） 八股 进程和线程的区别 线程的状态 什么是线程安全 Java里面是怎么保证线程安全的（答的有点乱感觉） 线程之间的通信方式 数据库的隔离级别，哪种级别可以解决幻读 常见的日志类型 MVCC是什么 Redis的数据结构 持久化机制 缓存穿透及其解决方案 HTTP和HTTPS的区别 HTTPS加密的过程 为什么传输的时候不用非对称加密（答：比对称加密慢。然后又问具体慢多少，这个是唯一没答上来的。。。） SQL注入 手撕： 最长递增子序列 反问","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"嗨吃地图面试版","slug":"嗨吃地图面试版","date":"2025-03-18T01:40:54.000Z","updated":"2025-03-31T01:47:50.486Z","comments":true,"path":"2025/03/18/嗨吃地图面试版/","permalink":"http://example.com/2025/03/18/%E5%97%A8%E5%90%83%E5%9C%B0%E5%9B%BE%E9%9D%A2%E8%AF%95%E7%89%88/","excerpt":"这个项目还是要好好打磨，因为网上资料多，比较透明，而且也看了好长时间了，还有待发掘的点。这里就快速再重新梳理一下项目，然后引出其中需要熟悉的八股","text":"这个项目还是要好好打磨，因为网上资料多，比较透明，而且也看了好长时间了，还有待发掘的点。这里就快速再重新梳理一下项目，然后引出其中需要熟悉的八股 一.概述该项目集商户发布优惠、用户打卡探店等功能于一体，采用多级存储架构，包括本地缓存、Redis和MySQL，实现了用户登录、下单购物、优惠券秒杀、笔记发布和点赞的功能。 登录模块：使用Redis实现黑名单，解决Session共享问题，通过双重拦截器校验和刷新token，实现会话保持。 缓存模块：采用双写模式保持缓存一致性，通过布隆过滤器解决缓存穿透问题，互斥锁方案解决缓存击穿问题， 优惠券模块： 点赞关注模块： 二.登录模块登录模块主要涉及两个内容：用户登录和保存登录状态。 用户登录很好理解，主要就是校验用户的账号密码； 由于HTTP是无状态协议，这意味着每次请求都是独立的，要想维持会话功能，就需要在服务器额外实现一套机制来实现会话功能。 1.验证码登录验证码登录分为两个步骤：发送验证码和登录校验。 1.发送验证码：手机号校验通过后，服务器调用相关接口（例如由腾讯提供的验证码接口）发送并获取验证码，然后将验证码存放到redis中，同时设置过期时间，用于校验时比对。 redis中验证码的存储：string数据类型，key为code+手机号，value为验证码 2.首次登录校验：用户登录向后端发送手机号和验证码，后台取出redis中的验证码进行比对，如果不通过则会拦截，通过校验后需要向数据库中查询该用户是否存在，如果不存在则创建新用户，并保存到数据库。无论用户是否存在，都会将用户信息保存到redis中并设置有效期，最后返回token。 将用户信息保存到redis中的具体做法为：使用UUID生成一个随机字符串作为token（令牌），用户信息（如userid:123,username:Tom）则转化为字符串，将这两个信息以key-value的形式存储到redis中。 2.会话保持会话保持即保存登录状态，同一个客户端发送多条请求时，服务器能够识别出这些请求来自同一用户。 通过用户的首次登录，后台已经返回了token，在后续的请求中，客户端会把token携带在HTTP头部的authorization字段中。 这里使用双重拦截器校验和刷新。 第一个拦截器拦截所有访问路径，如果请求头部中authorization字段携带了合法token，则刷新redis中该token的过期时间，并保存用户信息到Threadlocal中。其他情况全部放行由第二个拦截器处理。此拦截器的作用为，如果用户长时间访问不需要登陆权限路径，也能会话保持。而且对于已经登录的用户，可能他长时间停留在不需要登录的页面，但如果突然点到需要登录的请求，发现请求过期了！也会有不好的体验，这个也是给已经登录的用户token续期的手段！！ 第二个拦截器对需要登陆权限的路径生效，如果此时Threadlocal已经保存了用户信息则直接放行，否则进行拦截。此拦截器的作用是防止未登录用户访问需要登陆权限路径的内容。也就是拦截一切需要登录的相关请求 3.黑名单机制为了防止有人恶意登录，大量发送无效验证码，那么就会可能给服务器带来压力，同时增加公司的开销 因此需要对请求中的手机号获取验证码进行次数限制。在我们的日常使用中，一般一分钟只能获取一次验证码，这里的实现思路很简单，可以称为使用锁的思想。规则是：限制十分钟内最多发送三次验证码，超过三次则拉入黑名单，24小时后从黑名单中移除。 具体流程如下： 检查号码是否在黑名单里面，在的话就禁止请求 查看请求频率（也就是次数）如果要超过三次也禁止请求，并拉入黑名单 十分钟后，计数的键自动过期，24h后，黑名单的键自动过期 这里需要两个key存储，均用String类型，key为 登录请求频率 + 手机号，值为 请求频率，设置十分钟过期，如果十分钟内有新的请求过来，重新设置过期时间为十分钟；key为 登录黑名单 + 手机号，值为手机号，设置24h过期 4.总结登录模块主要分为三个部分，主要包括登录功能、会话保持、黑名单功能。 直接吟唱前面的部分，重点突出①redis存储token，基于token获取用户信息，这样做是为了保证用户信息不直接在网络中传输，保护隐私；②实现会话保持使用双重拦截器；③黑名单功能指的是将频繁获取验证码的手机号一段时间内不能再获取验证码，黑名单使用Redis实现 5.自测 拦截器和过滤器的区别是什么？为什么要用拦截器不使用过滤器？如果同时配置了过滤器和拦截器，哪个先执行，哪个后执行？ 过滤器工作在 Servlet 容器层面，处理所有进入 Servlet 容器的请求。过滤器在更底层工作，它会处理更多的请求（包括静态资源、JSP、WebSocket 请求等）。过滤器适用于需要在整个应用范围内进行预处理和后处理的场景，如安全检查、日志记录、编码设置等。 拦截器工作在 Spring MVC 框架层面，主要处理控制器（Controller）的方法调用。拦截器在过滤器之后执行。拦截器只处理与 Spring MVC 控制器相关的请求，在处理范围上更小。拦截器适用于只需要在处理 Spring MVC 控制器请求时进行预处理和后处理的场景，如业务逻辑处理、数据预处理、视图处理等。 为什么要使用双重拦截器，只用一个拦截器不行吗？这两个拦截器的作用分别是什么？ 第一个拦截器中拦截所有的路径，获取请求头中的token，使用token查询redis中存储的用户信息，将这个信息保存到threadlocal中，同时刷新token的有效期（更新redis中的过期时间），然后放行。如果这个请求中不包含token则直接放行，交由第二个拦截器处理。 第二个拦截器只拦截部分需要登录权限的路径，比如查询购物车、查询历史订单这种路径，拦截到相应的请求后会查询threadlocal中是否存在用户信息，如果不存在用户信息则直接拦截并返回401未授权状态码，如果用户信息存在于threadlocal中，则说明第一个拦截器已经进行了身份校验并拿到了合法的用户信息，则直接放行。 对于未登录的用户，只有访问登录路径和不需要登录授权的路径（比如浏览商品信息、浏览商户信息）才能够经过以上两个拦截器，否则均会被拦截并返回401。 使用两个拦截器的原因：这两个拦截器分别拦截不同的路径，第一个拦截器主要用于刷新token的有效期，第二个拦截器主要用于对授权路径进行鉴权。如果只使用一个拦截器，那么必须规定相同的拦截路径，如果拦截所有路径则会导致部分业务如浏览商品页面也需要登录才可以浏览，如果只拦截部分路径则会导致用户一直浏览商品信息，而token过期的情况。 什么是threadlocal？什么情况需要用到threadlocal？把用户信息存到Threadlocal中会有什么问题？你怎么解决这个问题？ 当一个共享变量是共享的，但是需要每个线程互不影响，相互隔离，就可以使用ThreadLocal：跨层传递信息，隔离线程存储一些线程不安全的工具对象（SimpleDataFormat），Spring中的事务管理器 ThreadLocal是Java中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存的数据。可以将ThreadLocal理解为对外暴露的，用于操作ThreadLocalMap的工具类，Map的key为ThreadLocal对象，Map的value为需要缓存的值。 如果在线程池中使用ThreadLocal会造成内存泄漏。因为当ThreadLocal对象使用完之后，应该要把设置的key，value，也就是Entry对象进行回收，但线程池中的线程不会回收，而线程对象是通过强引用指向ThreadLocalMap，ThreadLocalMap也是通过强引用指向Entry对象。线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏，解决办法是，在使用了ThreadLocal对象之后，手动调用ThreadLocal的remove方法清除Entry对象 三、商户信息缓存1.缓存更新策略为了维护商户信息在Redis中和数据库中的数据一致性，这里采取主动更新 + 超时剔除兜底 主动更新采取旁路缓存模式——先更新数据库，再删除缓存的模式。 2.缓存穿透产生原因：要查询的数据在缓存和数据库中都没有 对应场景：可能会有攻击者恶意构造大量不存在的商铺id进行查询。 解决方案：布隆过滤器，缓存null值。这里选择布隆过滤器。缓存null值可能会占用很多的内存 布隆过滤器的原理其实非常简单，就是bitmap + 多重hash，主要优势就是利用非常小的空间就可以实现在大规模数据下快速判断某一对象是否存在，缺点是存在误判的可能，但不会漏判，也就是存在的对象一定会判断为存在，而不存在的对象会有较低的概率为误判为存在，且不支持对象的删除，因为会增加误判的概率。 具体实现： Redis 实现布隆过滤器的底层就是通过 bitmap 这种数据结构，至于如何实现，这里就不重复造轮子了，介绍业界比较好用的一个客户端工具——Redisson。Redisson 是用于在 Java 程序中操作 Redis 的库，利用Redisson 我们可以在程序中轻松地使用 Redis。 下面我们就通过 Redisson 来构造布隆过滤器。 12345678910111213141516171819202122232425/** * 配置布隆过滤器 */@Configurationpublic class BloomFilterConfig &#123; @Autowired private RedissonClient redissonClient; /** * 创建商品信息布隆过滤器 * @return */ @Bean public RBloomFilter&lt;Long&gt; orderBloomFilter() &#123; //过滤器名称 String filterName = &quot;orderBloomFilter&quot;; // 预期插入数量 long expectedInsertions = 10000L; // 错误比率 double falseProbability = 0.01; RBloomFilter&lt;Long&gt; bloomFilter = redissonClient.getBloomFilter(filterName); bloomFilter.tryInit(expectedInsertions, falseProbability); return bloomFilter; &#125;&#125; 通过redisson创建布隆过滤器，然后初始化预期插入数量和错误比率即可。 redisson中的BloomFilter有2个核心方法： bloomFilter.add(orderId) 向布隆过滤器中添加id bloomFilter.contains(orderId) 判断id是否存在 查询流程如下： 而添加商铺信息的执行流程则是： 在添加商铺信息到数据库的同时，也要添加到布隆过滤器 3.缓存击穿产生原因：热点key突然失效，此时如果大量请求突然过来，会全部打到数据库上。失效原因一般是过期了 对应场景：热门商铺正在搞活动，然后这时热点key突然失效，可能就会导致商铺信息页面加载不出来 TODO解决方案：永不过期（逻辑过期），互斥锁更新。这里采用互斥锁更新，因为商铺信息可能变化比较快，如果采用逻辑过期内存占用大不说，而且数据一致性难以保持。虽然采用互斥锁在高并发情况下可能会有点问题，但后期可以补一个限流（TODO） 具体实现流程： 4.缓存雪崩产生原因：大量缓存同时失效，或者Redis宕机 解决方案： 针对大量缓存同时失效： 给缓存设置随机TTL，避免同时过期 数据永不过期+更新机制。对高频访问的热点数据设置为永不过期，并通过后台任务或消息队列监听数据库变化，异步更新缓存。 限流与降级。在缓存失效或服务不可用时，通过限流（如令牌桶、漏桶算法）限制请求量，或降级返回默认数据（如静态页面、历史数据），减少数据库压力。 预加载（缓存预热）。系统启动时或定期将热点数据预加载到缓存中，避免运行时集中失效。 xxl-job。 针对Redis宕机： Redis集群。使用Redis集群、主从复制或哨兵模式，确保缓存服务宕机时能快速切换到备用节点，避免整体失效。 多级缓存。引入多级缓存（如本地缓存 + 分布式缓存）。当分布式缓存（如Redis）失效时，先尝试从本地缓存（如Caffeine、Guava）读取，降低对数据库的直接冲击。 TODO这里可以优化的点很多。比如限流与降级+预加载+多级缓存。这些是可以尝试实现的点 5.总结主要是对缓存的使用中可能出现的问题。数据一致性+缓存三件套 6.自测 为什么要用redis做一层缓存，相比直接查mysql有什么优势？ 如何保证redis和mysql的数据一致性？延迟双删 如何保证缓存与数据库的操作的同时成功或失败？事务相关的八股，很多内容 缓存穿透、缓存击穿、缓存雪崩，什么是缓存xx？如何解决这个问题？这几个解决方案各自的优势和缺点分别是什么？ 缓存三兄弟的其他问法：①现在有一个场景，假如有一个key即将过期了，但是此时有100万个请求访问存入这个key的数据，这种情况该怎么办（击穿）？②现在有一个场景，假如有大量的key同时过期，但是这些key的访问频率很高，一瞬间会给数据库造成过大压力，该怎么办（雪崩）？③现在有一个场景，有大量的请求进来，访问一个并不存在的key，且这个数据也不存在于数据库中，该怎么办（穿透）？ 四、优惠券模块业务梳理 1.分布式ID：随着时间增长，订单ID可能会超出表限制，如果增加了服务器机器，可能需要分库分表，此时再用自增ID就无法满足生成的主键是唯一的了。所以需要分布式ID！ 2.优惠券分为普通优惠券和秒杀优惠券，普通优惠券无购买限制，但受库存数量限制；秒杀优惠券在普通优惠券的限制基础上还有时间限制和购买限制，一个人只能在秒杀时间段内购买一单，同时如果库存里面没有了，也购买失败。 梳理一下这里的数据表： 商品信息表：主要包含商品id，店铺id，商品名，商品描述，价格，类型（普通、限购、秒杀），状态（上下架） 普通商品库存表：主要包含商品id，库存 秒杀商品库存表：主要包含商品id，库存，限购数量，秒杀开始和结束时间 订单表：主要包含订单ID，商品id，购买用户 1.分布式ID的实现时间戳+序列号的方式，或者说UUID 这个分布式ID写了一个封装了一个工具类，是用于订单ID，而不是优惠券ID！！！！ 2.乐观锁解决普通优惠券超卖产生问题：并发环境下，因为查询操作和下单操作不是原子操作，可能就会产生数据不一致，进而导致超卖。比如还剩下最后一个库存，此时AB线程来了查到都允许购买，他俩就都下单，这就是一份库存结果卖出去了两份。 解决方案：基于乐观锁的版本号改进方案。乐观锁思想是假设每一次读取数据时都不会有冲突，在实际的业务场景中，普通类商品确实如此，很少会有冲突，符合乐观锁的预设。但这里将查询到的库存代替版本号，并且在下单时，不必强制令此时的库存是否&#x3D;查询到的库存才允许下单，只要此时的库存&gt;0就允许下单，因为如果是强制等于，可能造成明明有库存，但会下单失败的情形。 3.分布式锁解决秒杀优惠券一人一单问题使用的现成的Redisson，因为它不仅可以 互斥 高性能 自动过期 而且还有可重入锁，自动续期这俩功能 使用过程： 引入依赖——&gt;配置Redisson客户端——&gt;使用锁 1.引入依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.6&lt;/version&gt;&lt;/dependency&gt; 2.配置Redisson客户端 123456789101112131415161718192021222324252627@Configurationpublic class RedissonConfig &#123; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private String port; @Value(&quot;$&#123;spring.redis.password&#125;&quot;) private String password; /** * 创建Redisson配置对象，然后交给IOC管理 * * @return */ @Bean public RedissonClient redissonClient() &#123; // 获取Redisson配置对象 Config config = new Config(); // 添加redis地址，这里添加的是单节点地址，也可以通过 config.userClusterServers()添加集群地址 config.useSingleServer().setAddress(&quot;redis://&quot; + this.host + &quot;:&quot; + this.port) .setPassword(this.password); // 获取RedisClient对象，并交给IOC进行管理 return Redisson.create(config); &#125;&#125; 3.修改一下使用锁的地方，其它的业务代码都不需要该 12345// 3、创建订单（使用分布式锁）Long userId = ThreadLocalUtls.getUser().getId();RLock lock = redissonClient.getLock(RedisConstants.LOCK_ORDER_KEY + userId);boolean isLock = lock.tryLock(); 4.MQ异步下单秒杀优惠券这里有几个文件，配置了 VoucherOrderServiceImpl：处理用户请求，协调流程。 seckill.lua：原子性检查库存和下单记录。 MQSender 和 MQReceiver：通过消息队列异步处理订单。 RabbitMQTopicConfig：配置消息路由。 整体执行流程 用户发起秒杀请求：用户调用 VoucherOrderServiceImpl.seckillVocher(voucherId)，传入优惠券 ID 执行 Lua 脚本 ：VoucherOrderServiceImpl 调用 seckill.lua，传入 voucherId 和 userId，检查库存和下单记录： 如果返回 1（库存不足）或 2（已下单），直接返回失败。 如果返回 0，进入下一步。 创建订单并发送消息：创建 VoucherOrder 对象，生成订单 ID，通过MQSender 将订单信息发送到 seckillExchange（路由键 seckill.lua.message）。 消息路由：RabbitMQTopicConfig 配置的绑定确保消息从 seckillExchange 路由到 seckillQueue。 接收并处理消息：MQReceiver 从 seckillQueue 接收消息，解析为 VoucherOrder，检查用户下单情况，扣减数据库库存，保存订单。 困惑点补充： 1.Lua脚本怎么检查库存和下单记录的 因为Redis保存了库存数量，以及用set集合了下单记录，所以可以很快查找到 五.点赞关注模块1.点赞使用Zset的原因 点赞这种高频变化的数据，如果我们使用MySQL是十分不理智的，因为MySQL慢、并且并发请求MySQL会影响其它重要业务，容易影响整个系统的性能，继而降低了用户体验。 不重复 Zset，key为业务名+UserID，value为点赞数 1.判断是否点赞可以用ZSet的ZSCORE方法判断用户是否存在 123456789101112131415/** * 判断当前用户是否点赞该博客 */ private void isBlogLiked(Blog blog) &#123; UserDTO user = ThreadLocalUtls.getUser(); if (Objects.isNull(user))&#123; // 当前用户未登录，无需查询点赞 return; &#125; Long userId = user.getId(); String key = BLOG_LIKED_KEY + blog.getId(); Double score = stringRedisTemplate.opsForZSet().score(key, userId.toString()); blog.setIsLike(Objects.nonNull(score)); &#125; 2.SortedList可以使用ZRANGE方法实现范围查询 key为用户，value为点赞次数 123456789101112131415161718192021/** * 查询所有点赞博客的用户 * * @param id * @return */ @Override public Result queryBlogLikes(Long id) &#123; // 查询Top5的点赞用户 zrange key 0 4 Long userId = ThreadLocalUtls.getUser().getId(); String key = BLOG_LIKED_KEY + id; Set&lt;String&gt; top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4); if (top5 == null || top5.isEmpty()) &#123; return Result.ok(Collections.emptyList()); &#125; List&lt;Long&gt; ids = top5.stream().map(Long::valueOf).collect(Collectors.toList()); List&lt;UserDTO&gt; userDTOList = userService.listByIds(ids).stream() .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); return Result.ok(userDTOList); &#125; 2.关注&#x2F;共同关注Set记录关注博主，对于共同关注，可以用两个Set求交集 1234567891011121314151617181920212223/** * 查询共同关注 * * @param id * @return */ @Override public Result followCommons(Long id) &#123; Long userId = ThreadLocalUtls.getUser().getId(); String key1 = FOLLOW_KEY + userId; String key2 = FOLLOW_KEY + id; // 查询当前用户与目标用户的共同关注对象 Set&lt;String&gt; intersect = stringRedisTemplate.opsForSet().intersect(key1, key2); if (Objects.isNull(intersect) || intersect.isEmpty()) &#123; return Result.ok(Collections.emptyList()); &#125; List&lt;Long&gt; ids = intersect.stream().map(Long::valueOf).collect(Collectors.toList()); // 查询共同关注的用户信息 List&lt;UserDTO&gt; userDTOList = userService.listByIds(ids).stream() .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); return Result.ok(userDTOList); &#125;","categories":[],"tags":[]},{"title":"美团暑期面试","slug":"面经/美团暑期面试","date":"2025-03-08T09:06:26.000Z","updated":"2025-03-08T10:09:30.060Z","comments":true,"path":"2025/03/08/面经/美团暑期面试/","permalink":"http://example.com/2025/03/08/%E9%9D%A2%E7%BB%8F/%E7%BE%8E%E5%9B%A2%E6%9A%91%E6%9C%9F%E9%9D%A2%E8%AF%95/","excerpt":"美团暑期面试，希望能拿到offer","text":"美团暑期面试，希望能拿到offer 1.Ai面试(3.8日) TCP重传机制有哪些触发条件？超时重传和快速重传的区别？ 解释Linux管道的概念，给出一个使用管道的例子 对explain关键字的理解，包括它的用途如何使用典型输出信息的含义，以及如何利用这些信息进行查询优化 自动装箱和拆箱？给出一个例子 hashCode和equals的关系？为什么要重写hashcode和equals 解释Java中的线程，如何创建和启动一个线程 设计一个简单的文章热度计算系统考虑浏览量评论数和分享数等因素 追问：是否考虑过时间因素对文章热度的影响？比如，一篇文章中发布后的不同时间段内热度的变化情况，如果考虑的话，你会如何将时间因素整合到热度计算中呢？ 在编程学习中如何处理挫折感和持续保持学习动力的？举一个具体的例子","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"上海尖峰合讯面经","slug":"面经/上海尖峰合讯面经","date":"2025-03-03T07:13:03.000Z","updated":"2025-03-03T09:21:22.684Z","comments":true,"path":"2025/03/03/面经/上海尖峰合讯面经/","permalink":"http://example.com/2025/03/03/%E9%9D%A2%E7%BB%8F/%E4%B8%8A%E6%B5%B7%E5%B0%96%E5%B3%B0%E5%90%88%E8%AE%AF%E9%9D%A2%E7%BB%8F/","excerpt":"最近开学进度一直拖延，这场面试算是找回一下“手感”了，问的也比较简单，不过也不准备去，感觉是黑外包😅","text":"最近开学进度一直拖延，这场面试算是找回一下“手感”了，问的也比较简单，不过也不准备去，感觉是黑外包😅 自我介绍 面向对象三大特征，然后分别介绍一下 一个类能不能继承多个类 &#x3D;&#x3D;和equals的区别 常用集合 ArrayList如何去重 答：借助hashSet hashmap并发下有什么问题 mybatis的#和 $有什么区别 mybatis如何分页 答：使用limit关键字。还有一个pagehelper插件这个没答到 索引失效有哪些情况 漏答了模糊匹配和表达式计算这两个 拦截器和过滤器的区别（不会 创建线程的方式 runable和callable的区别 start和run有什么区别 能直接调用run方法吗 我用过git哪些命令 然后反问。问了一下进入做什么业务以及可能用到什么技术栈。不过感觉这个可能有点坑，实习到五月底之前不能离职否则有违约金，而且实习生当正式工用。 过了俩小时打电话oc，拒绝了","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[]},{"title":"ACM模式学习","slug":"ACM模式学习","date":"2025-02-01T03:56:05.000Z","updated":"2025-02-21T03:50:17.399Z","comments":true,"path":"2025/02/01/ACM模式学习/","permalink":"http://example.com/2025/02/01/ACM%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0/","excerpt":"由于之前刷题一直是在力扣用的核心模式，而在找工作时很多情况需要用ACM模式来做题，因此需要熟悉一下ACM模式的写法，后续也会用ACM模式重新做一遍hot100，进一步熟悉这种模式。加油！(≧∇≦)ﾉ","text":"由于之前刷题一直是在力扣用的核心模式，而在找工作时很多情况需要用ACM模式来做题，因此需要熟悉一下ACM模式的写法，后续也会用ACM模式重新做一遍hot100，进一步熟悉这种模式。加油！(≧∇≦)ﾉ hot100的ACM模式解题 1.区分next、nextInt、nextLine1. next() 功能：读取输入中的下一个单词（以空白符为分隔符）。 行为： 跳过输入中的前导空格&#x2F;换行符。 读取字符直到遇到空格、制表符或换行符。 不包含末尾的空白符，且不会消耗换行符。 示例： java 复制 12Scanner sc = new Scanner(System.in);String word = sc.next(); 输入 &quot; Hello World\\n&quot;，word = &quot;Hello&quot;，剩余输入为 &quot;World\\n&quot;。 2. nextInt() 功能：读取输入中的下一个整数。 行为： 跳过前导空格&#x2F;换行符。 读取连续数字字符，直到遇到非数字字符（如空格或字母）。 不会消耗后续的换行符或空格，可能导致后续nextLine()读到空字符串。 示例： java 复制 12Scanner sc = new Scanner(System.in);int num = sc.nextInt(); 输入 &quot; 42\\n&quot;，num = 42，剩余输入为 &quot;\\n&quot;。 输入 &quot;abc&quot; 会抛出 InputMismatchException。 3. nextLine() 功能：读取输入中的一整行内容（到换行符为止）。 行为： 读取从当前位置到换行符之间的所有字符（包括空格）。 消耗换行符，输入流中不再残留换行符。 示例： java 复制 12Scanner sc = new Scanner(System.in);String line = sc.nextLine(); 输入 &quot;Hello World\\n&quot;，line = &quot;Hello World&quot;，剩余输入为空。 常见问题及解决方案问题：混合使用nextInt()和nextLine()导致跳过输入 场景： java 复制 123Scanner sc = new Scanner(System.in);int num = sc.nextInt(); // 输入 &quot;42\\n&quot;String line = sc.nextLine(); // line 为空字符串 原因：nextInt()读取了42，但未消耗后面的换行符（\\n），nextLine()直接读取了残留的换行符。 解决：在nextInt()后调用一次nextLine()消耗换行符： java 复制 123int num = sc.nextInt();sc.nextLine(); // 清除残留的换行符String line = sc.nextLine(); 总结 **next()**：适合读取以空格分隔的单词。 **nextInt()**：读取整数，需注意处理残留的换行符。 **nextLine()**：读取整行内容，常用于处理含空格的字符串。 谨慎混用next() 和nextLine() 2.高效处理大量数据 BufferedReader： 用于高效读取输入流（比 Scanner 更快）。 readLine() 方法逐行读取输入。 StringTokenizer： 用于将每行输入按空格分割成多个整数。 hasMoreTokens() 检查是否还有未处理的标记。 nextToken() 获取下一个标记并转换为整数。 举例说明 123456789//输入：1 2 34 50 0 0 0 0 //输出690 123456789101112131415161718192021222324import java.io.*;import java.util.*;public class Main &#123; public static void main(String[] args) throws IOException &#123; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String line; // 逐行读取输入 while ((line = br.readLine()) != null) &#123; StringTokenizer st = new StringTokenizer(line); // 分割每行的数据 int sum = 0; // 遍历每行的所有整数 while (st.hasMoreTokens()) &#123; int num = Integer.parseInt(st.nextToken()); sum += num; &#125; // 输出当前行的求和结果 System.out.println(sum); &#125; &#125;&#125; 使用技巧 StringTokenizer 高效分割字符串 比 split() 更快 3.二叉树相关1.二叉树的构造这个是最常用的，可以配合读取一行数据，然后将该行数据转为字符串数组传入该函数得到树根节点 1234567891011121314151617181920212223242526public static TreeNode buildTree(String[] nodes)&#123; if(nodes == null || nodes.length == 0 || nodes[0].equals(&quot;null&quot;)) return null; TreeNode root = new TreeNode(Integer.parseInt(nodes[0])); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int index = 1; while (!queue.isEmpty() &amp;&amp; index &lt; nodes.length)&#123; TreeNode cur = queue.poll(); if(index &lt; nodes.length &amp;&amp; !nodes[index].equals(&quot;null&quot;))&#123; cur.left = new TreeNode(Integer.parseInt(nodes[index])); queue.offer(cur.left); &#125; index++; if(index &lt; nodes.length &amp;&amp; !nodes[index].equals(&quot;null&quot;))&#123; cur.right = new TreeNode(Integer.parseInt(nodes[index])); queue.offer(cur.right); &#125; index++; &#125; return root; &#125; 2.二叉树的层序遍历这个也要熟练掌握，因为有些题目的输出需要，而且有很多层序遍历的变种题目，作为最基础的层序遍历掌握了再写变种题目也会简单的多。 123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); if(root == null) return ans; ArrayDeque&lt;TreeNode&gt; deque = new ArrayDeque&lt;&gt;(); deque.offer(root); while (!deque.isEmpty())&#123; int size = deque.size(); ArrayList&lt;Integer&gt; temp = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; TreeNode node = deque.poll(); if(node.left != null) deque.offer(node.left); if(node.right != null) deque.offer(node.right); temp.add(node.val); &#125; ans.add(temp); &#125; return ans; &#125; 4.数组相关1.一维数组输出1Arrays.toString(nums) 2.二维数组输出1Arrays.deepToString(martrix) 3.由输入字符串构建整数数组1234567Scanner sc = new Scanner(System.in); String s = sc.nextLine(); String[] split = s.split(&quot;,&quot;); int[] nums = new int[split.length]; for (int i = 0; i &lt; nums.length; i++) &#123; nums[i] = Integer.parseInt(split[i]); &#125;","categories":[{"name":"学习","slug":"学习","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"刷题","slug":"刷题","permalink":"http://example.com/tags/%E5%88%B7%E9%A2%98/"}]},{"title":"springcloud学习","slug":"springcloud学习","date":"2025-01-18T12:32:05.000Z","updated":"2025-01-31T08:06:14.252Z","comments":true,"path":"2025/01/18/springcloud学习/","permalink":"http://example.com/2025/01/18/springcloud%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"一、Docker1.基础命令2.数据卷容器内部的数据不好修改，因此数据卷应运而生，它就是一个虚拟目录，是联通宿主机目录和容器目录的中间桥梁。 数据卷命令： 注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中，数据卷会自动创建。 数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似： 1234# 挂载本地目录-v 本地目录:容器内目录# 挂载本地文件-v 本地文件:容器内文件 注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。 例如： 12-v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷-v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录 二、项目 导入项目 出现错误：docker: Error response from daemon: Get “https://registry-1.docker.io/v2/“: net&#x2F;http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers). 在这里解决了，修改了daemon.json就可以了，效果如下 接下来连接数据库，这里账号密码应该是数据库的而不是虚拟机的 接下来按照视频里面启动后端项目，有两个小插曲，一个是lombok版本问题，修改为了1.18.30，另一个是8080端口被占用了，直接在任务管理器里面杀死了 后面为item-service创建单独数据库的时候，发现连接不上去，后面解决了，是docker里面的mysql没有启动，设置自启动好像有点问题，后面再看看 设置docker开启自启动： 1systemctl enable docker 然后启动MySQL容器 12# docker start 容器名docker start mysql 然后就是拆分了商品服务和购物车服务 二、注册中心在微服务远程调用的过程中，包括两个角色： 服务提供者：提供接口供其它微服务访问，比如item-service 服务消费者：调用其它微服务提供的接口，比如cart-service 在大型微服务项目中，服务提供者的数量会非常多，为了管理这些服务就引入了注册中心的概念。注册中心、服务提供者、服务消费者三者间关系如下： 流程如下： 服务启动时就会注册自己的服务信息（服务名、IP、端口）到注册中心 调用者可以从注册中心订阅想要的服务，获取服务对应的实例列表（1个服务可能多实例部署） 调用者自己对实例列表负载均衡，挑选一个实例 调用者向该实例发起远程调用 当服务提供者的实例宕机或者启动新实例时，调用者如何得知呢？ 服务提供者会定期向注册中心发送请求，报告自己的健康状态（心跳请求） 当注册中心长时间收不到提供者的心跳时，会认为该实例宕机，将其从服务的实例列表中剔除 当服务有新实例启动时，会发送注册服务请求，其信息会被记录在注册中心的服务实例列表 当注册中心服务列表变更时，会主动通知微服务，更新本地服务列表 1.服务注册接下来，我们把item-service注册到Nacos，步骤如下： 引入依赖 12345&lt;!--nacos 服务注册发现--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 配置Nacos地址 在item-service的application.yml中添加nacos地址配置： 123456spring: application: name: item-service # 服务名称 cloud: nacos: server-addr: 192.168.150.101:8848 # nacos地址 重启 2.服务发现服务的消费者要去nacos订阅服务，这个过程就是服务发现，步骤如下： 引入依赖 服务发现除了要引入nacos依赖以外，由于还需要负载均衡，因此要引入SpringCloud提供的LoadBalancer依赖。 我们在cart-service中的pom.xml中添加下面的依赖： 12345&lt;!--nacos 服务注册发现--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 可以发现，这里Nacos的依赖于服务注册时一致，这个依赖中同时包含了服务注册和发现的功能。因为任何一个微服务都可以调用别人，也可以被别人调用，即可以是调用者，也可以是提供者。 因此，等一会儿cart-service启动，同样会注册到Nacos 配置Nacos地址 1234spring: cloud: nacos: server-addr: 192.168.150.101:8848 发现并调用服务 三、OpenFeign在上一章，我们利用Nacos实现了服务的治理，利用RestTemplate实现了服务的远程调用。但是远程调用的代码太复杂了： 而且这种调用方式，与原本的本地方法调用差异太大，编程时的体验也不统一，一会儿远程调用，一会儿本地调用。 因此，我们必须想办法改变远程调用的开发模式，让远程调用像本地方法调用一样简单。而这就要用到OpenFeign组件了。 其实远程调用的关键点就在于四个： 请求方式 请求路径 请求参数 返回值类型 所以，OpenFeign就利用SpringMVC的相关注解来声明上述4个参数，然后基于动态代理帮我们生成远程调用的代码，而无需我们手动再编写，非常方便。 接下来，我们就通过一个快速入门的案例来体验一下OpenFeign的便捷吧。 以cart-service中的查询我的购物车为例 1.引入依赖在cart-service服务的pom.xml中引入OpenFeign的依赖和loadBalancer依赖： 12345678910&lt;!--openFeign--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--负载均衡器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; 2.启用OpenFeign在cart-service的CartApplication启动类上添加注解，启动OpenFeign功能： @EnableFeignClients 3.编写OpenFeign客户端在cart-service中，定义一个新的接口，编写Feign客户端： 123456789101112131415package com.hmall.cart.client;import com.hmall.cart.domain.dto.ItemDTO;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestParam;import java.util.List;@FeignClient(&quot;item-service&quot;)public interface ItemClient &#123; @GetMapping(&quot;/items&quot;) List&lt;ItemDTO&gt; queryItemByIds(@RequestParam(&quot;ids&quot;) Collection&lt;Long&gt; ids);&#125; 这里只需要声明接口，无需实现方法。接口中的几个关键信息： @FeignClient(&quot;item-service&quot;) ：声明服务名称 @GetMapping ：声明请求方式 @GetMapping(&quot;/items&quot;) ：声明请求路径 @RequestParam(&quot;ids&quot;) Collection&lt;Long&gt; ids ：声明请求参数 List&lt;ItemDTO&gt; ：返回值类型 有了上述信息，OpenFeign就可以利用动态代理帮我们实现这个方法，并且向http://item-service/items发送一个GET请求，携带ids为请求参数，并自动将返回值处理为List&lt;ItemDTO&gt;。 我们只需要直接调用这个方法，即可实现远程调用了。 4.连接池Feign底层发起http请求，依赖于其它的框架。其底层支持的http客户端实现包括： HttpURLConnection：默认实现，不支持连接池 Apache HttpClient ：支持连接池 OKHttp：支持连接池 因此我们通常会使用带有连接池的客户端来代替默认的HttpURLConnection。比如，我们使用OK Http. 连接池使用如下： 在cart-service的pom.xml中引入依赖： 12345&lt;!--OK http 的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 在cart-service的application.yml配置文件中开启Feign的连接池功能： 123feign: okhttp: enabled: true # 开启OKHttp功能","categories":[],"tags":[]},{"title":"分布式","slug":"八股/分布式","date":"2025-01-18T07:13:37.000Z","updated":"2025-05-18T10:35:09.918Z","comments":true,"path":"2025/01/18/八股/分布式/","permalink":"http://example.com/2025/01/18/%E5%85%AB%E8%82%A1/%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"分布式（distributed）是为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段，将一个业务拆分成不同的子业务，分布在不同的机器上执行。服务之间通过远程调用协同工作，对外提供服务。 一、分布式理论1、CAP原则在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这 3 个基本需求，最多只能同时满足其中的 2 个。 Consistency（一致性）： 指数据在多个副本之间能够保持一致的特性（严格的一致性） Availability（可用性）：指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据） Partition tolerance（分区容错性）：分布式系统即便是系统出现网络分区，整个系统也要持续对外提供服务。 什么是网络分区？ 分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）导致节点之间无法通信的情况， 整个网络就分成了几块区域，这就叫 网络分区。 2、为什么CAP不能同时满足首先，在分布式系统中，分区是必然存在的，因此P就必须要满足，否则就违背了分布式系统的初衷。 在满足P的前提下，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。 因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。 另外，需要补充说明的一点是：如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。 Spring Cloud在CAP法则上主要满足的是AP法则，Dubbo和Zookeeper在CAP法则主要满足的是CP法则 ，Nacos 不仅支持 CP 也支持 AP 3、BASE理论BASE 是 Basically Available（基本可用）、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。 其核心思想时：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。 Basically Available（基本可用）：什么是基本可用呢？假设系统出现了不可预知的故障，但还是能用，只是相比较正常的系统而言，可能会有响应时间上的损失，或者功能上的降级（正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用）。 Soft-state（软状态）：什么是硬状态呢？要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态也称为弱状态，相比较硬状态而言，允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 Eventually Consistent（最终一致性）：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 二、分布式锁的实现一个最基本的分布式锁需要满足： 互斥：任意一个时刻，锁只能被一个线程持有。 高可用：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过超时机制实现的。 可重入：一个节点获取了锁之后，还可以再次获取锁。 除了上面这三个基本条件之外，一个好的分布式锁还需要满足下面这些条件： 高性能：获取和释放锁的操作应该快速完成，并且不应该对整个系统的性能造成过大影响。 非阻塞：如果获取不到锁，不能无限期等待，避免对系统正常运行造成影响。 1、MYSQL实现 用数据库实现分布式锁比较简单，就是创建一张锁表，数据库对字段作唯一性约束。 加锁的时候，在锁表中增加一条记录即可；释放锁的时候删除记录就行。 如果有并发请求同时提交到数据库，数据库会保证只有一个请求能够得到锁。 这种属于数据库 IO 操作，效率不高，而且频繁操作会增大数据库的开销，因此这种方式在高并发、高性能的场景中用的不多。 2.Redis实现set nx ex，这样可以设置一个简单的分布式锁，set nx是如果key不存在，则创建key，否则失败；而ex则给这个key设置了过期时间，避免锁无法释放。而且Redis的命令都是原子性的，这样就保持了获得锁和设置过期时间是一起操作的 对于自己设计的分布式锁，如果要保证判断该锁是否为自己的和释放锁这两个操作为原子操作，就需要用Lua脚本。释放锁的时候判断是否与获得锁的线程id一样 Redisson 是一个开源的 Java 语言 Redis 客户端，提供了很多开箱即用的功能，不仅仅包括多种分布式锁的实现。 而redisson不仅实现了上述功能，还更为强大，有以下功能： 自动续期 可重入 读写锁 公平锁 下面介绍redisson原理 key是锁的名称，value是个map，map的key是线程id，value是锁的重入次数，然后设置锁过期时间 如果加锁成功，锁的重入次数加一，这就实现了重入锁的功能； 加锁成功后，就会执行一个看门狗的机制。看门狗机制是为了防止业务还没执行完，但锁到期了的问题。看门狗就是一个定时任务，只要当前线程任务没有挂掉，且没有主动释放锁，就会隔一段时间给锁续期。默认情况下，每过 10 秒，看门狗就会执行续期操作，将锁的超时时间设置为 30 秒。 如果失败，返回锁的过期时间 加锁失败后，会进入一个循环中，此线程会被semaphore阻塞，当之前的线程释放锁后，会通过semaphore来唤醒此线程，然后获得锁后跳出此循环 释放锁时，如果该锁的线程id不是自己的，就无权释放；如果是，就将重入次数减一，如果减后的重入次数还是＞0，就不能释放，更新锁到期时间，否则就释放锁，然后发送锁释放消息，唤醒被阻塞的线程 无论加锁成功或失败，都会有一个future结果器来接收加锁结果 3、Zookeeper实现 三、分布式事务 分布式事务，就是指不是在单个服务或单个数据库架构下，产生的事务，例如： 跨数据源的分布式事务 跨服务的分布式事务 综合情况 我们之前解决分布式事务问题是直接使用Seata框架的AT模式，但是解决分布式事务问题的方案远不止这一种。 四、分布式一致性算法","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"常用算法系列","slug":"算法学习","date":"2024-12-24T07:24:36.000Z","updated":"2025-03-14T03:03:52.434Z","comments":true,"path":"2024/12/24/算法学习/","permalink":"http://example.com/2024/12/24/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/","excerpt":"学习一下一些经典数据结构和排序算法","text":"学习一下一些经典数据结构和排序算法 1.快速排序1.基本思想快速排序是一种高效的分治算法，其核心思想是： 选择一个基准元素（pivot）：通常是数组中的某个元素。 分区（Partition）：将数组分为两部分，使得左边元素均 ≤ 基准，右边元素均 ≥ 基准。 递归排序：对左右子数组递归执行上述操作，直到子数组长度为1或0（已有序）。 2.分区（Partition）过程详解分区是快速排序的核心步骤，目的是将数组划分为两个子数组。以双指针法为例： 基准选择：通常选第一个元素 arr[left] 作为基准（也可随机选择优化性能）。 双指针移动： 左指针（i）：从左向右找第一个 &gt; 基准的元素。 右指针（j）：从右向左找第一个 &lt; 基准的元素。 交换元素：当找到后，交换这两个元素，继续移动指针。 放置基准：最终将基准元素交换到正确的位置，返回其下标。 3.Java 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; private static final Random RANDOM=new Random(); public int[] sortArray(int[] nums) &#123; if(nums==null||nums.length==0) return nums; quickselect(nums,0,nums.length-1); return nums; &#125; public void quickselect(int[] nums,int left,int right)&#123; if(left &lt; right)&#123; int pivotIndex=partition(nums,left,right); quickselect(nums,left,pivotIndex-1); quickselect(nums,pivotIndex+1,right); &#125; &#125; public int partition(int[] nums,int left,int right)&#123; //最关键核心的部分 int randomIndex=RANDOM.nextInt(right-left+1)+left; //随机选择基准 swap(nums,left,randomIndex); int i=left+1,j=right; int pivot=nums[left]; while(true)&#123; while(i&lt;=j &amp;&amp; nums[i]&lt;pivot) i++; while(i&lt;=j &amp;&amp; nums[j]&gt;pivot) j--; if(i&gt;=j) break; swap(nums,i,j); i++; j--; &#125; swap(nums,left,j); return j; &#125; public void swap(int[] nums,int i,int j)&#123; int tmp=nums[i]; nums[i]=nums[j]; nums[j]=tmp; &#125;&#125; 4.时间复杂度分析 平均情况：O(n log n)每次分区将数组大致分为两半。 最坏情况：O(n²)当数组已有序且总选第一个元素为基准时，退化为冒泡排序。 优化策略： 随机选择基准：减少最坏情况概率。 三数取中法：选左、中、右三个数的中位数作为基准。 2.动态规划之0-1背包问题为什么要压缩数组？1.0-1背包问题简介0-1背包问题是一个经典的动态规划问题。假设我们有 n 个物品，每个物品有重量 w[i] 和价值 v[i]，以及一个容量为W的背包。每个物品只能选择拿或不拿（0或1），目标是选择一些物品放入背包，使得总重量不超过 W，同时总价值最大。 2.二维DP的思路我们先从传统的二维DP数组讲起，因为它是一维DP的基础。 定义DP数组 定义 dp[i][j] 表示：前 i 个物品（从 0 到 i-1），背包容量为 j 时，能获得的最大价值。 其中： i 表示考虑前 i 个物品。 j 表示背包的当前容量。 状态转移方程 对于第 i 个物品（编号从 1 开始），我们有两种选择： 不拿第 i 个物品： dp[i][j] = dp[i-1][j]，即不放入当前物品，价值等于前 i-1 个物品在容量 j 下的最大价值。 拿第 i 个物品（前提是背包容量足够，即 j &gt;= w[i]）： dp[i][j] = dp[i-1][j - w[i]] + v[i]，即放入当前物品，用掉 w[i]的容量，价值增加 v[i]。 综合选择： dp[i][j] = max(dp[i-1][j], dp[i-1][j - w[i]] + v[i])（如果 j &gt;= w[i]）。 如果 j &lt; w[i]，则只能不拿，dp[i][j] = dp[i-1][j]。 初始化 当没有物品时（i &#x3D; 0），价值为 0，即 dp[0][j] = 0 对于所有 j。 目标 最终答案是 dp[n][W]，表示前 n 个物品在容量 W 下的最大价值。 空间复杂度 二维DP需要一个 n × W 的数组，空间复杂度是 O(nW)。 3.优化到一维DP观察二维DP的状态转移方程，我们发现dp[i][j]只依赖于上一行（i-1）的数据，即dp[i-1][j]和 dp[i-1][j - w[i]]。这意味着我们不需要存储整个二维数组，只需要用一个一维数组保存“上一行”的结果，并在计算当前物品时更新它。 定义一维DP数组 定义 dp[j] 表示：背包容量为 j 时，能获得的最大价值。 这个数组会随着物品的遍历不断更新，最终反映所有物品考虑后的结果。 状态转移方程 对于每个物品 i，更新 dp[j]： 如果 j &gt;= w[i]，则 dp[j] = max(dp[j], dp[j - w[i]] + v[i])。 如果 j &lt; w[i]，则 dp[j] 不变（因为装不下当前物品）。 关键问题：遍历顺序 在一维DP中，dp[j] 会被反复更新。如果我们正向遍历（从 j &#x3D; 0 到 W），会导致问题；而倒着遍历（从 j &#x3D; W 到 0）则能正确解决问题。接下来我会详细解释为什么。 为什么需要倒着遍历？ 在一维DP中，dp[j] 的更新依赖于 dp[j - w[i]]。如果遍历顺序不当，会导致当前物品被重复使用，而0-1背包要求每个物品只能用一次。我们通过一个例子来说明。 例子 假设： 背包容量 W &#x3D; 5。 只有一个物品，重量 w[1] &#x3D; 2，价值 v[1] &#x3D; 3。 初始dp[j] = 0对于所有 j。 正向遍历（从 0 到 W） j &#x3D; 2：dp[2] = max(dp[2], dp[2-2] + 3) = max(0, dp[0] + 3) = max(0, 0 + 3) = 3。 j &#x3D; 3：dp[3] = max(dp[3], dp[3-2] + 3) = max(0, dp[1] + 3) = max(0, 0 + 3) = 3。 j &#x3D; 4：dp[4] = max(dp[4], dp[4-2] + 3) = max(0, dp[2] + 3) = max(0, 3 + 3) = 6。 问题：dp[4] &#x3D; 6 表示价值达到 6，相当于拿了两次物品（2 × 3 &#x3D; 6），但0-1背包不允许重复拿取！ 原因：正向遍历时，dp[2] 被更新为 3 后，dp[4] 用到了更新后的 dp[2]，相当于当前物品被多次使用。 倒着遍历（从 W 到 0） j &#x3D; 5：dp[5] = max(dp[5], dp[5-2] + 3) = max(0, dp[3] + 3) = max(0, 0 + 3) = 3。 j &#x3D; 4：dp[4] = max(dp[4], dp[4-2] + 3) = max(0, dp[2] + 3) = max(0, 0 + 3) = 3。 j &#x3D; 3：dp[3] = max(dp[3], dp[3-2] + 3) = max(0, dp[1] + 3) = max(0, 0 + 3) = 3。 j &#x3D; 2：dp[2] = max(dp[2], dp[2-2] + 3) = max(0, dp[0] + 3) = max(0, 0 + 3) = 3。 结果：dp[5] &#x3D; 3，表示最多放入一个物品，符合0-1背包的规则。 原因：倒着遍历时，dp[j] 更新时用到的dp[j - w[i]]是还未被当前物品更新的值，相当于二维DP中的 dp[i-1][j - w[i]]。 一维DP的详细流程 初始化： dp[j] = 0 对于所有 j 从 0 到 W。 遍历物品 对于每个物品 i（从 1 到 n）： 倒着遍历容量 j（从 W 到 w[i]）： 如果 j &gt;&#x3D; w[i]，则 dp[j] &#x3D; max(dp[j], dp[j - w[i]] + v[i])。 如果 j &lt; w[i]，跳过（实际上不需要显式处理，因为循环从 w[i] 开始）。 结果 dp[W] 即为最终答案。 3.算法对比 算法 时间复杂度 稳定性 冒泡 O(n²) 稳定 插入 O(n²) 稳定 归并 O(nlogn); 需要 O(n) 额外空间 稳定 选择 O(n²) 不稳定 希尔 O(nlogn) 不稳定 堆排序 O(nlogn) 不稳定 快排 O(nlogn) ， O(n²) 最坏情况; 不稳定","categories":[{"name":"学习","slug":"学习","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"黑马点评记录","slug":"黑马点评记录","date":"2024-12-18T14:28:12.000Z","updated":"2025-02-19T09:57:43.269Z","comments":true,"path":"2024/12/18/黑马点评记录/","permalink":"http://example.com/2024/12/18/%E9%BB%91%E9%A9%AC%E7%82%B9%E8%AF%84%E8%AE%B0%E5%BD%95/","excerpt":"","text":"一、登录redis启动命令：在finalsell中systemctl start redis 1、发送验证码12345678910111213141516171819/** * 发送验证码 * @param phone * @param session * @return */ public Result sendCode(String phone, HttpSession session) &#123; //1、校验手机号格式 if (RegexUtils.isPhoneInvalid(phone)) &#123; return Result.fail(&quot;手机号无效&quot;); &#125; //2、如果成功，生成6位的验证码 String code = RandomUtil.randomNumbers(6); //3、保存到session session.setAttribute(&quot;code&quot;, code); //4、发送验证码需要调第三方接口，暂不做，打印日志 log.info(&quot;验证码为：&#123;&#125;&quot;, code); return Result.ok(); &#125; 2、登录功能这里一开始忘了在createNewUser用mp的sava将新生成的user保存到数据库了，我说怎么半天不见数据库有新数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 登录 * @param loginForm * @param session * @return */ public Result login(LoginFormDTO loginForm, HttpSession session) &#123; //1、校验手机号是否合规 String phone = loginForm.getPhone(); if (RegexUtils.isPhoneInvalid(phone)) &#123; return Result.fail(&quot;手机号无效&quot;); &#125; //2、校验验证码是否有效 String code = loginForm.getCode(); Object cacheCode = session.getAttribute(&quot;code&quot;); if(cacheCode == null || !cacheCode.equals(code))&#123; //验证码无效 return Result.fail(&quot;验证码无效&quot;); &#125; //3、查询用户——此处使用MP User user = query().eq(&quot;phone&quot;, phone).one(); if(user == null)&#123; //user不存在，则创建一个新的user user = createNewUser(phone); &#125; //4、根据用户是否存在，最终都保存到session中 //BeanUtil.copyProperties(user, UserDTO.class)将user的信息复制到UserDTO并创建一个UserDTO对象返回 session.setAttribute(&quot;user&quot;, BeanUtil.copyProperties(user, UserDTO.class)); return Result.ok(); &#125; private User createNewUser(String phone) &#123; //1、创建用户 User user = new User(); user.setPhone(phone); user.setNickName(&quot;user_&quot; + RandomUtil.randomString(10)); //2、保存用户，用的MP save(user); return user; &#125; 3、登录校验拦截器现在有一个问题：对于其它业务（Controller），每个都要写登录逻辑岂不是很麻烦 答：引入拦截器，可以在所有Controller之前判断是否放行 又有一个问题：如何把拦截器拦截到的信息传给其它Controller呢？ 答：ThreadLocal，每个请求都是一个独立的线程，也可以避免并发问题的出现 12345678910111213141516171819202122232425262728293031323334353637public class LoginInterceptor implements HandlerInterceptor &#123; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //1、获取session HttpSession session = request.getSession(); //2、从session中获取user Object user = session.getAttribute(&quot;user&quot;); //3、判断user是否存在 if(user == null)&#123; return false; &#125; //否则就保存到当前线程 UserHolder.saveUser((UserDTO) user); return true; &#125; /** * 渲染之后，将保存的信息删除，避免内存泄露 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; //直接调用UserHolder UserHolder.removeUser(); &#125;&#125; 拦截器写好了还没有生效，需要配置 123456789101112131415@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()). excludePathPatterns( //排除不需要被拦截登录的路径 &quot;/shop/**&quot;, &quot;/voucher/**&quot;, &quot;shop-type/**&quot;, &quot;/upload/**&quot;, &quot;/blog/hot&quot;, &quot;/user/code&quot;, &quot;/user/login&quot;); &#125;&#125; 4 、Redis代替session解决session问题STAR法则 S（Situation ）：尽管现在是一个单体式的架构，但为了应对并发，肯定要布置多台tomcat服务器形成负载均衡的集群。这时就有问题了：因为多台tomcat不能共享空间，可能导致多次请求打到不同的tomcat服务器上，出现数据丢失问题 T（Task）：session的替代方案应满足以下需求： 数据共享 内存存储（因为session就是基于内存的，所以读写效率才会比较高） key-value结构 A（Action ）： 12//修改发送验证码，保存验证码到redis，并设置有效期防止堆积占用内存stringRedisTemplate.opsForValue().set(LOGIN_CODE_KEY + phone, code, LOGIN_CODE_TTL, TimeUnit.MINUTES); 接下来修改登录逻辑，在登录逻辑实现中修改代码如下： 1234567//2、校验验证码是否有效，从redis中取 String code = loginForm.getCode(); Object cacheCode = redisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone); if(cacheCode == null || !cacheCode.equals(code))&#123; //验证码无效 return Result.fail(&quot;验证码无效&quot;); &#125; 123456789101112131415//保存用户信息到redis中 //1、生成token作为key UUID token = UUID.randomUUID(true); //2、将user转为map存储 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO); //3、存储到redis redisTemplate.opsForHash().putAll(LOGIN_USER_KEY + token, userMap); //3、设置token有效期 redisTemplate.expire(LOGIN_USER_KEY + token, LOGIN_USER_TTL, TimeUnit.MINUTES); return Result.ok(token); 拦截器中代码也要修改，同时只要拦截到请求，说明用户还在活跃状态，就刷新token的有效期（不然可能会出现用户一直在使用但token有效期过了就要重新登录的错误） 5、双重拦截器解决非登录页面token刷新问题但是又有一个问题，因为我们第一个拦截器只拦截了需要登录的页面的请求。如果用户一直处于不需要登录的页面，是在活跃的，但这时token有效期过了再发请求可能就要重新登录，所以可以再加一个拦截器来拦截一切请求，只要来了请求就说明用户还在活跃，然后更新token有效期。 最终双重拦截器的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class RefreshTokenInterceptor implements HandlerInterceptor &#123; private StringRedisTemplate stringRedisTemplate; public RefreshTokenInterceptor(StringRedisTemplate stringRedisTemplate)&#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //1、获取token String token = request.getHeader(&quot;authorization&quot;); if (StrUtil.isBlank(token)) &#123; return true; &#125; //2、根据token从redis中获取用户 Map&lt;Object, Object&gt; userMap = stringRedisTemplate.opsForHash().entries(RedisConstants.LOGIN_USER_KEY + token); //3、判断user是否存在 if(userMap.isEmpty())&#123; return true; &#125; //4、将map转为dto UserDTO userDTO = BeanUtil.fillBeanWithMap(userMap, new UserDTO(), false); //保存到当前线程 UserHolder.saveUser(userDTO); return true; &#125; /** * 渲染之后，将保存的信息删除，避免内存泄露 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; //直接调用UserHolder UserHolder.removeUser(); &#125;&#125; 12345678910111213141516public class LoginInterceptor implements HandlerInterceptor &#123; @Override /** * Controller执行之前调用此方法，做登录校验 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (UserHolder.getUser() == null) &#123; return false; &#125; return true; &#125;&#125; 同时需要在MvcConfig中更新配置，注意用order指定拦截器顺序 1234567891011121314151617181920@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Resource private StringRedisTemplate stringRedisTemplate; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()). excludePathPatterns( //排除不需要被拦截登录的路径 &quot;/shop/**&quot;, &quot;/voucher/**&quot;, &quot;/shop-type/**&quot;, &quot;/upload/**&quot;, &quot;/blog/hot&quot;, &quot;/user/code&quot;, &quot;/user/login&quot;).order(1); registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).addPathPatterns(&quot;/**&quot;).order(0); &#125;&#125; 二、商户查询缓存1、添加商铺缓存1234567891011121314151617181920212223242526272829@Servicepublic class ShopServiceImpl extends ServiceImpl&lt;ShopMapper, Shop&gt; implements IShopService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; //1、从redis中查，查到了直接返回 String shopJson = stringRedisTemplate.opsForValue().get(key); if(StrUtil.isNotBlank(shopJson))&#123; Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; //2、没有查到就去数据库查，如果数据库也没有，就返回 Shop shop = getById(id); if(shop == null) return Result.fail(&quot;商铺信息不存在&quot;); //3、如果数据库有，保存到redis便于下次查找，然后再返回 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop)); return Result.ok(shop); &#125;&#125; 2、练习：添加商铺类型缓存3、缓存更新策略issue1、采用什么缓存更新策略？ 内存淘汰 超时剔除 主动更新 说明 不用自己维护， 利用Redis的内存淘汰机制， 当内存不足时自动淘汰部分数据。 下次查询时更新缓存。 给缓存数据添加TTL时间， 到期后自动删除缓存。 下次查询时更新缓存。 编写业务逻辑， 在修改数据库的同时， 更新缓存。 一致性 差 一般 好 维护成本 无 低 高 业务场景 低一致性需求：使用内存淘汰机制，例如店铺类型的查询缓存（因为这个很长一段时间都不需要更新） 高一致性需求：主动更新，并以超时剔除作为兜底方案，例如店铺详情查询的缓存 ans1：本项目采用主动更新+超时剔除（兜底） 更新方案采用双写方案（Cache Aside Pattern）：人工编码方式，缓存调用者在更新完数据库后再去更新缓存。 issue2：在对缓存的更新上，对比删除缓存与更新缓存 更新缓存：每次更新数据库都需要更新缓存，无效写操作较多 删除缓存：更新数据库时让缓存失效，再次查询时更新缓存 ans2：所以我们采用直接删除缓存 issue3：是先操作缓存（先删除缓存，再更新数据库）还是先操作数据库（先更新数据库，再操作缓存）？ 对比如下： 先删除缓存，再更新数据库： 删除缓存的操作很快，但是更新数据库的操作相对较慢，如果此时有一个线程2刚好进来查询缓存，由于我们刚刚才删除缓存，所以线程2需要查询数据库，并写入缓存，但是我们更新数据库的操作还未完成，所以线程2查询到的数据是脏数据，出现线程安全问题 先更新数据库，再操作缓存 当线程1在查询缓存且未命中，此时线程1查询数据，查询完准备写入缓存时，由于没有加锁线程2乘虚而入，线程2在这期间对数据库进行了更新，此时线程1将旧数据返回了，出现了脏读，这个事件发生的概率很低，因为先是需要满足缓存未命中，且在写入缓存的那段事件内有一个线程进行更新操作，缓存的查询很快，这段空隙时间很小，所以出现脏读现象的概率也很低 这种方式的不足之处：存在脏读现象，但概率较小 ans3：虽然这二者都存在线程安全问题，但是相对来说，后者出现线程安全问题的概率相对较低，所以我们最终采用后者先操作数据库，再删除缓存的方案 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 根据id查询商铺数据（查询时，重建缓存） * * @param id * @return */@Overridepublic Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据 String shopJson = stringRedisTemplate.opsForValue().get(key); Shop shop = null; // 2、判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 2.1 缓存命中，直接返回店铺数据 shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 2.2 缓存未命中，从数据库中查询店铺数据 shop = this.getById(id); // 4、判断数据库是否存在店铺数据 if (Objects.isNull(shop)) &#123; // 4.1 数据库中不存在，返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 4.2 数据库中存在，重建缓存，并返回店铺数据 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop);&#125;/** * 更新商铺数据（更新时，更新数据库，删除缓存） * * @param shop * @return */@Transactional@Overridepublic Result updateShop(Shop shop) &#123; // 参数校验, 略 // 1、更新数据库中的店铺数据 boolean f = this.updateById(shop); if (!f)&#123; // 缓存更新失败，抛出异常，事务回滚 throw new RuntimeException(&quot;数据库更新失败&quot;); &#125; // 2、删除缓存 f = stringRedisTemplate.delete(CACHE_SHOP_KEY + shop.getId()); if (!f)&#123; // 缓存删除失败，抛出异常，事务回滚 throw new RuntimeException(&quot;缓存删除失败&quot;); &#125; return Result.ok();&#125; 4、缓存穿透概念：客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 解决方案： 缓存空对象 优点：实现简单，维护方便 缺点：额外的内存消耗，可能造成短期的不一致 布隆过滤 优点：内存占用较少，没有多余key 缺点：实现复杂，存在误判可能（有穿透的风险），无法删除数据 本文采用是缓存缓存空对象 12345678910111213141516171819202122232425262728@Overridepublic Result queryById(Long id) &#123; //先从Redis中查，这里的常量值是固定的前缀 + 店铺id String shopJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY + id); //如果不为空（查询到了），则转为Shop类型直接返回 if (StrUtil.isNotBlank(shopJson)) &#123; Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; //如果查询到的是空字符串，则说明是我们缓存的空数据 if (shopjson != null) &#123; return Result.fail(&quot;店铺不存在！！&quot;); &#125; //否则去数据库中查 Shop shop = getById(id); //查不到，则将空字符串写入Redis if (shop == null) &#123; //这里的常量值是2分钟 stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, &quot;&quot;, CACHE_NULL_TTL, TimeUnit.MINUTES); return Result.fail(&quot;店铺不存在！！&quot;); &#125; //查到了则转为json字符串 String jsonStr = JSONUtil.toJsonStr(shop); //并存入redis，设置TTL stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, jsonStr, CACHE_SHOP_TTL, TimeUnit.MINUTES); //最终把查询到的商户信息返回给前端 return Result.ok(shop);&#125; 5、缓存雪崩 概念：缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。 解决方案 给不同的Key的TTL添加随机值 利用Redis集群提高服务的可用性 给缓存业务添加降级限流策略，比如快速失败机制，让请求尽可能打不到数据库上 给业务添加多级缓存 这里采用方案1 6、缓存击穿 概念：缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。 解决方案 互斥锁（时间换空间）优点：内存占用小，一致性高，实现简单缺点：性能较低，容易出现死锁 逻辑过期（空间换时间）优点：性能高缺点：内存占用较大，容易出现脏读 两者相比较，互斥锁更加易于实现，但是容易发生死锁，且锁导致并行变成串行，导致系统性能下降，逻辑过期实现起来相较复杂，且需要耗费额外的内存，但是通过开启子线程重建缓存，使原来的同步阻塞变成异步，提高系统的响应速度，但是容易出现脏读 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//互斥锁解决方案/** * 根据id查询商铺数据 * * @param id * @return */ @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据，并判断缓存是否命中 Result result = getShopFromCache(key); if (Objects.nonNull(result)) &#123; // 缓存命中，直接返回 return result; &#125; try &#123; // 2、缓存未命中，需要重建缓存，判断能否能够获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); if (!isLock) &#123; // 2.1 获取锁失败，已有线程在重建缓存，则休眠重试 Thread.sleep(50); return queryById(id); &#125; // 2.2 获取锁成功，判断缓存是否重建，防止堆积的线程全部请求数据库（所以说双检是很有必要的） result = getShopFromCache(key); if (Objects.nonNull(result)) &#123; // 缓存命中，直接返回 return result; &#125; // 3、从数据库中查询店铺数据，并判断数据库是否存在店铺数据 Shop shop = this.getById(id); if (Objects.isNull(shop)) &#123; // 数据库中不存在，缓存空对象（解决缓存穿透），返回失败信息 stringRedisTemplate.opsForValue().set(key, &quot;&quot;, CACHE_NULL_TTL, TimeUnit.SECONDS); return Result.fail(&quot;店铺不存在&quot;); &#125; // 4、数据库中存在，重建缓存，响应数据 stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop); &#125;catch (Exception e)&#123; throw new RuntimeException(&quot;发生异常&quot;); &#125; finally &#123; // 5、释放锁（释放锁一定要记得放在finally中，防止死锁） unlock(key); &#125; &#125; /** * 从缓存中获取店铺数据 * @param key * @return */ private Result getShopFromCache(String key) &#123; String shopJson = stringRedisTemplate.opsForValue().get(key); // 判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 缓存数据有值，说明缓存命中了，直接返回店铺数据 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 判断缓存中查询的数据是否是空字符串(isNotBlank把 null 和 空字符串 给排除了) if (Objects.nonNull(shopJson)) &#123; // 当前数据是空字符串，说明缓存也命中了（该数据是之前缓存的空对象），直接返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 缓存未命中（缓存数据既没有值，又不是空字符串） return null; &#125; /** * 获取锁 * * @param key * @return */ private boolean tryLock(String key) &#123; Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, 10, TimeUnit.SECONDS); // 拆箱要判空，防止NPE return BooleanUtil.isTrue(flag); &#125; /** * 释放锁 * * @param key */ private void unlock(String key) &#123; stringRedisTemplate.delete(key); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//逻辑过期实现/** * 缓存重建线程池 */ public static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10); /** * 根据id查询商铺数据 * * @param id * @return */ @Override public Result queryById(Long id) &#123; String key = CACHE_SHOP_KEY + id; // 1、从Redis中查询店铺数据，并判断缓存是否命中 String shopJson = stringRedisTemplate.opsForValue().get(key); if (StrUtil.isBlank(shopJson)) &#123; // 1.1 缓存未命中，直接返回失败信息 return Result.fail(&quot;店铺数据不存在&quot;); &#125; // 1.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期 RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class); // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段 JSONObject data = (JSONObject) redisData.getData(); Shop shop = JSONUtil.toBean(data, Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) &#123; // 当前缓存数据未过期，直接返回 return Result.ok(shop); &#125; // 2、缓存数据已过期，获取互斥锁，并且重建缓存 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); if (isLock) &#123; // 获取锁成功，开启一个子线程去重建缓存 CACHE_REBUILD_EXECUTOR.submit(() -&gt; &#123; try &#123; this.saveShopToCache(id, 20L); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; finally &#123; unlock(lockKey); &#125; &#125;); &#125; // 3、获取锁失败，再次查询缓存，判断缓存是否重建（这里双检是有必要的） shopJson = stringRedisTemplate.opsForValue().get(key); if (StrUtil.isBlank(shopJson)) &#123; // 3.1 缓存未命中，直接返回失败信息 return Result.fail(&quot;店铺数据不存在&quot;); &#125; // 3.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期 redisData = JSONUtil.toBean(shopJson, RedisData.class); // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段 data = (JSONObject) redisData.getData(); shop = JSONUtil.toBean(data, Shop.class); expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) &#123; // 当前缓存数据未过期，直接返回 return Result.ok(shop); &#125; // 4、返回过期数据 return Result.ok(shop); &#125; /** * 从缓存中获取店铺数据 * @param key * @return */ private Result getShopFromCache(String key) &#123; String shopJson = stringRedisTemplate.opsForValue().get(key); // 判断缓存是否命中 if (StrUtil.isNotBlank(shopJson)) &#123; // 缓存数据有值，说明缓存命中了，直接返回店铺数据 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); &#125; // 判断缓存中查询的数据是否是空字符串(isNotBlank把 null 和 空字符串 给排除了) if (Objects.nonNull(shopJson)) &#123; // 当前数据是空字符串，说明缓存也命中了（该数据是之前缓存的空对象），直接返回失败信息 return Result.fail(&quot;店铺不存在&quot;); &#125; // 缓存未命中（缓存数据既没有值，又不是空字符串） return null; &#125; /** * 将数据保存到缓存中 * * @param id 商铺id * @param expireSeconds 逻辑过期时间 */ public void saveShopToCache(Long id, Long expireSeconds) throws InterruptedException &#123; // 从数据库中查询店铺数据 Shop shop = this.getById(id); Thread.sleep(200); // 封装逻辑过期数据 RedisData redisData = new RedisData(); redisData.setData(shop); redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds)); // 将逻辑过期数据存入Redis中 stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData)); &#125; 小结为了解决数据一致性问题，我们可以选择适当的缓存更新策略： 以缓存主动更新（双写方案+删除缓存模式+先操作数据库后操作缓存+事务）为主，超时剔除为辅 查询时，先查询缓存，缓存命中直接返回，缓存未命中查询数据库并重建缓存，返回查询结果 更新时，先修改数据删除缓存，使用事务保证缓存和数据操作两者的原子性、 除了会遇到数据一致性问题意外，我们还会遇到缓存穿透、缓存雪崩、缓存击穿等问题 对于缓存穿透，我们采用了缓存空对象解决 对于缓存击穿，我们分别演示了互斥锁（setnx实现方式）和逻辑过期两种方式解决 三、优惠券秒杀1、全局唯一ID自增ID存在的问题 当用户抢购时，就会生成订单并保存到tb_voucher_order这张表中，而订单表如果使用数据库自增ID就存在一些问题： id的规律性太明显，容易出现信息的泄露，被不怀好意的人伪造请求 受单表数据量的限制，MySQL中表能够存储的数据有限，会出现分库分表的情况，id不能够一直自增 那么该如何解决呢？我们需要使用分布式ID（也可以叫全局唯一ID），分布式ID满足以下特点： 全局唯一性：分布式ID保证在整个分布式系统中唯一性，不会出现重复的标识符。这对于区分和追踪系统中的不同实体非常重要。 高可用性：分布式ID生成器通常被设计为高可用的组件，可以通过水平扩展、冗余备份或集群部署来确保服务的可用性。即使某个节点或组件发生故障，仍然能够正常生成唯一的ID标识符。 安全性：分布式ID生成器通常是独立于应用程序和业务逻辑的。它们被设计为一个单独的组件或服务，可以被各种应用程序和服务所共享和使用，使得各个应用程序之间的ID生成过程互不干扰。 高性能：分布式ID生成器通常要求在很短的时间内生成唯一的标识符。为了实现低延迟，设计者通常采用高效的算法和数据结构，以及优化的网络通信和存储策略。 递增性：分布式ID通常可以被设计成可按时间顺序排序，以便更容易对生成的ID进行索引、检索或排序操作。这对于一些场景，如日志记录和事件溯源等，非常重要。 1234567891011121314151617181920212223242526272829303132//生成分布式ID@Componentpublic class RedisIdWorker &#123; @Resource private StringRedisTemplate stringRedisTemplate; /** * 开始时间戳 */ private static final long BEGIN_TIMESTAMP = 1640995200; /** * 序列化位数 */ private static final int COUNT_BITS = 32; /** * 生成分布式ID * @param keyPrefix * @return */ public long nextId(String keyPrefix)&#123; // 1、生成时间戳 LocalDateTime now = LocalDateTime.now(); long nowSecond = now.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; // 2、生成序列号 // 以当天的时间戳为key，防止一直自增下去导致超时，这样每天的极限都是 2^&#123;31&#125; String date = now.format(DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)); Long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix + &quot;:&quot; + date); // 3、拼接并返回 return timestamp &lt;&lt; COUNT_BITS | count; &#125;&#125; 注意：测试类包括CountDownLatch的使用 1234567891011121314151617181920212223242526272829303132333435//测试类@SpringBootTestpublic class RedisIdWorkerTest &#123; @Resource private RedisIdWorker redisIdWorker; private ExecutorService es = Executors.newFixedThreadPool(500); /** * 测试分布式ID生成器的性能，以及可用性 */ @Test public void testNextId() throws InterruptedException &#123; // 使用CountDownLatch让线程同步等待 CountDownLatch latch = new CountDownLatch(300); // 创建线程任务 Runnable task = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; long id = redisIdWorker.nextId(&quot;order&quot;); System.out.println(&quot;id = &quot; + id); &#125; // 等待次数-1 latch.countDown(); &#125;; long begin = System.currentTimeMillis(); // 创建300个线程，每个线程创建100个id，总计生成3w个id for (int i = 0; i &lt; 300; i++) &#123; es.submit(task); &#125; // 线程阻塞，直到计数器归0时才全部唤醒所有线程 latch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;生成3w个id共耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 2、秒杀券下单功能首先添加秒杀券，tb_voucher保存的是普通优惠券，而tb_seckill_voucher保存的是秒杀券的信息，也就是说，秒杀券也是优惠券，只是秒杀券比优惠券有更多的一些信息。在这里踩了一个坑。就是设置秒杀券的end_time时，这个时间必须在你电脑当前时间之后，否则就会不显示！！ 然后是秒杀券的下单功能 12345678910111213141516171819202122232425262728293031323334@Transactional public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 5、秒杀券合法，则秒杀券抢购成功，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .setSql(&quot;stock = stock -1&quot;)); if (!flag)&#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 6、秒杀成功，创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); save(voucherOrder); // 返回订单id return Result.ok(orderId); &#125; 这里也踩了一个坑，就是执行了半天点击但发现优惠券并没有扣除，甚至controller处的写的打印信息都没有在控制台打印，原因好像跟访问路径有关系？？刚解决完就忘了。。鱼的记忆-_- 3、单体下一人多单超卖问题上一节我们通过分布式ID+事务成功完成了优惠券秒杀功能，并且在测试后发现逻辑跑通了，看上去已经成功的解决了秒杀优惠券功能。但是前面我们只是正常的测试，那如果换到高并发的场景下能否成功解决？现在就让我们使用 Jmeter 来进行压力测试看看吧！ jmeter设置 经过测试， 发现有超卖问题。为什么会产生超卖呢？ 线程1查询库存，发现库存充足，创建订单，然后准备对库存进行扣减，但此时线程2和线程3也进行查询，同样发现库存充足，然后线程1执行完扣减操作后，库存变为了0，线程2和线程3同样完成了库存扣减操作，最终导致库存变成了负数！这就是超卖问题的完整流程 那么我们该如何有效防止超卖问题的发生呢，以下提供几种常见的解决方案 超卖问题的常见解决方案： 悲观锁，认为线程安全问题一定会发生，因此操作数据库之前都需要先获取锁，确保线程串行执行。常见的悲观锁有：synchronized、lock 乐观锁，认为线程安全问题不一定发生，因此不加锁，只会在更新数据库的时候去判断有没有其它线程对数据进行修改，如果没有修改则认为是安全的，直接更新数据库中的数据即可，如果修改了则说明不安全，直接抛异常或者等待重试。常见的实现方式有：版本号法、CAS操作、乐观锁算法 悲观锁和乐观锁的比较 悲观锁比乐观锁的性能低：悲观锁需要先加锁再操作，而乐观锁不需要加锁，所以乐观锁通常具有更好的性能。 悲观锁比乐观锁的冲突处理能力低：悲观锁在冲突发生时直接阻塞其他线程，乐观锁则是在提交阶段检查冲突并进行重试。 悲观锁比乐观锁的并发度低：悲观锁存在锁粒度较大的问题，可能会限制并发性能；而乐观锁可以实现较高的并发度。 应用场景：两者都是互斥锁，悲观锁适合写入操作较多、冲突频繁的场景；乐观锁适合读取操作较多、冲突较少的场景。 拓展：CAS CAS（Compare and Swap）是一种并发编程中常用的原子操作，用于解决多线程环境下的数据竞争问题。它是乐观锁算法的一种实现方式。 CAS操作包含三个参数：内存地址V、旧的预期值A和新的值B。CAS的执行过程如下： 比较（Compare）：将内存地址V中的值与预期值A进行比较。 判断（Judgment）：如果相等，则说明当前值和预期值相等，表示没有发生其他线程的修改。 交换（Swap）：使用新的值B来更新内存地址V中的值。 CAS操作是一个原子操作，意味着在执行过程中不会被其他线程中断，保证了线程安全性。如果CAS操作失败（即当前值与预期值不相等），通常会进行重试，直到CAS操作成功为止。 CAS操作适用于精细粒度的并发控制，可以避免使用传统的加锁机制带来的性能开销和线程阻塞。然而，CAS操作也存在一些限制和注意事项： ABA问题：CAS操作无法感知到对象值从A变为B又变回A的情况，可能会导致数据不一致。为了解决ABA问题，可以引入版本号或标记位等机制。 自旋开销：当CAS操作失败时，需要不断地进行重试，会占用CPU资源。如果重试次数过多或者线程争用激烈，可能会引起性能问题。 并发性限制：如果多个线程同时对同一内存地址进行CAS操作，只有一个线程的CAS操作会成功，其他线程需要重试或放弃操作。 在Java中，提供了相关的CAS操作支持，如AtomicInteger、AtomicLong、AtomicReference等类，可以实现基于CAS操作的线程安全操作。 乐观锁解决一人多单超卖问题 CAS法类似与版本号法，但是不需要另外在添加一个 version 字段，而是直接使用库存替代版本号，线程1查询完库存后进行库存扣减操作，线程2在查询库存时，发现库存充足，也准备执行库存扣减操作，但是需要判断当前的库存是否是之前查询时的库存，结果发现库存数量发生了改变，这就说明数据库中的数据已经发生了修改，需要进行重试（或者直接抛异常中断） qps200，异常90%，吞吐量1652.9 这又是什么原因呢？这就是乐观锁的弊端，我们只要发现数据修改就直接终止操作了，我们只需要修改一下判断条件，即只要库存大于0就可以进行修改，而不是库存数据修改我们就终止操作 12345// 5、秒杀券合法，则秒杀券抢购成功，秒杀券库存数量减一boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); 执行完之后库存恰好为0，订单表中恰好是一百条 4、单体下一人一单问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Override @Transactional public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 3、判断当前用户是否是第一单 int count = this.count(new LambdaQueryWrapper&lt;VoucherOrder&gt;() .eq(VoucherOrder::getUserId, UserHolder.getUser().getId())); if (count &gt;= 1) &#123; // 当前用户不是第一单 return Result.fail(&quot;用户已购买&quot;); &#125; // 4、用户是第一单，可以下单，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); if (!flag) &#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 6、秒杀成功，创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); save(voucherOrder); // 返回订单id return Result.ok(orderId); &#125; 现在是不是可以成功完成了一人一单的要求呢？让我们来使用 Jmeter 测一下吧 通过测试，发现并没有达到我们想象中的目标，一个人只能购买一次，但是发现一个用户居然能够购买10次。这说明还是存在超卖问题！ 问题原因：出现这个问题的原因和前面库存为负数数的情况是一样的，线程1查询当前用户是否有订单，当前用户没有订单准备下单，此时线程2也查询当前用户是否有订单，由于线程1还没有完成下单操作，线程2同样发现当前用户未下单，也准备下单，这样明明一个用户只能下一单，结果下了两单，也就出现了超卖问题 解决方案：一般这种超卖问题可以使用下面两种常见的解决方案 悲观锁 乐观锁 悲观锁解决超卖问题 乐观锁需要判断数据是否修改，而当前是判断当前是否存在，所以无法像解决库存超卖一样使用CAS机制，但是可以使用版本号法，但是版本号法需要新增一个字段，所以这里为了方便，就直接演示使用悲观锁解决超卖问题 代码这里注意，seckillVocher上面的@Transactional要去掉，然后要加一个依赖，启动类上加上一个注解@EnableAspectJAutoProxy(exposeProxy = true) 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.21&lt;/version&gt; &lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Override public Result seckillVocher(Long voucherId) &#123; // 1、查询秒杀券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); log.info(&quot;当前秒杀券&quot;); // 2、判断秒杀券是否合法 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) &#123; // 秒杀券的开始时间在当前时间之后 return Result.fail(&quot;秒杀尚未开始&quot;); &#125; if (voucher.getEndTime().isBefore(LocalDateTime.now())) &#123; // 秒杀券的结束时间在当前时间之前 return Result.fail(&quot;秒杀已结束&quot;); &#125; if (voucher.getStock() &lt; 1) &#123; return Result.fail(&quot;秒杀券已抢空&quot;); &#125; // 3、创建订单 Long userId = UserHolder.getUser().getId(); synchronized (userId.toString().intern()) &#123; // 创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效 IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(userId, voucherId); &#125; &#125; /** * 创建订单 * * @param userId * @param voucherId * @return */ @Transactional public Result createVoucherOrder(Long userId, Long voucherId) &#123;// synchronized (userId.toString().intern()) &#123; // 1、判断当前用户是否是第一单 int count = this.count(new LambdaQueryWrapper&lt;VoucherOrder&gt;() .eq(VoucherOrder::getUserId, userId)); if (count &gt;= 1) &#123; // 当前用户不是第一单 return Result.fail(&quot;用户已购买&quot;); &#125; // 2、用户是第一单，可以下单，秒杀券库存数量减一 boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper&lt;SeckillVoucher&gt;() .eq(SeckillVoucher::getVoucherId, voucherId) .gt(SeckillVoucher::getStock, 0) .setSql(&quot;stock = stock -1&quot;)); if (!flag) &#123; throw new RuntimeException(&quot;秒杀券扣减失败&quot;); &#125; // 3、创建对应的订单，并保存到数据库 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setUserId(UserHolder.getUser().getId()); voucherOrder.setVoucherId(voucherOrder.getId()); flag = this.save(voucherOrder); if (!flag) &#123; throw new RuntimeException(&quot;创建秒杀券订单失败&quot;); &#125; // 4、返回订单id return Result.ok(orderId); &#125; TODO这里代码的实现细节有点看不懂（以下内容看的别人的总结，这里回头再看看 锁的范围尽量小。synchronized尽量锁代码块，而不是方法，锁的范围越大性能越低 锁的对象一定要是一个不变的值。我们不能直接锁 Long 类型的 userId，每请求一次都会创建一个新的 userId 对象，synchronized 要锁不变的值，所以我们要将 Long 类型的 userId 通过 toString()方法转成 String 类型的 userId，toString()方法底层（可以点击去看源码）是直接 new 一个新的String对象，显然还是在变，所以我们要使用 intern() 方法从常量池中寻找与当前 字符串值一致的字符串对象，这就能够保障一个用户 发送多次请求，每次请求的 userId 都是不变的，从而能够完成锁的效果（并行变串行） 我们要锁住整个事务，而不是锁住事务内部的代码。如果我们锁住事务内部的代码会导致其它线程能够进入事务，当我们事务还未提交，锁一旦释放，仍然会存在超卖问题 Spring的@Transactional注解要想事务生效，必须使用动态代理。Service中一个方法中调用另一个方法，另一个方法使用了事务，此时会导致@Transactional失效，所以我们需要创建一个代理对象，使用代理对象来调用方法。 总结： 首先用全局唯一id代表优惠券的下单订单号。如果一个人可以买多单的情况下，在并发场景下，会出现超卖情况，此时用乐观锁的cas来实现防止超卖。然后是单体的一人一单，这里就是下单前需要验证当前用户是否已经下单了，确认是否存在，如果硬要用乐观锁，使用版本号法需要加一个字段，所以用的是悲观锁。但如果在集群环境下，由于锁依赖于jvm内部的监视器，如果是多台机器，每个机器内部的锁只能锁住自己这个进程的，所以要用分布式锁了。 四、分布式锁由于synchronized是本地锁，只能提供线程级别的同步，每个JVM中都有一把synchronized锁，不能跨 JVM 进行上锁，当一个线程进入被 synchronized 关键字修饰的方法或代码块时，它会尝试获取对象的内置锁（也称为监视器锁）。如果该锁没有被其他线程占用，则当前线程获得锁，可以继续执行代码；否则，当前线程将进入阻塞状态，直到获取到锁为止。而现在我们是创建了两个节点，也就意味着有两个JVM，所以synchronized会失效！从而出现超卖问题： 分布式锁的常见实现 基于关系数据库：可以利用数据库的事务特性和唯一索引来实现分布式锁。通过向数据库插入一条具有唯一约束的记录作为锁，其他进程在获取锁时会受到数据库的并发控制机制限制。 基于缓存（如Redis）：使用分布式缓存服务（如Redis）提供的原子操作来实现分布式锁。通过将锁信息存储在缓存中，其他进程可以通过检查缓存中的锁状态来判断是否可以获取锁。 基于ZooKeeper：ZooKeeper是一个分布式协调服务，可以用于实现分布式锁。通过创建临时有序节点，每个请求都会尝试创建一个唯一的节点，并检查自己是否是最小节点，如果是，则表示获取到了锁。 从性能角度（从高到低）： 缓存 &gt; Zookeeper &gt; 数据库 从可靠性角度（从高到低）： Zookeeper &gt; 缓存 &gt; 数据库 setnx指令的特点：setnx只能设置key不存在的值，值不存在设置成功，返回 1 ；值存在设置失败，返回 0 获取锁 12# 添加锁set [key] [value] ex [time] nx 释放锁 12# 释放锁（除了使用del手动释放，还可超时释放）del [key] 1、基于redis实现的分布式锁创建分布式锁 12345678910111213public interface ILock &#123; /** * 尝试获取锁 * @param timeoutSec 锁持有的时间，过期后自动释放 * @return true true代表获取锁成功，反之代表失败 */ boolean tryLock(long timeoutSec); /** * 释放锁 */ void unlock();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public class SimpleRedisLock implements ILock &#123; /** * RedisTemplate */ private StringRedisTemplate stringRedisTemplate; /** * 锁的名称 */ private String name; public SimpleRedisLock(StringRedisTemplate stringRedisTemplate, String name) &#123; this.stringRedisTemplate = stringRedisTemplate; this.name = name; &#125; /** * 获取锁 * * @param timeoutSec 超时时间 * @return */ @Override public boolean tryLock(long timeoutSec) &#123; String id = Thread.currentThread().getId() + &quot;&quot;; // SET lock:name id EX timeoutSec NX Boolean result = stringRedisTemplate.opsForValue() .setIfAbsent(&quot;lock:&quot; + name, id, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(result); &#125; /** * 释放锁 */ @Override public void unlock() &#123; stringRedisTemplate.delete(&quot;lock:&quot; + name); &#125;&#125; 使用分布式锁：改造前面VoucherOrderServiceImpl中的代码，将之前使用sychronized锁的地方，改成我们自己实现的分布式锁： 1234567891011121314Long userId = UserHolder.getUser().getId(); SimpleRedisLock lock = new SimpleRedisLock(stringRedisTemplate, &quot;order:&quot; + userId); boolean isLock = lock.tryLock(1200); if (!isLock) &#123; // 索取锁失败，重试或者直接抛异常（这个业务是一人一单，所以直接返回失败信息） return Result.fail(&quot;一人只能下一单&quot;); &#125; try &#123; // 索取锁成功，创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效 IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(userId, voucherId); &#125; finally &#123; lock.unlock(); &#125; 然后用apifox发送两个请求 可以看到8081端口为false，8082端口为true 这里遇到了一个bug，就是打了断点但是变量那里看不到，根本就没有进入断点。最后发现是apifox发送的请求中，携带登录token的参数Authorization应该是放在header中，我一开始放在了params中 2、分布式锁优化1——解决释放不属于自己锁的问题 上一节，我们实现了一个简单的分布式锁，但是会存在一个问题：当线程1获取锁后，由于业务阻塞，线程1的锁超时释放了，这时候线程2趁虚而入拿到了锁，然后此时线程1业务完成了，然后把线程2刚刚获取的锁给释放了，这时候线程3又趁虚而入拿到了锁，这就导致又出现了超卖问题！（但是这个在小项目（并发数不高）中出现的概率比较低，在大型项目（并发数高）情况下是有一定概率的） 备注：我们可以把锁的有效期降低一点，这样就能够测试上面哪种情况了(●’◡’●) 如何解决呢？我们为分布式锁添加一个线程标识，在释放锁时判断当前锁是否是自己的锁，是自己的就直接释放，不是自己的就不释放锁，从而解决多个线程同时获得锁的情况导致出现超卖 3、分布式锁优化2——释放锁时的原子性问题。说到底也是锁超时释放的问题 在上一节中，我们通过给锁添加一个线程标识，并且在释放锁时添加一个判断，从而防止锁超时释放产生的超卖问题，一定程度上解决了超卖问题，但是仍有可能发生超卖问题（出现超卖概率更低了）：当线程1获取锁，执行完业务然后并且判断完当前锁是自己的锁时，但就在此时发生了阻塞，结果锁被超时释放了，线程2立马就趁虚而入了，获得锁执行业务，但就在此时线程1阻塞完成，由于已经判断过锁，已经确定锁是自己的锁了，于是直接就删除了锁，结果删的是线程2的锁，这就又导致线程3趁虚而入了，从而继续发生超卖问题 备注：我们可以在判断删除锁的那行代码上打一个断点，然后user1发送一个请求，获取锁，手动把锁删了，模拟锁超时释放，然后使用user2发送一个请求，成功获取锁，从而模拟上诉过程，检验超卖问题 PS：虽然这个情况发生的概率较低，但是根据墨菲定律，我们最好不要抱有侥幸心理，不然最终我们会在这个细微的问题上付诸沉重的代价！你可能还会想，判断锁和释放锁在同一个方法中，并且两者之间没有别的代码，为什么会发生阻塞呢？JVM的垃圾回收机制会导致短暂的阻塞（我个人感觉这种情况发生的概率真的不高，但是我也没有实际接触过真正的大型高并发项目，所以具体也只能靠揣摩） 那么我们该如何保障 判断锁 和 释放锁 这连段代码的原子性呢？答案是使用Lua脚本 4、Redisson经过优化1和优化2，我们实现的分布式锁已经达到生产可用级别了，但是还不够完善，比如： 分布式锁不可重入：不可重入是指同一线程不能重复获取同一把锁。比如，方法A中调用方法B，方法A需要获取分布式锁，方法B同样需要获取分布式锁，线程1进入方法A获取了一次锁，进入方法B又获取一次锁，由于锁不可重入，所以就会导致死锁 分布式锁不可重试：获取锁只尝试一次就返回false，没有重试机制，这会导致数据丢失，比如线程1获取锁，然后要将数据写入数据库，但是当前的锁被线程2占用了，线程1直接就结束了而不去重试，这就导致数据发生了丢失 分布式锁超时释放：超市释放机机制虽然一定程度避免了死锁发生的概率，但是如果业务执行耗时过长，期间锁就释放了，这样存在安全隐患。锁的有效期过短，容易出现业务没执行完就被释放，锁的有效期过长，容易出现死锁，所以这是一个大难题！ 我们可以设置一个较短的有效期，但是加上一个 心跳机制 和 自动续期：在锁被获取后，可以使用心跳机制并自动续期锁的持有时间。通过定期发送心跳请求，显示地告知其他线程或系统锁还在使用中，同时更新锁的过期时间。如果某个线程持有锁的时间超过了预设的有效时间，其他线程可以尝试重新获取锁。 主从一致性问题：如果Redis提供了主从集群，主从同步存在延迟，线程1获取了锁 我们如果想要更进一步优化分布式锁，当然是可以的，但是没必要，除非是迫不得已，我们完全可以直接使用已经造好的轮子，比如：Redisson。Redssion是一个十分成熟的Redis框架，功能也很多，比如：分布式锁和同步器、分布式对象、分布式集合、分布式服务，各种Redis实现分布式的解决方案。简而言之Redisson就是一个使用Redis解决分布式问题的方案的集合，当然它不仅仅是解决分布式相关问题，还包含其它的一些问题。 所以说分布式锁的究极优化就是使用别人造好的轮子🤣redisson分布式锁的实现使用 1）、引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.6&lt;/version&gt;&lt;/dependency&gt; 2）、配置Redisson客户端 1234567891011121314151617@Configurationpublic class RedissonConfig &#123; /** * 创建Redisson配置对象，然后交给IOC管理 * * @return */ @Bean public RedissonClient redissonClient() &#123; // 获取Redisson配置对象 Config config = new Config(); // 添加redis地址，这里添加的是单节点地址，也可以通过 config.userClusterServers()添加集群地址 config.useSingleServer().setAddress(&quot;redis://192.168.200.100:6379&quot;).setPassword(&quot;123321&quot;); // 获取RedisClient对象，并交给IOC进行管理 return Redisson.create(config); &#125;&#125; 温馨提示：此外还有一种引入方式，可以引入 redission 的 starter 依赖，然后在yml文件中配置Redisson，但是不推荐这种方式，因为他会替换掉 Spring官方 提供的这套对 Redisson 的配置 3）、修改一下使用锁的地方，其它的业务代码都不需要改 123//SimpleRedisLock lock = new SimpleRedisLock(stringRedisTemplate, &quot;order:&quot; + userId); RLock lock = redissonClient.getLock(&quot;lock:order:&quot; + userId); boolean isLock = lock.tryLock(); 五、MQ异步优化此时先测一下之前同步的方式性能如何 用一下测试代码生成1000个登录用户的token并保存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.hmdp;import cn.hutool.core.bean.BeanUtil;import cn.hutool.core.bean.copier.CopyOptions;import com.hmdp.dto.UserDTO;import com.hmdp.entity.User;import com.hmdp.service.IUserService;import org.junit.jupiter.api.Test;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.StringRedisTemplate;import javax.annotation.Resource;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.UUID;import java.util.concurrent.TimeUnit;import static com.hmdp.utils.RedisConstants.LOGIN_USER_KEY;import static com.hmdp.utils.RedisConstants.LOGIN_USER_TTL;@SpringBootTestpublic class yibuTest &#123; @Resource IUserService userService; @Resource private StringRedisTemplate stringRedisTemplate; @Test public void testGetAll() &#123; List&lt;User&gt; users = userService.list();// for(User user : users)&#123;// System.out.println(user);// &#125;// System.exit(0); users.forEach( user -&gt; &#123; // 7.1,随机生成token,作为登录令牌 String token = UUID.randomUUID().toString();// 7.2,将User对象转化为HashMap存储 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); File file = new File(&quot;D:\\\\code\\\\token.txt&quot;); FileOutputStream output = null; try &#123; output = new FileOutputStream(file, true); byte[] bytes = token.getBytes(); output.write(bytes); output.write(&quot;\\r\\n&quot;.getBytes()); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; finally &#123; try &#123; output.close(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125; Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO, new HashMap&lt;&gt;(), CopyOptions.create() .setIgnoreNullValue(true) .setFieldValueEditor((fieldName, fieldValue) -&gt; fieldValue.toString()));// 7.3,存储 String tokenKey = LOGIN_USER_KEY + token; stringRedisTemplate.opsForHash().putAll(tokenKey, userMap);// 7.4,设置token有效期 stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES); &#125; ); &#125;&#125; 更改优惠券数量为200，并清空订单表 注意优惠券的过期时间！！！！！ 执行完之后，库存扣减为0，订单表中正好200条订单 jmeter显示结果如下：还是比较慢的 第二次测试 第三次测试 1、优化思路之前的流程如下： 2、安装rabbitMQ已有centOS7,docker,finalshell 安装参考链接：rabbitMQ安装参考 安装Erlang 成功截图 rabbitmq启动成功 开启web管理功能 开启后，在本机访问虚拟机ip加端口号15672即可访问 然后是创建用户。因为在finalshell开启了rabbitmq后，就不能继续输入命令了。所以这里我是先在centos里面开启rabbitmq，然后再在finalshell输入创建用户的命令。执行后如下： 然后登录web管理页面： 3.实现异步处理的代码新增代码结构如下： 配置mq通信为主题模式 12345678910111213141516171819202122232425262728293031package com.hmdp.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.context.annotation.Bean;import org.springframework.amqp.core.TopicExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Configuration;// 这段代码用于配置 RabbitMQ 的话题模式，包括队列、交换机和绑定。下面是加上注释后的代码：@Configurationpublic class RabbitMQTopicConfig &#123; public static final String QUEUE = &quot;seckillQueue&quot;; // 队列名 public static final String EXCHANGE = &quot;seckillExchange&quot;; // 交换机名 public static final String ROUTINGKEY = &quot;seckill.lua.#&quot;; @Bean public Queue queue()&#123; return new Queue(QUEUE); &#125; @Bean public TopicExchange topicExchange()&#123; return new TopicExchange(EXCHANGE); &#125; @Bean public Binding binding()&#123; return BindingBuilder.bind(queue()).to(topicExchange()).with(ROUTINGKEY); &#125;&#125; 123456789101112131415161718192021222324252627package com.hmdp.rabbitmq;import com.hmdp.config.RabbitMQTopicConfig;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * 消息发送者 */@Slf4j@Servicepublic class MQSender &#123; @Autowired private RabbitTemplate rabbitTemplate; private static final String ROUTINGKEY = &quot;seckill.lua.message&quot;; /** * 发送秒杀信息 * @param msg */ public void sendSeckillMessage(String msg)&#123; log.info(&quot;发送消息&quot;+msg); rabbitTemplate.convertAndSend(RabbitMQTopicConfig.EXCHANGE,ROUTINGKEY,msg); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.hmdp.rabbitmq;import com.alibaba.fastjson.JSON;import com.hmdp.config.RabbitMQTopicConfig;import com.hmdp.entity.VoucherOrder;import com.hmdp.service.ISeckillVoucherService;import com.hmdp.service.IVoucherOrderService;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import javax.annotation.Resource;/** * 消息消费者 */@Slf4j@Servicepublic class MQReceiver &#123; @Resource IVoucherOrderService voucherOrderService; @Resource ISeckillVoucherService seckillVoucherService; /** * 接收秒杀信息并下单 * @param msg */ @Transactional @RabbitListener(queues = RabbitMQTopicConfig.QUEUE) public void receiveSeckillMessage(String msg)&#123; log.info(&quot;接收到消息: &quot;+msg); VoucherOrder voucherOrder = JSON.parseObject(msg, VoucherOrder.class); Long voucherId = voucherOrder.getVoucherId(); //5.一人一单 Long userId = voucherOrder.getUserId(); //5.1查询订单 int count = voucherOrderService.query().eq(&quot;user_id&quot;,userId).eq(&quot;voucher_id&quot;, voucherId).count(); //5.2判断是否存在 if(count&gt;0)&#123; //用户已经购买过了 log.error(&quot;该用户已购买过&quot;); return ; &#125; log.info(&quot;扣减库存&quot;); //6.扣减库存 boolean success = seckillVoucherService .update() .setSql(&quot;stock = stock-1&quot;) .eq(&quot;voucher_id&quot;, voucherId) .gt(&quot;stock&quot;,0)//cas乐观锁 .update(); if(!success)&#123; log.error(&quot;库存不足&quot;); return; &#125; //直接保存订单 voucherOrderService.save(voucherOrder); &#125;&#125; 注意这里需要手动向redis中添加库存键及数量，键名就是下面lua代码中stockKey的名字，这里voucherId为7，键名就是stock:7，这里也算一个bug，搞了有一阵子 12345678910111213141516171819202122232425262728-- 1.参数列表-- 1.1优惠卷idlocal voucherId = ARGV[1]-- 1.2用户idlocal userId = ARGV[2]-- 2.数据key-- 2.1库存keylocal stockKey = &#x27;stock:&#x27; .. voucherId-- 2.2订单keylocal orderKey = &#x27;order:&#x27; .. voucherId-- 3.脚本业务-- 3.1判断库存是否充足if(tonumber(redis.call(&#x27;get&#x27;,stockKey)) &lt;= 0)then -- 3.2 库存不足 返回1 return 1end--3.2判断用户是否下单if(redis.call(&#x27;sismember&#x27;,orderKey,userId) == 1) then -- 3.3存在,说明是重复下单 return 2end-- 3.4扣库存redis.call(&#x27;incrby&#x27;,stockKey,-1)-- 3.5下单并保存用户redis.call(&#x27;sadd&#x27;,orderKey,userId)return 0 下面是VoucherOrderServiceImpl的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class VoucherOrderServiceImpl extends ServiceImpl&lt;VoucherOrderMapper, VoucherOrder&gt; implements IVoucherOrderService &#123; @Resource private MQSender mqSender; @Resource private RedisIdWorker redisIdWorker; //private RateLimiter rateLimiter = RateLimiter.create(10); @Resource private StringRedisTemplate stringRedisTemplate; //@Resource //private RedissonClient redissonClient; //lua脚本 private static final DefaultRedisScript&lt;Long&gt; SECKILL_SCRIPT; static &#123; SECKILL_SCRIPT = new DefaultRedisScript&lt;&gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(&quot;seckill.lua&quot;)); SECKILL_SCRIPT.setResultType(Long.class); &#125; @Override public Result seckillVocher(Long voucherId) &#123; //1.执行lua脚本 Long userId = UserHolder.getUser().getId(); Long r = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); //2.判断结果为0 int result = r.intValue(); if (result != 0) &#123; //2.1不为0代表没有购买资格 return Result.fail(r == 1 ? &quot;库存不足&quot; : &quot;该用户重复下单&quot;); &#125; //2.2为0代表有购买资格,将下单信息保存到阻塞队列 //2.3创建订单 VoucherOrder voucherOrder = new VoucherOrder(); //2.4订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); //2.5用户id voucherOrder.setUserId(userId); //2.6代金卷id voucherOrder.setVoucherId(voucherId); //2.7将信息放入MQ中 mqSender.sendSeckillMessage(JSON.toJSONString(voucherOrder)); //2.7 返回订单id return Result.ok(orderId); &#125;&#125; 4.结果分析注意在用jmeter测试之前，先清除之前的数据，如下： 实验结果如下： 可以看到最小耗时2ms，最大耗时112ms，提高了将近20倍，平均耗时34ms，提高了将近30倍左右","categories":[],"tags":[]},{"title":"字节跳动-番茄小说面经","slug":"面经/字节跳动-番茄小说面经","date":"2024-12-14T03:17:09.000Z","updated":"2024-12-21T06:18:19.192Z","comments":true,"path":"2024/12/14/面经/字节跳动-番茄小说面经/","permalink":"http://example.com/2024/12/14/%E9%9D%A2%E7%BB%8F/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-%E7%95%AA%E8%8C%84%E5%B0%8F%E8%AF%B4%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"Q：java并发编程并发的是线程还是进程？A：线程，不过说的很紊乱，讲了很多没必要讲的东西 以下是gpt回答 解释： 线程 是程序中的一个执行单元，线程是轻量级的，它们共享进程的资源，如内存和文件句柄。在Java中，线程是通过实现 Runnable 接口或继承 Thread 类来创建的。 进程 是操作系统分配资源的最小单位，每个进程都有自己独立的内存空间。Java程序通常运行在一个进程中，而该进程内可能有多个线程。 并发的定义： 并发 指的是多个任务的执行在时间上有重叠，而不一定是同时进行。通过多线程并发执行，Java能够在多核处理器上高效地利用多个CPU核心，但并发本身并不等同于并行。并行是指多个任务在同一时刻执行。 总结： Java并发编程中，“并发”是指 多个线程 的执行。 如果涉及多个进程，通常称之为 多进程 编程，而不属于并发的范畴。 Q：进程和线程的区别A：一个进程可能就是会包含多个线程，线程可以理解为轻量级的进程，上下文切换这个开销一般是比较小的，线程可以共享这个进程的一些资源比如说内存空间（内存空间埋雷了） Q：那你觉得你对于他们的底层结构了解吗，比如说你刚才提到了共享内存那你共享的资源嘛对吧那你能说一下比如说我启动了一个那个进程然后那进程跟线程之间应该是如何去申请这个资源以及实现资源共享呢。后续又补充了一点，比如说创建一个进程然后这个资源我是怎么申请的以及线程去怎么去共享这些资源的。A：的一塌糊涂 Q：线程池的作用以及实现原理。A：复用线程，实现原理不会（其实就是线程池处理任务的流程，不知道是这个题目，背了八股也没用上😭😭😭😭 以下是gpt回答 线程池的实现原理 线程池的核心思想是任务提交-线程复用。以下是线程池的基本组成和工作原理： 1. 基本组成 任务队列（Task Queue）： 一个线程安全的队列，用于存储提交但尚未被执行的任务。 任务是实现了某种接口（如 Runnable 或 Callable）的对象。 工作线程（Worker Threads）： 线程池中实际执行任务的线程集合。线程池在初始化时会创建一定数量的线程，并在任务提交后复用这些线程执行任务。 线程管理器： 管理线程的生命周期，维护线程池中线程的数量。 根据配置动态增加或减少线程数（如扩展或缩减线程池大小）。 任务提交接口： 提供给用户用于提交任务的方法，比如 execute() 或 submit()。 任务调度器： 从任务队列中获取任务并分配给工作线程。 如果任务队列为空，工作线程会进入等待状态。 2. 线程池的工作流程 线程池初始化： 根据配置，线程池创建一定数量的工作线程，并处于等待任务的状态。 任务提交： 用户通过线程池的接口（如 execute() 或 submit()）提交任务，任务被添加到任务队列中。 任务调度： 线程池中的工作线程会从任务队列中取出任务进行执行。 如果所有工作线程都在忙，任务会在任务队列中排队等待。 任务执行： 工作线程执行完任务后，线程不会被销毁，而是返回线程池继续等待新的任务。 动态扩展（可选）： 如果任务队列过长且所有线程都在忙，线程池可以动态创建新的线程来处理任务（受最大线程数限制）。 线程回收： 如果线程池中某些线程长时间没有任务可执行，线程池可以销毁这些空闲线程以节省资源。 Q、如果没有锁机制的话在并发编程的场景会出现什么问题。A：数据的一致性可能出现问题（问我还有没有补充，我也没想到其它的了 以下是在网上搜的，并发编程需要加锁的时候，如果就不加会怎么样？ 数据不一致：多个线程同时访问和修改共享资源时，如果没有加锁，可能会导致数据竞争，即一个线程在读取数据的同时，另一个线程修改了数据，从而导致最终的数据状态与预期不符。例如，在多线程环境下，多个线程同时对同一个账户余额进行操作，如果不加锁，可能会出现余额被重复扣款或重复加款的情况。 竞态条件：竞态条件是指在多线程环境中，由于线程调度的不确定性，导致程序的行为依赖于不可预测的执行顺序。如果不加锁，可能会导致程序在某些情况下出现不可预期的行为，如死锁、饥饿等问题。 线程安全问题：在多线程编程中，多个线程可能会同时访问共享资源，这很容易导致数据的不一致性和竞态条件。如果不加锁，可能会导致线程安全问题，影响程序的正确性和稳定性。 死锁风险：死锁是指两个或多个线程互相等待对方释放资源，导致所有线程都无法继续执行。如果不加锁，可能会增加死锁的风险，尤其是在复杂的并发场景中。 难以调试：在多线程环境中，如果不加锁，可能会导致难以调试的问题。由于线程的执行顺序是不可预测的，错误可能在某些特定的执行路径下才会出现，这使得调试变得非常困难。 Q：项目：怎么实现优惠券的秒杀A：这个基本答得是那么回事，就是乐观锁的cas Q：什么叫乐观锁？为什么不用悲观锁？A：适用读多写少，然后说了一下cas的实现（感觉都没答到点子上😅😅）；用悲观锁就是影响性能，因为会频繁的更新数据 Q：select语句的执行过程A：（这个答得应该大差不差，唯一画蛇添足的一点就是把废弃的那个缓存器也答上了，又给后面埋雷了😅😅😅😅）连接器——语法器——优化器——执行器 Q：缓存的粒度是什么？或者说它是怎么缓存的，缓存的东西是什么A：直接说不清楚，缓存的应该是语句吧。然后问如果缓存了SELECT A = 1再来执行SELECT A = 1 AND B = 1能用到缓存吗？猜的能 以下来自gpt 存储常用或最近使用的数据和查询结果，提高了查询性能，减少了对底层存储的访问。 存储查询的完整结果集，下一次遇到相同的查询语句时，直接返回结果。 适用于简单的 SELECT 查询，尤其是少更新、多读取的场景。 默认情况下，SELECT A = 1 的缓存不能直接用于 SELECT A = 1 AND B = 1，因为两者查询条件和结果集不同。 Q：SELECT语句想做查询优化，从哪些方面去优化？A：答了索引，避免查询不必要的列，数据量过大时从分表三点，问还有补充没， 以下来自gpt 优化 SELECT 语句的方法包括： 从表结构设计入手，建立合理的索引，优化字段类型，必要时分表或分区。 改进查询语句，减少不必要的字段、行和表，避免复杂计算。 提高数据访问效率，利用缓存和分页优化减少查询开销。 分析查询执行计划，通过工具发现潜在问题并调整查询结构和索引。 Q：索引的底层结构是啥？A：说了B+树，然后问只有B+树么？还有其它结构吗，然后又回答了还有哈希 Q：从数据结构的角度来说，能影响B+树的查询性能的，是这个树的什么A：树高 以下来自gpt Q：我们怎么影响这个树的高度呢？通过哪些方式让这个树的高度更扁平一点？A：不知道，瞎几把答了 以下来自gpt 树高主要受以下因素影响： 节点扇出数（由节点大小和键值大小决定）。 数据分布是否均匀。 数据量和磁盘块的大小。 键值的大小和排序。 问答18min。手撕环节。差不多三分钟说了一下思路。撕了差不多20min才跑通测试用例， Q：题目：给中缀表达式转后缀表达式思路： 遇到操作数（数字或变量）：直接输出到结果中。 遇到左括号 (：直接压入操作符栈。 遇到右括号 )： 弹出栈顶的操作符并加入结果，直到遇到左括号（左括号本身不加入结果）。 遇到运算符（如 +, -, *, /）： 将栈顶优先级高于或等于当前操作符的运算符弹出并加入结果。 然后将当前操作符压栈。 遍历结束后：将栈中剩余的运算符依次弹出并加入结果。 算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 定义运算符优先级 private static final Map&lt;Character, Integer&gt; precedence = new HashMap&lt;&gt;(); static &#123; precedence.put(&#x27;+&#x27;, 1); precedence.put(&#x27;-&#x27;, 1); precedence.put(&#x27;*&#x27;, 2); precedence.put(&#x27;/&#x27;, 2); precedence.put(&#x27;(&#x27;, 0); // 左括号优先级最低 &#125; public static String infixToPostfix(String infix) &#123; // 栈：存储操作符 Stack&lt;Character&gt; operatorStack = new Stack&lt;&gt;(); // 结果字符串 StringBuilder postfix = new StringBuilder(); // 遍历表达式中的每个字符 for (int i = 0; i &lt; infix.length(); i++) &#123; char ch = infix.charAt(i); // 如果是操作数（字母或数字），直接加入结果 if (Character.isLetterOrDigit(ch)) &#123; postfix.append(ch); &#125; // 如果是左括号，压入栈 else if (ch == &#x27;(&#x27;) &#123; operatorStack.push(ch); &#125; // 如果是右括号，弹出运算符直到遇到左括号 else if (ch == &#x27;)&#x27;) &#123; while (!operatorStack.isEmpty() &amp;&amp; operatorStack.peek() != &#x27;(&#x27;) &#123; postfix.append(operatorStack.pop()); &#125; if (!operatorStack.isEmpty() &amp;&amp; operatorStack.peek() == &#x27;(&#x27;) &#123; operatorStack.pop(); // 弹出左括号 &#125; &#125; // 如果是运算符 else &#123; // 弹出栈顶优先级大于等于当前运算符的运算符 while (!operatorStack.isEmpty() &amp;&amp; precedence.get(operatorStack.peek()) &gt;= precedence.get(ch)) &#123; postfix.append(operatorStack.pop()); &#125; // 当前运算符压入栈 operatorStack.push(ch); &#125; &#125; // 遍历结束后，弹出栈中剩余的运算符 while (!operatorStack.isEmpty()) &#123; postfix.append(operatorStack.pop()); &#125; // 返回后缀表达式 return postfix.toString(); &#125;","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"中科星图面经","slug":"面经/中科星图面经","date":"2024-12-14T03:16:45.000Z","updated":"2024-12-14T03:18:32.994Z","comments":true,"path":"2024/12/14/面经/中科星图面经/","permalink":"http://example.com/2024/12/14/%E9%9D%A2%E7%BB%8F/%E4%B8%AD%E7%A7%91%E6%98%9F%E5%9B%BE%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"自我介绍 问实习，做了啥，遇到了啥问题，叽里咕噜扯了一通 问我熟悉什么框架，必须boot啊，然后让我讲一下，讲不好，扯到spring讲讲ioc和aop了 然后问我注解，是通过反射吧好像，忘了 然后反问，聊了一下工作时间，做什么（全栈），。。","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"hot100一句话思路","slug":"hot100一句话思路","date":"2024-12-13T13:33:20.000Z","updated":"2025-03-06T04:08:52.727Z","comments":true,"path":"2024/12/13/hot100一句话思路/","permalink":"http://example.com/2024/12/13/hot100%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%9D%E8%B7%AF/","excerpt":"这里是我总结的leetcode平台hot100题单的“一句话思路”及代码，欢迎参考指正交流~💕☺️","text":"这里是我总结的leetcode平台hot100题单的“一句话思路”及代码，欢迎参考指正交流~💕☺️ ACM模式下的hot100解法在这里 一、哈希表1. 两数之和 思路：map（key存储元素值，value为索引）。遍历数组的过程中，判断map中是否有target - 当前元素，如果没有就把当前元素插入到map。 详细题解：1.两数之和 参考代码 1234567891011121314151617class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] ans = new int[2]; for (int i = 0; i &lt; nums.length; i++) &#123; if(map.containsKey(target - nums[i]))&#123; ans[0] = map.get(target - nums[i]); ans[1] = i; break; &#125; map.put(nums[i], i); &#125; return ans; &#125;&#125; 49. 字母异位词分组 思路：字母异位词转化为字符数组，经过排序再转为字符串，是相同的。利用这一点，使用map，key为经过排序后的字符串，value为当前异位词列表。最终将value值返回到一个列表中。 详细题解：49. 字母异位词分组 参考代码 1234567891011121314class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; HashMap&lt;String , List&lt;String&gt;&gt; map = new HashMap&lt;&gt;(); for (String str : strs) &#123; char[] array = str.toCharArray(); Arrays.sort(array); String key = new String(array); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;&gt;(map.values()); &#125;&#125; 128. 最长连续序列 思路：一个数字能不能作为序列的开始，取决于它前一个数字是否存在；一个数字能不能作为序列的结束，取决于它后一个数字是否不存在。借助此，我们可以用一个set来现把所有元素加入，然后直接遍历set集合来看 详细题解：128. 最长连续序列 参考代码 123456789101112131415161718class Solution &#123; public int longestConsecutive(int[] nums) &#123; HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); int ans = 0; for (int num : nums) &#123; set.add(num); &#125; for (int num : set) &#123; if(!set.contains(num - 1))&#123; int len = 1; while (set.contains(++num)) len++; ans = Math.max(ans, len); &#125; &#125; return ans; &#125;&#125; 二、双指针283. 移动零 思路：始终让慢指针指向零元素（如果不为0直接自增后跳出当前循环进入下一次循环），快指针去寻找不为零的元素，然后找到了就设置慢指针所指的元素为快指针所指的元素，再让慢指针自增 补充（2025&#x2F;2&#x2F;6） 为什么 fast 无论如何都要加一：无论 fast 指向的元素是否为 0，fast 都需要加一，以确保能够遍历数组中的每一个元素。如果 fast 指向的元素为 0，那么 fast 继续向前移动，寻找下一个非零元素。如果 fast 指向的元素不为 0，那么就将该元素移动到 slow 的位置，并将 fast 指向的位置置为 0，然后 fast 继续向前移动。 详细题解：283. 移动零 参考代码 123456789101112131415class Solution &#123; public void moveZeroes(int[] nums) &#123; int slow = 0, fast = 1; while (fast &lt; nums.length)&#123; if(nums[slow] == 0 &amp;&amp; nums[fast] != 0)&#123; nums[slow] = nums[fast]; nums[fast] = 0; slow++; &#125; if(nums[slow]!= 0) slow++; fast++; &#125; &#125;&#125; 11. 盛最多水的容器 思路：从两边向中间靠，每次计算此时的体积（高为左右线的较低者），然后较低的线那一边向中间靠拢 详细题解： 参考代码 123456789101112131415class Solution &#123; public int maxArea(int[] height) &#123; int low = 0; int high = height.length - 1; int ans = Integer.MIN_VALUE; while (low &lt;= high)&#123; ans = Math.max(ans, (high - low) * Math.min(height[low], height[high])); if(height[low] &lt; height[high]) low++; else high--; &#125; return ans; &#125;&#125; 15. 三数之和 思路：首先将数组排成有序。然后遍历数组，有两个退出条件：1.当前数字大于0，break；2.当前元素和前一个元素一样，continue（相当于对第一个元素的去重），然后在剩下元素中，从首尾向中间靠拢，如果满足条件了，再对左右指针所指元素去重 详细题解：15. 三数之和 参考代码： 12345678910111213141516171819202122232425262728class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i++) &#123; if(nums[i] &gt; 0) break; if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.length - 1; while (l &lt; r)&#123; int temp = nums[i] + nums[l] + nums[r]; if(temp &lt; 0) l++; else if (temp &gt; 0) &#123; r--; &#125;else &#123; ans.add(Arrays.asList(nums[i], nums[l], nums[r])); while (l &lt; r &amp;&amp; nums[l] == nums[l + 1]) l++; while (l &lt; r &amp;&amp; nums[r] == nums[r - 1]) r--; l++; r--; &#125; &#125; &#125; return ans; &#125;&#125; 42. 接雨水 思路：首尾位置不装雨水，其余每个位置所装雨水 = min（左边柱子最大值，右边柱子最大值）- 当且柱子高。左右指针的更新类似11. 盛最多水的容器 这一题，每次移动较低的那根柱子 补充（此题步骤） 数组长度&lt;&#x3D;2，直接返回0 初始化左右最大值分别为第一个元素和最后一个元素 初始化左右指针分别为第二个元素和倒数第二个元素 在循环中先更新左右最大值，再根据左右最大值来决定此时结果应该加多少 详细题解：42. 接雨水 参考代码： 1234567891011121314151617181920class Solution &#123; public int trap(int[] height) &#123; if(height.length &lt;= 2) return 0; int maxLeft = height[0]; int maxRight = height[height.length - 1]; int left = 0; int right = height.length - 1; int ans = 0; while (left &lt;= right)&#123; maxLeft = Math.max(maxLeft, height[left]); maxRight = Math.max(maxRight, height[right]); if(maxLeft &lt; maxRight) ans += maxLeft - height[left++]; else ans += maxRight - height[right--]; &#125; return ans; &#125;&#125; 三、滑动窗口3. 无重复字符的最长子串 思路：双指针之快慢指针。将快指针所遍历的字符加入set，当添加失败时（说明有重复字符），将慢指针向快指针收缩，直到此时快指针所指字符可以加入set，再继续移动快指针 详细题解：3. 无重复字符的最长子串 参考代码： 1234567891011121314151617class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int l = 0; int ans = 0; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int r = l; r &lt; s.length(); r++) &#123; char c = s.charAt(r); while (l &lt; r &amp;&amp; set.contains(c))&#123; set.remove(s.charAt(l)); l++; &#125; set.add(c); ans = Math.max(ans, r - l + 1); &#125; return ans; &#125;&#125; 438. 找到字符串中所有字母异位词 思路：快慢指针＋哈希（数组）。用数组哈希记录p每个字符出现的次数，快指针遍历s中的字符，每次让数组中对应字符的值减一，如果当前这个数组元素值小于0，说明出现了p中没有的字符，收缩慢指针同时恢复字符次数状态，直到慢指针赶上快指针的时候才能填补上这个差距。如果快慢指针的长度等于p的长度，可以将此时慢指针的坐标添加到结果 详细题解：438. 找到字符串中所有字母异位词 参考代码： 12345678910111213141516171819202122class Solution &#123; public List&lt;Integer&gt; findAnagrams(String s, String p) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int[] cnt = new int[26]; for (int i = 0; i &lt; p.length(); i++) &#123; cnt[p.charAt(i) - &#x27;a&#x27;]++; &#125; for (int r = 0, l = 0; r &lt; s.length(); r++) &#123; char c = s.charAt(r); cnt[c - &#x27;a&#x27;]--; while (cnt[c - &#x27;a&#x27;] &lt; 0)&#123; //这里前面的条件 l &lt;= r &amp;&amp; 一般就别写了，有时候写是正确的有时候不写是正确的，一律不写反而大多数都会正确 //左指针右移 cnt[s.charAt(l) - &#x27;a&#x27;]++; l++; &#125; if(r - l + 1 == p.length()) ans.add(l); &#125; return ans; &#125;&#125; 四、字符串560. 和为 K 的子数组 思路：利用前缀和加上一个哈希表记录前缀和出现的次数，通过查找当前前缀和减去目标和k的值是否已经存在于哈希表中，快速统计满足条件的子数组个数。 详细题解：560. 和为 K 的子数组 参考代码： 1234567891011121314class Solution &#123; public int subarraySum(int[] nums, int k) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); int ans = 0; int pre = 0; for (int i = 0; i &lt; nums.length; i++) &#123; pre += nums[i]; ans += map.getOrDefault(sum - k, 0); map.put(pre, map.getOrDefault(pre, 0) + 1); &#125; return ans; &#125;&#125; 239. 滑动窗口最大值（难） 思路：借助单调队列，来存储可能成为最大值的元素。具体而言，如果当前元素比队列末尾元素要小，就直接进入队列。这样队头就是最大的元素。注意：在窗口移动过程中，如果当前队头元素和即将被（窗口）移除的元素一样大，那队头元素也要出队。 详细题解：239. 滑动窗口最大值 参考代码： 12345678910111213141516171819202122232425class Solution &#123; public int[] maxSlidingWindow(int[] nums, int k) &#123; int[] ans = new int[nums.length - k + 1]; LinkedList&lt;Integer&gt; deque = new LinkedList&lt;&gt;(); //未形成窗口时 for (int i = 0; i &lt; k; i++) &#123; while (!deque.isEmpty() &amp;&amp; deque.peekLast() &lt; nums[i]) deque.removeLast(); deque.addLast(nums[i]); &#125; ans[0] = deque.peekFirst(); //形成窗口时 for (int i = k; i &lt; nums.length; i++) &#123; if(nums[i - k] == deque.peekFirst()) deque.removeFirst(); while (!deque.isEmpty() &amp;&amp; deque.peekLast() &lt; nums[i]) deque.removeLast(); deque.addLast(nums[i]); ans[i - k + 1] = deque.peekFirst(); &#125; return ans; &#125;&#125; 76. 最小覆盖子串在做这题之前，可以先试一下这题的“简单版”——438. 找到字符串中所有字母异位词 思路：和438类似，不过这题要维护一个变量，用于记录t中字符是否匹配完了 详细题解：这个是我在题解下面看的别人的 参考代码 12345678910111213141516171819202122232425262728class Solution &#123; public String minWindow(String s, String t) &#123; int[] cnt = new int[128]; int count = 0;//记录t中需要匹配的字符个数 for (int i = 0; i &lt; t.length(); i++) &#123; cnt[t.charAt(i) - &#x27;A&#x27;]++; count++; &#125; int start = -1, end = s.length(); for (int r = 0, l = 0; r &lt; s.length(); r++) &#123; char cur = s.charAt(r); if(--cnt[cur - &#x27;A&#x27;] &gt;= 0)//如果当前消除的是有效（t中的）字符 count--; while (l &lt;= r &amp;&amp; count == 0) &#123; //当前需要匹配的字符全部匹配完了 if(++cnt[s.charAt(l) - &#x27;A&#x27;] &gt; 0)&#123; //说明当前左指针指向的字符是有效字符 if(r - l &lt; end - start)&#123; //更新有效区间 end = r; start = l; &#125; count++; &#125; l++; &#125; &#125; return start == -1 ? &quot;&quot; : s.substring(start, end + 1); &#125;&#125; 五、普通数组53. 最大子数组和 思路：dp。dp[i]代表以下标i结尾的最大子数组和为dp[i]，所以我们要找的是： max (dp[i]), i ∈ {0, n - 1} 还要注意的是，状态转移方程dp[i] = max(dp[i-1]+nums[i]，nums[i]) 详细题解：53.最大子数组和 参考代码 1234567891011121314class Solution &#123; public int maxSubArray(int[] nums) &#123; int[] dp = new int[nums.length]; int pre = nums[0]; int ans = pre; for (int i = 1; i &lt; nums.length; i++) &#123; pre += nums[i]; pre = Math.max(nums[i], pre); ans = Math.max(ans, pre); &#125; return ans; &#125;&#125; 因为当前状态仅和上一个状态有关，因此也可以这样写： 12345678910class Solution &#123; public int maxSubArray(int[] nums) &#123; int pre = 0, maxAns = nums[0]; for (int x : nums) &#123; pre = Math.max(pre + x, x); //状态转移 maxAns = Math.max(maxAns, pre); &#125; return maxAns; &#125;&#125; 56. 合并区间 思路：用一个数组类型的列表来存储最终结果。遍历所给二维数组，如果当前数组的第一个元素&lt;&#x3D;列表中最后一个元素p（数组）的第二个元素，那就要对p的第二个数字进行更新。例如：[1,3], [2, 4] &#x3D;&gt; [1, 4] 详细题解：56.合并区间 参考代码： 1234567891011121314class Solution &#123; public int[][] merge(int[][] intervals) &#123; Arrays.sort(intervals, (p, q) -&gt; p[0] - q[0]); List&lt;int[]&gt; list = new ArrayList&lt;&gt;(); for (int[] interval : intervals) &#123; int m = list.size(); if(m &gt; 0 &amp;&amp; list.get(m - 1)[1] &gt;= interval[0]) list.get(m - 1)[1] = Math.max(interval[1], list.get(m - 1)[1]); else list.add(interval); &#125; return list.toArray(new int[list.size()][]); &#125;&#125; 189. 轮转数组 思路：先对整个数组逆置。再对前k个元素逆置。再对后n - k个元素逆置。注意先对k进行处理 详细题解：189.轮转数组 参考代码 1234567891011121314151617class Solution &#123; public void rotate(int[] nums, int k) &#123; int n = nums.length; k = k % n; reverse(nums, 0, n - 1); reverse(nums, 0, k - 1); reverse(nums, k, n - 1); &#125; private void reverse(int[] nums, int low, int high) &#123; while (low &lt;= high)&#123; int temp = nums[high]; nums[high--] = nums[low]; nums[low++] = temp; &#125; &#125;&#125; 238. 除自身以外数组的乘积 思路：一种简单的思路是，使用两个数组，一个数组存储每个元素左边元素的乘积，另一个数组存储每个元素右边元素的乘积。最后结果就是这两个数组对应位置相乘，就是每个元素除自身以外数组的乘积。但是可以省略记录右边元素乘积的这个数组，之间将其存储到结果数组中。见代码。 详细题解：238.除自身以外数组的乘积 参考代码 12345678910111213141516class Solution &#123; public int[] productExceptSelf(int[] nums) &#123; int n = nums.length; int[] ans = new int[n]; //记录左边元素的乘积 ans[0] = 1; for (int i = 1; i &lt; n; i++) &#123; ans[i] = ans[i - 1] * nums[i - 1]; &#125; int temp = 1; for (int i = n - 1; i &gt;= 0; i--)&#123; ans[i] = ans[i] * temp; temp *= nums[i]; &#125; return ans; &#125;&#125; 41. 缺失的第一个正数 （★★ 思路：数组内置哈希（置换法）——源自GPT 将正整数放到对应的位置上： 如果数组中存在数字 x，且 1≤x≤n（n 是数组长度），我们可以尝试将它放到索引 x−1 的位置上。 通过不断交换数字和它应该在的位置，将所有可能的正整数放到正确的位置。 遍历数组寻找缺失的最小正整数： 经过上述处理后，索引 i 应该存储 i+1。 如果某个位置 i不满足 nums[i]&#x3D;i+1，那么 i+1 就是缺失的最小正整数。 若所有位置都正确： 如果数组中所有位置都满足 nums[i]&#x3D;i+1，则缺失的最小正整数是 n+1（数组范围之外的第一个正整数）。 详细题解：41.缺失的第一个正数 参考代码： 123456789101112131415161718192021class Solution &#123; public int firstMissingPositive(int[] nums) &#123; int n = nums.length; int x = 0; for (int i = 0; i &lt; n; i++) &#123; x = nums[i]; while (x &gt; 0 &amp;&amp; x &lt;= n &amp;&amp; x != nums[x - 1])&#123; int temp = nums[x - 1]; nums[x - 1] = x; x = temp; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if(nums[i] != i + 1) return i + 1; &#125; return n + 1; &#125;&#125; 六、矩阵73. 矩阵置零 思路：1、扫描首行首列，标记首行首列是否要置零；2、扫描剩余元素（非首行首列的其余元素），如果某个元素为0，就将其首行对应行索引，首列对应列索引设置为0，方便后续对该行该列置零；3、扫描首行首列，如果有元素0，就将对应列&#x2F;行置零。4、最后根据第一步的标记位，对首行首列置零 详细题解：73.矩阵置零 参考代码： 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public void setZeroes(int[][] matrix) &#123; int m = matrix.length; int n = matrix[0].length; boolean b1 = false, b2 = false; //1、先扫描第一行第一列，记录第一行，第一列是否要置0 for (int i = 0; i &lt; n; i++) if(matrix[0][i] == 0) b1 = true; for (int i = 0; i &lt; m; i++) if(matrix[i][0] == 0) b2 = true; //2、扫描其余，如果有元素为0，将它最左方和最上方的元素置零 for (int i = 1; i &lt; m; i++) for (int j = 1; j &lt; n; j++) if(matrix[i][j] == 0)&#123; matrix[0][j] = 0; matrix[i][0] = 0; &#125; //3、按照首行首列所记录元素，如果为0将对应行列置为0 for (int i = 1; i &lt; n; i ++) if(matrix[0][i] == 0) for (int j = 1; j &lt; m; j++) matrix[j][i] = 0; for (int i = 1; i &lt; m; i++) if(matrix[i][0] == 0) Arrays.fill(matrix[i], 0); //4、根据第一步得到的结果对第一行列置零 if(b1) Arrays.fill(matrix[0], 0); if(b2) for (int j = 0; j &lt; m; j++) matrix[j][0] = 0; &#125;&#125; 54. 螺旋矩阵 思路：设置上下左右四个指针，按照→↓←↑的方向，每次到了最边界，就缩减边界。 详细题解： 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public List&lt;Integer&gt; spiralOrder(int[][] matrix) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int m = matrix.length; int n = matrix[0].length; int l = 0, r = n - 1; int s = 0, x = m - 1; int i = 0; while (i &lt; m * n)&#123; for (int j = l; j &lt;= r; j++)&#123; ans.add(matrix[s][j]); i++; if(i == m * n) return ans; &#125; s++; for (int j = s; j &lt;= x; j++)&#123; ans.add(matrix[j][r]); i++; if(i == m * n) return ans; &#125; r--; for (int j = r; j &gt;= l; j--)&#123; ans.add(matrix[x][j]); i++; if(i == m * n) return ans; &#125; x--; for (int j = x; j &gt;= s; j--)&#123; ans.add(matrix[j][l]); i++; if(i == m * n) return ans; &#125; l++; &#125; return ans; &#125;&#125; 48. 旋转图像 思路：先沿着主对角线交换元素，然后再对每一行进行逆置 详细题解： 参考代码 12345678910111213141516171819202122class Solution &#123; public void rotate(int[][] matrix) &#123; int m = matrix.length; int n = matrix[0].length; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int temp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = temp; &#125; &#125; for (int i = 0; i &lt; m; i++) &#123; int l = 0, r = n - 1; while (l &lt;= r)&#123; int temp = matrix[i][l]; matrix[i][l++] = matrix[i][r]; matrix[i][r--] = temp; &#125; &#125; &#125;&#125; 240. 搜索二维矩阵 II 思路：以第一行最后一个元素作为根节点，可将矩阵看作是一个BST。在不越界的前提下，如果元素比target大，往左找，否则，往下找 详细题解： 参考代码： 123456789101112131415161718192021class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; int m = matrix.length; int n = matrix[0].length; int i = 0; int j = n - 1; while (i &lt; m &amp;&amp; j &gt;=0)&#123; int temp = matrix[i][j]; if(target &gt; temp)&#123; //往下找 i++; &#125; else if (target &lt; temp) &#123; //往左找 j--; &#125;else return true; &#125; return false; &#125;&#125; 七、链表160. 相交链表 思路：如果两个链表相交，设相交部分为c，另外两个链表各自的部分分别为a、b。有a + c + b &#x3D; b + c + a，这就是说，当两个指针从各自链表开头走，走完链表再从对方链表的开头走，它们会在相交部分的起点相遇。这里的代码写法很妙，值得记忆一下。而如果两个链表不相交，核心是m + n &#x3D; n + m，这就是说，当两个指针各自走完自己的链表，再去走完对方的链表，此时两个指针均指向一个共同的“交点‘——null 详细题解：160.相交链表 参考代码 12345678910111213public class Solution &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; //两个指针分别走完各自的链表，再从对方的链表节点开始走，然后它俩相等的时候，就是相交节点 ListNode A = headA; ListNode B = headB; while (A != B)&#123; A = A == null ? headB : A.next; B = B == null ? headA : B.next; &#125; return A; &#125;&#125; 206. 反转链表最基础的操作，这题是后面好几题进阶链表反转的基础核心 思路：借用三个指针，pre，temp，cur，这题可以看着代码手动模拟一下 详细题解：206.反转链表 参考代码： 1234567891011121314class Solution &#123; public ListNode reverseList(ListNode head) &#123; ListNode pre = null; ListNode temp = pre; while (head != null)&#123; temp = head.next; head.next = pre; pre = head; head = temp; &#125; return pre; &#125;&#125; 234. 回文链表 思路：补充最优思路（达到O(1)空间复杂度的解）。1.用快慢指针找到中间节点；2.翻转后半段链表；3.比较前后两段链表，就可以得到结果了 详细题解： 参考代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; public boolean isPalindrome(ListNode head) &#123; if (head == null || head.next == null) &#123; return true; &#125; // 1. 快慢指针找中点 ListNode slow = head, fast = head; while (fast != null &amp;&amp; fast.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; // 2. 反转后半部分链表 ListNode reversedHalf = reverseList(slow); // 3. 比较前后两部分 ListNode p1 = head, p2 = reversedHalf; boolean result = true; while (p2 != null) &#123; // 只需比较后半部分的长度 if (p1.val != p2.val) &#123; result = false; break; &#125; p1 = p1.next; p2 = p2.next; &#125; // 4. 恢复链表（可选） reverseList(reversedHalf); return result; &#125; private ListNode reverseList(ListNode head) &#123; ListNode pre = null, cur = head; while (cur != null) &#123; ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; &#125; return pre; &#125;&#125; 141. 环形链表 思路：快慢指针。如果有环，二者肯定能相遇 详细题解：141.环形链表 参考代码： 12345678910111213141516public class Solution &#123; public boolean hasCycle(ListNode head) &#123; if(head == null) return false; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; if(slow == fast) return true; &#125; return false; &#125;&#125; 142. 环形链表 II 思路：直接给结论，还是快慢指针，当二者相遇的时候，再创建一个指针从链表头节点开始走，同时慢指针也开始走，当这俩指针相遇的时候，就是环的入口。详细验证请看详细题解 详细题解：142.环形链表Ⅱ 参考代码： 123456789101112131415161718192021public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; if (slow == fast)&#123; //此时相遇了，让slow和头指针一起往后走 ListNode cur = head; while (cur != slow)&#123; cur = cur.next; slow = slow.next; &#125; return cur; &#125; &#125; return null; &#125;&#125; 21. 合并两个有序链表 思路：双指针，两两比较 详细题解：21.合并两个有序链表 参考代码： 12345678910111213141516171819class Solution &#123; public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; ListNode dummy = new ListNode(); ListNode cur = dummy; while (list1 != null &amp;&amp; list2 != null)&#123; if(list1.val &lt; list2.val)&#123; cur.next = list1; list1 = list1.next; &#125;else &#123; cur.next = list2; list2 = list2.next; &#125; cur = cur.next; &#125; cur.next = list1 == null ? list2 : list1; return dummy.next; &#125;&#125; ❤️类似题目：”两数相加“类型 21. 合并两个有序链表 67. 二进制求和 2. 两数相加 2. 两数相加 思路：通过创建新节点，同时需要一位来记录进位。新节点的值设置为(x + y + temp) % 10，进位temp更新为(x + y + temp) / 10。注意这个while循环的条件和获取当前两个节点值的三目运算符写法，这个在这种类型的题目中经常这样使用 详细题解： 参考代码： 12345678910111213141516171819202122232425class Solution &#123; public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; ListNode ans = new ListNode(); ListNode dummy = ans; int temp = 0; while (l1 != null || l2 != null)&#123; int x = l1 == null ? 0 : l1.val; int y = l2 == null ? 0 : l2.val; int cur = (x + y + temp) % 10; ans.next = new ListNode(cur); temp = (x + y + temp) / 10; //作为下一个节点要累加的值 if(l1 != null) l1 = l1.next; if(l2 != null) l2 = l2.next; ans = ans.next; &#125; if(temp == 1) ans.next = new ListNode(1); return dummy.next; &#125;&#125; 19. 删除链表的倒数第 N 个结点 思路：要删除这个节点，只需找到它前面的一个节点就可以了。快慢指针，快指针从哨兵节点开始，先走n+1步，此时快指针在要删除节点的前一个节点。此时快慢指针同时移动（慢指针也是从哨兵节点开始的），当快指针指向null，此时慢指针就正好指向要删除节点的前一个节点。 详细题解：19.删除链表的倒数第N个节点 参考代码： 1234567891011121314151617class Solution &#123; public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode slow = new ListNode(); slow.next = head; ListNode fast = slow, dummy = slow; for (int i = 0; i &lt;= n; i++) &#123; fast = fast.next; &#125; while (fast != null)&#123; slow = slow.next; fast = fast.next; &#125; slow.next = slow.next.next; return dummy.next; &#125;&#125; 24. 两两交换链表中的节点 思路：这题就是两个数交换的稍微复杂一点的版本。用temp指向要交换两个节点的前一个节点，head指向要交换两个节点的第一个节点 详细题解：24.两两交换链表中的节点 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041//这样写更直观class Solution &#123; public ListNode swapPairs(ListNode head) &#123; ListNode dummyHead = new ListNode(0); dummyHead.next = head; ListNode temp = dummyHead; //temp要始终位于要交换的两个节点之前的一个节点 //如果没有节点或只有一个节点，直接返回 while (temp.next != null &amp;&amp; temp.next.next != null)&#123; ListNode node1 = temp.next; ListNode node2 = temp.next.next; //开始交换这两个节点 temp.next = node2; //先让temp连向node2 node1.next = node2.next; //node2后面还连接着剩余的链表，要先把剩余的接上再调整node2和node1的关系 node2.next = node1; //此时让node2的后面连接node1，现在的关系就是temp——&gt;node2——&gt;node1了 //更新temp，不用更新node1和node2，下次进入循环会更新它俩 temp = node1; //假如后面还有两个节点要更换，比如node3和node4，那node3的前面节点此时就是现在的node1，所以要设置temp指向node1 &#125; //虚拟节点的后一个才是真正的头节点 return dummyHead.next; &#125;&#125;//简单写就是这样class Solution &#123; public ListNode swapPairs(ListNode head) &#123; ListNode dummy = new ListNode(); dummy.next = head; ListNode temp = dummy; while (head != null &amp;&amp; head.next != null)&#123; temp.next = head.next; head.next = head.next.next; temp.next.next = head; temp = head; head = head.next; &#125; return dummy.next; &#125;&#125; 25. K 个一组翻转链表这题还是有点难度的，在做这题之前，可以先理解这几题： 206.翻转链表 92.翻转链表Ⅱ 思路：先统计链表长度，然后每翻转一组，长度-k，直到不能翻转为止。再翻转每组时，要维护好这段链表和其前后的关系。这题和上面两题不同的是，要显式的为这k组链表的第一个节点来声明，以此来维护前后关系。这题最好还是手动模拟一两轮就知道是怎么回事了 详细题解：25.K个一组翻转链表 参考代码： 1234567891011121314151617181920212223242526272829303132class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; ListNode dummy = new ListNode(); dummy.next = head; ListNode cur = head; int count = 0; while (cur != null)&#123; cur = cur.next; count++; &#125; cur = head; ListNode node = dummy; ListNode pre = null; ListNode temp = pre; while (k &lt;= count)&#123; for (int i = 0; i &lt; k; i++) &#123; temp = cur.next; cur.next = pre; pre = cur; cur = temp; &#125; ListNode tail = node.next; node.next = pre; tail.next = cur; node = tail; count -= k; &#125; return dummy.next; &#125;&#125; 138. 随机链表的复制还有一个133. 克隆图 ，本质上和这题一样 思路：哈希表，先创建原链表每个节点和新链表每个节点的映射关系，然后再对新链表每个节点的next和random关系进行维护 详细题解：138.随机链表的复制 参考代码： 123456789101112131415161718class Solution &#123; public Node copyRandomList(Node head) &#123; HashMap&lt;Node, Node&gt; hashMap = new HashMap&lt;&gt;(); Node cur = head; while (cur != null)&#123; hashMap.put(cur, new Node(cur.val)); cur = cur.next; &#125; cur = head; while (cur != null)&#123; hashMap.get(cur).next = hashMap.get(cur.next); hashMap.get(cur).random = hashMap.get(cur.random); cur = cur.next; &#125; return hashMap.get(head); &#125;&#125; 148. 排序链表分治+递归，有点像归并排序（这个我暂时还没学习） 思路：将链表分成两段，这两段调用这个函数都排成有序的了，然后再对这两段链表做合并，类似21. 合并两个有序链表 详细题解：148.排序链表 参考代码： 123456789101112131415161718192021222324252627282930class Solution &#123; public ListNode sortList(ListNode head) &#123; if(head == null || head.next == null) return head; ListNode slow = head, fast = head.next; while (fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; &#125; ListNode temp = slow.next; slow.next = null; ListNode left = sortList(head); ListNode right = sortList(temp); ListNode dummy = new ListNode(); ListNode cur = dummy; while (left != null &amp;&amp; right != null)&#123; if(left.val &lt; right.val)&#123; cur.next = left; left = left.next; &#125;else &#123; cur.next = right; right = right.next; &#125; cur = cur.next; &#125; cur.next = left == null ? right : left; return dummy.next; &#125;&#125; 23. 合并 K 个升序链表(难★) 思路：分治、归并 详细题解： 参考代码： 1234567891011121314151617181920212223242526272829class Solution &#123; public ListNode mergeKLists(ListNode[] lists) &#123; if(lists == null || lists.length == 0) return null; return merge(lists, 0, lists.length - 1); &#125; private ListNode merge(ListNode[] lists, int begin, int end) &#123; if(begin == end) return lists[begin]; int mid = begin + (end - begin)/2; ListNode left = merge(lists, begin, mid); ListNode right = merge(lists, mid + 1, end); return mergeList(left, right); &#125; //合并两个有序链表 private ListNode mergeList(ListNode a, ListNode b) &#123; if(a == null || b == null) return a == null ? b : a; if(a.val &lt; b.val)&#123; a.next = mergeList(a.next, b); return a; &#125;else &#123; b.next = mergeList(a, b.next); return b; &#125; &#125;&#125; 146. LRU 缓存(难)属于是完全不想写第二遍的题目 思路：抽书 双向循环链表（带哨兵节点）负责方便插入删除 哈希表负责O(1)复杂度来寻找元素 要写三个函数： 在双向链表中移除节点x 在链表头部添加一个节点x 确定当前链表中是否有节点x（通过哈希表对值为key的映射来判断 参考题解：灵茶山的题解 详细题解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class LRUCache &#123; //双向循环链表的节点结构 private static class Node&#123; int key,value; Node prev, next; Node(int key, int value)&#123; this.key = key; this.value = value; &#125; &#125; private final int capacity; private final Node dummy = new Node(0,0); //哨兵节点 //哈希表，用以保存值和节点的关系， private final HashMap&lt;Integer, Node&gt; keyToNode = new HashMap&lt;&gt;(); public LRUCache(int capacity) &#123; this.capacity = capacity; dummy.prev = dummy; dummy.next = dummy; &#125; public int get(int key) &#123; //如果哈希表不存在，返回-1 Node node = getNode(key); //如果哈希表存在，则返回该节点的值，同时该节点用了，要把它移动到链表头部，怎么移动呢，直接删除再添加到头部 return node == null ? -1: node.value; &#125; public void put(int key, int value) &#123; //如果哈希表有这个key，就把它移到链表头部，同时更新value Node node = getNode(key); if(node != null)&#123; //移动操作在getNode里面做过了，直接更新返回即可 node.value = value; return; &#125; //如果没有这个key，就新建一个节点，插入头部，同时插入哈希表 node = new Node(key, value); pushFront(node); keyToNode.put(key, node); if(keyToNode.size() &gt; capacity)&#123; //如果插入后大于容量，就要移除链表尾部的节点,同时在哈希表中也要移除 Node backNode = dummy.prev; //哨兵的前一个节点就是链表尾部节点 remove(backNode); keyToNode.remove(backNode.key); &#125; &#125; //get和put都需要确定哈希表中是否有key所对应的节点，因此可以抽象成一个函数 private Node getNode(int key)&#123; //不含这个key所对应的节点 if(!keyToNode.containsKey(key))&#123; return null; &#125; //含的话，不仅要返回这个节点，还要把它移动到链表头部，怎么移动呢，直接删除再添加到头部 Node node = keyToNode.get(key); remove(node); pushFront(node); return node; &#125; //删除一个节点 private void remove(Node x)&#123; x.next.prev = x.prev; x.prev.next = x.next; &#125; //在链表头部添加一个节点 private void pushFront(Node x)&#123; dummy.next.prev = x; x.next = dummy.next; x.prev = dummy; dummy.next = x; &#125;&#125; 八、二叉树94. 二叉树的中序遍历 思路：递归or迭代（栈）。这两种都要掌握。递归就不说了，说一下迭代的大致思路 维护一个栈，一直往最左边走，同时不断添加节点到栈，找到最左节点后加入结果，然后向右遍历，详细过程见代码，可手动模拟一下就清晰了 详细题解： 参考代码： 递归版 123456789101112131415class Solution &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; lnr(root); return ans; &#125; private void lnr(TreeNode root) &#123; if(root == null) return; lnr(root.left); ans.add(root.val); lnr(root.right); &#125;&#125; 迭代版 123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); if(root == null) return ans; ArrayDeque&lt;TreeNode&gt; stack = new ArrayDeque&lt;&gt;(); while (root != null || !stack.isEmpty())&#123; while (root != null)&#123; stack.push(root); root = root.left; &#125; root = stack.pop(); ans.add(root.val); root = root.right; &#125; return ans; &#125;&#125; 104. 二叉树的最大深度 思路：二叉树的最大深度等于MAX(左子树最大深度，右子树最大深度)+1 详细题解：104.二叉树的最大深度 参考代码： 123456789class Solution &#123; public int maxDepth(TreeNode root) &#123; if(root == null) return 0; int left = maxDepth(root.left); int right = maxDepth(root.right); return Math.max(left, right) + 1; &#125;&#125; 226. 翻转二叉树 思路：类似在数组中交换两个元素。这题先交换两个左右子树，然后再递归的对左子树和右子树这样操作 详细题解：226.翻转二叉树 参考代码： 123456789101112class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; if(root == null) return null; TreeNode temp = root.left; root.left = root.right; root.right = temp; invertTree(root.left); invertTree(root.right); return root; &#125;&#125; 101. 对称二叉树 思路：左右子树要想对称，左子树的右节点——右子树的左节点；左子树的左节点——右子树的右节点 详细题解：101.对称二叉树 参考代码： 123456789101112131415161718class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; return isD(root.left, root.right); &#125; private boolean isD(TreeNode left, TreeNode right) &#123; if(left == null &amp;&amp; right == null) return true; else if (left != null &amp;&amp; right != null) &#123; if(left.val != right.val) return false; &#125;else return false; boolean b1 = isD(left.left, right.right); boolean b2 = isD(left.right, right.left); return b1 &amp;&amp; b2; &#125;&#125; 543. 二叉树的直径该题和124. 二叉树中的最大路径和 类似 思路：二叉树的直径 &#x3D; MAX(ans， 左子树+右子树)。这题特殊的是这个’链长’的写法。如果为空节点了，返回-1，左子树和右子树的链长在递归的基础上+1，可抵消这个-1，然后递归函数返回左右子树中较大的那个 详细题解：543.二叉树的直径 参考代码： 12345678910111213141516class Solution &#123; int ans = 0; public int diameterOfBinaryTree(TreeNode root) &#123; dfs(root); return ans; &#125; private int dfs(TreeNode root) &#123; if(root == null) return -1; int left = dfs(root.left) + 1; int right = dfs(root.right) + 1; ans = Math.max(ans, left + right); return Math.max(left, right); &#125;&#125; 102. 二叉树的层序遍历BFS，迭代（队列）。这个题也是基础，后续很多题都是在这个基础上改了一点点 思路：先把头节点入队列，每次弹出队列中的节点，并把该节点的左右节点入队列 详细题解：102.二叉树的层序遍历 参考代码： 1234567891011121314151617181920212223class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); if(root == null) return ans; ArrayDeque&lt;TreeNode&gt; deque = new ArrayDeque&lt;&gt;(); deque.offer(root); while (!deque.isEmpty())&#123; int size = deque.size(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; TreeNode remove = deque.remove(); path.add(remove.val); if(remove.left != null) deque.offer(remove.left); if(remove.right != null) deque.offer(remove.right); &#125; ans.add(path); &#125; return ans; &#125; &#125; ❤️二叉树BFS（队列）类题目 102. 二叉树的层序遍历 199. 二叉树的右视图 下面为150的题目 117. 填充每个节点的下一个右侧节点指针 II 173. 二叉搜索树迭代器 637. 二叉树的层平均值 103. 二叉树的锯齿形层序遍历 108. 将有序数组转换为二叉搜索树 思路：类似二分查找 详细题解：108.将有序数组转换为二叉搜索树 参考代码： 123456789101112131415class Solution &#123; public TreeNode sortedArrayToBST(int[] nums) &#123; return build(0, nums.length - 1, nums); &#125; private TreeNode build(int low, int high, int[] nums) &#123; if(low &gt; high) return null; int mid = low + (high - low) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = build(low, mid - 1, nums); root.right = build(mid + 1, high, nums); return root; &#125;&#125; ❤️BST题目汇总分治： 108. 将有序数组转换为二叉搜索树 、 二叉树性质（严格递增）： 98. 验证二叉搜索树 230. 二叉搜索树中第 K 小的元素 530. 二叉搜索树的最小绝对差 98. 验证二叉搜索树 思路：如果当前节点&lt;&#x3D;前一个节点，说明不满足BST性质。这题要特别注意节点值的范围，要用long型 详细题解：98.验证二叉搜索树 参考代码： 123456789101112131415class Solution &#123; long pre = Long.MIN_VALUE; public boolean isValidBST(TreeNode root) &#123; if(root == null) return true; if(!isValidBST(root.left)) return false; if(root.val &lt;= pre) return false; pre = root.val; if(!isValidBST(root.right)) return false; return true; &#125;&#125; 230. 二叉搜索树中第 K 小的元素 思路：中序遍历，初始化index &#x3D; 1 详细题解： 参考代码： 123456789101112131415161718class Solution &#123; int ans = Integer.MAX_VALUE; int index = 1; public int kthSmallest(TreeNode root, int k) &#123; dfs(root, k); return ans; &#125; private void dfs(TreeNode root, int k) &#123; if(root == null) return; dfs(root.left, k); if(index == k) ans = root.val; index++; dfs(root.right, k); &#125;&#125; 199. 二叉树的右视图 思路：层序遍历，到了最后一个节点就保存记录。 详细题解：199.二叉树的右视图 参考代码： 12345678910111213141516171819202122class Solution &#123; public List&lt;Integer&gt; rightSideView(TreeNode root) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); ArrayDeque&lt;TreeNode&gt; deque = new ArrayDeque&lt;&gt;(); if(root == null) return ans; deque.offer(root); while (!deque.isEmpty())&#123; int size = deque.size(); for (int i = 0; i &lt; size; i++) &#123; TreeNode node = deque.remove(); if(i == size - 1) ans.add(node.val); if(node.left != null) deque.offer(node.left); if(node.right != null) deque.offer(node.right); &#125; &#125; return ans; &#125;&#125; 114. 二叉树展开为链表 思路：不断地将左子树替换为root的右子树，并将之前的右子树拼到其新右子树（也就是之前的左子树）的最右节点之后，然后更新root 详细题解：114.二叉树展开为链表 参考代码： 1234567891011121314151617class Solution &#123; public void flatten(TreeNode root) &#123; while (root != null)&#123; if(root.left != null)&#123; TreeNode temp = root.left; TreeNode cur = temp; while (cur.right != null)&#123; cur = cur.right; &#125; cur.right = root.right; root.left = null; root.right = temp; &#125; root = root.right; &#125; &#125;&#125; 105. 从前序与中序遍历序列构造二叉树难倒是不难，就是繁琐，得慢慢模拟那个传入的值 类似的还有：106. 从中序与后序遍历序列构造二叉树 思路：借助哈希表和全局数组，前者存储中序遍历数组&lt;值，索引&gt;，后者赋值为前序遍历数组。通过哈希表得知当前节点值在中序遍历数组中的索引。这题最关键的是如何确定在左右子树中传递的值 详细题解：105.从前序与中序遍历序列构造二叉树 参考代码： 123456789101112131415161718192021class Solution &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] p ; public TreeNode buildTree(int[] preorder, int[] inorder) &#123; p = preorder; for (int i = 0; i &lt; inorder.length; i++) &#123; map.put(inorder[i], i); &#125; return build(0, preorder.length - 1, 0, inorder.length - 1); &#125; private TreeNode build(int pb, int pe, int ib, int ie) &#123; if(pb &lt; 0 || ib &lt; 0 || pb &gt; pe || ib &gt; pe) return null; int index = map.get(p[pb]); TreeNode root = new TreeNode(p[pb]); root.left = build(pb + 1, pb + index - ib, ib, index - 1); root.right = build(pb + index + 1 - ib, pe, index + 1, ie); return root; &#125;&#125; 后面几题都有点邪乎了。。 437. 路径总和 III （小难哈希表+前缀和，类似560. 和为 K 的子数组 思路：哈希表保存&lt;当前路径从根节点到当前节点的节点值之和，出现次数&gt;，如果想在当前路径找到一段路径之和为target，那么哈希表中必须有这样的元素，即当前节点值之和 - 该元素的key &#x3D; target。还有一些细节参考详细题解，这题核心思路就是这样，但还有一些繁琐的小细节，比如哈希表key的类型，状态恢复（因为题目要求只能是从父节点到子节点，也即是不能跨越父节点有两段子树参与） 详细题解：437.路径总和 III 参考代码： 1234567891011121314151617181920212223class Solution &#123; HashMap&lt;Long, Integer&gt; map = new HashMap&lt;&gt;(); int targrt; public int pathSum(TreeNode root, int targetSum) &#123; targrt =targetSum; map.put(0L, 1); return dfs(root, 0L); &#125; private int dfs(TreeNode root, long curSum) &#123; if(root == null) return 0; curSum += root.val; int ans = 0; ans += map.getOrDefault(curSum - targrt, 0); map.put(curSum, map.getOrDefault(curSum, 0) + 1); int left = dfs(root.left, curSum); int right = dfs(root.right, curSum); ans += left + right; map.put(curSum, map.get(curSum) - 1); return ans; &#125;&#125; 236. 二叉树的最近公共祖先 （思路有点懵懂 思路：这题可直接参考Krahets 的题解，他这个思路很清晰，代码我是参考的灵茶山艾府的，这个代码比较好写 详细题解： 参考代码： 1234567891011class Solution &#123; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if(root == null || p == root || q == root) return root; TreeNode l = lowestCommonAncestor(root.left, p, q); TreeNode r = lowestCommonAncestor(root.right, p, q); if(l != null &amp;&amp; r != null) return root; return l == null ? r : l; &#125;&#125; 124. 二叉树中的最大路径和 思路：递归函数返回当前节点及其左右子树较大值之和与0的比较，而ans要取当前节点和其左右子树之和与and的较大值 详细题解： 参考代码： 12345678910111213141516class Solution &#123; int ans = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) &#123; dfs(root); return ans; &#125; private int dfs(TreeNode root) &#123; if(root == null) return 0; int left = dfs(root.left); int right = dfs(root.right); ans = Math.max(ans, left + right + root.val); return Math.max(0, Math.max(left, right) + root.val); &#125;&#125; 九、图论四个题目分别涉及了DFS、BFS、拓扑排序 200. 岛屿数量 思路：遍历每个单元格，当遇到陆地（&#39;1&#39;）时，将其所有相连的陆地标记为已访问，从而统计为一个岛屿。 遍历整个网格的每一个格子。 当遇到一个’1’时，岛屿数量加一。 然后使用DFS或BFS将这个岛屿的所有相连的’1’都标记为’0’，防止重复计数。 继续遍历剩下的格子，重复上述过程。 详细题解： 参考代码： 1234567891011121314151617181920212223242526class Solution &#123; public int numIslands(char[][] grid) &#123; int m = grid.length; int n = grid[0].length; int ans = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if(grid[i][j] == &#x27;1&#x27;)&#123; dfs(i, j, grid); ans++; &#125; &#125; &#125; return ans; &#125; private void dfs(int i, int j, char[][] grid) &#123; if(i &lt; 0 || j &lt; 0 || i &gt;= grid.length || j &gt;= grid[0].length || grid[i][j] != &#x27;1&#x27;) return; grid[i][j] = &#x27;0&#x27;; dfs(i - 1, j, grid); dfs(i + 1, j, grid); dfs(i, j - 1,grid); dfs(i, j + 1,grid); &#125;&#125; 994. 腐烂的橘子 思路：BFS（队列）。逐层处理队列中的腐烂橘子，将周围的新鲜橘子感染，并加入队列。每一层对应一分钟的扩散时间。 详细题解：994.腐烂的橘子 参考代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; public int orangesRotting(int[][] grid) &#123; int m = grid.length; int n = grid[0].length; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); int fresh = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if(grid[i][j] == 2) //说明是腐烂的橘子，将坐标加入队列 queue.offer(new int[]&#123;i, j&#125;); else if (grid[i][j] == 1) &#123; fresh++; &#125; &#125; &#125; if(fresh == 0) //说明没有新鲜橘子 return 0; int time = 0; int[][] direction = &#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;; while (!queue.isEmpty())&#123; int size = queue.size(); boolean flag = false; //用于标记当前遍历是否感染了新鲜橘子 for (int i = 0; i &lt; size; i++) &#123; int[] cur = queue.poll(); for (int[] dire : direction) &#123; int x = cur[0] + dire[0]; int y = cur[1] + dire[1]; //如果没越界且是新鲜橘子，就给腐烂 if(x &gt;=0 &amp;&amp; x &lt; m &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; n &amp;&amp; grid[x][y] == 1)&#123; grid[x][y] = 2; queue.offer(new int[]&#123;x, y&#125;); fresh--; flag = true; &#125; &#125; &#125; if(flag) time++; &#125; return fresh == 0 ? time : -1; &#125;&#125; 207. 课程表 思路：拓扑排序（DFS检测环） 详细题解： 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public boolean canFinish(int numCourses, int[][] prerequisites) &#123; List&lt;List&lt;Integer&gt;&gt; graph = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; numCourses; i++) &#123; //邻接表构建图 graph.add(new ArrayList&lt;&gt;()); &#125; for (int[] pre : prerequisites) &#123; //(a,b)要想学习a得先学习b，因此构建b——&gt;a的有向边 graph.get(pre[1]).add(pre[0]); &#125; int[] visited = new int[numCourses]; //状态数组，0=未访问，1=正在访问，2=已访问 for (int i = 0; i &lt; numCourses; i++) &#123; //检测每个节点是否存在环 if(hasCycle(graph, visited, i)) return false; &#125; return true; &#125; private boolean hasCycle(List&lt;List&lt;Integer&gt;&gt; graph, int[] visited, int course) &#123; if(visited[course] == 1) // 如果课程已经访问过且在当前路径上，说明存在环 return true; if(visited[course] == 2) // 如果课程已经访问过且不在当前路径上，说明没有环 return false; visited[course] = 1; for (int nextCourse : graph.get(course)) &#123; // 递归访问当前课程的所有依赖课程 if(hasCycle(graph, visited, nextCourse)) return true; &#125; visited[course] = 2; return false; &#125;&#125; 208. 实现 Trie (前缀树)这里要构建一个图，它的节点代表的是索引号，而边上面存储的是一个一个的字符 思路：自定义图节点的属性，然后模拟图的创建和查找过程 详细题解：参考代码注释，写的很详细 参考代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Trie &#123; /* 定义节点类，相当于每个节点有26个子节点，但只有真正有值的才有节点，其余都为null。 另外还有一个标志位用来标记当前节点是否为最后一个节点 */ public class TrieNode&#123; TrieNode[] children; boolean isEnd; TrieNode()&#123; children = new TrieNode[26]; isEnd = false; &#125; &#125; TrieNode root; public Trie() &#123; root = new TrieNode(); &#125; public void insert(String word) &#123; TrieNode node = root; for (char c : word.toCharArray()) &#123; int index = c - &#x27;a&#x27;; //得到有值的节点的索引 if(node.children[index] == null) node.children[index] = new TrieNode(); node = node.children[index]; //相当于节点后移 &#125; node.isEnd = true; //此时该字符串遍历完了，node一定是最后一个节点 &#125; /* 根据这个单词的路径一直走，如果中间哪个为null了说明字符未出现直接返回false 否则安全遍历完之后还要确认当前字符是否为最后一个字符，如果不是说明它只是一个前缀，还要返回false */ public boolean search(String word) &#123; // TrieNode node = root; for (char c : word.toCharArray()) &#123; int index = c - &#x27;a&#x27;; if(node.children[index] == null) return false; node = node.children[index]; &#125; return node.isEnd; &#125; /* 思路同上，不同的是最后不需要关注它是否为最后一个字符了，因为这里只是找前缀 */ public boolean startsWith(String prefix) &#123; TrieNode node = root; for (char c : prefix.toCharArray()) &#123; int index = c - &#x27;a&#x27;; if(node.children[index] == null) return false; node = node.children[index]; &#125; return true; &#125;&#125; 十、回溯回溯，主要就是套模板。我感觉最关键的就是两个要素： 回溯传递的参数 回溯退出的条件 46. 全排列 思路：可以用一个list来存储每组的元素。退出条件就是list.size() == nums.length，同时要能加入list的前提是list不含当前元素 详细题解： 参考代码： 1234567891011121314151617181920class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; backTracking(nums); return ans; &#125; private void backTracking(int[] nums) &#123; if(path.size() == nums.length) ans.add(new ArrayList&lt;&gt;(path)); for (int num : nums) &#123; if(!path.contains(num))&#123; path.add(num); backTracking(nums); path.remove(path.size() - 1); &#125; &#125; &#125;&#125; 78. 子集 思路：这题有点特殊的是，每个分组都要添加到结果，所以不用写退出条件了 详细题解： 参考代码： 1234567891011121314151617class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; backTracking(nums, 0); return ans; &#125; private void backTracking(int[] nums, int begin) &#123; ans.add(new ArrayList&lt;&gt;(path)); for (int i = begin; i &lt; nums.length; i++) &#123; path.add(nums[i]); backTracking(nums, i + 1); path.remove(path.size() - 1); &#125; &#125;&#125; 17. 电话号码的字母组合 思路：借助哈希表存储电话号码和字符串的映射关系，传入字符串即开始索引begin，退出条件为begin == digits.length() 详细题解：17.电话号码的字母组合 参考代码： 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); HashMap&lt;Character, String&gt; map = new HashMap&lt;&gt;(); StringBuilder sb = new StringBuilder(); public List&lt;String&gt; letterCombinations(String digits) &#123; if(digits.isEmpty()) return ans; map.put(&#x27;2&#x27;, &quot;abc&quot;); map.put(&#x27;3&#x27;, &quot;def&quot;); map.put(&#x27;4&#x27;, &quot;ghi&quot;); map.put(&#x27;5&#x27;, &quot;jkl&quot;); map.put(&#x27;6&#x27;, &quot;mno&quot;); map.put(&#x27;7&#x27;, &quot;pqrs&quot;); map.put(&#x27;8&#x27;, &quot;tuv&quot;); map.put(&#x27;9&#x27;, &quot;wxyz&quot;); backTracking(digits, 0); return ans; &#125; private void backTracking(String digits, int begin) &#123; if(begin == digits.length())&#123; ans.add(sb.toString()); return; &#125; char c = digits.charAt(begin); String curS = map.get(c); for (int i = 0; i &lt; curS.length(); i++) &#123; sb.append(curS.charAt(i)); backTracking(digits, begin + 1); sb.deleteCharAt(sb.length() - 1); &#125; &#125;&#125; 39. 组合总和 思路：传入数组开始索引begin，当前和cur，目标值，数组。结束条件是begin == candidates.length || cur == target，也有可能提前退出，那就是cur &gt; target 详细题解：39.组合总和 参考代码： 123456789101112131415161718192021222324class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; backTracking(0, 0, target, candidates); return ans; &#125; private void backTracking(int begin, int cur, int target, int[] candidates) &#123; if(cur == target)&#123; ans.add(new ArrayList&lt;&gt;(path)); return; &#125; if(cur &gt; target || begin == candidates.length) return; for (int i = begin; i &lt; candidates.length; i++) &#123; cur += candidates[i]; path.add(candidates[i]); backTracking(i, cur, target, candidates); path.remove(path.size() - 1); cur -= candidates[i]; &#125; &#125;&#125; 22. 括号生成 思路：传入当前左括号剩余left和右括号剩余right以及当前字符串cur。退出条件是left == 0 &amp;&amp; right == 0。还要一个提前退出条件，就是left &gt; right，此时无法组成合法的括号。这里回溯的写法形式也不太一样。 详细题解：22.括号生成 参考代码： 123456789101112131415161718192021class Solution &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); public List&lt;String&gt; generateParenthesis(int n) &#123; backTracking(n, n, &quot;&quot;); return ans; &#125; private void backTracking(int left, int right, String cur) &#123; if(left == 0 &amp;&amp; right == 0)&#123; ans.add(cur); return; &#125; if(left &gt; right) return; if(left &gt; 0)&#123; backTracking(left-1, right, cur + &quot;(&quot;); &#125; if(right &gt; 0) backTracking(left, right-1, cur + &quot;)&quot;); &#125;&#125; 79. 单词搜索 思路：DFS，从矩阵每个元素开始匹配，匹配了修改当前字符为&#96;.&#96;&#96;,表示已经用过，搜索完之后回溯为之前的字符 详细题解：79.单词搜索 参考代码： 123456789101112131415161718192021222324252627public boolean exist(char[][] board, String word) &#123; int m = board.length; int n = board[0].length; int k = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if(backTracking(i, j, board, word, k)) return true; &#125; &#125; return false; &#125; private boolean backTracking(int i, int j, char[][] board, String word, int k) &#123; if(i &lt; 0 || j &lt; 0 || i &gt;= board.length || j &gt;= board[0].length || word.charAt(k) != board[i][j]) return false; if(k == word.length() - 1) //这一步要注意，因为上面没有对k的越界判断，所以这里就要有一个判真的退出 return true; char tem = board[i][j]; board[i][j] = &#x27;.&#x27;; boolean ans = backTracking(i + 1, j, board, word, k + 1) || backTracking(i - 1, j, board, word, k + 1) || backTracking(i, j + 1, board, word, k + 1) || backTracking(i, j - 1, board, word, k + 1); board[i][j] = tem; return ans; &#125; 131. 分割回文串 思路：每个字符在回溯循环中往后匹配，需要写一个判断是否为回文串的函数，如果是就添加进中间结果集。回溯传入字符串和开始索引，退出条件为开始索引等于字符串长度 详细题解：131. 分割回文串 参考代码： 123456789101112131415161718192021222324252627282930313233class Solution &#123; List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;String&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; backTracking(s, 0); return ans; &#125; private void backTracking(String s, int begin) &#123; if(begin == s.length())&#123; ans.add(new ArrayList&lt;&gt;(path)); return; &#125; for (int i = begin; i &lt; s.length(); i++) &#123; if(isH(s, begin, i))&#123; String substring = s.substring(begin, i + 1); path.add(substring); backTracking(s, i + 1); path.remove(path.size() - 1); &#125; &#125; &#125; private boolean isH(String s, int l, int r) &#123; while (l &lt;= r)&#123; if(s.charAt(l) != s.charAt(r)) return false; l++; r--; &#125; return true; &#125;&#125; 51. N 皇后 思路：回溯函数传入棋盘数组和当前行索引，退出条件为当前行索引等于棋盘宽，回溯里面的循环是列循环。同上题一样，需要写一个函数来判断是否满足条件，判断当前字符是否可以作为Q。具体来说，就是判断当前行，列，主对角，副对角是否有其它Q。 详细题解：51. N 皇后 参考代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123; List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;&gt;(); List&lt;String&gt; path = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; char[][] chars = new char[n][n]; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; chars[i][j] = &#x27;.&#x27;; &#125; &#125; backTracking(0, chars); return ans; &#125; private void backTracking(int row, char[][] chars) &#123; if(row == chars.length)&#123; ans.add(chars2List(chars)); return; &#125; for (int col = 0; col &lt; chars[0].length; col++) &#123; if(isT(row, col, chars))&#123; chars[row][col] = &#x27;Q&#x27;; backTracking(row + 1, chars); chars[row][col] = &#x27;.&#x27;; &#125; &#125; &#125; private List&lt;String&gt; chars2List(char[][] chars) &#123; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; chars.length; i++) &#123; ans.add(new String(chars[i])); &#125; return ans; &#125; private boolean isT(int row, int col, char[][] chars) &#123; int m = chars.length; int n = chars[0].length; for (int i = 0; i &lt; m; i++) &#123; if(chars[i][col] == &#x27;Q&#x27;) return false; &#125; for (int i = 0; i &lt; n; i++) &#123; if(chars[row][i] == &#x27;Q&#x27;) return false; &#125; for (int i = row, j = col; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) if(chars[i][j] == &#x27;Q&#x27;) return false; for (int i = row, j = col; i &gt;= 0 &amp;&amp; j &lt; n; i--, j++) if(chars[i][j] == &#x27;Q&#x27;) return false; return true; &#125;&#125; 十一、二分查找35. 搜索插入位置 思路：二分查找找存在时的元素这没什么好说的，当元素不存在时，为什么返回low 就可以了呢，观察while退出条件，退出时，low &#x3D; high + 1 详细题解：35. 搜索插入位置 参考代码： 123456789101112131415class Solution &#123; public int searchInsert(int[] nums, int target) &#123; int low = 0, high = nums.length- 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] == target) return mid; else if (nums[mid] &gt; target) &#123; high = mid - 1; &#125;else low = mid + 1; &#125; return low; &#125;&#125; 74. 搜索二维矩阵 思路：将矩阵按行展开拼成一个一维数组，可以发现就是对这个数组来进行二分查找，每次得到的mid和行列有一个对应关系，row = mid / n, col = mid % n 详细题解： 参考代码： 12345678910111213141516171819class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; int m = matrix.length; int n = matrix[0].length; int low = 0, high = m * n - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; int row = mid / n; int col = mid % n; if(matrix[row][col] == target) return true; else if (matrix[row][col] &gt; target) &#123; high = mid - 1; &#125;else low = mid + 1; &#125; return false; &#125;&#125; 34. 在排序数组中查找元素的第一个和最后一个位置 思路：二分查找，如果找不到，那就正常套路，如果找到了，直接从当前位置向左右扩散，直到扩散的元素不等于target 详细题解：34. 在排序数组中查找元素的第一个和最后一个位置 参考代码： 12345678910111213141516171819class Solution &#123; public int[] searchRange(int[] nums, int target) &#123; int low = 0, high = nums.length - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] &gt; target) high = mid - 1; else if(nums[mid] &lt; target) low = mid + 1; else &#123; int l = mid, r = mid; while (l &gt;= 0 &amp;&amp; nums[l] == target) l--; while (r &lt; nums.length &amp;&amp; nums[r] == target) r++; return new int[]&#123;l + 1, r - 1&#125;; &#125; &#125; return new int[] &#123;-1, -1&#125;; &#125;&#125; 33. 搜索旋转排序数组 思路：这种数组是局部有序，全局无序，比如前半部分是有序的，后半部分也是有序的。我们做二分查找时，如果当前mid元素不等于target，那就判断当前元素是处于左边有序区间还是右边有序区间，然后再分别做区间缩减 详细题解：33. 搜索旋转排序数组 参考代码： 12345678910111213141516171819202122class Solution &#123; public int search(int[] nums, int target) &#123; int low = 0, high = nums.length - 1; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; if(nums[mid] == target) return mid; else if (nums[mid] &lt; nums[high]) &#123; if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[high]) low = mid + 1; else high = mid - 1; &#125;else &#123; if(target &gt;= nums[low] &amp;&amp; target &lt; nums[mid]) high = mid - 1; else low = mid + 1; &#125; &#125; return -1; &#125;&#125; 153. 寻找旋转排序数组中的最小值 思路：同上题一样，这种旋转数组要分区间。如果是在左边区间，就将最小值和left比较，如果是在最右边，就将最小值和mid比较 详细题解：153. 寻找旋转排序数组中的最小值 参考代码： 123456789101112131415161718class Solution &#123; public int findMin(int[] nums) &#123; int low = 0, high = nums.length - 1; int ans = Integer.MAX_VALUE; while (low &lt;= high)&#123; int mid = low + (high - low) / 2; int temp = nums[mid]; if(temp &lt; nums[high])&#123; ans = Math.min(ans, temp); high = mid - 1; &#125;else &#123; ans = Math.min(ans, nums[low]); low = mid + 1; &#125; &#125; return ans; &#125;&#125; 4. 寻找两个正序数组的中位数 （难） 思路： 详细题解： 参考代码： 1 十二、栈20. 有效的括号 思路：借助栈，如果是左括号直接入栈，右括号就根据栈顶元素来确定对右括号的策略 详细题解：20. 有效的括号 参考代码： 123456789101112131415161718192021222324class Solution &#123; public boolean isValid(String s) &#123; ArrayDeque&lt;Character&gt; stack = new ArrayDeque&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if(c == &#x27;[&#x27; || c == &#x27;(&#x27; || c == &#x27;&#123;&#x27;) stack.push(c); else &#123; if(stack.isEmpty()) return false; else if (c == &#x27;]&#x27; &amp;&amp; stack.peek() == &#x27;[&#x27;) &#123; stack.pop(); &#125;else if (c == &#x27;)&#x27; &amp;&amp; stack.peek() == &#x27;(&#x27;) &#123; stack.pop(); &#125;else if (c == &#x27;&#125;&#x27; &amp;&amp; stack.peek() == &#x27;&#123;&#x27;) &#123; stack.pop(); &#125;else return false; &#125; &#125; if (!stack.isEmpty()) return false; return true; &#125;&#125; 155. 最小栈 思路：另外创建一个只存储栈中最小元素的辅助栈，来模拟最小栈的操作 详细题解：155. 最小栈 参考代码： 12345678910111213141516171819202122232425262728class MinStack &#123; ArrayDeque&lt;Integer&gt; nums = new ArrayDeque&lt;&gt;(); ArrayDeque&lt;Integer&gt; minStack = new ArrayDeque&lt;&gt;(); public MinStack() &#123; nums = new ArrayDeque&lt;&gt;(); minStack = new ArrayDeque&lt;&gt;(); minStack.push(Integer.MAX_VALUE); &#125; public void push(int val) &#123; nums.push(val); minStack.push(Math.min(minStack.peek(), val)); &#125; public void pop() &#123; nums.pop(); minStack.pop(); &#125; public int top() &#123; return nums.peek(); &#125; public int getMin() &#123; return minStack.peek(); &#125;&#125; 394. 字符串解码 思路：双栈模拟，一个栈仅存数字，另一个栈仅存字符串。遍历s的字符，根据字符为数字、左括号、右括号、字符四种情况分类操作。详细可见代码及详细题解 详细题解：394. 字符串解码 参考代码： 1234567891011121314151617181920212223242526272829class Solution &#123; public String decodeString(String s) &#123; ArrayDeque&lt;Integer&gt; numStack = new ArrayDeque&lt;&gt;(); ArrayDeque&lt;String&gt; strStack = new ArrayDeque&lt;&gt;(); int num = 0; String curStr = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if(Character.isDigit(c))&#123; num = num * 10 + c - &#x27;0&#x27;; &#125; else if (c == &#x27;[&#x27;) &#123; numStack.push(num); strStack.push(curStr); num = 0; curStr = &quot;&quot;; &#125; else if (c == &#x27;]&#x27;) &#123; int loop = numStack.pop(); StringBuilder sb = new StringBuilder(strStack.pop()); for (int j = 0; j &lt; loop; j++) &#123; sb.append(curStr); &#125; curStr = sb.toString(); &#125;else curStr += c; &#125; return curStr; &#125;&#125; 739. 每日温度单调栈，这题以及84. 柱状图中最大的矩形 都是单调栈，略微难想 思路：这里也别在意这个所谓的单调栈到底是怎么单调的了，就这题而言，我们可以这样考虑，每次遍历数组元素的时候就把当前下标加入栈，但是在加入之前呢，得先看看栈最顶的下标所指元素是否找到了下一个更大的元素，如果找到了，就弹出然后设置。同时这个操作还得循环进行，比如当前遍历的元素比前几个元素都大，那就是说前几个元素的下一个更大元素都找到了。详细可参照代码理解 详细题解：739.每日温度 参考代码： 123456789101112131415class Solution &#123; public int[] dailyTemperatures(int[] temperatures) &#123; int[] ans = new int[temperatures.length]; ArrayDeque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for (int i = 0; i &lt; temperatures.length; i++) &#123; while (!stack.isEmpty() &amp;&amp; temperatures[i] &gt; temperatures[stack.peek()])&#123; int p = stack.pop(); //弹出的索引该处的元素下一个更大元素找到了！ ans[p] = i - p; &#125; stack.push(i); &#125; return ans; &#125;&#125; 84. 柱状图中最大的矩形 思路： 单调栈：维护一个单调递增的栈，用于快速找到每个柱子左边和右边第一个比它矮的柱子。 遍历每个柱子，当遇到比栈顶柱子矮的柱子时，弹出栈顶并计算其面积，更新最大面积。 详细题解： 参考代码： 123456789101112131415161718192021public int largestRectangleArea(int[] heights) &#123; int ans = Integer.MIN_VALUE; ArrayDeque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); stack.push(-1); for (int i = 0; i &lt; heights.length; i++) &#123; while (stack.peek() != -1 &amp;&amp; heights[i] &lt;= heights[stack.peek()])&#123; int high = heights[stack.pop()]; int width = i - stack.peek() - 1; ans = Math.max(ans, high * width); &#125; stack.push(i); &#125; while (stack.peek() != -1)&#123; int high = heights[stack.pop()]; int width = heights.length - stack.peek() - 1; ans = Math.max(ans, high * width); &#125; return ans; &#125; 十三、堆215. 数组中的第K个最大元素 思路：快排 详细题解： 参考代码： 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; private static final Random rand = new Random(); public int findKthLargest(int[] nums, int k) &#123; quickSort(nums, 0, nums.length - 1); return nums[nums.length - k]; &#125; private void quickSort(int[] nums, int l, int r) &#123; if(l &lt; r)&#123; int pivotIndex = partition(nums, l, r); quickSort(nums, l, pivotIndex - 1); quickSort(nums, pivotIndex + 1, r); &#125; &#125; private int partition(int[] nums, int l, int r) &#123; int random = rand.nextInt(r - l + 1) + l; swap(nums, random, l); int i = l, j = r; int pivot = nums[l]; while (i &lt; j)&#123; while (i &lt; j &amp;&amp; nums[j] &gt;= pivot) j--; while (i &lt; j &amp;&amp; nums[i] &lt;= pivot) i++; if(i &lt; j) swap(nums, i, j); &#125; swap(nums, l, i); return i; &#125; private void swap(int[] nums, int l, int r) &#123; int temp = nums[l]; nums[l] = nums[r]; nums[r] = temp; &#125;&#125; 347. 前 K 个高频元素 思路： 统计频率：使用HashMap遍历数组，记录每个元素的出现次数。 最小堆维护：优先队列按元素频率升序排列，当堆的大小超过k时，移除堆顶的最小频率元素，确保堆中保留当前最大的k个频率元素。 结果提取：将堆中的元素依次取出，转换为数组返回。由于题目允许任意顺序，无需额外排序。 详细题解： 参考代码： 12345678910111213141516171819202122232425 class Solution &#123; public int[] topKFrequent(int[] nums, int k) &#123; // 统计每个元素的频率 HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int num : nums) &#123; map.put(num, map.getOrDefault(num, 0) + 1); &#125; // 创建最小堆，按频率升序排列 PriorityQueue&lt;Map.Entry&lt;Integer, Integer&gt;&gt; heap = new PriorityQueue&lt;&gt;((a, b) -&gt; a.getValue() - b.getValue()); for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; //遍历map，而不是堆 heap.offer(entry); if(heap.size() &gt; k) heap.poll(); &#125; int[] ans = new int[k]; int idx = 0; while (!heap.isEmpty())&#123; ans[idx++] = heap.poll().getKey(); &#125; return ans; &#125;&#125; 295. 数据流的中位数 十四、贪心算法121. 买卖股票的最佳时机 思路：记录今天及之前的最小值，然后更新可获得的最大利润 详细题解： 参考代码： 1234567891011class Solution &#123; public int maxProfit(int[] prices) &#123; int pre = Integer.MAX_VALUE; int ans = Integer.MIN_VALUE; for (int price : prices) &#123; pre = Math.min(pre, price); ans = Math.max(ans, price - pre); &#125; return ans; &#125;&#125; 55. 跳跃游戏 思路：对当前最大可跳跃步数做循环，同时维护更新最大步数，如果这个值超过了数组长度 - 1，说明可以到达最后一个元素 详细题解：55. 跳跃游戏 参考代码： 1234567891011class Solution &#123; public boolean canJump(int[] nums) &#123; int maxStep = 0; for (int i = 0; i &lt;= maxStep; i++) &#123; maxStep = Math.max(maxStep, i + nums[i]); if(maxStep &gt;= nums.length - 1) return true; &#125; return false; &#125;&#125; 45. 跳跃游戏 II 思路：遍历数组元素，不断维护更新可到达最远位置，如果到了最边界就更新边界同时ans++。这题要注意的是不必到达最后一个元素才判断，到达倒数第二个元素就可以了（详细看官方题解下对于这点说明 详细题解：45. 跳跃游戏 II 参考代码： 123456789101112131415class Solution &#123; public int jump(int[] nums) &#123; int ans = 0; int maxPosition = 0; int end = 0; for (int i = 0; i &lt; nums.length - 1; i++) &#123; maxPosition = Math.max(maxPosition, i + nums[i]); if(i == end)&#123; end = maxPosition; ans++; &#125; &#125; return ans; &#125;&#125; 763. 划分字母区间 思路：先记录每个字符的最远索引是在哪。然后定义begin和end来处理每个区间的长度。每次遍历不断更新end。如果到了end，则将当前区间长度添加进入ans，然后更新begin为end的下一个位置 详细题解：763. 划分字母区间 参考代码： 12345678910111213141516171819class Solution &#123; public List&lt;Integer&gt; partitionLabels(String s) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int[] maxP = new int[26]; for (int i = 0; i &lt; s.length(); i++) &#123; maxP[s.charAt(i) - &#x27;a&#x27;] = i; &#125; int end = 0, begin = 0; for (int i = 0; i &lt; s.length(); i++) &#123; end = Math.max(end, maxP[s.charAt(i) - &#x27;a&#x27;]); if(i == end)&#123; ans.add(end - begin + 1); begin = end + 1; &#125; &#125; return ans; &#125;&#125; 十五、动态规划70. 爬楼梯 思路：定义dp数组i为到达当前位置的方案，当前状态可由dp[i-1]或者dp [i-2]转移过来 详细题解： 参考代码： 123456789101112131415class Solution &#123; public int climbStairs(int n) &#123; int[] dp = new int[n + 1]; if(n == 1) return 1; if(n == 2) return 2; dp[1] = 1; dp[2] = 2; for (int i = 3; i &lt;= n; i++) &#123; dp[i] = dp[i - 1] + dp[i - 2]; &#125; return dp[n]; &#125;&#125; 118. 杨辉三角 思路：当前状态可由上一行的两个元素转移过来 详细题解： 参考代码： 1234567891011121314151617181920class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); ans.add(List.of(1)); if(numRows == 1) return ans; for (int i = 1; i &lt; numRows; i++) &#123; List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); path.add(1); if(i &gt; 1)&#123; for (int j = 0; j &lt; i - 1; j++) &#123; path.add(ans.get(i - 1).get(j) + ans.get(i - 1).get(j + 1)); &#125; &#125; path.add(1); ans.add(path); &#125; return ans; &#125;&#125; 198. 打家劫舍 思路：dp[i]为到当前i所能获得的最高金额，这个金额取决于前面一家(也就是i-1是否打劫了)，dp[i]=max(dp[i-1],dp [i-2]+nums [i]) 详细题解：198. 打家劫舍 参考代码： 1234567891011121314151617class Solution &#123; public int rob(int[] nums) &#123; int n = nums.length; int[] dp = new int[n]; if(n == 1) return nums[0]; if(n == 2) return Math.max(nums[0], nums[1]); dp[0] = nums[0]; dp[1] = Math.max(nums[0], nums[1]); for (int i = 2; i &lt; n; i++) &#123; dp[i] = Math.max(dp[i - 1], dp[i - 2] + nums[i]); &#125; return dp[n - 1]; &#125;&#125; 279. 完全平方数 思路： 动态规划的思路通常是这样的：我们定义一个数组dp，其中dp[i]表示和为i的完全平方数的最少数量。然后，我需要找出状态转移方程。 比如，对于每个i，我需要遍历所有可能的平方数jj，其中jj &lt;&#x3D;i。然后，dp[i]可能等于dp[i - jj] +1，因为如果i-jj可以由dp[i-jj]个平方数组成，那么加上当前的jj（也就是一个平方数），总共有dp[i-j*j]+1个。这时候我需要取所有可能的j中的最小值。 这样，状态转移方程应该是dp[i] &#x3D; min(dp[i], dp[i - j*j] +1)。初始条件是dp[0]&#x3D;0，因为和为0不需要任何平方数。然后从1到n依次计算每个dp[i]。 那具体怎么实现呢？比如n&#x3D;12的时候，dp数组的大小应该是n+1，也就是13个元素。初始化的时候，所有元素设为最大值，比如n+1，因为最大的情况是全部由1组成，也就是n个1，所以初始值可以设为n+1，这样后续比较时就能找到更小的值。 举个例子，计算dp[12]的时候，我们需要遍历所有可能的j，其中j的平方不超过12。j可以是1、2、3，因为3的平方是9，4的平方是16就超过了。对于每个j，我们计算dp[12 - j*j] +1的值，并取最小值。 比如当j&#x3D;3时，12-9&#x3D;3，所以要看dp[3]的值加上1。那dp[3]是多少呢？dp[3]的可能分解是1+1+1，也就是3个1，或者1+2的平方？但2的平方是4，比3大，所以只能是1的平方相加。所以dp[3]应该是3。那么这时候，dp[12]可能等于3+1&#x3D;4？或者可能有更优的情况？ 或者，比如当j&#x3D;2的时候，j²是4。12-4&#x3D;8。那么要看dp[8]的值加上1。假设dp[8]的最优解是2（比如4+4），那么加上当前的4，就是3次。所以这时候，dp[12]的最小值就是3。这应该就是示例中的正确情况。 所以动态规划的步骤应该是： 初始化dp数组，dp[0] &#x3D;0，其他初始化为较大的值，比如n。 遍历每个i从1到n。 对于每个i，遍历所有j，其中j的平方&lt;&#x3D;i。 更新dp[i]为min(dp[i], dp[i -j*j]+1)。 最后返回dp[n]。 详细题解： 参考代码： 12345678910public int numSquares(int n) &#123; int[] dp = new int[n + 1]; Arrays.fill(dp, n + 1); dp[0] = 0; for (int i = 1; i * i &lt;= n; i++) &#123; //遍历所有小于等于 n 的完全平方数 i * i。 for (int j = i * i; j &lt;= n; j++) //根据当前的完全平方数，更新 dp[j]，表示构成 j 的最小完全平方数的个数。 dp[j] = Math.min(dp[j], dp[j - i * i] + 1); &#125; return dp[n]; &#125; 322. 零钱兑换 思路：完全背包的组合问题，dp[i]表示组成金额i所需的最少硬币个数，怎么转移过来的呢，比如当前i，前提是硬币小于金额i，如果选取了此时的硬币，那就是dp[i - 硬币金额] + 1，这个1就是此时选的硬币，如果不选的话，那就是dp[i] 详细题解：322. 零钱兑换 参考代码： 123456789101112131415class Solution &#123; public int coinChange(int[] coins, int amount) &#123; int[] dp = new int[amount + 1]; Arrays.fill(dp, amount + 1); dp[0] = 0; for (int i = 0; i &lt;= amount; i++) &#123; for (int j = 0; j &lt; coins.length; j++) &#123; if(i &gt;= coins[j]) dp[i] = Math.min(dp[i], dp[i - coins[j]] + 1); &#125; &#125; return dp[amount] &gt; amount ? -1 : dp[amount]; &#125;&#125; 139. 单词拆分 思路：完全背包的排列问题，dp[i]代表以前i个字符是否能由数组里面的字符串组成，可以先把数组里面的字符串存到set里面，对于j &lt; i，如果dp[j]为true，且从j到i的字符串在set里面有，那就说明dp[i]也为true 详细题解：139. 单词拆分 参考代码： 1234567891011121314151617class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; HashSet&lt;String&gt; set = new HashSet&lt;&gt;(); for (String string : wordDict) &#123; set.add(string); &#125; boolean[] dp = new boolean[s.length() + 1]; dp[0] = true; for (int i = 0; i &lt;= s.length(); i++) &#123; for (int j = 0; j &lt; i; j++) &#123; if(dp[j] &amp;&amp; set.contains(s.substring(j, i))) dp[i] = true; &#125; &#125; return dp[s.length()]; &#125;&#125; 300. 最长递增子序列 思路：dp[i]代表以nums[i]结尾的字符的最长递增子序列，对于（j &lt; i）的所有dp[j]，如果此时nums[j] &lt; nums[i]，那么就有dp[i] = max(dp[i], dp[j] + 1)来更新此时的dp[i]，而更核心的在于，我们要在所有的dp[i]中选择最大的那个，来作为答案，所以要用一个变量ans来记录最大的那个dp[i] 详细题解：300. 最长递增子序列 参考代码： 1234567891011121314151617class Solution &#123; public int lengthOfLIS(int[] nums) &#123; int ans = Integer.MIN_VALUE; int[] dp = new int[nums.length]; Arrays.fill(dp, 1); for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; if(nums[i] &gt; nums[j]) dp[i] = Math.max(dp[i], dp[j] + 1); &#125; ans = Math.max(ans, dp[i]); &#125; return ans; &#125;&#125; 152. 乘积最大子数组 思路：因为负数的存在，它可能会使前面最大的子数组乘上负数变成最小的，反之亦然，因此在不断获取最大子数组的同时，也要维护当前最小的子数组，如果当前元素是小于0的，就进行交换来获得结果 详细题解： 参考代码： 123456789101112131415161718192021222324252627public int maxProduct(int[] nums) &#123; // 初始化 int maxPre = nums[0]; // 以当前元素结尾的最大乘积 int minPre = nums[0]; // 以当前元素结尾的最小乘积 int result = nums[0]; // 全局最大乘积 // 从第二个元素开始遍历————这点格外注意！！！！！ for (int i = 1; i &lt; nums.length; i++) &#123; // 如果当前元素是负数，交换 maxProd 和 minProd // 因为负数会使最大变最小，最小变最大 if (nums[i] &lt; 0) &#123; int temp = maxPre; maxPre = minPre; minPre = temp; &#125; // 更新 maxProd 和 minProd // maxProd 和 minProd 都需要考虑当前元素单独作为一个子数组的情况 maxPre = Math.max(nums[i], maxPre * nums[i]); minPre = Math.min(nums[i], minPre * nums[i]); // 更新全局最大值 result = Math.max(result, maxPre); &#125; return result;&#125; 416. 分割等和子集 思路：转化为是否存在这样一个子数组：元素之和等于输入数组的元素之和一半。在此之前先做判断：如果输入数组元素之和为奇数，那肯定不存在这样的子数组直接返回。剩下的就是 0-1 背包问题：从数组中选择一些元素（每个元素只能选一次），使得它们的和恰好为 target。 定义dp[i]为：是否存在一个子集，其和为 i。 dp[0] &#x3D; true（表示和为 0 总是可行，不选任何元素即可） 状态转移： 对于数组中的每个元素 nums[i]，我们需要更新 dp 数组。 从后向前遍历 j（从 target 到 nums[i]），更新规则如下： dp[j] = dp[j] || dp[j - nums[i]] 含义：如果不选当前元素，和为 j 的可能性保持不变（dp[j]）；如果选当前元素，则需要看dp[j - nums[i]]是否为 true。 从后向前遍历的目的是避免重复使用同一个元素，确保符合 0-1 背包的规则。 ​ 详细题解： 参考代码： 123456789101112131415161718192021222324252627282930public boolean canPartition(int[] nums) &#123; // 计算数组总和 int sum = 0; for (int num : nums) &#123; sum += num; &#125; // 如果总和是奇数，无法分割成两个和相等的子集 if (sum % 2 != 0) &#123; return false; &#125; // 目标值：总和的一半 int target = sum / 2; // 初始化 dp 数组 boolean[] dp = new boolean[target + 1]; dp[0] = true; // 和为 0 总是可行 // 动态规划过程 for (int num : nums) &#123; // 从后向前更新 dp 数组 for (int j = target; j &gt;= num; j--) &#123; dp[j] = dp[j] || dp[j - num]; &#125; &#125; // 返回结果 return dp[target];&#125; 32. 最长有效括号（难 思路： 详细题解： 参考代码： 1 十六、多维动态规划 62. 不同路径 思路：当前状态仅可由左边或上边这两个来转移 详细题解：62. 不同路径 参考代码： 12345678910111213141516171819class Solution &#123; public int uniquePaths(int m, int n) &#123; int[][] dp = new int[m][n]; for (int i = 0; i &lt; n; i++) &#123; dp[0][i] = 1; &#125; for (int i = 0; i &lt; m; i++) &#123; dp[i][0] = 1; &#125; for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; dp[i][j] = dp[i - 1][j] + dp[i][j - 1]; &#125; &#125; return dp[m - 1][n - 1]; &#125;&#125; 64. 最小路径和 思路：同上题，当前状态仅可由上边和左边转移过来，取二者较小值加上当前元素大小。值得注意的是，本题的初始化 详细题解： 参考代码： 123456789101112131415161718192021222324class Solution &#123; public int minPathSum(int[][] grid) &#123; int m = grid.length; int n = grid[0].length; int[][] dp = new int[m][n]; dp[0][0] = grid[0][0]; for (int i = 1; i &lt; n; i++) &#123; dp[0][i] = dp[0][i - 1] + grid[0][i]; &#125; for (int i = 1; i &lt; m; i++) &#123; dp[i][0] = dp[i - 1][0] + grid[i][0]; &#125; for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; dp[i][j] = Math.min(dp[i - 1][j], dp[i][j - 1]) + grid[i][j]; &#125; &#125; return dp[m - 1][n - 1]; &#125;&#125; 5. 最长回文子串 思路：中心扩展法。本题要记住循环上限2 * n - 1，以及左指针初始值i / 2，右指针l + i % 2 详细题解： 参考代码： 12345678910111213141516171819class Solution &#123; public String longestPalindrome(String s) &#123; int n = s.length(); String ans = &quot;&quot;; for (int i = 0; i &lt; 2 * n - 1; i++) &#123; int l = i / 2; int r = l + i % 2; while (l &gt;= 0 &amp;&amp; r &lt; n &amp;&amp; s.charAt(l) == s.charAt(r))&#123; if(r - l + 1 &gt; ans.length())&#123; ans = s.substring(l, r + 1); &#125; l--; r++; &#125; &#125; return ans; &#125;&#125; 1143. 最长公共子序列 思路：本题主要是状态方程的定义都很新颖。dp[i][j]表示字符串1前i个字符和字符串2的前j个字符的最长公共子序列。然后分当前字符相同和不同两种情况来转移状态。如果相同，dp[i][j] = dp[i - 1][j - 1] + 1 ，否则，Math.max(dp[i - 1][j], dp[i][j - 1]) 。另外需要注意循环上限以及下标问题 详细题解： 参考代码： 1234567891011121314151617class Solution &#123; public int longestCommonSubsequence(String text1, String text2) &#123; int m = text1.length(); int n = text2.length(); int[][] dp = new int[m + 1][n + 1]; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; if(text1.charAt(i- 1) == text2.charAt(j- 1)) dp[i][j] = dp[i - 1][j - 1] + 1; else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); &#125; &#125; return dp[m][n]; &#125;&#125; 72. 编辑距离 思路： 方法思路 状态定义：定义二维数组 dp[i][j]，表示将 word1 的前 i 个字符转换为 word2 的前 j 个字符所需的最少操作次数。 初始状态： dp[i][0] = i：删除所有 i 个字符。 dp[0][j] = j：插入所有 j 个字符。 状态转移： 字符相同：dp[i][j] = dp[i-1][j-1]（无需操作）。 字符不同：取三种操作的最小值加1： 替换：dp[i-1][j-1] + 1。 删除：dp[i-1][j] + 1。 插入：dp[i][j-1] + 1。 详细题解： 参考代码： 12345678910111213141516171819202122232425class Solution &#123; public int minDistance(String word1, String word2) &#123; int m = word1.length(); int n = word2.length(); int[][] dp = new int[m + 1][n + 1]; for (int i = 0; i &lt;= n; i++) &#123; dp[0][i] = i; &#125; for (int i = 0; i &lt;= m; i++) &#123; dp[i][0] = i; &#125; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; if(word1.charAt(i - 1) == word2.charAt(j - 1)) dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = Math.min(dp[i - 1][j - 1], Math.min(dp[i - 1][j], dp[i][j - 1])) + 1; &#125; &#125; return dp[m][n]; &#125;&#125; 十七、技巧136. 只出现一次的数字 思路：数字与， 任何数和 0 做异或运算，结果仍然是原来的数，即 a⊕0=a。 任何数和其自身做异或运算，结果是 0，即 a⊕a=0。 异或运算满足交换律和结合律，即 a⊕b⊕a=b⊕a⊕a=b⊕(a⊕a)=b⊕0=b。 根据以上三条性质，可对数组中所有数字进行与运算，最终得到的结果就是只出现一次的数字 详细题解： 参考代码： 1234567891011class Solution &#123; public int singleNumber(int[] nums) &#123; if(nums.length == 1) return nums[0]; int k = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; k = k ^ nums[i]; &#125; return k; &#125;&#125; 169. 多数元素 思路：摩尔投票，维护一个vote代表当前投票数，先假设众数就是当前遍历的数字，然后继续遍历，如果当前数与众数相同，vote+1，反之则减1，如果vote为0就设置众数为当前数，最终返回众数即是答案 详细题解：169. 多数元素 参考代码： 12345678910111213141516class Solution &#123; public int majorityElement(int[] nums) &#123; int ans = 0; int vote = 0; for (int num : nums) &#123; if(vote == 0)&#123; ans = num; &#125; if(num == ans) vote++; else vote--; &#125; return ans; &#125;&#125; 75. 颜色分类“荷兰国旗”问题，详细题解可参照 思路：三指针，因为要将数据分成三部分，有一个指针c用于遍历数组，a指针分隔0，1；b指针分隔1，2，退出条件为 c &gt; b，然后根据c当前元素做出不同的操作 c当前元素为0，那么就交换a和c所指的元素，同时a，c右移 当前元素为1，那么a，b线都不动，让c右移 当前元素为2，那交换a和b所指的元素，但c不能右移，因为交换过来的可能是0， 如果右移了但a没有同步移动，就会出错，所以c要停留，到下次知道这个c所指的元素是什么再做判断 详细题解：75.颜色分类 参考代码： 123456789101112131415161718class Solution &#123; public void sortColors(int[] nums) &#123; int a = 0, c = 0, b = nums.length - 1; while (c &lt;= b)&#123; if(nums[c] == 0)&#123; int temp = nums[c]; nums[c++] = nums[a]; nums[a++] = temp; &#125; else if (nums[c] == 1) &#123; c++; &#125;else &#123; int temp = nums[b]; nums[b--] = nums[c]; nums[c] = temp; &#125; &#125; &#125;&#125; 31. 下一个排列 （思路 思路：从后往前找到第一个不满足递增的元素a，然后从这个元素后面找到一个比它大一点的元素b，让它俩交换，最后让元素b后面的所有元素用双指针两两交换，成为从前往后是递增的 详细题解：31. 下一个排列 参考代码： 1234567891011121314151617181920212223class Solution &#123; public void nextPermutation(int[] nums) &#123; int i = nums.length - 2; while (i &gt;= 0 &amp;&amp; nums[i] &gt;= nums[i + 1]) i--; if(i &gt;= 0)&#123; int j = nums.length - 1; while (j &gt; i &amp;&amp; nums[j] &lt;= nums[i]) j--; int temp = nums[j]; nums[j] = nums[i]; nums[i] = temp; &#125; int low = i + 1; int high = nums.length - 1; while (low &lt;= high)&#123; int temp = nums[low]; nums[low++] = nums[high]; nums[high--] = temp; &#125; &#125;&#125; 287. 寻找重复数 思路：龟兔赛跑算法，类似链表环问题，让元素映射到链表节点上，通过快慢指针，第一步先找到环，当两个指针相遇后，将其中一个指针移回起点，并以相同速度前进，直到两个指针再次相遇。再次相遇的点即为环的起点，也就是重复的数字。 详细题解：使用 Floyd 的循环检测算法 将数组映射为链表： 由于 nums 中的值范围是 [1, n]，我们可以将每个数字视为链表的下标。 例如，nums[i] 指向下标 nums[nums[i]]。 重复的数字会导致形成环。 检测环的起点： 使用两个指针：一个慢指针（slow）和一个快指针（fast）。 slow 每次移动一步，fast 每次移动两步。 如果存在环，slow 和 fast 最终会相遇。 找到环的起点（重复数字）： 当两个指针相遇后，将其中一个指针移回起点，并以相同速度前进，直到两个指针再次相遇。 再次相遇的点即为环的起点，也就是重复的数字。 参考代码： 123456789101112131415class Solution &#123; public int findDuplicate(int[] nums) &#123; int slow = nums[0], fast = nums[0]; do &#123; slow = nums[slow]; fast = nums[nums[fast]]; &#125; while (slow != fast); slow = nums[0]; while (slow != fast) &#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;","categories":[{"name":"学习","slug":"学习","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"刷题","slug":"刷题","permalink":"http://example.com/tags/%E5%88%B7%E9%A2%98/"}]},{"title":"其它","slug":"八股/其它","date":"2024-11-28T12:57:13.000Z","updated":"2025-05-29T15:35:43.556Z","comments":true,"path":"2024/11/28/八股/其它/","permalink":"http://example.com/2024/11/28/%E5%85%AB%E8%82%A1/%E5%85%B6%E5%AE%83/","excerpt":"这里是有关设计模式，Linux，Git的一些八股，后续会补充场景题","text":"这里是有关设计模式，Linux，Git的一些八股，后续会补充场景题 1.设计模式1.概述 创建型模式：创建型模式关注对象的创建过程，让对象的创建更灵活、更可控。 这类模式的特点是，不让用户依赖于对象的创建或排列方式，避免用户直接使用new运算符创建对象。 结构型模式：结构型模式关注类和对象的组合，形成更大的结构，提升系统的灵活性。 和类有关的结构型模式设计如何合理地使用继承机制；和对象有关的结构型模式涉及如何合理地使用对象组合机制。 行为型模式：行为型模式关注对象之间的通信和职责分配，让协作更清晰。 创建型模式 创建型模式关注对象的创建过程，让对象的创建更灵活、更可控。 这类模式的特点是，不让用户依赖于对象的创建或排列方式，避免用户直接使用new运算符创建对象。 单例模式：确保一个类只有一个实例，并提供一个全局访问点。 核心：保证整个程序里只有一个对象实例。 抽象工厂模式：提供一个创建一系列相关或依赖对象的接口，而无需指定它们具体的类。 核心：一次性创建一组相关的对象。 解释：像订购一个套餐，里面包含多个搭配好的东西。 工厂方法模式：定义一个创建对象的接口，但让子类决定实例化哪个类。 核心：让子类来决定创建哪种对象。 解释：就像工厂流水线，具体生产什么产品由“分厂”自己定。 建造者模式：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 核心：分步骤把复杂对象拼装起来。 解释：就像搭积木，一步步把房子建好。 原型模式：通过复制现有对象来创建新对象。 结构型模式 结构型模式关注类和对象的组合，形成更大的结构，提升系统的灵活性。 和类有关的结构型模式设计如何合理地使用继承机制；和对象有关的结构型模式涉及如何合理地使用对象组合机制。 适配器模式：将一个类的接口转换成客户端期望的另一个接口。 核心：让不兼容的东西能一起用。 解释：就像电源转换器，把插头改成能用的形状。 桥接模式：将抽象部分与它的实现部分分离，使它们可以独立地变化。 核心：把抽象和实现分开，让它们独立变化。 解释：像手机和充电器，分开设计但能搭配使用。 组合模式：将对象组合成树形结构以表示“部分-整体”的层次结构。 解释：像文件夹和文件，层层嵌套但统一管理。 装饰者模式：动态地给一个对象添加一些额外的职责。 核心：动态给对象加点新功能。 解释：就像给蛋糕加奶油，随时装饰一下。 外观模式：为子系统中的一组接口提供一个统一的接口。 核心：给复杂系统提供一个简单入口。 解释：像遥控器，一个按钮控制一堆功能。 享元模式：运用共享技术有效地支持大量细粒度的对象。 核心：共享对象来省内存。 解释：就像公共自行车，大家轮着用同一辆。 代理模式：为其他对象提供一种代理以控制对这个对象的访问。 核心：通过中间人控制对对象的访问。 解释：像中介，帮你跟房东谈租房。 行为型模式 行为型模式关注对象之间的通信和职责分配，让协作更清晰。 责任链模式：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。 核心：把请求扔给一串处理者，谁能搞定谁上。 解释：像客服转接，问题层层传递。 命令模式： 将请求封装成一个对象，从而使你可用不同的请求对客户进行参数化。 核心：把请求打包成对象来处理。 解释：像点外卖，把订单写好再交给厨师。 解释器模式： 给定一个语言，定义它的文法的一种表示，并定义一个解释器。 核心：为特定语言定义解释规则。 解释：像翻译官，解读外语的意思。 迭代器模式： 提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露该对象的内部表示。 核心：挨个访问集合里的东西，不用管里面怎么存。 解释：像翻书，一页页看过去。 中介者模式： 用一个中介对象来封装一系列的对象交互。 核心：用一个中间人协调多个对象的关系。 解释：像群聊管理员，帮大家沟通。 备忘录模式： 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 核心：保存对象的状态，随时可以恢复。 解释：像游戏存档，随时读档重来。 观察者模式： 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 核心：一个对象变了，其他跟着知道。 解释：像订阅公众号，有更新就通知你。 状态模式：允许一个对象在其内部状态改变时改变它的行为。 核心：状态变了，行为也跟着变。 解释：像红绿灯，颜色不同规则就不同。 策略模式： 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。 核心：封装一堆方案，随时换着用。 解释：像导航选路线，走快路还是省钱路随便挑。 模板方法模式： 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。 核心：定个大框架，细节留给别人填。 解释：像做菜的食谱，大步骤固定，调料你自己加。 访问者模式： 在不改变数据结构的前提下，定义作用于这些元素的新操作。 核心：不改结构也能加新功能。 解释：像请专家来检查设备，不用自己动手改。 2.单例模式单例模式是一种创建型设计模式， 让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。 单例模式通常用于管理全局共享资源，例如数据库连接池、日志对象等。 所有单例的实现都包含以下两个相同的步骤： 将默认构造函数设为私有， 防止其他对象使用单例类的 new运算符。 新建一个静态构建方法作为构造函数。 该函数会 “偷偷” 调用私有构造函数来创建对象， 并将其保存在一个静态成员变量中。 此后所有对于该函数的调用都将返回这一缓存对象。 如果你的代码能够访问单例类， 那它就能调用单例类的静态方法。 无论何时调用该方法， 它总是会返回相同的对象。 实现单例模式的关键点 私有构造方法：确保外部代码不能通过构造器创建类的实例。 私有静态实例变量：持有类的唯一实例。 公有静态方法：提供全局访问点以获取实例，如果实例不存在，则在内部创建。 常见写法如下（重点掌握懒汉，饿汉，双重锁检查）： 1、 饿汉式（线程安全） 饿汉式在类加载时就创建实例，因此线程安全，不会出现多次创建实例的问题。缺点是即使不需要该实例，类也会被加载。 123456789101112public class Singleton &#123; // 类加载时就创建实例 private static final Singleton INSTANCE = new Singleton(); // 私有构造方法，防止外部实例化 private Singleton() &#123;&#125; // 提供全局访问点 public static Singleton getInstance() &#123; return INSTANCE; &#125;&#125; 2、 懒汉式（线程不安全） 在这种方式中，单例对象是在首次使用时被创建的。但由于没有同步处理，多个线程同时访问时可能会创建多个实例。 1234567891011121314public class Singleton &#123; // 声明静态实例，但不立即初始化 private static Singleton instance; private Singleton() &#123;&#125; // 在第一次调用时创建实例 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 3、 懒汉式（线程安全） 通过 synchronized 关键字来保证多线程下的安全性，但性能较差，因为每次调用 getInstance() 时都会进行同步。 12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; // 使用 synchronized 保证线程安全 public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 4、双重锁检查（DCL） 双重检查锁定是一种优化的懒汉式实现，它结合了懒加载和线程安全的优点，只有在实例为空时才会进入同步块，从而减少了锁的竞争。 懒加载 （lazy loading）：使⽤的时候再创建对象 1234567891011121314151617public class Singleton &#123; // 使用 volatile 防止指令重排 private static volatile Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; // 第一次检查 synchronized (Singleton.class) &#123; if (instance == null) &#123; // 第二次检查 instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 1. 为什么要双重检查？ 检查次数 目的 性能影响 第一次检查 避免不必要的同步（实例已存在时） 减少锁竞争 第二次检查 防止重复创建实例（当多个线程通过第一次检查时） 保证单例 场景：多线程并发调用getInstance() 线程A首次调用getInstance() 第一次检查instance == null：true（实例尚未创建） 进入同步块（获取类锁） 第二次检查instance == null：true 执行new DoubleCheckedSingleton() 释放锁 返回新创建的实例 线程B在A创建实例期间调用getInstance() 第一次检查instance == null： 可能看到null（未完全构造的对象） 也可能看到非null（已构造完成） 如果看到null： 尝试获取锁（此时线程A持有锁，线程B阻塞） 当线程A释放锁后： 线程B获得锁 第二次检查instance == null：false（已被线程A创建） 直接返回已存在的实例 线程C在实例创建完成后调用getInstance() 第一次检查instance == null：false 直接返回已存在的实例（不进入同步块） 5、枚举单例 枚举单例是实现单例模式的最佳方式之一。它由 JVM 保证线程安全和单例，并且防止反序列化创建新的对象。 1234567public enum Singleton &#123; INSTANCE; public void someMethod() &#123; // 实现方法 &#125;&#125; 6、静态内部类 利用 JVM 的类加载机制，通过静态内部类实现延迟加载。内部类只有在 getInstance() 被调用时才会加载。 123456789101112public class Singleton &#123; private Singleton() &#123;&#125; // 静态内部类，只有在调用时才加载 private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 总结 懒汉式（线程不安全）：适用于多线程环境下，但不安全。 懒汉式（线程安全）：通过 synchronized 确保线程安全，但性能较差。 饿汉式：类加载时即创建实例，线程安全，但缺乏灵活性。 双重锁检查：性能较好，推荐使用。 枚举单例：推荐使用，简洁且线程安全。 3.工厂模式Java 中的 工厂模式（Factory Pattern）是一种创建型设计模式，旨在通过定义一个接口来创建对象，但让子类决定实例化哪个类。工厂模式可以帮助减少客户端与具体产品类之间的耦合，提高代码的灵活性和扩展性。 1、简单工厂模式 简单工厂模式通过一个工厂类来根据提供的信息生成不同类型的对象。它不需要暴露创建对象的具体逻辑，只暴露一个工厂方法供客户端调用。 结构： 工厂类：负责创建实例。 产品接口：定义产品的公共接口。 具体产品：实现产品接口的具体类。 12345678910111213141516171819202122232425262728293031323334353637383940414243// 产品接口public interface Product &#123; void use();&#125;// 具体产品Apublic class ConcreteProductA implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品A&quot;); &#125;&#125;// 具体产品Bpublic class ConcreteProductB implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品B&quot;); &#125;&#125;// 简单工厂类public class SimpleFactory &#123; public static Product createProduct(String type) &#123; if (&quot;A&quot;.equals(type)) &#123; return new ConcreteProductA(); &#125; else if (&quot;B&quot;.equals(type)) &#123; return new ConcreteProductB(); &#125; throw new IllegalArgumentException(&quot;未知产品类型&quot;); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Product productA = SimpleFactory.createProduct(&quot;A&quot;); productA.use(); // 输出: 使用产品A Product productB = SimpleFactory.createProduct(&quot;B&quot;); productB.use(); // 输出: 使用产品B &#125;&#125; 优缺点： 优点：客户端只需要知道工厂类和产品接口，无需关心具体实现。 缺点：工厂类一旦增加新的产品，需修改工厂类代码，违反开闭原则。 2、工厂方法模式 工厂方法模式通过在抽象类中定义一个工厂方法，让子类去实现这个方法，从而决定创建哪种产品。这种模式通过继承和多态来让子类决定创建的产品类型，避免了修改工厂类。 结构： 抽象工厂：声明工厂方法。 具体工厂：实现工厂方法，负责创建具体产品。 产品接口：定义产品的公共接口。 具体产品：实现产品接口的具体类. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 产品接口public interface Product &#123; void use();&#125;// 具体产品Apublic class ConcreteProductA implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品A&quot;); &#125;&#125;// 具体产品Bpublic class ConcreteProductB implements Product &#123; @Override public void use() &#123; System.out.println(&quot;使用产品B&quot;); &#125;&#125;// 抽象工厂public abstract class Creator &#123; public abstract Product factoryMethod();&#125;// 具体工厂Apublic class ConcreteCreatorA extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductA(); &#125;&#125;// 具体工厂Bpublic class ConcreteCreatorB extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductB(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Creator creatorA = new ConcreteCreatorA(); Product productA = creatorA.factoryMethod(); productA.use(); // 输出: 使用产品A Creator creatorB = new ConcreteCreatorB(); Product productB = creatorB.factoryMethod(); productB.use(); // 输出: 使用产品B &#125;&#125; 优缺点： 优点：遵循了开闭原则，可以通过扩展子类来增加新产品，不需要修改原有代码。 缺点：需要创建大量的具体工厂类，如果产品种类过多，工厂类会急剧增加。 3、抽象工厂模式 3.Spring 框架中都用到了哪些设计模式？ 【单例模式】 Spring 中的 Bean 默认都是单例的 【简单工厂】 由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。 Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。 【工厂方法】 实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean.getOjbect()方法的返回值。 【模板方法模式】 Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现。 最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。 【包装器设计模式 】 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 【观察者模式】 Spring 事件驱动模型就是观察者模式很经典的一个应用。 spring的事件驱动模型使用的是 观察者模式 ，Spring中Observer模式常用的地方是listener的实现 【适配器模式】 Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 Spring定义了一个适配接口，使得每一种Controller有一种对应的适配器实现类，让适配器代替controller执行相应的方法。这样在扩展Controller时，只需要增加一个适配器类就完成了SpringMVC的扩展了 【装饰器模式】 动态地给一个对象添加一些额外的职责。就增加功能来说，Decorator模式相比生成子类更为灵活。 Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。 【动态代理】 切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。 织入：把切面应用到目标对象并创建新的代理对象的过程。 【策略模式】 Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了Resource 接口来访问底层资源。 2.Linux1.Linux文件系统在Linux中，“一切都是文件 ” 1.1.inode硬盘以扇区为最小存储单位，操作系统以块为单位进行读写，块由多个扇区组成，inode存储了文件元信息（例如权限、大小、修改时间以及数据块位置） ，inode 的访问速度非常快 inode：记录文件的属性信息，可以使用 stat 命令查看 inode 信息。 block：实际文件的内容，如果一个文件大于一个块时候，那么将占用多个 block，但是一个块只能存放一个文件。（因为数据是由 inode 指向的，如果有两个文件的数据存放在同一个块中，就会乱套了） 1.2.硬链接和软链接在 Linux&#x2F;类 Unix 系统上，文件链接（File Link）是一种特殊的文件类型，可以在文件系统中指向另一个文件。常见的文件链接类型有两种： 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表， 所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode， 那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接相当于重新创建一个文件，这个文件有独立的 inode， 但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候， 实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的， 甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。 2.Linux常用命令2.1.文件相关 ls：列出目录内容。 cd：更改当前目录。cd ..回到上级目录，cd ~回到用户的主目录。 rm：删除文件或目录。rm -r递归删除目录及其内容。 mkdir：创建新目录。 cat：查看文件内容。 pwd：显示当前工作目录的完整路径。 cp：复制文件或目录。 mv：移动或重命名文件或目录。 文件权限详解 Linux 中的权限可以应用于三种类别的用户： 文件所有者（u） 与文件所有者同组的用户（g） 其他用户（o） ①、符号模式 符号模式使用字母来表示权限，如下： 读（r） 写（w） 执行（x） 所有（a） 例如： chmod u+w file：给文件所有者添加写权限。 chmod g-r file：移除组用户的读权限。 chmod o+x file：给其他用户添加执行权限。 chmod u=rwx,g=rx,o=r file：设置文件所有者具有读写执行权限，组用户具有读执行权限，其他用户具有读权限。 ②、数字模式 数字模式使用三位八进制数来表示权限，数字是其各自权限值的总和： 读（r）&#x3D; 4 写（w）&#x3D; 2 执行（x）&#x3D; 1 因此，权限模式可以是从 0（无权限）到 7（读写执行权限）的任何值。 chmod 755 file：使得文件所有者有读写执行（7）权限，组用户和其他用户有读和执行（5）权限。 chmod 644 file：使得文件所有者有读写（6）权限，而组用户和其他用户只有读（4）权限。 2.2.系统管理相关 ps：显示当前运行的进程。 top：实时显示进程动态。 kill：终止进程。kill -9 PID强制终止。 慎用 kill -9：可能导致数据不一致，优先用 kill -15 正常终止。 chmod：更改文件或目录的权限。 df：显示磁盘空间使用情况。df -h以易读格式显示。 du：显示目录或文件的磁盘使用情况。 3.高频问题 如何查看 Java 进程？ ps -ef | grep java 如何实时查看日志文件？ tail -f filename.log ，-f表示循环读取，常用于查看递增的日志文件 如何查看端口占用情况？ netstat -tunlp | grep 8080 ，起码记住netstat和grep 如何杀死一个进程？ kill，-9是强制杀死，-15是正常终止 如何查看服务器内存&#x2F;CPU使用情况？ top 如何查找文件？ find 高级题目 CPU飙升或100%问题怎么排查？ 找到占用 CPU 最高的 Java 进程：top 找到占用 CPU 最高的线程：top Hp 进程id，H参数表示要显示线程级别的信息，p则表示指定的pid，也就是进程id。 保存线程堆栈信息：jstack 用于生成 Java 进程的线程快照（thread dump）。线程快照是一个关于 Java 进程中所有线程当前状态的快照，包括每个线程的堆栈信息。 将罪魁祸首的线程id转为16进制，然后在jstack输出的日志中查找该线程的信息 导致CPU飙到100的情况可能有哪些？ 无限循环 内存不足 高流量 循环等待 3.Git git clone &lt;repository-url&gt;：克隆远程仓库。 git status：查看工作区和暂存区的状态。 git add &lt;file&gt;：将文件添加到暂存区。 git commit -m &quot;message&quot;：提交暂存区的文件到本地仓库。 git log：查看提交历史。 git merge &lt;branch-name&gt;：合并指定分支到当前分支。 git checkout &lt;branch-name&gt;：切换分支。 git pull：拉取远程仓库的更新。 1.git merge和 git rebase的区别 Rebase（变基）是将一个分支上的提交逐个地应用到另一个分支上，使得提交历史变得更加线性。 简而言之，rebase可以将提交按照时间顺序线性排列。 Merge（合并）是将两个分支上的代码提交历史合并为一个新的提交。 在执行merge时，Git会创建一个新的合并提交，将两个分支的提交历史连接在一起。 3.场景1.秒杀系统设计什么是秒杀 通俗一点讲就是网络商家为促销等目的组织的网上限时抢购活动 业务特点 高并发：秒杀的特点就是这样时间极短、 瞬间用户量大。 库存量少：一般秒杀活动商品量很少，这就导致了只有极少量用户能成功购买到。 业务简单：流程比较简单，一般都是下订单、扣库存、支付订单 恶意请求，数据库压力大 解决方案 前端：页面资源静态化，按钮控制，使用答题校验码可以防止秒杀器的干扰，让更多用户有机会抢到 nginx：校验恶意请求，转发请求，负载均衡；动静分离，不走tomcat获取静态资源；gzip压缩，减少静态文件传输的体积，节省带宽，提高渲染速度 业务层：集群，多台机器处理，提高并发能力 redis：集群保证高可用，持久化数据；分布式锁（悲观锁）；缓存热点数据（库存） mq：削峰限流，MQ堆积订单，保护订单处理层的负载，Consumer根据自己的消费能力来取Task，实际上下游的压力就可控了。重点做好路由层和MQ的安全 数据库：读写分离，拆分事务提高并发度 秒杀系统设计小结 秒杀系统就是一个“三高”系统，即高并发、高性能和高可用的分布式系统 秒杀设计原则：前台请求尽量少，后台数据尽量少，调用链路尽量短，尽量不要有单点 秒杀高并发方法：访问拦截、分流、动静分离 秒杀数据方法：减库存策略、热点、异步、限流降级 访问拦截主要思路：通过CDN和缓存技术，尽量把访问拦截在离用户更近的层，尽可能地过滤掉无效请求。 分流主要思路：通过分布式集群技术，多台机器处理，提高并发能力。 2.分布式ID一个分布式ID需要满足 全局唯一：ID 的全局唯一性肯定是首先要满足的！ 高性能：分布式 ID 的生成速度要快，对本地资源消耗要小。 高可用：生成分布式 ID 的服务要保证可用性无限接近于 100%。 实现方案1——UUID","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"集合","slug":"八股/集合","date":"2024-11-24T09:11:53.000Z","updated":"2025-06-13T07:50:15.468Z","comments":true,"path":"2024/11/24/八股/集合/","permalink":"http://example.com/2024/11/24/%E5%85%AB%E8%82%A1/%E9%9B%86%E5%90%88/","excerpt":"主要是Java常用集合介绍","text":"主要是Java常用集合介绍 0. 概述 Java 集合，也叫作容器，主要是由两大接口派生而来：一个是 Collection接口，主要用于存放单一元素；另一个是 Map 接口，主要用于存放键值对。 对于Collection 接口，下面又有三个主要的子接口：List、Set 、 Queue。 在 java.util 包中的线程安全的类主要 2 个，其他都是非线程安全的。 Vector Hashtable 此外，java.util.concurrent 包提供的都是线程安全的集合： 1.List1.ArrayList和LinkedList的区别 底层数据结构：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 操作效率不同：多数情况下，ArrayList更利于查找，LinkedList更利于增删，LinkedList只有在首尾的增删效率是O(1)，如果是中间的元素也是O(n) 占用空间：ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间， 而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 是否支持随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList（实现了 RandomAccess 接口） 支持。 2.ArrayList的扩容机制ArrayList底层采用的是Object[] 动态数组实现，当我们向ArrayList中添加元素时，它会自动调整数组的大小以适应新的元素。当数组的容量不足以容纳新元素时，ArrayList会创建一个更大的数组，并将原数组中的元素复制到新数组中。 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。 插入时候，会先检查是否需要扩容，如果当前容量+1超过数组长度，就会进行扩容。 ArrayList的扩容是创建一个1.5倍的新数组，然后把原数组的值拷贝过去。 扩容完成后更新引用到新的数组上 之所以扩容是 1.5 倍，是因为 1.5 可以充分利用移位操作，减少浮点数或者运算时间和运算次数。 核心源码： 123transient Object[] elementData; // 实际存储元素的数组private int size; // 当前元素数量（非数组长度）private static final int DEFAULT_CAPACITY = 10; // 默认初始容量 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // 关键扩容检查 elementData[size++] = e; return true;&#125; 12345678910111213141516171819202122private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 并发修改标记 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); // 真正扩容&#125;private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 1.5倍扩容 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); // 数据拷贝&#125; 3. 为什么ArrayList不是线程安全的在高并发添加数据下，ArrayList会暴露三个问题; （主要理解前两个即可） 部分值为null（我们并没有add null进去） 索引越界异常 size与我们add的数量不符 如何产生的： 部分值为null：当线程1走到了扩容那里发现当前size是9，而数组容量是10，所以不用扩容，这时候cpu让出执行权，线程2也进来了，发现size是9，而数组容量是10，所以不用扩容，这时候线程1继续执行，将数组下标索引为9的位置set值了，还没有来得及执行size++，这时候线程2也来执行了，又把数组下标索引为9的位置set了一遍，这时候两个先后进行size++，导致下标索引10的地方就为null了。 索引越界异常：线程1走到扩容那里发现当前size是9，数组容量是10不用扩容，cpu让出执行权，线程2也发现不用扩容，这时候数组的容量就是10，而线程1set完之后size++，这时候线程2再进来size就是10，数组的大小只有10，而你要设置下标索引为10的就会越界(数组的下标索引从0开始); size与我们add的数量不符：这个基本上每次都会发生，这个理解起来也很简单，因为size++本身就不是原子操作，可以分为三步:获取size的值，将size的值加1，将新的size值覆盖掉原来的，线程1和线程2拿到一样的size值加完了同时覆盖，就会导致一次没有加上，所以肯定不会与我们add的数量保持一致的; 4.CopyOnWriteArrayList为什么线程安全CopyOnWriteArrayList就是线程安全版本的ArrayList。它可以保证读读不互斥、读写不互斥、只有写写互斥 CopyOnWriteArrayList底层也是通过一个数组保存数据， 使用volatile关键字修饰数组，保证当前线程对数组对象重新赋值后， 其他线程可以及时感知到。 add方法内部用到了 ReentrantLock 加锁，保证了同步，避免了多线程写的时候会复制出多个副本出来。 CopyOnWriteArrayList采用了一种读写分离的并发策略。CopyOnWriteArrayList容器允许并发读，读操作是无锁的，性能较高。至于写操作，比如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。 5.Copy-On-Write思想这个是一种思想，在Redis的RDB持久化那里也用到了这种技术——来应对在持久化的过程中数据发生了改变。 维基百科对 Copy-On-Write 的介绍，介绍的挺不错： 写入时复制（英语：Copy-on-write，简称 COW）是一种计算机程序设计领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源 这里再以 CopyOnWriteArrayList为例介绍：当需要修改（ add，set、remove 等操作） CopyOnWriteArrayList 的内容时，不会直接修改原数组，而是会先创建底层数组的副本，对副本数组进行 修改，修改完之后再将修改后的数组赋值回去，这样就可以保证写操作不会影响读操作了。 可以看出，写时复制机制非常适合读多写少的并发场景，能够极大地提高系统的并发性能。 不过，写时复制机制并不是银弹，其依然存在一些缺点，下面列举几点： 内存占用：每次写操作都需要复制一份原始数据，会占用额外的内存空间，在数据量比较大的情况下，可能会导致内存资源不足。 写操作开销：每一次写操作都需要复制一份原始数据，然后再进行修改和替换，所以写操作的开销相对较大，在写入比较频繁的场景下，性能可能会受到影响。 数据一致性问题：修改操作不会立即反映到最终结果中，还需要等待复制完成，这可能会导致一定的数据一致性问题。 2.Set1.List和Set的区别？ List：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。 List 支持for循环，也就是通过下标来遍历，也可以用迭代器 Set：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性 。set只能用迭代器，因为他无序，无法用下标来取得想要的值。 2.HashSet怎么判断有没有重复的值的HashSet 是由 HashMap 实现的，只不过值由一个固定的 Object 对象填充，而键用于操作。 HashSet：无序，底层基于哈希表 TreeSet：有序，底层基于红黑树 LinkedHashSet：有序，底层基于链表（双向）和哈希表 3.MapHashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个 1.HashMap怎么处理Hash冲突 链接法：使用链表或其他数据结构来存储冲突的键值对，将它们链接在同一个哈希桶中。 开放寻址法：在哈希表中找到另一个可用的位置来存储冲突的键值对，而不是存储在链表中。常见的开放寻址方法包括线性探测、二次探测和双重散列。 再哈希法(Rehashing)：当发生冲突时，使用另一个哈希函数再次计算键的哈希值，直到找到一个空位来存储键值对。 2.HasMap的底层数据结构及实现原理 数组（Node[] table）用来存储键值对。数组中的每个元素被称为“桶”（Bucket） 计算每个桶的索引流程：通过 key 的 hashcode() 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash得到实际索引。详见5.hashmap的寻址算法 扰动函数hash() 的目标是尽量减少哈希冲突，保证元素能够均匀地分布在数组的每个位置上。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 存储时，如果出现hash值相同的key，此时有两种情况。(1)如果key相同，则覆盖原始值；(2)如果key不同（出现冲突），则将当前的放入链表或红黑树中 不过，链表过长时，查询效率会比较低，于是当链表的长度超过 8 时（且数组的长度大于 64），链表就会转换为红黑树。红黑树的查询效率是 **O(logn)**，比链表的 O(n) 要快。 如果仅仅只是链表长度超过8，但数组长度并没有&gt;&#x3D;64，那么仅仅对数组进行扩容。 当从 HashMap 中读取元素时，也会使用 hash() 计算键的位置【HashMap 通过 key 的 hashcode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度）】，然后根据位置在数组查找元素。 HashMap 的初始容量是 16，随着元素的不断添加，HashMap 的容量可能不足，于是就需要进行扩容，阈值是capacity * loadFactor，capacity 为容量，loadFactor 为负载因子，默认为 0.75。 3.HashMap的put流程 根据key的哈希码计算它要插入的索引 判断数组是否为空或者长度为0，如果是则进行扩容操作。 否则就判断该索引处是否为空，如果为空就直接插入 如果不为空，判断key是否相同，如果相同直接覆盖value 否则，判断是否为树节点，如果是树节点就直接插入红黑树 否则，说明就是链表，遍历链表是否存在key，如果存在就覆盖，否则就插入链表，同时还要注意链表长度，超过8且数组长度超过64就将链表转为红黑树 插入成功后，判断此时数组键值对数量是否超过了阈值threshold(数组长度*0.75【负载因子】)，如果超过，进行扩容 4.HashMap的扩容机制 第1步是对哈希表长度的扩展（2倍） 第2步是将旧哈希表中的数据放到新的哈希表中。 因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置 ，要么是在原位置再移动2次幂的位置。 我们在扩充HashMap的时候，不需要重新计算hash， 只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变， 是1的话索引变成 “原索引+旧容量（oldCapacity）” 。既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，可以均匀的把之前的冲突的节点分散到新的bucket了 为什么负载因子设为0.75？ 答：这是从时间成本和空间成本综合考虑的结果 负载因子决定元素个数达到多少时候扩容 如果设的太大，等要扩容的时候基本没多少空位了，发生哈希冲突的概率非常大，会增加我们查找的时间成本 如果设的太小，有点浪费，我们就需要更多的空间去存储元素，增加了空间成本 5.HashMap的寻址算法1.获取键的哈希码 当你向HashMap中插入一个键值对时，首先会计算键（key）的哈希值。哈希值是通过键的hashCode()方法得到的。hashCode()是Java中Object类提供的一个方法，返回一个32位的整数，表示对象的哈希码。如果键是null，则哈希值直接返回0。 2.扰动处理 单纯使用hashCode()得到的哈希值可能会导致分布不均匀，尤其当HashMap的容量较小时。 为了解决这个问题，HashMap会对原始的hashCode()进行一次扰动处理。 具体实现是在hash()方法中完成的，代码如下： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这里，h是键的hashCode()。 h &gt;&gt;&gt; 16表示将h无符号右移16位，提取高16位。 然后通过h ^ (h &gt;&gt;&gt; 16)进行异或操作，将高16位和低16位混合。 这样做的目的是让哈希值分布更均匀，避免冲突。 简单说，为啥需要扰动处理呢？因为索引的计算公式是（n - 1）&amp; hash，如果hash仅在低位有变化，容易产生哈希冲突 3.计算索引 在扰动处理后，得到的哈希值需要映射到HashMap的数组索引上。 index = (n - 1) &amp; hash 6.HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标 哈希值与数组大小范围不匹配；hashCode()方法返回的是int整数类型，int 的范围是 -2147483648~2147483647，加起来大概 40 亿上下的浮动。 范围远超HashMap的容量范围 解决方法： HashMap 的长度（容量capacity）为什么是2的幂次方？（TODO 了解） 不用重新计算hash，元素的位置要么是在原位置 ，要么是在原位置再移动2次幂的位置。 只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变， 是1的话索引变成“原索引+旧容量（oldCapacity）”，省去了重新计算hash值的时间 由于新增的1bit是0还是1可以认为是随机的，可以均匀的把之前的冲突的节点分散到新的bucket了 7.HashMap在多线程下可能会出现的问题 问题：在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。 解决：为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 HashMap，因为多线程下使用 HashMap 还是会存在数据覆盖的问题，多线程同时执行 put 操作，如果计算出来的索引位置是相同的， 那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。并发环境下，推荐使用concurrentHashMap 8.ConcurrentHashMap的底层原理 jdk1.7 底层数据结构：数组＋链表。一个ConcurrentHashMap有一个Segment的数组，每个Segment又有一个HashEntry数组，然后每个HashEntry又是一个链表结构的，HashEntry 则用于存储键值对数据。Segment（分段锁） 是一种可重入的锁 ReentrantLock 将数据分段，对每个Segment分配一把锁。当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 同一Segment可以并发读，不能并发写，可以有一个写其它的读；不同Segment可以并发读写，前提是获得锁 get： 通过 hash(key) 定位到 segment 再遍历链表定位到具体的元素上。 需要注意的是 value 是 volatile 的，所以 get 是不需要加锁的。 put： 计算 hash，定位到 segment，segment 如果是空就先初始化； 使用 ReentrantLock 加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定能获取到锁； 遍历 HashEntry，key 相同就直接替换，不存在就插入。 释放锁。 jdk1.8 和1.7的变化： 数据结构改为Node节点数组+链表+红黑树，Node存储键值对 和Hash Map一样，链表长度达到8的时候会转化成红黑树 放弃了Segment分段锁来保证安全，改为使用volatile + CAS 或者 synchronized 只对（链表或红黑树的）头节点来加锁，从而实现的线程安全的。 get： 通过计算哈希值快速定位桶，在桶中查找目标节点，多个 key 值时链表遍历和红黑树查找。读操作是无锁的，依赖 volatile 保证线程可见性。 put流程： 根据存储的元素计算该位置是否为空。 如果根据存储的元素计算结果为空，则利用 CAS 设置该节点，写入数据； 如果根据存储的元素计算结果不为空，则使用 synchronized ，然后，遍历桶中的数据，并替换或新增节点到桶中， 最后再判断是否需要转为红黑树 总的来说，相比前代，舍弃了Segment分段锁臃肿的设计，改为只用锁头节点的方式，锁粒度更细，发生冲突和加锁的频率降低，提高并发性能。 另一方面，链表转为红黑树的操作也会使增加查找效率 9.HashTable的底层原理Hashtable的底层数据结构是数组+链表 HashTable是线程安全的，它采用的是全表锁。它使用 synchronized 来保证线程安全，效率非常低下。 10.ConcurrentHashMap 和 Hashtable 的区别 底层数据结构 jdk7之前的ConcurrentHashMap底层采用的是分段的数组+链表实现，jdk8之后采用的是数组+链表&#x2F;红黑树; HashTable采用的是数组+链表，数组是主体，链表是解决hash冲突存在的。 实现线程安全的方式 idk8以前，ConcurrentHashMap采用分段锁，对整个数组进行了分段分割，每一把锁只锁容器里的一部分数据，多线程访问不同数据段里的数据，就不会存在锁竞争，提高了并发访问;idk8以后，直接采用数组+链表&#x2F;红黑树，并发控制使用CAS和synchronized操作，更加提高了速度。 HashTable:使用 synchronized 来保证线程安全，效率非常低下 ，当一个线程访问同步方法另一个线程也访问的时候，就会陷入阻塞或者轮询的状态。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JavaSE","slug":"JavaSE","permalink":"http://example.com/tags/JavaSE/"}]},{"title":"中间件","slug":"八股/中间件","date":"2024-11-24T05:10:08.000Z","updated":"2025-03-13T04:58:25.170Z","comments":true,"path":"2024/11/24/八股/中间件/","permalink":"http://example.com/2024/11/24/%E5%85%AB%E8%82%A1/%E4%B8%AD%E9%97%B4%E4%BB%B6/","excerpt":"这里是有关消息队列的一些八股","text":"这里是有关消息队列的一些八股 1.MQ的作用 异步处理：系统可以将那些耗时的任务放在消息队列中异步处理，从而快速响应用户的请求。比如说，用户下单后，系统可以先返回一个下单成功的消息，然后将订单信息放入消息队列中，后台系统再去处理订单信息。 削峰&#x2F;限流：用于应对系统高并发请求的瞬时流量高峰，通过消息队列，可以将瞬时的高峰流量转化为持续的低流量，从而保护系统不会因为瞬时的高流量而崩溃。先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 降低耦合：生产者将消息放入队列，消费者从队列中取出消息，这样一来，生产者和消费者之间就不需要直接通信，生产者只管生产消息，消费者只管消费消息，这样就实现了解耦。 2.几种MQ的对比(技术选型) RabbitMQ Kafka RocketMQ 公司 Rabbit Apache 阿里 架构 传统的消息队列架构 基于主题（Topic）的发布-订阅模型 采用分布式架构 消息可靠性 高 高 一般 吞吐量 高 超高 超高 RabbitMQ：强调消息的可靠传递和灵活路由，适合中小规模的企业应用和微服务架构。 RocketMQ：专注于高性能、高可靠性和大规模分布式系统支持，适合复杂业务场景。 Kafka：专为高吞吐量的流数据处理设计，适合实时数据管道和大数据分析。 3.RabbitMQ的工作模式 简单模式：一对一模式，一个生产者、一个消费者，一个队列，生产者发送消息，消费者消费消息 工作队列模式：一对多模式，一个生产者，多个消费者，一个队列，每个消费者从队列中获取唯一的消息。适用于资源密集型任务， 单个消费者处理不过来，需要多个消费者进行处理的场景。 发布订阅模式： 多了一个 Exchange 角色，而且过程略有变化： 生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） 消费者，消息的接收者，会一直等待消息到来 消息队列，接收消息、缓存消息 交换机一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange与消息队列的绑定模式： Fanout（广播模式）：将消息交给所有绑定到交换机的队列，当发送一条消息到fanout交换器上时，它会把消息投放到所有附加在此交换器上的队列 Direct（路由模式）：消息发送者通过指定不同的路由键将消息发送到交换机，交换机根据路由键将消息发送到对应的队列。 Topic（主题模式）：消息发送者通过指定主题(可以使用通配符)将消息发送到交换机，交换机根据主题将消息发送到对应的队列。 4.AMQP协议模型 Broker：代表着一个中间件应用，负责接收消息生产者的消息，然后将消息发送至消息接受者或者其他的broker。一个 RabbitMQ Broker 可以简单地看作一个 RabbitMQ 服务节点，或者 RabbitMQ 服务实例。 Channel：代表着producer、consumer和broker之间的逻辑连接，一个Connection可以包含多个Channel。Channel使得基于同一连接的不同进程之间与broker之间的交互相互隔离，不干扰。而不需要重新建立连接，channel在发生协议错误的时候会被关闭。 Exchange：这是所有被发送的消息首先到达的目的地，Exchange负责根据路由规则将消息路由到不同的目的地。路由规则包括下面几种：direct（point-to-point）、topic（publish-subscribe）和fanout（multicast）。 Queue：这是消息到达的最终目的地，到达queue的消息是已经准备好被消费的消息，一个消息可以被exchange copy发送至多个queue。 Binding：这是queue和exchange之间的虚拟连接，使得消息从哪个exchange路由到Queue。routing key可以通过binding和exchange routing规则关联。 5.延迟队列？rabbitmq怎么实现延迟队列？延迟队列指的是存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。 RabbitMQ 本身是没有延迟队列的，要实现延迟消息，一般有两种方式： 通过 RabbitMQ 本身队列的特性来实现，需要使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。生产者发送带TTL的消息到一个队列，消息过期后路由到死信队列。然后消费者订阅死信队列 在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang&#x2F;OPT 18.0 及以上。 也就是说，AMQP 协议以及 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过 TTL 和 DLX 模拟出延迟队列的功能。 6.死信队列消息在一个队列中变成死信 (dead message) 之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX（Dead-Letter-Exchange），绑定 DLX 的队列就称之为死信队列。死信队列是用来处理无法被正常消费或处理的消息的特殊队列。 导致的死信的几种原因： 1.消息被拒绝(Rejected):当消费者拒绝消费消息或者消息超过消费者的最大重试次数时，消息会被发送到死信队列。2.消息过期(Expired):如果消息在一定时间内没有被消费者处理，即超过了消息的过期时间，该消息也会被发送到死信队列。3.队列达到最大长度(Queue Length Limit):当队列达到了定义的最大长度限制，新的消息无法进入队列，会将旧的消息发送到死信队列。 7.如何保证消息的可靠性（防止数据丢失）？丢失的情况：消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。 生产者到 RabbitMQ：事务机制和 Confirm 机制，推荐：可以通过生产者启用Confirm 机制，在消息成功发送给RabbitMQ后接收确认回执，确保消息已被正确接收。 注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。 RabbitMQ 自身：持久化、集群、普通模式、镜像模式。 持久化： Exchange 设置为持久化 。 Queue 设置为持久化 。 消息在发送时设置为持久化模式，即 deliveryMode=2 RabbitMQ 到消费者：手动消息确认：消费者在处理完消息后，需要显式地发送一个 ACK 确认信号给 RabbitMQ，RabbitMQ 才会从内存（和磁盘，如果是持久化消息的话）中移除消息。这样可以确保消息在处理过程中不会因为消费者进程挂掉而丢失 8.如何避免消息堆积？ 优化消费者代码，提高消费能力。减少消费时间 消息TTL：可以为消息设置生存时间（TTL），即消息在队列中停留的最大时间。超过TTL的消息将被自动丢弃或死信 队列长度限制：可以通过策略或队列参数设置队列的最大长度。当队列达到最大长度时，RabbitMQ会根据策略丢弃或死信队列的前端消息 增加消费者数量（Horizontal Scaling）：当消费者处理速度跟不上生产者发送消息的速度时，可以通过增加更多的消费者实例来并行处理消息，从而提升总体处理能力 使用死信队列（Dead Letter Queue, DLQ）：对于无法立即处理或处理失败的消息，可以配置死信交换器和队列，当消息达到一定重试次数或者超过一定期限未被成功ACK时，消息将被转发到死信队列中，后续可以单独处理这部分消息，避免阻塞正常的消息流 9.如何防止消息重复消费（保证消费幂等性）?RabbitMQ消息重复消费问题通常是由以下原因导致的:1.生产者用于发送消息失败后的重试，导致又发送了一次重复的消息2.消费者应用程序在处理消息时发生了错误，导致消息确认(ack)没有发送给RabbitMQ，从而导致RabbitMQ将消息重新分发给其他消费者进行消费。3.网络问题或消费者应用程序重启时，RabbitMQ无法收到消息确认，也会导致消息重新分发。 为了解决消息重复消费问题(保证消费幂等性)，可以采取以下措施: 使用消息唯一ID（幂等性）：确保消息的处理是幂等的，即无论同一条消息被消费多少次，结果都是相同的。每个消息用一个唯一标识来区分，消费前先判断标识有没有被消费过，若已消费过，则直接ACK 消息确认:消费者应及时地发送消息确认(ack)给RabbitMQ，表示已经成功处理了消息。这样RabbitMQ就不会将消息重新分发给其他消费者。 加锁：消费者在处理消息之前，用Redis对当前消息设置分布式锁，key为消息id，如果设置失败，就拒绝处理 10.如何保证消息的顺序性？RabbitMQ的queue本身就是队列，是可以保证消息的顺序投递的。 但是消息的顺序消费则是另一回事了，所谓的“顺序消费”意味着是否顺序达到目的地，比如：数据库。 看看以下场景： 一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1&#x2F;data2&#x2F;data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1&#x2F;data3。这不明显乱了。 产生多个consumer去消费一个queue，极有可能是因为：消息消费太慢，所以盲目让多个consumer同时来消费，而忽略了消息消费顺序性。 在某些情况下，消息是需要保证顺序性的，如果上图中的data1, data2, data3 分别意味着对某条数据的增改删，但是如果乱序以后就变成了：删改增。 将原来的一个queue拆分成多个queue，每个queue都有一个自己的consumer。这种方案的核心是生产者在投递消息的时候根据业务数据关键值将需要保证顺序的同一类数据发送到一个queue中。 多个queue保证了消息消费的效率，每个queue对应单个消费者保证了消息消费的有序性。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}]},{"title":"实习日记","slug":"实习日记","date":"2024-11-06T12:32:56.000Z","updated":"2024-11-06T12:38:46.389Z","comments":true,"path":"2024/11/06/实习日记/","permalink":"http://example.com/2024/11/06/%E5%AE%9E%E4%B9%A0%E6%97%A5%E8%AE%B0/","excerpt":"","text":"今天2024-11-06是我实习的第四个星期，终于算是有点产出了😭😭😭😭激动的心，颤抖的手，吭吭哧哧终于给做出来了，虽然只是很简单的一个页面和查询接口，我记得研发云好像是10.29才登上去的，哎，之前连前端三件套都没系统学过的我，更别提vue了，现在快速用vue做出来界面，也慢慢熟悉了中间是怎么交互的，最难的环节感觉就是前后端联调了，主要还是前端vue不太熟悉 11.4：完成前端页面的修改美化，基本符合设计原型 11.5：想着怎么测试接口的，上午一直在搞swagger，发现直接前后端联调即可，下午就一直在搞，也没搞好 11.6：前后端联调失败，有很多小错误，比如自动装配的注解忘了加，下午联通了但查询不到数据，跟state这个字段有关好像，涉及到字符串查询的时候用单引号，总之感觉莫名其妙的错误但又莫名其妙的好了；然后又是时间的问题，Cause: java.lang.IllegalArgumentException: invalid comparison: java.util.Date and java.lang.String。发现mybatis的if对时间判断时只要判断null就行了，不用判断空。然后又发现后端查到的数据不能显示在前端的表格上，发现是表格的列名要和返回的数据VO字段对应。。","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"实习","slug":"实习","permalink":"http://example.com/tags/%E5%AE%9E%E4%B9%A0/"}]},{"title":"wireshark抓包学习","slug":"技术类/wireshark抓包学习","date":"2024-10-30T12:40:35.000Z","updated":"2024-10-30T13:13:26.804Z","comments":true,"path":"2024/10/30/技术类/wireshark抓包学习/","permalink":"http://example.com/2024/10/30/%E6%8A%80%E6%9C%AF%E7%B1%BB/wireshark%E6%8A%93%E5%8C%85%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"过滤规则按IP过滤 想看源ip为xx的包：ip.src == xx 想看目标ip为xx的包：ip.dst == xx 想看源或者目标ip为xx的包：ip.addr == xx 按MAC地址过滤 想看源mac为xx的包：eth.src == xx 想看目标mac为xx的包：eth.dst == xx 想看源或者目标mac为xx的包：eth.addr == xx 按端口过滤 想看源端口为4694的包：tcp.srcport == 4694 想看目标端口为4694的包：eth.dstport == 4694 过滤tcp端口为4694的包：tcp.port == 4694 按协议类型过滤 arp dhcp https 规则组会 and 想看dhcp包且只想看某台电脑的dhcp包 or ！非","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"OS","slug":"八股/OS","date":"2024-10-28T12:30:49.000Z","updated":"2025-04-07T06:52:04.332Z","comments":true,"path":"2024/10/28/八股/OS/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/OS/","excerpt":"本文主要是找工作时针对操作系统可能会碰到的一些问题","text":"本文主要是找工作时针对操作系统可能会碰到的一些问题 0.操作系统基础1.什么是操作系统？操作系统（Operating System, OS）是计算机系统中管理硬件和软件资源的中间层系统，屏蔽了硬件的复杂性，并且为用户提供了便捷的交互方式，比如说 Windows、Linux、MacOS 等。 2.操作系统有哪些功能？ 进程和线程的管理：进程的创建、撤销、阻塞、唤醒，进程间的通信等。 存储管理：内存的分配和管理、外存（磁盘等）的分配和管理等。 文件管理：文件的读、写、创建及删除等。 设备管理：完成设备（输入输出设备和外部存储设备等）的请求或释放，以及设备启动等功能。 网络管理：操作系统负责管理计算机网络的使用。网络是计算机系统中连接不同计算机的方式，操作系统需要管理计算机网络的配置、连接、通信和安全等，以提供高效可靠的网络服务。 3.用户态和内核态 什么是用户态和内核态？ 用户态(User Mode) : 用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。 **内核态(Kernel Mode)**：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。 简单说：二者的权限级别不同，这样做是为了安全性、稳定性、性能考虑。 用户态和内核态是如何切换的？ 系统调用（Trap）：用户态进程 主动 要求切换到内核态的一种方式。主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。 中断（Interrupt）：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 异常（Exception）：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 在系统的处理上，中断和异常类似，都是通过中断向量表来找到相应的处理程序进行处理。区别在于，中断来自处理器外部，不是由任何一条专门的指令造成，而异常是执行当前指令的结果。 4.系统调用系统调用是应用程序与操作系统之间进行交互的一种方式，通过系统调用，应用程序可以访问操作系统底层资源例如文件、设备、网络等。 系统调用的过程 用户态的程序发起系统调用，因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。 发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。 内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。 1.进程管理这里附一个小插曲： 竞态条件：是指当多个线程同时访问和操作同一块数据时，最终结果依赖于线程的执行顺序， 这可能导致数据的不一致性。 1.并发和并行 并发（Concurrency） 并发就是在一段时间内，多个任务都会被处理；但在某一时刻，只有一个任务在执行。单核处理器做到的并发，其实是利用时间片的轮转 并行（Parallelism） 并行就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成 ，因为每个任务在不同的核心或处理器上独立执行。 并发更多的是处理“任务管理”，比如多任务的切换与调度。并行更多的是需要硬件的支持 2.进程上下文切换上下文切换是操作系统在多任务处理环境中，将 CPU 从一个进程切换到另一个进程的过程。通过让多个进程共享 CPU 资源，使系统能够并发执行多个任务。 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源， 还包括了内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候， 我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中 3.进程的状态 **创建状态(new)**：进程正在被创建，尚未到就绪状态。 **就绪状态(ready)**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 **运行状态(running)**：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 **阻塞状态(waiting)**：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 **结束状态(terminated)**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行 4.什么是PCB？PCB（Process Control Block） 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB。 PCB 是进程存在的唯一标识 ，包含以下信息： 进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中， 以便进程重新执行时，能从断点处继续执行。 5.僵尸进程&#x2F;孤儿进程 僵尸进程 子进程已经终止，但是其父进程仍在运行，且父进程没有调用 wait()或 waitpid()等系统调用来获取子进程的状态信息，释放子进程占用的资源，导致子进程的 PCB 依然存在于系统中， 但无法被进一步使用。 这种情况下，子进程被称为“僵尸进程”。避免僵尸进程的产生，父进程需要及时调用 wait()或 waitpid()系统调用来回收子进程。 孤儿进程 一个进程的父进程已经终止或者不存在，但是该进程仍在运行。这种情况下，该进程就是孤儿进程。 孤儿进程通常是由于父进程意外终止或未及时调用 wait()或 waitpid()等系统调用来回收子进程导致的。 为了避免孤儿进程占用系统资源，操作系统会将孤儿进程的父进程设置为 init 进程（进程号为 1），由 init 进程来回收孤儿进程的资源。 6.进程调度算法 1.先来先服务 从就绪队列中选择一个最先进入该队列的进程为之分配资源 然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。 当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 可能会导致较短的进程等待较长进程执行完成，从而产生“饥饿”现象 2.短作业优先 优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。 对长作业不利，很容易造成一种极端现象。 3.时间片轮转 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。 如果进程在时间片结束时还没有完成，它将被放回队列的末尾。 公平的 4.优先级调度 这种调度方式中，每个进程都被分配一个优先级。CPU 首先分配给优先级最高的进程。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 可能会导致低优先级的进程永远不会运行。 5.多级反馈队列 既能使高优先级的作业得到响应又能使短作业（进程）迅速完成 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程， 转而去运行优先级高的队列； 工作流程： 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短（意思是允许它执行的时间越短）； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完， 可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了， 所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 7.进程间的通信方式 管道（匿名管道）：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 命名管道：允许无亲缘关系的进程通信，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。 缺点：管道的效率低，而且只能单向通信，不适合进程间频繁地交换数据。 信号：用于通知接收进程某个事件已经发生； 消息队列：消息队列是保存在内核中的消息链表，按照消息的类型进行消息传递，具有较高的可靠性和稳定性。 缺点：消息体有一个最大长度的限制，不适合比较大的数据传输；存在用户态与内核态之间的数据拷贝开销。 共享内存：允许两个或多个进程共享一个给定的内存区，一个进程写⼊的东西，其他进程⻢上就能看到。 共享内存是最快的进程间通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。缺点：当多进程竞争同一个共享资源时，会造成数据错乱的问题。 信号量：它本质上是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。 用来控制对共享资源的访问数量。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 套接字socket：不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信， 可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式， 一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。 8.进程和线程的区别 进程：进程是程序在操作系统中的执行实例，是系统资源分配的基本单位。每个进程拥有自己的地址空间、数据段、堆栈、程序计数器等，进程间相互独立，通常不能直接共享内存。 特点： 进程之间相互独立，有各自的资源和内存空间。 进程创建、销毁的开销比较大。 进程切换时，操作系统需要保存和恢复上下文，因此开销较大。 线程：线程是进程中的一个执行单元，它是比进程更小的执行单位。一个进程可以包含多个线程， 它们共享进程的内存空间和资源(如堆，全局变量，静态变量，文件等公共资源)，但拥有独立的栈和程序计数器。 特点： 线程之间共享进程的内存空间和资源，因此创建和销毁的开销较小。 线程切换的开销比进程小 由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。 协程：协程是一种用户态的轻量级线程，由程序员在代码中显式控制调度，而非操作系统。 特点： 协程切换的开销极小，比线程更轻量，因为不需要操作系统的干预。 协程通常在同一个线程中执行，因此它们共享线程的所有资源。 协程是非抢占式的调度（即协程必须显式让出控制权），避免了线程的切换和同步的复杂性。 适用场景 高隔离性任务——进程 高并发共享数据任务——线程 高并发 I&#x2F;O 密集型任务——协程 9.线程间的通信方式(TODO)也即线程间的同步方式，因为线程共享同一进程的内存空间，通信相对容易，但也需要同步机制来避免竞争条件。 互斥锁：只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 读写锁：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。 读写锁的工作原理是：当「写锁」没有被线程持有时，多个线程 能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景， 所以多个线程同时持有读锁也不会破坏共享资源的数据。但是，一旦「写锁」被线程持有后，读线程的 获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。所以说，写锁是独占锁，因 为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线 程同时持有。知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 通常信号量表示资源的数量 对应的变量是一个整型（sem）变量。 还有两个原子操作的系统调用函数来控制信号量的。分别是：P 操作：将 sem 减 1，相减 后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem &lt;&#x3D; 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞； 10.线程上下文切换得看线程是不是属于同⼀个进程： 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样； 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 所以，线程的上下⽂切换相⽐进程，开销要⼩很多。 11.死锁 什么是死锁？ 死锁（Deadlock） 是指两个或多个线程在执行过程中，由于竞争资源而导致的相互等待的状态，最终使得它们都无法继续执行，造成系统无法恢复的情况。简单来说，死锁发生时，线程永远处于等待状态，不会释放它们持有的资源，因此其他线程也无法继续执行 死锁产生有哪些条件？ 产生死锁需要同时满足四个必要条件： 互斥：资源不能被多个进程共享，即资源一次只能被一个进程使用。如果一个资源已经被分配给了一个进程，其他进程必须等待，直到该资源被释放。 持有并等待：一个进程已经持有了至少一个资源，同时还在等待获取其他被占用的资源。在此期间，该进程不会释放已经持有的资源。 不可剥夺：已分配给进程的资源不能被强制剥夺，只有持有该资源的进程可以主动释放资源。 循环等待：有两个及以上的进程获取资源的顺序形成了环 如何避免死锁？ 破坏产生死锁的条件之一就可以了 消除持有并等待：在线程开始时，确保它一次性请求并持有所有资源。如果不能一次性获取所有资源，线程就不会获得任何资源，而是等待其他线程释放资源。 消除不可剥夺：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源 消除循环等待：在系统中对所有的资源进行排序，线程在获取资源时，必须按顺序请求资源。这样即使多个线程竞争资源，也不会形成循环等待。 活锁&#x2F;饥饿锁 饥饿锁，这个饥饿指的是资源饥饿，某个线程一直等不到它所需要的资源，从而无法向前推进，就像一个人因为饥饿无法成长。 活锁：是指线程或进程虽然处于“活动”状态，但它们在不断地互相干扰，导致无法有效完成任务，系统始终处于忙碌状态，但没有任何实质性的进展。活锁通常是因为线程在执行过程中不停地尝试重新进入某个操作，但由于不断调整或重试，导致无法有效执行工作。 2.内存管理操作系统的内存管理非常重要，主要负责下面这些事情： 内存的分配与回收：对进程所需的内存进行分配和释放，malloc 函数：申请内存，free 函数：释放内存。 地址转换：将程序中的虚拟地址转换成内存中的物理地址。 内存扩充：当系统没有足够的内存时，利用虚拟内存技术或自动覆盖技术，从逻辑上扩充内存。 内存映射：将一个文件直接映射到进程的进程空间中，这样可以通过内存指针用读写内存的办法直接存取文件内容，速度更快。 内存优化：通过调整内存分配策略和回收算法来优化内存使用效率。 内存安全：保证进程之间使用内存互不干扰，避免一些恶意程序通过修改内存来破坏系统的安全性。 1.什么是内存碎片?通常分为两种 内部内存碎片：简单说就是已经分配的内存但没有用完，未用完的部分就是内存碎片 外部内存碎片： 简单说就是未分配的连续内存太小了，不能再用了，所以就是外部内存碎片 2.局部性原理程序在执行时，倾向于频繁访问特定的数据和指令。局部性原理的核心思想是，程序通常不会随机地访问内存中的任何位置，而是有规律地集中访问某些区域。 时间局部性：如果程序访问了某个内存位置，那么它在不久的将来可能会再次访问该位置。换句话说，程序倾向于重复访问最近使用过的数据或指令。 优化方法：为了利用时间局部性，缓存系统会将最近使用的数据存储在高速缓存（如CPU缓存）中，这样当数据再次需要时，可以快速从缓存中获取，而不需要从较慢的内存或磁盘中读取。 空间局部性：如果程序访问了内存中的某个位置，它很可能会在不久的将来访问该位置附近的内存地址。即，程序倾向于集中访问内存中的相邻位置。 优化方法：为了利用空间局部性，操作系统和硬件会尽量将数据按照地址的顺序加载到缓存中，或者将连续的内存块存储在一起。 3.虚拟内存操作系统设计了虚拟内存，每个进程都有自己的独立的虚拟内存，我们所写的程序不会直接与物理内打交道。 本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。 虚拟地址和物理地址 虚拟地址：是由程序使用的地址，程序通过虚拟地址访问内存。 物理地址：是计算机硬件（如RAM）中的实际内存地址。 优点： 扩展内存容量：虚拟内存允许程序使用的内存空间超过物理内存的大小。操作系统通过将不常用的页面存储到硬盘中，使得程序可以“认为”它有更大的内存。 内存隔离和保护：每个进程都有独立的虚拟地址空间，进程间的内存是隔离的，这提供了更好的内存保护和安全性。进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 【补充】：还可以避免用户可以直接访问到物理地址 简化程序设计：程序员不需要关心物理内存的具体分配，虚拟内存使得每个程序可以拥有独立的内存空间，极大地简化了内存管理。 虚拟地址和物理地址的映射方式主要有 分页，分段，段页 4.分页机制分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。 虚拟地址与物理地址之间通过页表来映射，如下图： 在分页机制下，每个进程都会有一个对应的页表。 分页机制下的虚拟地址由两部分组成： 页号：通过虚拟页号可以从页表中取出对应的物理页号； 页内偏移量：物理页起始地址+页内偏移量&#x3D;物理内存地址。 因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。 为了减少页表的开销，操作系统引入了 多级页表 ，多级页表对应多个页表，每个页表与前一个页表相关联。 为了能够快速得到经常访问的数据，又引入了快表（TLB），利用了局部性原理。这样就是先访问快表，再访问页表了。 5.分段机制程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。 分段机制下的虚拟地址由两部分组成，段号和段内偏移量。 虚拟地址和物理地址通过段表映射，段表主要包括段号、段的界限。 6.分页和分段的区别 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 段的大小不固定，有它所完成的功能决定；页的大小固定，由系统决定 7.页面置换算法当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断， 请求操作系统将所缺页从磁盘调入到物理内存。 如果物理内存中没有空闲的物理页面可用的话。操作系统就必须将物理内存中的一个物理页淘汰出去，这样就可以腾出空间来加载新的页面了。 用来选择淘汰哪一个物理页的规则叫做 页面置换算法 ，我们可以把页面置换算法看成是淘汰物物理页的规则。 当物理内存不足时，操作系统会将一部分不常用的页面从内存中换出（换出），并将需要的页面加载到内存中（换入）。这一过程称为页面置换。 页面置换算法的任务就是选择合适的页面进行置换，避免频繁的页面交换（也称为“页面抖动”），从而提高系统的效率。 最佳页面置换算法：选择在未来最长时间内不会被访问的页面进行置换 缺点：需要提前知道未来的页面访问模式，这在实际应用中是不可能实现的，因此它通常作为性能对比的基准，或者用来评估其他算法的效果。 先进先出算法：选择内存中最早进入的页面进行置换 缺点：FIFO并不考虑页面的实际使用频率和最近使用情况，因此可能会导致一些“反直觉”的效果（即置换掉一些未来会频繁使用的页面）。这也就是所谓的Belady异常（即增加物理内存时，页面错误反而增多）。 最近最久未使用的置换算法(LRU)：选择最久未使用的页面进行置换。 该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。 最不常用算法（LFU）：选择使用频率最少的页面进行置换。 LFU需要维护每个页面的访问计数。当一个页面被访问时，它的计数器会增加；当内存需要置换时，选择访问次数最少的页面进行换出。 时钟页面置换算法：通过使用一个圆形链表和一个指针来模拟时钟的走动，决定哪个页面应当被置换。 实现：每个页面都有一个引用位（reference bit），在每次访问页面时，引用位被设置为1。当发生页面置换时，算法从指针指向的页面开始，如果该页面的引用位为0，则置换该页面；如果引用位为1，则将引用位清零，并将指针移向下一个页面。这样，Clock算法可以在近似LRU的同时减少开销。 3.文件系统文件系统主要负责管理和组织计算机存储设备上的文件和目录，其功能包括以下几个方面： 存储管理：将文件数据存储到物理存储介质中，并且管理空间分配，以确保每个文件都有足够的空间存储，并避免文件之间发生冲突。 文件管理：文件的创建、删除、移动、重命名、压缩、加密、共享等等。 目录管理：目录的创建、删除、移动、重命名等等。 文件访问控制：管理不同用户或进程对文件的访问权限，以确保用户只能访问其被授权访问的文件，以保证文件的安全性和保密性。 1.硬链接和软链接的区别在 Linux&#x2F;类 Unix 系统上，文件链接（File Link）是一种特殊的文件类型，可以在文件系统中指向另一个文件。常见的文件链接类型有两种： 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表， 所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode， 那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接相当于重新创建一个文件，这个文件有独立的 inode， 但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候， 实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的， 甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。 2.常见的磁盘调度算法磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能， 一般是通过优化磁盘的访问请求顺序来做到的。 先来先服务：按照请求到达磁盘调度器的顺序进行处理，先到达的请求的先被服务。 4.I&#x2F;O1.I&#x2F;O模型五种I&#x2F;O模式 Java的IO模型是一个综合性的概念，既包括本地数据IO（文件读写等），也涵盖网络IO（Socket通信等）。它们的核心区别在于数据来源和底层实现，但共享相同的设计思想。 阻塞I&#x2F;O——BIO 应用程序发出一个 read 调用，内核空间需要经历准备数据的几个阶段，准备好之后返回数据给应用程序。期间如果另一个应用程序也需要 read 调用，那么它必须等待；这就是阻塞。 非阻塞I&#x2F;O——NIO 应用程序发起I&#x2F;O操作后立即返回，不会被阻塞，但需要不断轮询或者使用。 特点：用户进程需要不断的主动询问kernel数据好了没有 第一个阶段：等待数据的时候是非阻塞的，第二个阶段：从内核拷贝数据到用户空间仍然是阻塞的 当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error 。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call ，那么它马上就将数据拷贝到了用户内存，然后返回。 I&#x2F;O多路复用 特点：一个线程能同时等待多个文件描述符，而这些文件描述符（套接字）其中的任意一个进入读就绪状态，select()函数就可以返回。 它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 信号驱动I&#x2F;O 信号驱动I0是与内核建立SIGI0的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，而无需等待 缺点： 当有大量I0操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出 而且内核空间与用户空间的频繁信号交互性能也较低。 异步I&#x2F;O——AIO 异步I0的整个过程都是非阻塞的，用户进程调用完异步API后就可以去做其它事情，内核等待数据就绪并拷贝到用户空间后才会递交信号，通知用户进程。 缺点：忙的忙死，闲的闲死。用户进程由于可以一直做其它业务，然而内核却要一直准备数据，可能导致内核承受不住。所以要想使用这种方式，一个是增加用户进程处理数据的复杂度，让用户进程没那么“闲”，另一个是对用户进程限流。 最后，再举几个不是很恰当的例子来说明这四个IO Model:有A，B，C，D四个人在钓鱼：A用的是最老式的鱼竿，所以呢，得一直守着，等到鱼上钩了再拉杆；B的鱼竿有个功能，能够显示是否有鱼上钩，所以呢，B就和旁边的MM聊天，隔会再看看有没有鱼上钩，有的话就迅速拉杆；C用的鱼竿和B差不多，但他想了一个好办法，就是同时放好几根鱼竿，然后守在旁边，一旦有显示说鱼上钩了，它就将对应的鱼竿拉起来；D是个有钱人，干脆雇了一个人帮他钓鱼，一旦那个人把鱼钓上来了，就给D发个短信。 2.I&#x2F;O多路复用传统的 I&#x2F;O 模型中，如果服务端需要支持多个客户端，我们可能要为每个客户端分配一个进程&#x2F;线程。 引入多路复用之后，一个进程&#x2F;线程维护多个 Socket，这个多路复用就是多个连接复用一个进程&#x2F;线程。 它们允许单个线程同时监控多个 I&#x2F;O 操作，是高并发服务器（如 Nginx、Redis）的核心技术。 1.select select 实现多路复用的方式是，将已连接的 Socket（一个Socket连接对应一个文件描述符fd） 都放到一个文件描述符集合（fd_set），然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写，返回给用户空间的是就绪的事件个数，接着再把整个文件描述符集合拷贝回用户态里（实际上是覆盖原来的fd_set），然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里， 一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合， 所支持的文件描述符的个数是有限制的，默认最大值为 1024 缺点： 两次拷贝：先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 需要遍历才能得知就绪的fd 可传入的fd数量有限制 2.poll 流程基本和select类似 唯一不同的是，在传入fd的数量上有了突破，用户空间传入的是可自定义大小的pollfd数组，然后传入内核空间后，用链表形式组织。所以说fd的数量理论上是没有限制的（但实际受限于查询效率的问题，不可能没有限制的）。但仍然没有解决select的问题，拷贝，遍历。 3.epoll 执行流程 epoll_create()创建epoll实例，返回对应的句柄epfd。具体而言，这个实例包括一个红黑树和一个链表。红黑树用于记录要监听的fd，每个节点就是一个fd。而链表用于记录就绪的fd epoll_ctl()将要监听的fd添加到红黑树中，当这个fd就绪的时候，内核通过回调函数将该fd添加到链表中 epoll_wait()等待fd就绪，调用该方法会在用户空间创建一个数组，用于接受就绪的fd 改进点 红黑树结构增加效率：基于红黑树保存要监听的fd，增删改查效率高 减少重复拷贝：每个fd只需要一次epoll_ctl()添加到红黑树，无需重复拷贝fd到内核空间（相对于select和poll） 无需遍历就能得到就绪fd：内核将就绪的fd拷贝到用户空间的数组中，用户空间无需再次遍历，可以直接得到就绪的fd 3.epoll的边缘触发和水平触发epoll事件的通知机制有两种模式，分别是： 水平触发（levelTrrigered， LT）：当有fd就绪时，会重复通知多次，直至数据被处理完。是epoll的默认模式 边缘触发（edgeTrrigered， ET）：当有fd就绪时，仅通知一次，如果数据没有被处理完就会丢失 LT模式的缺点： 频繁调用epoll_wait()会产生很多开销 可能会产生“惊群”现象，比如当前剩余没有被处理的数据仅仅一两个线程就能解决，但在这种模式下会唤醒所有线程处理数据，也就是会产生不必要的唤醒 ET模式如何保证数据可以被处理完毕？ 采用非阻塞IO一次性把就绪fd处理完。不能采用阻塞IO，如果采用阻塞IO在处理完就绪的fd后会阻塞等待未就绪的fd到就绪的状态，而非阻塞IO在处理完就绪的fd后就会返回错误，代表就绪的fd已经处理完了，剩下的都是未就绪的fd了。 手动把未处理完的fd添加到epoll实例中。（类似手动挡的LT） 前置了解：在拷贝就绪fd到用户空间时，会在就绪链表中移除拷贝的fd，同时会检查当前通知模式时ET还是LT，如果是ET，会永久的移除拷贝的fd，如果是LT，则会检查就绪fd数据有没有被处理完毕，如果没有，会重新把移除的fd添加到链表中。 我们可以调用epoll_ctl()手动将未处理完的fd添加到epoll实例上，完了之后红黑树检测到fd就绪，就会重新给这些就绪的fd添加到链表上。 4.零拷贝零拷贝（Zero-copy）是一种优化数据传输的技术，旨在减少或消除数据在用户态和内核态之间的拷贝操作，从而提高I&#x2F;O性能。在传统的I&#x2F;O操作中，数据通常需要从内核缓冲区拷贝到用户缓冲区，或者从用户缓冲区拷贝回内核缓冲区，这会带来额外的CPU和内存开销。零拷贝技术通过避免这些不必要的拷贝，显著提升数据传输的效率，尤其在高并发、大数据量的场景下效果尤为明显。 1.DMA技术 在DMA技术出现之前，IO过程如下： 可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。 简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU来搬运的话，肯定忙不过来。 所以引出了DMA技术 什么是 DMA 技术？简单理解就是，在进行 I&#x2F;O 设备和内存的数据传输的时候， 数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情， 这样 CPU 就可以去处理别的事务。 使用DMA技术的IO流程如下： 2.传统的文件传输 123456781. 应用程序调用read()，触发DMA将磁盘数据拷贝到内核缓冲区 （用户态→内核态切换）2. 内核将数据从内核缓冲区拷贝到用户缓冲区 （内核态→用户态切换）3. 应用程序调用write()，将数据从用户缓冲区拷贝到Socket缓冲区 （用户态→内核态切换）4. DMA将Socket缓冲区数据拷贝到网卡进行传输 （内核态→用户态切换） 期间共发生了 4 次用户态与内核态的上下文切换， 因为发生了两次系统调用，一次是 read() ，一次是 write() ，每次系统调用都得先从用户态切换到内核态，等内核完成任务后， 每次系统调用都得先从用户态切换到内核态，等内核完成任务后， 再从内核态切换回用户态。 4次数据拷贝：2次CPU拷贝 + 2次DMA拷贝 所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。 在前面我们知道了，传统的文件传输方式会历经4次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。 因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的， 3.零拷贝的实现 1.mmap + write（内存映射） mmap替换read系统调用函数 12341. DMA拷贝到内核缓冲区2. 共享缓冲区（用户空间直接访问内核缓冲区）3. CPU拷贝到Socket缓冲区4. DMA拷贝到网卡 特点： 减少1次CPU拷贝 仍然需要4次上下文切换 2.sendfile 在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，可以替代前面的 read() 和 write() 这两个系统调用 ，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态， 这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图： DMA拷贝到内核缓冲区 CPU拷贝到Socket缓冲区 DMA拷贝到网卡 如果网卡支持 SG-DMA 技术（和普通的 DMA 有所不同），可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。 DMA拷贝到内核缓冲区 SG-DMA直接从内核缓冲区到网卡 这个零拷贝技术可以实现只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输 ，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。 相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[]},{"title":"计算机网络","slug":"八股/计算机网络","date":"2024-10-28T12:30:41.000Z","updated":"2025-03-30T03:11:53.871Z","comments":true,"path":"2024/10/28/八股/计算机网络/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"这里是计算机网络的一些八股","text":"这里是计算机网络的一些八股 计算机网路层次结构 OSI参考模型 应用层，负责给应用程序提供统一的接口; 表示层，负责把数据转换成兼容另一个系统能识别的格式 会话层，负责建立、管理和终止表示层实体之间的通信会话， 传输层，负责端到端的数据传输 网络层，负责数据的路由、转发、分片; 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址; 物理层，负责在物理网络中传输数据帧; TCP&#x2F;IP模型 应用层 主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输 协议：HTTP 、DNS 、SMTP 、FTP 传输层 处理主机到主机的通信 协议：TCP、UDP 网络层 寻址和路由数据包(IP 协议)——（转发与路由 ） 协议：IP、ARP、ICMP 、NAT、OSPF、RIP、BGP 链路层 通过网络的物理电线、电缆或无线信道移动比特 一、HTTPHTTP、HTTPS、DNS、FTP(文件传输协议 ) 都是应用层协议 http 是 80，https 默认是 443。 DNS默认端口号：53 1.HTTP常用的状态码 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 400 Bad Request：发送的 HTTP 请求存在问题。比如请求参数不合法、请求方法错误。 404 Not Found：你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 500（Internal Server Error）表示服务器内部错误，通常由服务器端代码问题引起。 [502 Bad Gateway」表示网关或代理服务器从上游服务器(服务端)收到了无效响应，通常与服务器之间的通信问题有关。 504 Gateway Time-out:表示网关或代理服务器在等待上游服务器的响应时超时，通常是由于上游服务器处理时间过长或无法访问。 举一个例子，假设 nginx 是代理服务器，收到客户端的请求后，将请求转发到后端服务器(tomcat 等)。 当nginx收到了无效的响应时，就返回502。 当nginx超过自己配置的超时时间，还没有收到请求时，就返回504错误。 2.HTTP头部常见字段HTTP报文组成如下： 请求报文 响应报文 请求行 状态行 请求头部 响应头部 空行 空行 请求体 响应体 其中头部字段主要有； Host 字段 ：客户端发送请求时，用来指定服务器的域名。 Host: www.A.com。有了 Host 字段，就可以将请求发往「同一台」服务器上的不同网站。 Content-Length 字段 ：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。 HTTP 是基于 TCP 传输协议进行通信的，而使用了 TCP 传输协议， 就会存在一个“粘包”的问题，HTTP 协议通过设置回车符、 换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题。 Connection 字段 ：Connection 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用，Connection: Keep-Alive。 HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 Content-Type 字段 ：Content-Type 字段用于服务器回应时，告诉客户端，本次数据是什么格式。 客户端请求的时候，可以使用 Accept 字段声明自己可以接受哪些数据格式。 Content-Encoding 字段 ：Content-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。 3.HTTP和HTTPS的区别⭐区别主要有以下五点: 安全性和资源消耗： HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 是运行在 SSL&#x2F;TLS 之上的 HTTP 协议，SSL&#x2F;TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。 所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。 连接过程：HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。 端口号，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 SEO（搜索引擎优化）：搜索引擎通常会更青睐使用 HTTPS 协议的网站，因为 HTTPS 能够提供更高的 安全性和用户隐私保护。使用 HTTPS 协议的网站在搜索结果中可能会被优先显示，从而对 SEO 产生影响。 4. 1.0和1.1的区别主要是前三个 连接方式 : HTTP&#x2F;1.0 默认情况下为短连接，HTTP&#x2F;1.1 支持长连接。HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。 管道化（Pipelining）： HTTP&#x2F;1.0：不支持管道化，客户端必须等待前一个请求的响应后才能发送下一个请求。 HTTP&#x2F;1.1：支持管道化，允许客户端发送多个请求而不必等待每个响应，这可以进一步提高性能。 1.1允许请求部分资源：HTTP&#x2F;1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP&#x2F;1.1 则在请求头引入了 range 头域，它允许只请求 资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用 带宽和连接。 状态响应码 : HTTP&#x2F;1.1 引入了更多的状态码和错误处理机制，提供了更详细的错误信息。 Host 头（Host Header）处理 :HTTP&#x2F;1.1 引入了 Host 头字段，允许在同一 IP 地址上托管多个域名， 从而支持虚拟主机的功能。而 HTTP&#x2F;1.0 没有 Host 头字段，无法实现虚拟主机。 5. 1.1和2.0的区别 头部压缩（Header Compression）： HTTP&#x2F;2 会压缩头（Header）如果你同时发出多个请求， 他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表， 所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 多路复用（Multiplexing）：HTTP&#x2F;1.1每个请求和响应需要独立的 TCP 连接，或者通过 Keep-Alive 在同一连接上串行处理请求。由于是串行传输，存在“队头阻塞”问题，即一个请求的延迟会阻塞后续请求。HTTP&#x2F;2.0支持多路复用，允许在单个 TCP 连接上并行发送多个请求和响应。消息被分解为独立的帧，交错传输并在另一端重新组装，有效消除了队头阻塞。 二进制帧（Binary Frames）：HTTP&#x2F;2.0 使用二进制帧进行数据传输，而 HTTP&#x2F;1.1 则使用文本格式的报文。二进制帧更加紧凑和高效，减少了传输的数据量和带宽消耗。 服务器推送（Server Push）：HTTP&#x2F;2.0 支持服务器推送，服务器可以主动向客户端推送资源，而不需要客户端明确请求。 6.2.0和3.0的区别前面我们知道了 HTTP&#x2F;1.1 和 HTTP&#x2F;2 都有队头阻塞的问题： HTTP&#x2F;1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞， 但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长， 那么只能等响应完这个请求后， 才能处理下一个请求， 这属于 HTTP 层队头阻塞。 HTTP&#x2F;2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。 HTTP&#x2F;2 队头阻塞的问题是因为 TCP，所以 HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP 传输协议：HTTP&#x2F;2.0 是基于 TCP 协议实现的，HTTP&#x2F;3.0 新增了 QUIC（Quick UDP Internet Connections） 协议来实现可靠的传输，提供与 TLS&#x2F;SSL 相当的安全性，具有较低的连接和传输延迟。 你可以将 QUIC 看作是 UDP 的升级版本，在其基础上新增了很多功能比如加密、重传等等。 队头阻塞：虽然支持多路复用，但在 TCP 层面仍存在队头阻塞问题。TCP 要求数据包按序到达，若一个数据包丢失，整个连接的传输会暂停，等待重传。而基于QUIC协议的3.0一个连接建立多个不同的数据流，这些数据流之间独立互不影响，某个数据流发生丢包了，其数据流不受影响 更快的连接建立：HTTP&#x2F;2.0 需要经过经典的 TCP 三次握手过程（由于安全的 HTTPS 连接建立还需要 TLS 握手，共需要大约 3 个 RTT）。 由于 QUIC 协议的特性（TLS 1.3，TLS 1.3 除了支持 1 个 RTT 的握手，还支持 0 个 RTT 的握手）连接建立仅需 0-RTT 或者 1-RTT。 这意味着 QUIC 在最佳情况下不需要任何的额外往返时间就可以建立新连接。 连接迁移：基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。 这个四元组中一旦有一项值发生改变，这个连接也就不能用了。 而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID 来标记通信的两个端点，只要 ID 不变就不会中断，网络环境改变时（如从 Wi-Fi 切换到移动数据）也能保持连接。 7.HTTP如何保存用户状态？HTTP 是无状态的协议（对于事务处理没有记忆能力，每次客户端和服务端会话完成时，服务端不会保存任何会话信息）：每个请求都是完全独立的，服务端无法确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的发送者是不是同一个人。所以服务器与浏览器为了进行会话跟踪（知道是谁在访问我），就必须主动的去维护一个状态，这个状态用于告知服务端前后两个请求是否来自同一浏览器。而这个状态需要通过 cookie 或者 session 去实现。 那么我们如何保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。 Cookie 被禁用怎么办? 最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。 8.URI和URL的区别 URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。 URL(Uniform Resource Locator) 是统一资源定位符，可以提供该资源的路径。 URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息 9.GET和POST的区别⭐ 语义（主要区别）：GET 通常用于获取或查询资源，而 POST 通常用于创建或修改资源。 幂等：GET 请求是幂等的，即多次重复执行不会改变资源的状态，而 POST 请求是不幂等的，即每次执行可能会产生不同的结果或影响资源的状态。 格式：GET 请求的参数通常放在 URL 中，形成查询字符串（querystring），而 POST 请求的参数通常放在请求体（body）中，可以有多种编码格式，如 application&#x2F;x-www-form-urlencoded、multipart&#x2F;form-data、application&#x2F;json 等。GET 请求的 URL 长度受到浏览器和服务器的限制，而 POST 请求的 body 大小则没有明确的限制。不过，实际上 GET 请求也可以用 body 传输数据，只是并不推荐这样做，因为这样可能会导致一些兼容性或者语义上的问题。 缓存：由于 GET 请求是幂等的，它可以被浏览器或其他中间节点（如代理、网关）缓存起来，以提高性能和效率。而 POST 请求则不适合被缓存，因为它可能有副作用，每次执行可能需要实时的响应。 安全性：GET 请求和 POST 请求如果使用 HTTP 协议的话，那都不安全，因为 HTTP 协议本身是明文传输的，必须使用 HTTPS 协议来加密传输数据。另外，GET 请求相比 POST 请求更容易泄露敏感数据，因为 GET 请求的参数通常放在 URL 中。 10、键入网址到浏览器显示期间发生了什么？⭐在牛客看到一个简答： 首先根据dns协议解析url获取服务器的ip，然后对服务器进行三次握手tcp链接，然后客户端这边会发起http请求来获取资源，然后服务端会响应请求，会返回资源，客户端拿到资源后对前端进行渲染后，执行tcp四次挥手断开链接 DNS 解析： 浏览器通过 DNS 协议，获取域名对应的 IP 地址。 TCP 连接： 浏览器根据 IP 向目标服务器发起一个 TCP 连接请求。这一步涉及到 TCP 的三次握手 发送 HTTP 请求： 浏览器在 TCP 连接上，向服务器发送一个 HTTP 请求报文，请求获取网页的内容。 服务器处理请求： 服务器收到 HTTP 请求报文后，处理请求，并返回 HTTP 响应报文给浏览器。 浏览器接收 HTTP 响应： 浏览器收到 HTTP 响应报文后，解析响应体中的 HTML 代码，渲染网页的结构和样式，同时根据 HTML 中的其他资源的 URL（如图片、CSS、JS 等），再次发起 HTTP 请求，获取这些资源的内容，直到网页完全加载显示。 断开连接：TCP 四次挥手，连接结束。 解析URL：确定要访问Web 服务器和文件名 DNS解析：查询服务器域名对应的 IP 地址（这里可以有个问题：域名解析的工作流程） 获取MAC地址：当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，（传输层TCP）因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。（网络层IP）网络层会将本机地址作为源地址，获取的IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相结合，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。 建立TCP连接：主机将使用目标IP地址和目标MAC地址发送一个TCP SYN包，请求建立一个TCP连接然后交给路由器转发，等路由器转到目标服务器后，服务器回复一个SYN-ACK包，确认连接请求。然后，主机发送一个ACK包，确认已收到服务器的确认，然后TCP连接建立完成。 HTTPS 的 TLS 四次握手:如果使用的是 HTTPS 协议，在通信前还存在 TLS 的四次握手。 发送HTTP请求:连接建立后，浏览器会向服务器发送HTTP请求。请求中包含了用户需要获取的资源的信息，例如网页的URL、请求方法(GET、POST等)等。 服务器处理请求并返回响应:服务器收到请求后，会根据请求的内容进行相应的处理。例如，如果是请求网页，服务器会读取相应的网页文件，并生成HTTP响应。 11.Cookie和Session有什么区别在 Web 开发中，Cookie、Session、Token、JWT 是用于身份验证和状态管理的核心概念 1.cookie 存储在客户端（浏览器） 登录成功后，服务器返回用户名给前端，前端把用户名保存到浏览器的cookie。这样后续浏览器再访问后端都会自动带上cookie，从而维持状态信息。 可能存在的问题： 用户可以自己修改cookie里面存储的用户名，不安全 cookie的大小有限制 还可能会被用户禁用cookie 安全性：容易被窃取（XSS 攻击）或伪造（CSRF 攻击），需设置 HttpOnly、Secure、SameSite 等属性增强安全性。 2.session 存储在服务端（通常配合cookie使用） session 是基于 cookie 实现的，session 存储在服务器端，sessionId 会被存储到客户端的cookie 中 登录信息传到服务端之后，服务器会在session中存储当前登录信息，并在响应头中把这个唯一的sessionId返回给前端（用的set-cookie），前端收到set-cookie后就会把这个唯一的sessionId存到cookie中，以后的每次请求都会把这个cookie发给后端 可能存在的问题： 占用服务器资源 依然需要依赖cookie 服务器需维护 Session 存储，在分布式系统中需共享 Session 存储（如 Redis 集群）。（集群模式下，前端的每次请求通过负载均衡可能会发到不同的服务器上，比如第一次发到A服务器上登录成功后，第二次发到B服务器上会判定你未登录） 问：如果客户端禁用了cookie，session还能用吗？ 默认情况下禁用 Cookie 后，Session 是无法正常使用的， 因为大多数 Web 服务器都是依赖于 Cookie 来传递 Session 的会话 ID 的。 但是，可以通过将Session ID附加到URL中作为参数来继续使用，服务器端需要相应地解析 URL 来获取 Session ID，并维护用户的会话状态。如果用户通过电子邮件或其他方式分享了这样的链接， 可能导致Session ID的意外泄露 12.Token和JWT1. Token 每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库 Token 是一种授权凭证，通常由服务器生成，用于客户端在后续请求中标识身份和权限。 特点： 存储在客户端（如浏览器 LocalStorage 或移动端本地存储）。 用途：无状态身份验证（如 API 调用）。 安全性：需通过 HTTPS 传输防止窃听；若使用 JWT 格式，需签名防篡改。 无状态性：服务器不存储 Token，仅通过签名验证有效性。 工作流程： 用户登录后，服务器生成 Token 并返回给客户端。 客户端后续请求在 Authorization 头中携带 Token（如 Bearer &lt;token&gt;）。 服务器验证 Token 有效性后处理请求。 Token的无状态是什么意思？ 在网络通信和系统设计中，Token的“无状态”（Stateless）是指在使用Token进行身份验证和授权时，服务器不需要在本地存储或维护客户端的会话状态信息。简单来说，每个Token本身包含了所有必要的信息，服务器只需要验证Token的有效性，就能识别用户的身份和权限，而无需依赖额外的存储或之前的请求记录。 2.JWT（JSON Web Token） 是目前最流行的跨域认证解决方案。 JWT 本质上就是一组字符串，通过（.）切分成三个为 Base64 编码的部分 Header（头部） : 描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型 Payload（载荷） : 用来存放实际需要传递的数据 Signature（签名）：服务器通过 Payload、Header 和一个密钥(Secret)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。 Header 和 Payload 都是 JSON 格式的数据，Signature 由 Payload、Header 和 Secret(密钥)通过特定的计算公式和加密算法得到。 Signature 部分是对前两部分的签名，作用是防止 JWT（主要是 payload） 被篡改 这个签名的生成需要用到： Header + Payload。 存放在服务端的密钥(一定不要泄露出去)。 加密算法。 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，这个字符串就是 JWT 如何基于JWT进行身份验证？ 在基于JWT 进行身份验证的的应用程序中，服务器通过 Payload、Header和 Secret(密钥)创建 JWT 并将JWT 发送给客户端。客户端接收到JWT之后，会将其保存在 Cookie 或者localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。 建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。 如何防止JWT被篡改 有了签名之后，即使 JWT 被泄露或者截获，黑客也没办法同时篡改 Signature、Header、Payload。 这是为什么呢？因为服务端拿到 JWT 之后，会解析出其中包含的 Header、Payload 以及 Signature 。服务端会根据 Header、Payload、密钥再次生成一个 Signature。拿新生成的 Signature 和 JWT 中的 Signature 作对比，如果一样就说明 Header 和 Payload 没有被修改。 不过，如果服务端的秘钥也被泄露的话，黑客就可以同时篡改 Signature、Header、Payload 了。黑客直接修改了 Header 和 Payload 之后，再重新生成一个 Signature 就可以了。 密钥一定保管好，一定不要泄露出去。JWT 安全的核心在于签名，签名安全的核心在密钥。 13.HTTP为什么不安全HTTP 由于是明文传输，所以安全上存在以下三个风险: 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL&#x2F;TLS 协议，可以很好的解决了上述的风险: 信息加密:交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制:无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书:证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。 14.HTTPS建立连接的过程 前置知识 加密&#x2F;解密 如果用的是同一套规则，就是对称加密，否则就是非对称加密 非对称的加密规则叫公钥，解密规则叫私钥 通过公钥加密后的数据，可以通过私钥进行解密，反之亦然 接下来看看HTTPS的连接过程（主要是TLS&#x2F;SSL四次握手） TCP连接 TLS&#x2F;SLL四次握手连接 第一次握手：客户端告诉服务端TLS版本以及加密算法和客户端随机数 第二次握手：服务端确认使用的TLS版本以及加密算法，以及给客户端一个服务端随机数和服务器证书 第三次握手：客户端首先会验证数字证书的真实性，如果没有问题，客户端从服务器证书中取出服务器公钥，生成一个随机数（pre-master key），用服务器公钥加密后发送给服务端，然后用此时这边的三个随机数（客户端随机数，服务端随机数，pre-master-key）生成一个会话密钥，然后把迄今为止的通信数据生成一个摘要，也叫finished报文，用会话密钥加密后发送给服务端，供服务端校验 第四次握手：服务端对客户端发送过来的随机数pre-master-key解密（用的是服务器私钥），然后用这边的三个随机数生成一个会话密钥，同样生成一个finished报文，发送给客户端做校验 加密通信 接下来，客户端与服务器就会用这个生成的会话密钥做加密通信 HTTPS是对称加密还是非对称加密？ 都用到了，四次握手本质是利用了非对称加密的特点来生成会话密钥，后面就是利用会话密钥来进行对称加密的加密通信 为什么不都用非对称加密呢？ 非对称加密慢 第二次握手中的服务器证书是什么？怎么从里面取出公钥？ 服务器证书是被CA(证书权威机构) 的私钥对服务器公钥加密后的东西，即CA私钥+服务器公钥——&gt;服务器证书 所以可以用CA公钥对服务器证书解密——&gt;服务器公钥 为什么不能直接传公钥？还要拿CA私钥加密后再传过去 直接传公钥的话如果被黑客替换成自己的公钥，那客户端拿着假公钥加密pre-master-key，黑客经过解密就可以得到这个pre-master-key，又因为另外两个随机数是明文，就可以计算出会话密钥，然后就可以破解通信内容了 15.HTTP和RPC的区别16.HTTP建立连接的过程服务器在 80 端口等待客户的请求。 浏览器发起到服务器的 TCP 连接（创建套接字 Socket）。 服务器接收来自浏览器的 TCP 连接。 浏览器（HTTP 客户端）与 Web 服务器（HTTP 服务器）交换 HTTP 消息。 关闭 TCP 连接。 17.HTTPS中间人攻击以及如何防范攻击原理 在HTTPS通信中，客户端通过服务器提供的数字证书来验证服务器的身份。证书由受信任的证书颁发机构（CA）签发，客户端会检查证书的有效性以确保通信安全。然而，在中间人攻击中，攻击者会伪造证书，冒充服务器与客户端通信。具体步骤如下： 拦截通信：攻击者拦截客户端发往服务器的请求。 伪装身份：攻击者伪装成服务器与客户端建立连接，同时与真正的服务器建立连接，充当中间人的角色。 伪造证书：攻击者向客户端提供一个伪造的证书，使客户端误以为与真正的服务器建立了安全连接。 窃听或篡改：攻击者可以窃听客户端和服务器之间的通信内容，甚至篡改数据。 防范 加密：https 握手期间会通过非对称加密的方式来协商出对称加密密钥。 身份校验：客户端会验证证书的合法性，包括检查证书的有效期、颁发机构的信任等。 18.HTTP和RPC的区别HTTP（HyperText Transfer Protocol） 是一种用于传输超文本的 应用层协议，最初设计目的是在 Web 浏览器和服务器之间传输 HTML 页面。 设计目标是提供一种通用的、标准化的请求-响应通信方式，广泛用于 Web 服务、API 和客户端-服务器通信。 强调通用性、跨平台性和易用性。 RPC（Remote Procedure Call） 是一种 进程间通信机制，用于让程序像调用本地函数一样调用远程服务。 设计目标是屏蔽底层网络通信的复杂性，提供透明的远程调用体验，强调性能和效率。 更专注于系统间的直接通信，常用于分布式系统和服务间调用。 二、DNS1、作用DNS（Domain Name System）域名管理系统，是当用户使用浏览器访问网址之后，使用的第一个重要协议。DNS 要解决的是域名和 IP 地址的映射问题。 DNS扮演着重要的角色，使得人们可以通过易记的域名访问互联网资源，而无需记住复杂的IP地址。 在一台电脑上，可能存在浏览器 DNS 缓存，操作系统 DNS 缓存，路由器 DNS 缓存。如果以上缓存都查询不到，那么 DNS 就闪亮登场了。 2、域名解析的流程 客户端先访问本地DNS服务器（假如网址是www.server.com 没找到就（由本地DNS服务器）访问根DNS服务器（.），根DNS返回给本地DNS服务器要找的网址的顶级域DNS服务器（com) （本地DNS服务器）访问顶级域服务器（com），顶级域服务器返回给本地DNS服务器要找的网址的权威DNS服务器（server.com） （本地DNS服务器）访问权威DNS服务器（server.com），权威DNS服务器返回给本地DNS服务器要找IP地址 是不是每次解析域名都要经过那么多的步骤呢？ （了解，反正就是知道会先看缓存有没有就行 浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地DNS 服务器」。 3.DNS劫持了解吗DNS 劫持是一种网络攻击，它通过修改 DNS 服务器的解析结果，使用户访问的域名指向错误的 IP 地址， 从而导致用户无法访问正常的网站，或者被引导到恶意的网站。DNS 劫持有时也被称为 DNS 重定向、DNS 欺骗或 DNS 污染。 三、WebSocket1.什么是WebSocketWebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。 WebSocket 协议本质上是应用层的协议，用于弥补 HTTP 协议在持久通信能力上的不足。客户端和服务器仅需一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 这意味着连接是持久的，它一直保持打开，直到有一方主动关闭连接。这使得WebSocket 非常适合用于实时应用程序，因为它不需要不断地建立和关闭连接。 WebSocket 的常见应用场景： 视频弹幕 实时消息推送 实时游戏对战 多用户协同编辑 社交聊天 。。。 2.为什么有了HTTP还需要WebSocket？或者说：WebSocket和HTTP有什么区别？ HTTP是基于TCP协议的，同一时间里，客户端和服务器只能有一方主动发数据，是半双工通信。 通常，打开某个网页，我们每点击一次网页上的某个选项前端就会发送一次HTTP请求，网站返回一次HTTP响应。这种由客户端主动请求，服务器响应的方式满足大部分网页的功能场景。但这种情况下，服务器不会主动给客户端发消息。而类似网页游戏这样的场景，是需要客户端和服务器之间互相主动发大量数据的。因此，我们需要一个基于TCP的新协议，即新的应用层协议WebSocket. 3.WebSocket的工作过程WebSocket 连接通常在客户端(例如浏览器)和服务器之间建立。客户端发送一个 HTTP 请求来建立连接，然后服务器返回一个确认消息，表示已建立连接。之后，客户端和服务器可以通过这个连接进行双向通信。客户端可以向服务器发送消息，服务器也可以向客户端发送消息。 客户端或服务器可以主动发送一个关闭帧，表示要断开连接。另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。 四、TCP与UDPTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 1.TCP报文的头部字段 一个 TCP 报文段主要由报文段头部（Header）和数据两部分组成。 源&#x2F;目的端口号：用于表示发送端和接收端 序列号：用于标识从 TCP 发送者发送的数据字节流中的第一个字节的顺序号。 通过 SYN 包传给接收端 确认号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。** 校验和：用于检测报文段在传输过程中的变化。 窗口大小：用于流量控制 控制位： 常见的有 ACK：确认字段是否有效 SYN：同步序号，用于建立连接 FIN：结束发送数据 2.TCP和UDP的区别 连接：TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接，即刻传输数据。 服务对象：TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 可靠性：TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 传输方式：TCP 面向字节流传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 3.什么时候选择TCP，什么时候选择UDP？ UDP 一般用于即时通信，比如：语音、 视频、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等 4.TCP三次握手 第一次握手（SYN）：客户端通知服务器它希望建立连接，并告知服务器自己的初始序列号。 客户端发送一个 SYN 报文（SYN=1），并携带客户端的初始序列号 seq=x，表示请求建立连接。然后客户端进入SYN_SEND状态目的：客户端告知服务器“我想建立连接，我的初始序列号是 x”。 第二次握手（SYN-ACK）：服务器告诉客户端，它的连接请求被接受了，并通知客户端自己的初始序列号。 服务器收到 SYN 后，回复一个 SYN-ACK 报文（SYN=1, ACK=1），携带服务器的初始序列号 seq=y，以及对客户端 SYN 的确认号 ack=x+1。然后服务端进入SYN_RCVD状态目的：服务器告知客户端“我收到了你的请求，同意建立连接，我的初始序列号是 y”。 第三次握手（ACK）：客户端进入 ESTABLISHED 状态，当服务器接收到这个包时，也进入 ESTABLISHED 状态 客户端收到 SYN-ACK 后，回复一个 ACK 报文（ACK=1），确认号为 ack=y+1。目的：客户端告知服务器“我收到了你的确认，连接已建立”。然后客户端进入ESTABLISHED状态 第三次握手是可以携带数据的（如果携带数据就消耗一个序号，不携带的话就不消耗），前两次握手是不可以携带数据的 5.TCP全连接和半连接 半连接队列（SYN队列），服务端收到第一次握手后，会将socket加入到这个队列中， 队列内的socket都处于SYN_RECV 状态。 全连接队列（ACCEPT队列），在服务端收到第三次握手后，会将半连接队列的socket取出， 放到全连接队列中。队列里的socket都处于 ESTABLISHED状态。 这里面的连接，就等着服务端执行accept()后被取出了。 虽然都叫队列，但其实全连接队列（icsk_accept_queue）是个链表， 而半连接队列（syn_table）是个哈希表。 为什么半连接要设置为哈希表呢？ 先对比下全连接队列，他本质是个链表，因为也是线性结构，说它是个队列也没毛病。它里面放的都是已经建立完成的连接，这些连接正等待被取走。而服务端取走连接的过程中，并不关心具体是哪个连接只要是个连接就行，所以直接从队列头取就行了。这个过程算法复杂度为0(1)。而半连接队列却不太一样，因为队列里的都是不完整的连接，嗷嗷等待着第三次握手的到来。那么现在有个第三次握手来了，则需要从队列里把相应IP端口的连接取出，如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。而如果将半连接队列设计成哈希表，那么查找半连接的算法复杂度就回到 0(1)了。因此出于效率考虑，全连接队列被设计成链表，而半连接队列被设计为哈希表。 6.TCP连接为什么三次握手，而不是两次或四次TCP 采用三次握手建立连接的核心目的是确保通信双方都能可靠地确认彼此的发送和接收能力，并同步初始序列号，从而为后续的可靠数据传输奠定基础。 (1) 防止旧的重复连接初始化（核心原因） 假设网络中存在延迟的旧 SYN 报文（例如客户端多次重试后建立的连接）： 两次握手的缺陷：如果只有两次握手（客户端发 SYN，服务器回复 SYN-ACK），服务器在收到 SYN 后直接建立连接。若旧的 SYN 报文延迟到达服务器，服务器会误认为这是一个新连接并分配资源，导致资源浪费。 三次握手的解决：客户端在收到服务器的 SYN-ACK 后，会检查确认号 ack 是否匹配自己的初始序列号。若不匹配（例如旧连接的 SYN 被服务器响应），客户端会发送 RST 报文终止连接，避免无效连接占用资源。 (2) 确保双方收发能力正常 第一次握手：客户端发送 SYN → 验证客户端的发送能力。 第二次握手：服务器发送 SYN-ACK → 验证服务器的发送能力和客户端的接收能力。 第三次握手：客户端发送 ACK → 验证客户端的发送能力和服务器的接收能力。只有三次握手能双向确认双方的收发能力。 (3) 同步初始序列号（ISN） TCP 依赖序列号实现可靠传输。三次握手确保双方交换并确认了初始序列号： 客户端通过 SYN 发送 seq=x，服务器通过 ACK 确认 x+1。 服务器通过 SYN 发送 seq=y，客户端通过 ACK 确认 y+1。若只有两次握手，服务器无法确认客户端是否已正确接收自己的序列号。 3. 两次或四次握手的问题 两次握手：无法解决旧 SYN 报文的重复连接问题，且服务器无法确认客户端的接收能力。 四次握手：在三次握手的基础上，若增加第四次确认（例如服务器再回复一个 ACK），会导致冗余，三次已足够可靠。 7.TCP四次挥手 假设客户端主动发起关闭连接： 第一次挥手（FIN）：客户端发送 FIN 报文（FIN=1），序列号为 seq=u，表示客户端不再发送数据，但仍可接收数据。客户端进入FIN-WAIT-1状态 第二次挥手（ACK）：服务器收到 FIN 后，回复 ACK 报文（ACK=1），确认号为 ack=u+1，表示已收到客户端的关闭请求。此时服务器可能还有未发送完的数据。服务端进入CLOSE-WAIT状态，客户端进入FIN-WAIT-2状态 第三次挥手（FIN）：服务器完成数据发送后，发送自己的 FIN 报文（FIN=1），序列号为 seq=v，表示服务器也准备关闭连接。服务端进入LAST-ACK状态 第四次挥手（ACK）：客户端收到服务器的 FIN 后，回复 ACK 报文（ACK=1），确认号为 ack=v+1。客户端进入TIME-WAIT状态，也就是还要再等2MSL才能进入关闭状态。而服务器收到此 ACK 后，连接正式关闭，进入关闭状态 8.为什么要四次挥手？TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 举个例子：A 和 B 打电话，通话即将结束后。 第一次挥手：A 说“我没啥要说的了” 第二次挥手：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话 第三次挥手：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 第四次挥手：A 回答“知道了”，这样通话才算结束。 确保数据完全传输 第二次挥手的 ACK：服务器收到客户端的 FIN 后，先确认收到请求，但可能仍有数据需要发送。 第三次挥手的 FIN：服务器发送完剩余数据后，才通知客户端自己也要关闭。若合并第二次和第三次挥手（即服务器直接回复 FIN+ACK），可能因数据未发送完导致数据丢失。 为什么四次挥手之后要等2MSL? 若第四次挥手的ACK丢失，服务器没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文 ，而客户端进入了关闭状态，就会导致服务器无法进入关闭状态 另一个，在 TIME_WAIT 持续的 2MSL 时间后，确保旧数据包完全消失，避免它们干扰未来建立的新连接。 9.如果TIME_WAIT状态过多，会有什么问题？如何解决？第⼀是内存资源占⽤； 每个TIME_WAIT连接会占用一个四元组（源IP、源端口、目标IP、目标端口），导致端口和内存资源被占用。 第⼆是对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝； 如果客户端使用固定端口（如HTTP短连接频繁启闭），可能导致端口耗尽（Cannot assign requested address错误）。 解决方案：长连接替代短连接 使用HTTP&#x2F;1.1的Keep-Alive或数据库连接池，减少连接频繁创建&#x2F;销毁。 9.TCP为什么可靠传输？ 连接管理：即三次握手和四次挥手。连接管理机制能够建立起可靠的连接，这是保证传输可靠性的前提。 序列号&#x2F;确认应答：TCP 将数据分成多个小段，每段数据都有唯一的序列号 。 既能防止数据丢失，又能避免数据重复。 同时，接收方接收到发送方的数据，会回复一个ACK来确认收到了 校验和：TCP 报文段包括一个校验和字段，用于检测报文段在传输过程中的变化。如果接收方检测到校验和错误，就会丢弃这个报文段。 重传机制 :发生超时或者收到重复ACK会触发重新传送。 流量控制：接收端处理数据的速度是有限的，如果发送方发送数据的速度过快，就会导致接收端的缓冲区溢出，进而导致丢包。为了避免上述情况的发生，TCP支持根据接收端的处理能力，来决定发送端的发送速度。这就是流量控制。流量控制是通过在TCP报文段首部维护一个滑动窗口来实现的。 拥塞控制：TCP 会采用慢启动的策略，一开始发的少，然后逐步增加，当检测到网络拥塞时，会降低发送速率。在网络拥塞缓解后，传输速率也会自动恢复。 这里补充一下超时重传 当发送端发送一个数据包后，如果在一定时间内没有收到接收端的确认（ACK），发送端会认为这个数据包可能丢失了，于是会重新发送这个数据包。这就是“超时重传”。 每次发送一个数据段，发送端都会启动一个定时器，叫做 RTO（Retransmission Timeout，重传超时时间）。如果在 RTO 时间内没有收到 ACK，发送端就认为数据包可能丢失了，会触发重传。 RTT：从发送数据包到收到 ACK 的时间。 10.滑动窗口本来TCP是只能等到上次请求得到确认，才能继续发下次请求的，但这样通信效率低呀！ 所以引入了窗口的概念，啥意思呢，就是这个窗口内可以连续发多条请求，而不必等一个请求得到应答了再发下一条，这样就极大提高了效率。而且有一个好处，那就是累计确认 比如图中ACK600这条确认丢失了，没事呀，我ACK700都接收到了，就代表之前的我都收到了！ 窗口大小由哪一方决定？ 当然是接收方啦 发送方的滑动窗口示意图 分成四个部分： 已发送并收到ACK确认 已发送但未收到ACK确认 未发送但总大小在接收方处理范围内，也就是还可用的窗口 未发送但总大小超过接收方处理范围内 程序可以通过三个指针来表示各个部分 SND.WND：表示发送窗口的大小 SND.UNA ：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号 SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号 可用窗口大小 &#x3D; SND.WND -（SND.NXT - SND.UNA） 也就是总窗口 - 已用窗口 接收方的窗口示意 分成三个部分： 已接收并确认的数据 未收到但可以接收的数据 未收到并且不可以接收的数据 11.流量控制TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 为什么需要流量控制? 这是因为双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来。如果接收方处理不过来的话，就只能把处理不过来的数据存在 接收缓冲区(Receiving Buffers) 里（失序的数据包也会被存放在缓存区里）。 如果缓存区满了发送方还在狂发数据的话，接收方只能把收到的数据包丢掉。出现丢包问题的同时又疯狂浪费着珍贵的网络资源。因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。 这里需要注意的是（常见误区）： 发送端不等同于客户端 接收端不等同于服务端 TCP 为全双工(Full-Duplex, FDX)通信，双方可以进行双向通信，客户端和服务端既可能是发送端又可能是服务端。因此，两端各有一个发送缓冲区与接收缓冲区，两端都各自维护一个发送窗口和一个接收窗口。接收窗口大小取决于应用、系统、硬件的限制（TCP 传输速率不能大于应用的数据处理速率）。通信双方的发送窗口和接收窗口的要求相同 12.拥塞控制TCP拥塞控制是为了防止网络中的拥塞，确保数据在网络中可靠传输。它的目标是动态地调整数据发送速度，以适应网络的状况。 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP 的拥塞控制采用了四种算法，即 慢开始、 拥塞避免、快重传 和 快恢复。 慢开始：慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd加倍（指数增长）。 拥塞避免：当cwnd达到阈值（ssthresh）后，进入拥塞避免阶段。 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1.（线性增长） 拥塞发生： 当网络拥塞发生丢包时，会有两种情况： 超时重传 阈值设置为cwnd的一半，cwnd重置为1，然后启动慢开始 快速重传 如果发送方在连续收到3个相同的ACK时，认为发生了丢包，立即重传丢失的数据包，而不等待超时重传。此时进入快恢复 快恢复（Fast Recovery）： 在丢包发生后，进入快恢复阶段，阈值不变，cwnd被调整为原来的一半，并进入拥塞避免阶段，而不是回到慢启动。 13.TCP粘包⭐TCP粘包是指在TCP协议中，由于数据的发送和接收没有明确的边界，多个数据包在传输过程中可能会被合并成一个数据包。这种情况会导致接收端无法准确区分每个独立的消息，从而无法正确解析数据。 解决方法： 固定长度的消息：发送方将每个消息填充到固定的长度（例如，每个消息固定为100字节，不足的部分用特定字符填充）。接收方每次读取固定长度的数据即可分割消息。 特殊字符作为边界：在每个消息的末尾添加一个特殊的分隔符（例如，换行符\\n或自定义字符）。接收方通过检测分隔符来分割消息。 消息头包含长度：在每个消息的头部添加一个字段（例如，4字节），用来指示该消息的长度。接收方先读取消息头的长度字段，然后根据这个长度读取后续的完整消息。 五、IP1.IP协议的定义和作用IP 协议（Internet Protocol）用于在计算机网络之间传输数据包，它定义了数据包的格式和处理规则，确保数据能够从一个设备传输到另一个设备，可能跨越多个中间网络设备（如路由器）。 ①、寻址：每个连接到网络的设备都有一个唯一的 IP 地址。IP 协议使用这些地址来标识数据包的源地址和目的地址，确保数据包能够准确地传输到目标设备。 ②、路由：IP 协议负责决定数据包在网络传输中的路径。比如说路由器使用路由表和 IP 地址信息来确定数据包的最佳传输路径。 ③、分片和重组：当数据包过大无法在某个网络上传输时，IP 协议会将数据包分成更小的片段进行传输。接收端会根据头部信息将这些片段重新组装成完整的数据包。 2.域名和IP的关系？一个IP可以对应多个域名吗？ IP 地址在同一个网络中是惟一的，用来标识每一个网络上的设备，其相当于一个人的身份证号 域名在同一个网络中也是惟一的，就像是一个人的名字、绰号 假如你有多个不用的绰号，你的朋友可以用其中任何一个绰号叫你，但你的身份证号码却是惟一的。但同时你的绰号也可能和别人重复，假如你不在，有人叫你的绰号，其它人可能就答应了。 一个域名可以对应多个 IP，但这种情况 DNS 做负载均衡的，在用户访问过程中，一个域名只能对应一个 IP。 而一个 IP 却可以对应多个域名，是一对多的关系。 一个域名只能实际对应一个IP，一个IP可以对应多个域名 3.为什么既有IP地址又有MAC地址 MAC 地址和 IP 地址都有什么作用？ MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址，用来定义网络设备的位置，不可变更。 IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。 类似物理地址（MAC）和逻辑地址（IP）的关系 为什么有了 MAC 地址还需要 IP 地址？ 如果我们只使用 MAC 地址进行寻址的话，我们需要路由器记住每个 MAC 地址属于哪个子网，不然一次路由器收到数据包都要满世界寻找目的 MAC 地址。而我们知道 MAC 地址的长度为 48 位，也就是最多共有 2 的 48 次方个 MAC 地址，这就意味着每个路由器需要 256T 的内存，显然是不现实的。 和 MAC 地址不同，IP 地址是和地域相关的，在一个子网中的设备，我们给其分配的 IP 地址前缀都是一样的，这样路由器就能根据 IP 地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。 简单说，就是MAC地址太长了，路由器存储起来占用内存；另一方面，一个子网内的IP地址具有相同的前缀，因此寻址起来只需要知道该IP地址在哪个子网，剩下的寻址就交给子网内部实现，可大大减少路由器所需内存 4.ARP协议ARP（Address Resolution Protocol，地址解析协议）是网络通信中的一种协议，主要目的是将网络层的 IP 地址解析为链路层的 MAC 地址。 ARP 工作原理： 记住几个关键词：ARP 表、广播问询、单播响应。 ARP 协议工作时有一个大前提，那就是 ARP 表。 在一个局域网内，每个网络设备都自己维护了一个 ARP 表，ARP 表记录了某些其他网络设备的 IP 地址-MAC 地址映射关系，该映射关系以 &lt;IP, MAC, TTL&gt; 三元组的形式存储。其中，TTL 为该映射关系的生存周期，典型值为 20 分钟，超过该时间，该条目将被丢弃。 工作流程 ①、ARP 请求 当主机 A 要发送数据给主机 B 时，首先会在自己的 ARP 表中查找主机 B 的 MAC 地址。 如果没有找到，主机 A 会向网络中广播一个 ARP 请求数据包，请求网络中的所有主机告诉它们的 MAC 地址；这个请求包含了请求设备和目标设备的 IP 和 MAC 地址。 ②、ARP 应答 网络中的所有主机都会收到这个 ARP 请求，但只有主机 B 会回复 ARP 应答，告诉主机 A 自己的 MAC 地址。 并且主机 B 会将主机 A 的 IP 和 MAC 地址映射关系缓存到自己的 ARP 缓存中，以便下次通信时直接使用。 ③、更新 ARP 缓存 主机 A 收到主机 B 的 ARP 应答后，也会将主机 B 的 IP 和 MAC 地址映射关系缓存到自己的 ARP 缓存中。 六、网络攻击1.什么是DDOS攻击？怎么防范？分布式拒绝服务（DDoS）攻击是通过大规模互联网流量淹没目标服务器或其周边基础设施， 以破坏目标服务器、服务或网络正常流量的恶意行为。 DDoS 攻击是通过连接互联网的计算机网络进行的。这些网络由计算机和其他设备例如 IoT 设备）组成，它们感染了恶意软件，从而被攻击者远程控制。这些个体设备称为机器人（或僵尸），一组机器人则称为僵尸网络。 一旦建立了僵尸网络，攻击者就可通过向每个机器人发送远程指令来发动攻击。 当僵尸网络将受害者的服务器或网络作为目标时，每个机器人会将请求发送到目标的 IP 地址， 这可能导致服务器或网络不堪重负，从而造成对正常流量的拒绝服务。 由于每个机器人都是合法的互联网设备，因而可能很难区分攻击流量与正常流量。 2.CSRF攻击CSRF（跨站请求伪造）是一种攻击手段，攻击者通过诱导用户执行恶意操作，从而获取用户数据或执行恶意代码。CSRF攻击通常通过伪造一个合法的HTTP请求来实现，这个请求看起来是合法的，但实际上是为了执行一个攻击者控制的操作。 3.XSS攻击XSS是跨站脚本攻击，攻击者通过在Web页面中插入恶意脚本代码，然后诱使用户访问该页面， 从而使得恶意脚本在用户浏览器中执行，从而盗取用户信息、会话信息等敏感数据，甚至控制用户账户。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"JVM","slug":"八股/JVM","date":"2024-10-28T12:29:13.000Z","updated":"2025-05-24T00:33:38.551Z","comments":true,"path":"2024/10/28/八股/JVM/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/JVM/","excerpt":"这里是有关JVM的八股","text":"这里是有关JVM的八股 1.引言1.JVM的特性对字节码文件中的指令，实时解释成机器码，让机器执行 最重要的特性还是跨平台，以下是其它特性 ①、垃圾回收：JVM 可以自动管理内存，通过垃圾回收机制（Garbage Collection）释放不再使用的对象所占用的内存。 ②、JIT：JVM 包含一个即时编译器（JIT Compiler），它在运行时将热点代码缓存到 codeCache 中，下次执行的时候不用再一行一行解释，而是直接执行缓存后的机器码，执行效率会提高很多。 ③、多语言支持：任何可以通过 Java 编译的语言，比如说 Groovy、Kotlin、Scala 等，都可以在 JVM 上运行。 所以主要关注四个部分，字节码文件，类加载器，运行时数据区，垃圾回收器 2.字节码文件12int i = 0;i = i++; 这个代码的执行结果是什么？ 先来分析字节码指令的执行过程 答案是0，通过分析字节码指令发现，i++先把0取出来放入临时的操作数栈中，接下来对i进行加1，i变成了1，最后再将之前保存的临时值0放入i，最后i就变成了0。 而++i的执行结果则不一样 PS：这里iload_1写错了，应该是将1复制一份到操作数栈中， 然后istore_1是将操作数栈中的1对局部变量表中的1进行一个覆盖 所以，如果是 12int i = 0;i = i++; 执行结果则是1 总结：关键的是++这个命令是直接对局部变量表上的值进行增加。而i++和++i有不同的执行顺序。前者是先将原值拷贝一份，然后对变量表中的进行操作，最后将拷贝的那份进行了一个覆盖，所以不管怎么操作，i的值仍然不变。而后者是先操作，再拷贝，最后覆盖的仍然是操作后的数据，因此就可以实现变化。 3.JVM的组成 2.内存管理1.JVM的内存区域JVM 的内存区域，有时叫 JVM 的内存结构，有时也叫 JVM 运行时数据区 主要包括 程序计数器（Program Counter Register） Java 虚拟机栈（Java Virtual Machine Stacks） 本地方法栈（Native Method Stack） 堆（Heap） 方法区（Method Area）其中 线程私有的：程序计数器，虚拟机栈，本地方法栈 线程共享的：堆，方法区，直接内存 (也即本地内存) 下面依次介绍这些区域： 2.程序计数器程序计数器（Program Counter Register）也被称为 PC 寄存器，是一块较小的内存空间。 线程私有的，每个线程一份，内部保存的字节码的行号。可以看作是当前线程所执行的字节码的行号指示器。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 从上面的介绍中我们知道了程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 3.虚拟机栈Java 虚拟机栈（JVM 栈）中是一个个栈帧，每个栈帧对应一个被调用的方法。当线程执行一个方法时，会创建一个对应的栈帧，并将栈帧压入栈中。当方法执行完毕后，将栈帧从栈中移除。 每个线程有一个私有的栈，生命周期和线程一样。 栈帧：用于存储局部变量表、操作数栈、动态链接、方法出口等信息 局部变量表：局部变量表的作用是在方法执行过程中存放所有的局部变量。局部变量表分为两种，一种是字节码文件中的，另外一种是栈帧中的也就是保存在内存中。栈帧中的局部变量表是根据字节码文件中的内容生成的。 操作数栈：操作数栈是栈帧中虚拟机在执行指令过程中用来存放中间数据的一块区域。 动态链接：当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号到运行时常量池的内存地址的映射关系。 方法出口：方法出口指的是方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，需要存储此方法出口的地址。 可能出现的问题： StackOverFlowError： 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 垃圾回收是否涉及栈内存? 垃圾回收主要指就是堆内存，当栈帧弹栈以后，内存就会释放 栈内存分配越大越好吗?未必，默认的栈内存通常为1024k，栈过大会导致线程数变少 方法内的局部变量是否线程安全?如果方法内局部变量没有逃离方法的作用范围，它是线程安全的 如果是局部变量引用了对象（传入有参数），并逃离方法的作用范围（有返回值），需要考虑线程安全 什么情况下会导致栈内存溢出? 栈帧过多导致栈内存溢出，典型问题:递归调用栈帧过大导致栈内存溢出 堆栈的区别是什么? 堆属于线程共享的内存区域，几乎所有的对象都在堆上分配，生命周期不由单个方法调用所决定，可以在方法调用结束后继续存在，直到不再被任何变量引用，然后被垃圾收集器回收。 栈属于线程私有的内存区域，主要存储局部变量、方法参数、对象引用等，通常随着方法调用的结束而自动释放，不需要垃圾收集器处理。 4.本地方法栈与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； 在本地方法栈中，主要存放了 native 方法的局部变量表、操作数栈、动态链接、出口信息。当一个 Java 程序调用一个 native 方法时，JVM 会切换到本地方法栈来执行这个方法。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 5.堆堆（heap）是 JVM 中最大的一块内存区域，被所有线程共享，在 JVM 启动时创建，主要用来存储对象的。 从内存回收的角度来看，由于垃圾收集器大部分都是基于分代收集理论设计的，所以堆也会被划分为新生代、老年代。新生代又会划分为Eden空间、From Survivor空间、To Survivor空间 简单介绍一下JIT和逃逸分析： 常见的编译型语言如 C++，通常会把代码直接编译成 CPU 所能理解的机器码来运行。而 Java 为了实现“一次编译，处处运行”的特性，把编译的过程分成两部分，首先它会先由 javac 编译成通用的中间形式——字节码，然后再由解释器逐条将字节码解释为机器码来执行。所以在性能上，Java 可能会干不过 C++ 这类编译型语言。 为了优化 Java 的性能 ，JVM 在解释器之外引入了 JIT 编译器：当程序运行时，解释器首先发挥作用，代码可以直接执行。随着时间推移，即时编译器逐渐发挥作用，把越来越多的代码编译优化成本地代码，来获取更高的执行效率。解释器这时可以作为编译运行的降级手段，在一些不可靠的编译优化出现问题时，再切换回解释执行，保证程序可以正常运行。 逃逸分析（Escape Analysis）是一种编译器优化技术，用于判断对象的作用域和生命周期。如果编译器确定一个对象不会逃逸出方法或线程的范围，它可以选择在栈上分配这个对象，而不是在堆上。这样做可以减少垃圾回收的压力，并提高性能。 堆最容易出现OOM问题： OutOfMemoryError: GC Overhead Limit Exceeded：当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生该错误。 java.lang.OutOfMemoryError: Java heap space：假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发该错误。和本机的物理内存无关，和我们配置的虚拟机内存大小有关！ 6.方法区方法区并不真实存在，属于 Java 虚拟机规范中的一个逻辑概念。每个JVM 只有一个方法区，它是一个共享的资源。 当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。 方法区是存放基础信息的位置，线程共享，主要包含三部分内容： 类的元信息，保存了所有类的基本信息 运行时常量池，保存了字节码文件中的常量池内容 字符串常量池，保存了字符串常量 类的元信息 方法区是用来存储每个类的基本信息（元信息），一般称之为InstanceKlass对象。在类的加载阶段完成。其中就包含了类的字段、方法等字节码文件中的内容，同时还保存了运行过程中需要使用的虚方法表（实现多态的基础）等信息。 运行时常量池 方法区除了存储类的元信息之外，还存放了运行时常量池。常量池中存放的是字节码中的常量池内容。 字节码文件中通过编号查表的方式找到常量，这种常量池称为静态常量池。当常量池加载到内存中之后，可以通过内存地址快速的定位到常量池中的内容，这种常量池称为运行时常量池。 字符串常量池 方法区中除了类的元信息、运行时常量池之外，还有一块区域叫字符串常量池(StringTable)。 字符串常量池存储在代码中定义的常量字符串内容。比如“123” 这个123就会被放入字符串常量池。 字符串常量池和运行时常量池有什么关系？ 早期设计时，字符串常量池是属于运行时常量池的一部分，他们存储的位置也是一致的。后续做出了调整，将字符串常量池和运行时常量池做了拆分。 静态变量存储在哪里呢？ JDK6及之前的版本中，静态变量是存放在方法区中的，也就是永久代。 JDK7及之后的版本中，静态变量是存放在堆中的Class对象中，脱离了永久代。具体源码可参考虚拟机源码：BytecodeInterpreter针对putstatic指令的处理。 全局变量（可以认为是static修饰的变量）就是放在方法区中。成员变量放在堆中，局部变量放在栈中。 方法区和永久代以及元空间是什么关系呢？ 方法区和永久代以及元空间的关系很像 Java 中 接口和类的关系，类实现了接口，这里的类就可以看作是永久代和元空间， 接口可以看作是方法区，也就是说永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。 并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。 元空间使用的是本地内存 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢? 整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整（也就是受到 JVM 内存的限制），而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。 直接内存（不属于JVM的内存结构 操作系统划分的一块用于NIO（new io）的数据缓冲区，可以提高读写性能，不属于JVM的内存结构，不受JVM内存回收管理 8.JDK1.6、1.7、1.8内存区域的变化两方面：1.方法区的实现2.字符串常量池的位置 JDK1.6 使用永久代实现方法区： 此时的常量池包括运行时常量池和字符串常量池，这两个还没有分开 JDK1.7 时发生了一些变化，将字符串常量池、静态变量，存放在堆上，而运行时常量池还在永久代中 在 JDK1.8 时彻底干掉了永久代，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。 9.四种引用类型四种，分别是强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）。 强引用：是 Java 中最常见的引用类型。使用 new 关键字赋值的引用就是强引用，发生 gc 的时候不会被回收。 软引用：是一种相对较弱的引用类型，可以通过 SoftReference 类实现。 有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：可以通过 WeakReference 类实现。他的强度比软引用更低一点， 有用但不是必须的对象，在下一次GC时会被回收，而不管内存是否足够。 虚引用：是最弱的引用关系， 可以通过 PhantomReference 类实现。虚引用对象在任何时候都可能被回收。主要用于跟踪对象被垃圾回收的状态，可以用于管理直接内存。 虚引用的用途是在 gc 时返回一个通知。 引用关系从强到弱：强引用 &gt; 软引用 &gt; 弱引用 &gt; 虚引用 10.内存溢出和内存泄露内存溢出（Out of Memory，俗称 OOM）和内存泄漏（Memory Leak）是两个不同的概念，但它们都与内存管理有关。 ①、内存溢出：是指当程序请求分配内存时，由于没有足够的内存空间满足其需求，从而触发的错误。在 Java 中，这种情况会抛出 OutOfMemoryError,OOM。 内存溢出可能是由于内存泄漏导致的，也可能是因为程序一次性尝试分配大量内存，内存直接就干崩溃了导致的，比如堆内存不足以存放新创建的对象时 。 ②、内存泄漏：是指程序在使用完内存后，未能释放已分配的内存空间，导致这部分内存无法再被使用。随着时间的推移，内存泄漏会导致可用内存逐渐减少，最终可能导致内存溢出。 在 Java 中，内存泄漏通常发生在长期存活的对象持有短期存活对象的引用，而长期存活的对象又没有及时释放对短期存活对象的引用，从而导致短期存活对象无法被回收。 用一个比较有味道的比喻来形容就是，内存溢出是排队去蹲坑，发现没坑了；内存泄漏，就是有人占着茅坑不拉屎，占着茅坑不拉屎的多了可能会导致坑位不够用。 在JVM运行时数据区中，除了程序计数器不会发生内存溢出，其余的堆，栈，方法区都会发生内存溢出 对象什么时候进入老年代？（TODO） 对象通常会先在年轻代中分配，然后随着时间的推移和垃圾收集的处理，某些对象会进入到老年代中。 ①、长期存活的对象将进入老年代 对象在年轻代中存活足够长的时间（即经过足够多的垃圾回收周期）后，会晋升到老年代。 每次 GC 未被回收的对象，其年龄会增加。当对象的年龄超过一个特定阈值（默认通常是 15），它就会被移动到老年代。这个年龄阈值可以通过 JVM 参数-XX:MaxTenuringThreshold来设置。 ②、大对象直接进入老年代 为了避免在年轻代中频繁复制大对象，JVM 提供了一种策略，允许大对象直接在老年代中分配。 这些是所谓的“大对象”，其大小超过了预设的阈值（由 JVM 参数-XX:PretenureSizeThreshold控制）。直接在老年代分配可以减少在年轻代和老年代之间的数据复制。 ③、动态对象年龄判定 除了固定的年龄阈值，还会根据各个年龄段对象的存活大小和内存空间等因素动态调整对象的晋升策略。 比如说，在 Survivor 空间中相同年龄的所有对象大小总和大于 Survivor 空间的一半，那么年龄大于或等于该年龄的对象就可以直接进入老年代。 2.类加载器1.对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头包括两部分信息： 标记字段（Mark Word）：存储对象自身运行时的数据：HashCode、GC 状态（年龄、标记位）、锁状态（锁记录／偏向锁信息）等。 Mark Word 的低 3 位作为锁状态标识（00 &#x3D; 无锁，01 &#x3D; 偏向锁，10 &#x3D; 轻量级锁，11 &#x3D; 重量级锁）（在并发那里需要了解这个） 类型指针（Klass pointer）：指向对象元数据（Class 元信息）的指针。 虚拟机通过这个指针来确定这个对象是哪个类的实例。 Java 数组对象在头部还多一个 length 字段（4 字节） 对象头 Mark Word 的多种状态 ：无锁态、偏向锁态、轻量级锁态、重量级锁态、GC 标记态 等，由 JVM 动态切换。 HotSpot 特殊优化 TLAB（线程本地分配缓冲），小对象由线程本地分配，减少竞争。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 2.对象创建的过程 类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存：在类加载检查通过后，接下来虚拟机将为新生对象分配内存。 对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。 初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 这一步保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用， 程序能访问到这些字段的数据类型所对应的零值。 设置对象头：初始化零值完成之后，虚拟机要对对象进行必要的设置， 例如这个对象是哪个类的实例、如何才能找到类的元数据信息、 对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行 init 方法：在上面工作都完成之后，从虚拟机的视角来看， 一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始——构造函数， 即class文件中的方法还没有执行，所有的字段都还为零， 对象需要的其他资源和状态信息还没有按照预定的意图构造好。 所以一般来说，执行 new 指令之后会接着执行方法， 把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全被构造出来。 3.为对象分配内存（堆内存如何分配）类加载完成后，接着会在Java堆中划分一块内存分配给对象。内存分配根据Java堆是否规整，有两种方式： 指针碰撞 原理：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。 空闲列表： 原理：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。 选择哪种分配方式是由 Java 堆是否规整来决定的，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 指针碰撞适用于管理简单、碎片化较少的内存区域（如年轻代），而空闲列表适用于内存碎片化较严重或对象大小差异较大的场景（如老年代）。 4.处理并发安全问题对象的创建在虚拟机中是一个非常频繁的行为，哪怕只是修改一个指针所指向的位置，在并发情况下也是不安全的，可能出现正在给对象 A 分配内存，指针还没来得及修改，对象 B 又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案： 对分配内存空间的动作进行同步处理（采用 CAS + 失败重试来保障更新操作的原子性）； 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配， 当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 5.JVM如何访问对象（对象的访问定位）Java 程序通过栈上的 reference 数据来操作堆上的具体对象。 对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄、直接指针。 句柄 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 直接指针 如果使用直接指针访问，reference 中存储的直接就是对象的地址。 句柄的好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 直接指针的好处是速度快，它节省了一次指针定位的时间开销。 6.类加载的过程（类的生命周期） 类从被加载到虚拟机内存开始，到卸载出内存为止，它的整个生命周期包括以下 7 个阶段： 连接或作链接，都一样的。 1.加载：通过类的全限定名获取字节码文件，并将其转换为方法区内的运行时数据结构。 通过类的全限定名（包名 + 类名），获取到该类的.class文件的二进制字节流，将二进制字节流所代表的静态存储结构，转化为方法区运行时的数据结构，在内存中生成一个代表该类的Java.lang.Class对象，作为方法区这个类的各种数据的访问入口 2.验证：对字节码进行校验，确保符合Java虚拟机规范。 确保class文件中的字节流包含的信息，符合当前虚拟机的要求，保证这个被加载的class类的正确性，不会危害到虚拟机的安全。验证阶段大致会完成以下四个阶段的检验动作：文件格式校验、元数据验证、字节码验证、符号引用验证 3.准备：为类的静态变量分配内存，并设置默认初始值。 为类中的静态字段分配内存，并设置默认的初始值（比如int的默认值就是0），但如果这个字段还被final修饰，会直接设置为我们设置的初始值，比如public static final a = 1，就会设置为1。 被final修饰的static字段不会设置，因为final在编译的时候就分配了 也就是说，final分配内存更早！在编译阶段，static分配内存在准备阶段！ 4.解析：将符号引用转换为直接引用，即将类、方法、字段等解析为具体的内存地址。 符号引用是以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用的时候可以无歧义地定位到目标即可。直接引用可以是直接指向目标的指针、 相对偏移量或是一个能间接定位到目标的句柄，直接引用是和虚拟机实现的内存布局相关的。如果有了直接引用， 那引用的目标必定已经存在在内存中了。 5.初始化：执行类的初始化代码，包括静态变量赋值和静态代码块的执行。 6.类卸载 卸载类需要满足 3 个要求: 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 拓展一下： JVM 判定两个 Java 类是否相同的具体规则：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。 只有两者都相同的情况，才认为两个类是相同的。 7.什么是类加载器，类加载器有哪些简而言之，类加载器的主要作用就是加载 Java 类的字节码（ .class 文件）到 JVM 中，详细如下： 类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步。 每个 Java 类都有一个引用指向加载它的 ClassLoader。 数组类不是通过 ClassLoader 创建的（数组类没有对应的二进制字节流），是由 JVM 直接生成的。 以下是常见的类加载器 启动类加载器(Bootstrap ClassLoader)：用来加载java核心类库，无法被java程序直接引用。负责加载 JAVA_HOME&#x2F;jre&#x2F;lib 目录下的jar包和类,（如 String、System等） 扩展类加载器(extensions class loader)：它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。它负责加载JRE的扩展目录（ %JAVA_HOME%&#x2F;jre&#x2F;lib&#x2F;ext ）中jar包的类 应用程序类加载器（application class loader）：负责加载用户类路径（ClassPath）上的指定类库 ，是我们平时编写Java程序时默认使用的类加载器。 它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 用户自定义类加载器：开发者可以根据需求定制类的加载方式 ，通过继承 java.lang.ClassLoader类的方式实现。 层级关系：启动类加载器——&gt;扩展类加载器——&gt;应用程序类加载器——&gt;自定义类加载器 加载流程：自底向上判断是否加载过，自顶向下尝试加载类 8.什么是双亲委派机制？为什么采用双亲委派机制双亲委派机制是指类加载器在加载类时，首先不会自己去尝试加载这个类 ，而是将加载请求委托给父类加载器，只有当父类加载器无法加载时（每种类加载器有自己的加载目录），才自己尝试加载。从而确保类的加载安全和防止类的重复加载。 保证类的唯一性 ：通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。 保证安全性： 为了安全，保证类库API不会被修改，避免恶意代码替换JDK中的核心类库 3.垃圾收集垃圾回收就是对内存堆中已经死亡的或者长时间没有使用的对象进行清除或回收。 JVM 在做 GC 之前，会先搞清楚什么是垃圾，什么不是垃圾，通常会通过可达性分析算法来判断对象是否存活。 在确定了哪些垃圾可以被回收后，垃圾收集器（如 CMS、G1、ZGC）要做的事情就是进行垃圾回收，可以采用标记清除算法、复制算法、标记整理算法、分代收集算法等。 1.判断垃圾的方法也可以问：如何判断对象仍然存活？对象什么时候可以被垃圾器回收？ 如果一个或多个对象没有任何的引用指向它了，那么这个对象现在就是垃圾，如果定位了垃圾，则有可能会被垃圾回收器回收。 通常有两种方式：引用计数算法（reference counting）和可达性分析算法。 引用计数法 每个对象有一个引用计数器，记录引用它的次数。当计数器为零时，对象可以被回收。 但无法解决循环引用问题。例如，两个对象互相引用，但不再被其他对象引用，它们的引用计数都不为零，因此不会被回收。 可达性分析算法 通过一组名为 “GC Roots” 的根对象，进行递归扫描。那些无法从根对象到达的对象是不可达的，可以被回收；反之，是可达的，不会被回收。 2.哪些对象可以作为GC Root**GC Roots就是对象，而且是JVM确定当前绝对不能被回收的对象(如方法区中类静态属性引用的对象 )**。只有找到这种对象，后面的搜寻过程才有意义，不能被回收的对象所依赖的其他对象肯定也不能回收嘛。 方法区中类静态属性引用的对象：全局对象的一种，Class对象本身很难被回收，回收的条件非常苛刻，只要Class对象不被回收，静态成员就不能被回收 方法区中常量引用的对象：也属于全局对象，例如字符串常量池，常量本身初始化后不会再改变，因此作为GC Roots也是合理的。 虚拟机栈(栈帧中的局部变量表) 中正在引用的对象：属于执行上下文中的对象，线程在执行方法时，会将方法打包成一个栈帧入栈执行，方法里用到的局部变量会存放到栈帧的本地变量表中。只要方法还在运行，还没出栈，就意味这本地变量表的对象还会被访问，GC就不应该回收，所以这一类对象也可作为GC Roots 本地方法栈中正在引用的对象：和上一条本质相同，无非是一个是Java方法栈中的变量引用，一个是native方法(C、C++)方法栈中的变量引用 被同步锁持有的对象：被synchronized锁住的对象也是绝对不能回收的，当前有线程持有对象锁呢，GC如果回收了对象，锁不就失效了嘛 3.finalize()方法的作用对象可以被回收，就代表一定会被回收吗？ 不一定 用一个不太贴切的比喻，垃圾回收就是古代的秋后问斩，finalize()就是刀下留人，在人犯被处决之前，还要做最后一次审计，青天大老爷看看有没有什么冤情，需不需要刀下留人。 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行 finalize()方法。如果对象在在 finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己 （this 关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它就”逃过一劫“；但是如果没有抓住这个机会，那么对象就真的要被回收了。 4.垃圾收集算法 标记-清除算法： 标记-清除算法分为“标记”和“清除”两个阶段，首先通过可达性分析，标记出所有需要回收的对象， 然后统一回收所有被标记的对象。 缺点：一个是效率问题，标记和清除的过程效率都不高 ；另一个就是，清除结束后会造成大量不连续的碎片空间。 复制算法：为了解决碎片空间的问题，出现了“复制算法”。 它把内存空间划为两个相等的区域，每次只使用其中一个区域（from区）。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域（to区）中，最后将当前区域（from）清空。 然后将两块区间的名字互换，即from区变to区，to区变from区，之后继续在from区创建对象 缺点：因为每次在申请内存时，都只能使用一半的内存空间。内存利用率严重不足。 标记-整理算法： 复制算法在 GC 之后存活对象较少的情况下效率比较高，但如果存活对象比较多时， 会执行较多的复制操作，效率就会下降。 标记-整理算法的“标记”过程与“标记-清除算法”的标记过程一致，但标记之后不会直接清理。 而是将所有存活对象都移动到内存的一端。移动结束后直接清理掉剩余部分。 缺点：由于多了整理这一步，因此效率也不高 分代回收算法： 年轻代通常使用复制算法，老年代使用标记-清除或标记-整理算法。 分代回收时，创建出来的对象，首先会被放入Eden伊甸园区。 eden[首次]满时，会触发垃圾回收，根据可达性判断存活的对象，将存活的对象复制到某个幸存区（假设为From区），同时Eden区清空。 当后续eden再满时，就会触发年轻代的GC，称为Minor GC或者Young GC。 Minor GC会把eden中和From需要回收的对象回收，把没有回收的对象放入To区。 然后交换from区和to区的名字，下次edan区满了还是放入from区，这个就是复制算法的“换名” 如果Minor GC后对象的年龄达到阈值（最大15，默认值和垃圾回收器有关），对象就会被晋升至老年代。 当老年代中空间不足，无法放入新的对象时，先尝试minor gc。如果还是不足，就会触发Full GC，涉及整个 Java 堆和方法区（或元空间）。它是最耗时的 GC，通常在 JVM 压力很大时发生。 5.为什么要分为新生代和老年代？首先我们要知道堆内存中对象的特性： 系统中的大部分对象，都是创建出来之后很快就不再使用可以被回收，比如用户获取订单数据，订单数据返回给用户之后就可以释放了。 老年代中会存放长期存活的对象，比如Spring的大部分bean对象，在程序启动之后就不会被回收了。 在虚拟机的默认设置中，新生代大小要远小于老年代的大小。 分代GC算法将堆分成年轻代和老年代主要原因有： 1、可以通过调整年轻代和老年代的比例来适应不同类型的应用程序，提高内存的利用率和性能。 2、新生代和老年代使用不同的垃圾回收算法，新生代一般选择复制算法，老年代可以选择标记-清除和标记-整理算法，由程序员来选择灵活度较高。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃 圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 3、分代的设计中允许只回收新生代（minor gc），如果能满足对象分配的要求就不需要对整个堆进行回收(full gc),STW时间就会减少。分代设计的核心思想，尽可能的做minor gc 不做full gc 6.CMS垃圾收集器CMS垃圾回收器关注的是系统的暂停时间，允许用户线程和垃圾回收线程在某些步骤中同时执行，减少了用户线程的等待时间。 以获取最短GC回收停顿时间为目标的收集器，具有高并发、低停顿的特点，采取标记——清除算法，回收老年代 工作步骤 初始标记： 短暂停顿（Stop-The-World，STW），标记直接与 GCRoots 相连的对象（根对象），该阶段需要STW，由于只标记直接引用的对象，这一阶段通常很快。 并发标记： 指的是对「初始标记阶段」标记的对 象进行整个引用链的扫描，该阶段与用户线程同时运行, 不需要STW 。因为是并发进行，应用线程可能修改对象图，导致标记可能不完全准确。 即： 并发标记的时候，引用可能发生变化，因此可能发生漏标（本应该回收的垃圾没有被回收）和多标（本不应该回收的垃圾被回收）了。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短，需要STW 并发清除：指的是将标记为垃圾的对象进行清 除，该阶段与用户线程同时运行,不需要STW 缺点： 无法处理在并发清理过程中产生的“浮动垃圾”， 不能做到完全的垃圾回收 它使用的回收算法“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 如果老年代内存不足无法分配对象，CMS就会退化成Serial Old单线程回收老年代。 7.G1收集器G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征。 同时注重吞吐量(Throughput)和低延迟 工作步骤： 初始标记： 短暂停顿，标记从 GC Roots 可直接引用的对象，即标记所有直接可达的活跃对象 并发标记：与应用并发运行，标记所有可达对象。 这一阶段可能持续较长时间，取决于堆的大小和对象的数量。 最终标记： 短暂停顿（STW），处理并发标记阶段结束后残留的少量未处理的引用变更。 筛选回收：根据标记结果，选择回收价值高的区域，复制存活对象到新区域，回收旧区域内存。这一阶段包含一个或多个停顿（STW），具体取决于回收的复杂度。 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。 特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 停顿时间可控： G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象。 CMS和G1的区别 6.Minor GC&#x2F;Young GC、Major GC&#x2F;Old GC、Mixed GC、Full GC 都是什么意思？ Minor GC 也称为 Young GC，是指发生在年轻代（Young Generation）的垃圾收集。年轻代包含 Eden 区以及两个 Survivor 区。 触发条件：当Eden区空间不足时，JVM会触发一次Minor GC， 将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代（Old Generation）。 Major GC 也称为 Old GC，主要指的是发生在老年代的垃圾收集。CMS 收集器的特有行为。 触发条件：当老年代空间不足时，或者系统检测到年轻代对象晋升到老年代的速度过快 ，可能会触发Major GC。 Mixed GC 是 G1 垃圾收集器特有的一种 GC 类型，它在一次 GC 中同时清理年轻代和部分老年代。 Full GC 是最彻底的垃圾收集，涉及整个 Java 堆和方法区（或元空间）。它是最耗时的 GC，通常在 JVM 压力很大时发生。 直接调用System.gc()或Runtime.getRuntime().gc()方法时， 虽然不能保证立即执行，但JVM会尝试执行Full GC。 Minor GC（新生代垃圾回收）时，如果存活的对象无法全部放入老年代 ，或者老年代空间不足以容纳存活的对象， 则会触发Full GC，对整个堆内存进行回收。 2.3.3、简述分代回收器怎么工作的？（分代收集算法） 分代回收器有两个分区：老生代和新生代，新生代和老生代空间占比是1：2 新生代使用的是复制算法，新生代里有 3 个分区：Eden（一den）、To 、From ，它们的默认占比是 8:1:1，它的执行流程如下： 把 Eden + From 存活的对象放入 To 区； 清空 Eden 和 From 分区； From 和 To 分区交换，From 变 To ，To 变 From 。 每次在 From 到 To 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。 老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"Redis","slug":"八股/Redis","date":"2024-10-28T12:14:56.000Z","updated":"2025-03-26T13:00:59.028Z","comments":true,"path":"2024/10/28/八股/Redis/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/Redis/","excerpt":"这里是Redis相关的八股","text":"这里是Redis相关的八股 Redis默认端口6379 1.基础1.Redis为什么快？ 内存操作：完全基于内存，绝大部分请求是纯粹的内存操作，非常快速 单线程模型：避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。 I&#x2F;O多路复用模型：采用了 I&#x2F;O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中， 同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 2.Redis有哪些数据类型？常用的使用场景 String：存储单个值，适用于缓存和键值存储，常用命令:SET用于设置值，GET用于获取值。 分布式锁、分布式Session、值缓存、浏览数、分库分表主键序列号 List：有序、可重复的字符串集合，适用于消息队列和发布&#x2F;订阅系统，常用命令:LPUSH用于从列表左侧添加元素，LRANGE用于获取指定范围的元素。 分布式Duque、消息队列、Push式信息流 Set：无序、不可重复的字符串集合，适用于标签系统和好友关系等，常用命令:SADD用于向集合添加成员，SMEMBERS用于获取集合所有成员。 点赞、抽奖、集合运算 Hash：包含键值对的无序散列表，适用于存储对象、缓存和计数器，常用命令:HSET用于设置字段值，HGETALL用于获取散列的所有字段和值。 购物车、对象存储 Zset：也就是Sorted Set，有序的字符串集合，每个成员关联一个分数，适用于排行榜和按分数范围获取成员，常用命令:ZADD用于添加成员及其分数，ZRANGE用于获取指定范围的成员， 热搜、最近播放 3.String还是Hash存储对象更好呢？性能 String：适合存储和读取大对象，因为它是整体操作，性能较高。 Hash：适合操作大量小字段，可以只处理需要的字段，减少不必要的数据传输。 内存 String：存储大对象时内存开销可能较大，尤其是对象频繁序列化和反序列化。 Hash：在存储大量小对象时更节省内存，因为字段共享同一个键名。 操作需求 String：如果对象不可变，或者总是整体读写，String更简单。 Hash：如果需要频繁访问或修改对象的某个字段，Hash更合适。 3.Redis可以用来做什么？ 缓存 排行榜 分布式计数器 分布式锁 消息队列 延时队列 分布式 token 限流 2.持久化什么是持久化？ 大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了做数据同步（比如 Redis 集群的主从节点通过 RDB 文件同步数据）。 Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制: 1.RDBRDB：是缩写快照 RDB(Redis DataBase)是Redis默认的持久化方式。将某一时刻的内存数据，以二进制的方式写入磁盘； 对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。 因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时 ，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。 为了解决这个问题，Redis 增加了 RDB 快照。 RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据 Redis 提供了两个命令来生成 RDB 快照文件： save:同步保存操作，会阻塞 Redis 主进程； bgsave:fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。 2.RDB写时复制（Copy-on-Write）假如RDB持久化过程中数据发生了改变怎么办？ 在 RDB 快照生成过程中，如果数据发生了改变，Redis 的处理机制可以保证快照的一致性，同时不会丢失后续的修改。具体来说，Redis 使用了一种叫做 Copy-on-Write（写时复制） 的技术来解决这个问题。 先回顾快照的生成过程： 当 Redis 触发 RDB 持久化时（比如通过 SAVE 或 BGSAVE 命令），它会创建一个子进程。 子进程负责将内存中的数据写入磁盘，生成 .rdb 文件。 主进程继续处理客户端的请求（比如读写操作）。 Copy-on-Write 机制 ： 在子进程生成快照时，它会基于某个时间点（触发快照的瞬间）的内存数据进行操作。 如果主进程在这期间修改了数据，操作系统会利用 写时复制： 被修改的数据会被复制一份，主进程在新副本上操作。 子进程仍然使用原始数据（未修改时的内存快照）生成快照。 这样，主进程的修改不会影响子进程正在生成的快照，快照仍然是触发时刻的一致性数据。 数据丢失风险：快照生成后到下一次快照之间的修改，如果没来得及保存（比如 Redis 崩溃），会丢失。 3.AOFAOF持久化(即Append Only File)，Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里， 然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。 AOF为什么是在执行完写命令才将该命令记录到AOF日志？ 避免额外的检查开销，AOF 记录日志不会对命令进行语法检查； 在命令执行完之后再记录，不会阻塞当前的命令执行。 潜在风险 如果刚执行完命令 Redis 就宕机会导致对应的修改丢失； 可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的，也就是说这两个操作是同步的，如果在将日志内容写入到硬盘时，服务器的硬盘的 I&#x2F;O 压力太大，就会导致写硬盘的速度很慢， 进而阻塞住了，也就会导致后续的命令无法执行。 优点：首先，AOF提供了更好的数据安全性，因为它默认每接收到一个写命令就会追加到文件末尾。 即使Redis服务器宕机，也只会丢失最后一次写入前的数据。 缺点：因为记录了每一个写操作，所以AOF文件通常比RDB文件更大，消耗更多的磁盘空间。 总结：RDB是Redis的快照持久化方式，通过周期性的快照将数据保存到硬盘，占用更少的磁盘空间和 CPU资源，适用于数据备份和恢复，但可能存在数据丢失的风险。AOF 是追加日志持久化方式，将每个写操作以追加的方式记录到日志文件中，确保了更高的数据完整性和持久性，但相对于RDB 消耗更多的磁盘空间和写入性能，适用于数据持久化和灾难恢复，且可以通过配置实现不同的同步频率。 4.如何选择1.RDB 缺点：周期性保存快照，但如果下次快照前宕机，会丢失数据很多 优点：保存的是原始数据，恢复起来比AOF更快（因为AOF保存的是命令还要执行）；文件小，适合做数据的备份，灾难恢复。 2.AOF 缺点：恢复慢 优点：数据更加完整（即使Redis服务器宕机，也只会丢失最后一次写入前的数据） 建议开启混合模式 3.Redis内存管理1.过期键的删除策略有哪些 定时过期（CPU不友好，内存友好）：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期（CPU友好，内存不友好）：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 定期过期（前两种的折中）：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 Redis key的过期时间和永久有效分别怎么设置 expire命令和persist命令 2.内存淘汰粗略有哪些 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？ redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 全局的键空间选择性移除 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 设置过期时间的键空间选择性移除 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，挑选将要过期的数据淘汰。 4.缓存篇1.缓存一致性方案 1、Cache Aside Pattern （旁路缓存模式，双写模式） 对于读：从缓存中读取，如果读不到，就从数据库中读取，并把这个数据写入缓存 对于写：先更新数据库，然后直接删除缓存 为什么不是采用更新缓存模式，而是采用删除缓存？ 答：可能会造成无效写操作。如果更新的缓存很多，但这期间并没有查询操作，就造成了无效的写操作 为什么先更新数据库，而不是先删除缓存，再更新数据库？ 答：因为数据不一致。写线程A删除了缓存，但还没来得及更新数据库，此时，读线程B未命中缓存，去数据库读取旧数据，并写入缓存返回了，然后线程A更新了数据库中的数据，此时就数据不一致了。在这个过程中，写线程更新数据库的时间都比读线程读数据库+写回Redis的时间长了，所以非常有可能发生数据不一致 采用先更新数据库，再删除缓存就没有问题了吗？ 答：也有可能会有问题，但概率会小的多！只有这种恰巧的情况：读线程读的时候缓存失效了，而且就在它访问完数据库之后，准备写回缓存之前，这是写线程一口气执行完了更新数据库和删缓存这两个操作，然后读线程把旧的数据写回了缓存。但这种可能性很低，因为一般来说更新数据库是非常耗时的。 问题3如何解决？ 答：延迟双删。在读线程把旧数据写回缓存后，然后写线程隔一小段时间再把这个缓存给删了，就是写线程要删除两次缓存。或者消息队列（TODO） 2、Read&#x2F;Write Through Pattern（读写穿透，直写缓存模式 ，写穿） 在此模式下，所有写操作都会先更新缓存，然后再同步更新数据库。 对于读：从缓存中读取，如果读不到，从数据库中读取，然后写回cache后再返回（和双写模式一样） 对于写：先查缓存，缓存中没有就直接更新数据库，缓存中有，先更新缓存，再接着更新数据库。 3、Write behind Pattern（异步缓存写入，异步写） 写操作只更新缓存，不立即同步到数据库，而是延迟批量更新数据库。 对于读：和双写模式一样 对于写：只更新缓存，然后异步的更新数据库，可以将更新数据库的任务交给消息队列或者线程池 Read&#x2F;Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。 很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。 这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。 Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。 三种模式比较 三者读性能一样的，主要区别就是写性能 旁路缓存模式：高并发场景可能存在短暂数据不一致。适合读操作频繁、写操作较少且数据一致性要求高的场景，例如用户信息、商品详情查询等。 写穿模式：写入最慢，一致性最好。适合数据一致性要求较高的场景，例如金融交易系统。 异步写模式：写入最快，一致性最差。适合写操作频繁、对一致性要求不高且容忍一定延迟的场景，例如日志系统、计数统计等。 2.缓存穿透缓存和数据库中都没有用户要访问的数据，当有大量这样的请求到来时，数据库的压力骤增 ，造成数据库短时间内承受大量请求而崩掉。 解决方案： 非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在， 如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 缓存空值或者默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据， 在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值， 返回给应用，而不会继续查询数据库。 这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。 布隆过滤器：我们可以在写入数据库数据时，使用布隆过滤器做个标记， 然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在， 如果不存在，就不用通过查询数据库来判断数据是否存在。即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行 3.布隆过滤器布隆过滤器主要是为了解决海量数据的存在性问题。对于海量数据中判定某个数据是否存在且容忍轻微误差这一场景（比如缓存穿透、海量数据去重）来说，非常适合。 布隆过滤器由一个二进制数组和多个哈希函数组成 开始时，布隆过滤器的每个位都被设置为 0。 当一个元素被添加到过滤器中时，它会被 k 个哈希函数分别计算得到 k 个位置，然后将位数组中对应的位设置为 1。 当检查一个元素是否存在于过滤器中时，同样使用 k 个哈希函数计算位置，如果任一位置的位为 0，则该元素肯定不在过滤器中；如果所有位置的位都为 1，则该元素可能在过滤器中。 为什么会误判？ 当布隆过滤器保存的元素越多，被置为 1 的 bit 位就会越多。假设元素 x 没有存储过，但其他元素的哈希函数映射到位数组的三个位刚好都为 1 且恰好覆盖了元素 x 映射的位置，那么对于布隆过滤器来讲，元素 x 这个值就是存在的，也就是说布隆过滤器存在一定的误判率。 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。 4.缓存击穿缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 解决方案： 互斥锁方案（看情况）：保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求， 要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 永不过期（不推荐）：设置热点数据永不过期或者过期时间比较长。 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 5.缓存雪崩当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求， 都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增， 严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃， 解决方案： 针对 Redis 服务不可用的情况： Redis 集群：采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster 和 Redis Sentinel 是两种最常用的 Redis 集群实现方案 多级缓存：设置多级缓存，例如本地缓存+Redis 缓存的二级缓存组合，当 Redis 缓存出现问题时，还可以从本地缓存中获取到部分数据。 针对大量缓存同时失效的情况： 设置随机失效时间（可选）：为缓存设置随机的失效时间， 这样可以避免大量缓存同时到期，从而减少缓存雪崩的风险。 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 设置缓存锁:在缓存失效时，设置一个短暂的锁定时间，只允许一个请求查询数据库并刷新缓存，其他请求等待锁释放后再读取缓存。 6.大Key问题 什么是大key？ Redis大key问题指的是某个key对应的value值所占的内存空间比较大， bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。 bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。 如何找到大key？ 1、使用 Redis 自带的 –bigkeys 参数来查找。 如何处理大key？ 分割 bigkey：将一个 bigkey 分割为多个小 key。 例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。 删除大 key：Redis 4.0以上可以使用 UNLINK 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 SCAN 命令结合 DEL 命令来分删除。 7.热Key 什么是热key？ 如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey（热 Key）。例如在 Redis 实例的每秒处理请求达到 5000 次，而其中某个 key 的每秒访问量就高达 2000 次，那这个 key 就可以看作是 hotkey。 处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。 此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。 这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。 hotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。 如何找到热key？ 使用 Redis 自带的 –hotkeys 参数来查找。 如何处理大key？ 读写分离：主节点处理写请求，从节点处理读请求。 使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。 8.缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 常见的缓存预热方式有两种： 使用定时任务，比如 xxl-job，来定时触发缓存预热的逻辑，将数据库中的热点数据查询出来并存入缓存中。 使用消息队列，比如 Kafka，来异步地进行缓存预热，将数据库中的热点数据的主键或者 ID 发送到消息队列中，然后由缓存服务消费消息队列中的数据，根据主键或者 ID 查询数据库并更新缓存。 5.底层结构String——动态字符串SDS List——双向链表 Set——哈希表 主要是ZSet的底层数据结构实现——跳表 1.SDSRedis 是用 C 语言实现的，但其String类型是采用了一个叫做简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串。 为什么不用C语言中的字符串呢？ 获取字符串长度的时间复杂度为 O（N）； 字符串的结尾是以 “\\0” 字符标识，这就要求字符串里面不能包含有 “\\0” 字符， 因此不能保存二进制数据； 字符串操作函数不高效且不安全， 比如有缓冲区溢出的风险，有可能会造成程序运行终止； 例：strcat 函数是可以将两个字符串拼接在一起。 C 语言的字符串是不会记录自身的缓冲区大小的， 所以 strcat 函数假定程序员在执行这个函数时，已经为拼接的字符串分配了足够多的内存，而如果没有，就会发生溢出 SDS结构 引入了len，alloc，flags解决了C语言字符串的问题 len，记录了字符串长度。 获取字符串长度 时间复杂度只需要 O（1）。 alloc，分配给字符数组的空间长度。 这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。 flags，用来表示不同类型的 SDS。 能灵活保存不同大小的字符串，从而有效节省内存空间。 buf[]，字节数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。 2.双向链表 优点： listNode 链表节点的结构里带有 prev 和 next 指针， 获取某个节点的前置节点或后置节点的时间复杂度只需O(1)， list 结构因为提供了表头指针 head 和表尾节点 tail， 所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**； list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**； 缺点： 链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存。 能很好利用 CPU 缓存的数据结构就是数组， 因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。 3.压缩列表ZipList压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构， 有点类似于数组。 压缩列表在表头有三个字段： zlbytes，记录整个压缩列表占用的内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址有多少字节， 也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。 压缩列表解决了双向列表内存碎片的问题，因为双向链表每个节点存放在内存中不连续的位置。另外，ziplist 为了在细节上节省内存，对于值的存储采用了 变长编码方式， 大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。 压缩列表的缺点是会发生连锁更新的问题，因此连锁更新一旦发生， 就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。 因此，压缩列表只会用于保存的节点数量不多的场景， 只要节点数量足够小，即使发生连锁更新，也是能接受的。 4.哈希表dictionary 字典 dict 哈希表结构，哈希冲突，链式哈希这些都不说了，比较熟悉了，下面是不太熟悉的 1.rehash 也就是哈希表的扩容（不过注意处理哈希冲突有个再哈希法，那个意思是再用另一个哈希函数计算要插入的位置），一图说明 原哈希表的数据迁移到新的哈希表（长度是原来的2倍） 迁移完成后，释放原哈希表的空间，并让新哈希表指向原哈希表的地址 这样有个问题，就是如果哈希表数据过多，在迁移的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。 所以引出了渐进式hash 2.渐进式hash 渐进式hash把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中， 避免了一次性 rehash 的耗时操作。 为了支持渐进式重哈希，Redis 的 dict 结构包含两个哈希表： **ht[0]**：当前正在使用的哈希表。 **ht[1]**：用于重哈希的目标哈希表（初始为空）。 渐进式 rehash 步骤如下： 哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找， 如果没找到，就会继续到哈希表 2 里面进行找到。 在渐进式 rehash 进行期间，新增一个 key-value 时， 会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作， 这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成， 最终「哈希表 1 」就会变成空表。 3.rehash触发条件 和负载因子有关。负载因子 &#x3D; 哈希表已经保存的节点数&#x2F;哈希表大小 *当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 写的时候，就会进行 rehash 操作。 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了， 不管有没有有在执行 RDB 快照或 AOF 重写， 都会强制进行 rehash 操作。 5.整数集合intset 是一个由整数组成的 有序集合，从而便于在上面进行二分查找，用于快速地判断一个元素是否属于这个集合。 它在内存分配上与 ziplist 有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。 对于小集合使用 intset 来存储，主要的原因是节省内存。特别是当存储的元素个数较少的时候， dict 所带来的内存开销要大得多（包含两个哈希表、链表指针以及大量的其它元数据）。所以，当存储大量的小集合而且集合元素都是数字的时候，用 intset 能节省下一笔可观的内存空间。 实际上，从时间复杂度上比较， intset 的平均情况是没有 dict 性能高的。以查找为例，intset 是 OO(lgn) 的，而 dict 可以认为是 O(1) 的。但是，由于使用 intset 的时候集合元素个数比较少，所以这个影响不大。 6.跳表链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N) ，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表， 这样的好处是能快读定位数据。 6.Redis线程模型1.单线程模型 如果仅仅聊Redis的核心业务部分(命令处理)，答案是单线程 如果是聊整个Redis，那么答案就是多线程 Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。 但是在其他模块，比如：持久化，会使用多个线程。 Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 文件事件处理器如下： 文件事件处理器的结构包含 4 个部分： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 2.为什么Redis单线程模型也能效率这么高？抛开持久化不谈，Redis是纯内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。 纯内存操作 避免多线程频繁的上下文切换开销，以及并发加锁开销 IO多路复用模型，允许同时监听多个socket 7.高可用1.主从复制为了应对并发能力问题，可以搭建主从集群，实现读写分离，Redis大多都是读多写少的场景 多台服务器要保存同一份数据，这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？ Redis 提供了主从复制模式，来避免上述的问题。 第一次同步——全量同步 如何确定主从关系？比如想让服务器B变成服务器A的从服务器 12# 服务器 B 执行这条命令replicaof &lt;服务器 A 的 IP 地址&gt; &lt;服务器 A 的 Redis 端口号&gt; 在介绍第一次同步的过程之前，需要先介绍两个参数 从服务器就会给主服务器发送 sync 命令，表示要进行数据同步。 sync 命令包含两个参数 ，可以判断从服务器是否第一次来同步数据 Replicationld：简称replid，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。 从服务器会继承主服务器的replid offset：偏移量，表示复制的进度，随着记录在repl_baklog中的数据增多而逐渐增大。主节点用offset记录自己写的位置，从节点用offset记录自己读的位置。slave完成同步时也会记录当前同步的offset。 如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。 全量同步的流程如下： slave节点发送sync请求，表示要进行数据同步 master将执行 bgsave 命令（异步，不会阻塞主线程）生成RDB，发送RDB到slave。 slave清空本地数据，加载master的RDB master将生成RDB期间、发送RBD期间的命令记录在replication_backlog_buffer，并持续将log中的命令发送给slave slave执行接收到的命令，保持与master之间的同步 至此，主从服务器的第一次同步的工作就完成了。 断开后的同步——增量同步 从节点断开后重启，采用增量同步 repl_backlog_buffer，是一个「环形」缓冲区， 用于主从服务器断连后，从中找到差异的数据； slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave repl_baklog大小有上限，是一个环形区域，写满后会覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。 因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该设置repl_backlog_buffer 缓冲区尽可能的大一些， 减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。 主从复制的作用 ①、数据冗余： 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 ②、故障恢复： 如果主节点挂掉了，可以将一个从节点提升为主节点，从而实现故障的快速恢复。 通常会使用 Sentinel 哨兵来实现自动故障转移，当主节点挂掉时，Sentinel 会自动将一个从节点升级为主节点，保证系统的可用性。 假如是从节点挂掉了，主节点不受影响，但应该尽快修复并重启挂掉的从节点，使其重新加入集群并从主节点同步数据。 ③、负载均衡： 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 ，分担服务器负载。尤其是在读多写少的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。 ④、高可用基石： 除了上述作用以外，主从复制还是哨兵和集群能够实施的 基础。 2.哨兵（Sentinel）机制用于监控主节点和从节点的状态，实现自动故障转移。如果主节点发生故障，哨兵可以自动将一个从节点升级为新的主节点。 故障转移整体流程：监控——主观下线——客观下线——（哨兵集群）选举Leader——故障转移 为什么要有哨兵机制？ 主节点如果要是挂了，就没办法接收写操作了。而哨兵本身是一个独立运行的进程，它能监控多个节点，发现主节点宕机后能进行自动切换。 哨兵的三个作用（功能） 集群监控：负责监控 Redis Master 和 Slave 进程是否正常工作 故障转移：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主 通知： Sentinel充当Redis客户端（比如RedisTemplate）的服务发现来源，当集群发生故障转移时，通知 client 客户端新的 Master 地址。 如何判断节点是否故障？ Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令 主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。 客观下线：若超过指定数量(quorum)的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令， 其他哨兵收到这个命令后，就会根据自身和主节点的网络状况， 做出赞成投票或者拒绝投票的响应。 由哪个哨兵进行主从故障转移？哨兵选举Leader 每个哨兵都有可能成为leader，它会先向其他哨兵拉票，当一个哨兵收到一个投票时，如果还没有投票，就可以投出去一票，否则就拒绝投票。当哪个哨兵的票数超过了哨兵总数目&#x2F;2 + 1，就是新的leader 选出新的主节点的规则？ 首先要把网络状态不好的从节点给过滤掉。然后对所有从节点进行三轮考察：优先级、复制进度、ID 号。 优先级最高的从节点胜出 节点的offset值（反映了复制进度）越大说明数据越新，优先级越高 从节点的ID大小，越小优先级越高。 故障转移的过程？ 选出一个新的主节点 让旧主节点的从节点成为新主节点的从节点，开始从新的主节点同步数据 将新主节点信息，通知给客户端（通过 Redis 的发布者&#x2F;订阅者机制来实现） 继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点 TODO 脑裂Sentinel 可以防止脑裂吗？（在小林”主从复制是怎么实现的“那里最后有提到脑裂，可结合gpt看看） 3.分片集群（Cluster ）最少三主三从 Redis 集群通过分片的方式存储数据，每个节点存储数据的一部分，用户请求可以并行处理。集群模式支持自动分区、故障转移，并且可以在不停机的情况下进行节点增加或删除。 Redis Cluster 功能强大，直接集成了 主从复制 和 哨兵 的功能。 核心概念 数据分片： Redis集群将整个数据集划分为 16384个哈希槽（slots）。每个键通过哈希计算被分配到一个特定的槽位，而这些槽位由集群中的节点负责管理。这样的设计使得数据可以均匀分布在多个节点上。 重定向机制：客户端可以向集群中的任意节点发送请求。如果请求的键所在的槽位不由当前节点负责，该节点会返回一个重定向响应，告诉客户端应该联系哪个节点。这种机制确保客户端最终能访问到正确的节点。 主从复制与高可用性： Redis集群支持主从复制。每个槽位可以有一个主节点和多个从节点。主节点负责处理写请求。 从节点负责处理读请求，并在主节点故障时作为备份。 当主节点发生故障时，集群会自动从其从节点中选举一个新的主节点接管服务，从而保证高可用性。 故障转移 ：Redis集群使用一种类似于Raft的共识算法来实现故障转移。当主节点不可用时，集群会自动检测并将某个从节点提升为主节点，确保服务的连续性。 动态伸缩 ：Redis集群支持在线添加或删除节点，允许在不中断服务的情况下扩展存储容量和处理能力。 散列插槽 Redis集群将整个数据集划分为 16384个哈希槽（slots）。这些槽被Redis节点共同负责，每个节点负责一部分。对key计算 CRC16 值 （也就是哈希值），然后用这个值对16384取余，可以得到这个key对应的哈希槽，然后去对应的Redis节点找数据 如果请求的键所在的槽位不由当前节点负责，该节点会返回一个重定向响应，告诉客户端应该联系哪个节点。 集群伸缩 集群扩容和缩容的关键，在于槽和节点之间的对应关系。 当需要扩容时，新的节点被添加到集群中，集群会自动执行数据迁移，以重新分布哈希槽到新的节点。数据迁移的过程可以确保在扩容期间数据的正常访问和插入。 当数据正在迁移时，客户端请求可能被路由到原有节点或新节点。 如果请求被路由到正在迁移数据的哈希槽，Redis Cluster 会返回一个 MOVED 响应，指示客户端重新路由请求到正确的目标节点。这种机制也就保证了数据迁移过程中的最终一致性。 当需要缩容时，Redis 集群会将槽从要缩容的节点上迁移到其他节点上，然后将要缩容的节点从集群中移除。 Redis Cluster 中的节点是怎么进行通信的 Redis Cluster 支持重新分配哈希槽吗？ 7.场景1.分布式锁一个最基本的分布式锁需要满足： 互斥：任意一个时刻，锁只能被一个线程持有。 高可用：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过超时机制实现的。 可重入：一个节点获取了锁之后，还可以再次获取锁。 除了上面这三个基本条件之外，一个好的分布式锁还需要满足下面这些条件： 高性能：获取和释放锁的操作应该快速完成，并且不应该对整个系统的性能造成过大影响。 非阻塞：如果获取不到锁，不能无限期等待，避免对系统正常运行造成影响。 使用Redis命令设计的基础分布式锁 setnx ex，这样可以设置一个简单的分布式锁，setnnx是如果key不存在，则创建key，否则失败；而ex则给这个key设置了过期时间，避免锁无法释放。 而且Redis的命令都是原子性的，这样就保持了获得锁和设置过期时间是一起操作的 对于自己设计的分布式锁，如果要保证判断该锁是否为自己的和释放锁这两个操作为原子操作，就需要用Lua脚本。释放锁的时候判断是否与获得锁的线程id一样 Redisson Redisson 是一个开源的 Java 语言 Redis 客户端，提供了很多开箱即用的功能，不仅仅包括多种分布式锁的实现。 而redisson不仅实现了上述功能，还更为强大，有以下功能： 自动续期 读写锁 公平锁 下面介绍redisson原理 加锁 key是锁的名称，value是个map，map的key是线程id，value是锁的重入次数，然后设置锁过期时间 如果加锁成功，锁的重入次数加一，这就实现了重入锁的功能； 加锁成功后，就会执行一个看门狗的机制。看门狗机制是为了防止业务还没执行完，但锁到期了的问题。看门狗就是一个定时任务，只要当前线程任务没有挂掉，且没有主动释放锁，就会隔一段时间给锁续期。默认情况下，每过 10 秒，看门狗就会执行续期操作，将锁的超时时间设置为 30 秒。 如果失败，返回锁的过期时间 加锁失败后，会进入一个循环中，此线程会被semaphore阻塞，当之前的线程释放锁后，会通过semaphore来唤醒此线程，然后获得锁后跳出此循环 释放锁时，如果该锁的线程id不是自己的，就无权释放；如果是，就将重入次数减一，如果减后的重入次数还是＞0，就不能释放，更新锁到期时间，否则就释放锁，然后发送锁释放消息，唤醒被阻塞的线程 无论加锁成功或失败，都会有一个future结果器来接收加锁结果 2.如何设计一个秒杀场景","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Mysql","slug":"八股/Mysql","date":"2024-10-28T12:14:46.000Z","updated":"2025-05-24T00:33:48.563Z","comments":true,"path":"2024/10/28/八股/Mysql/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/Mysql/","excerpt":"这里是数据库MYSQL的一些八股知识","text":"这里是数据库MYSQL的一些八股知识 MySQL默认端口3306 1.基础知识1.MyISAM与InnoDB区别存储引擎（Storage Engine）是用来定义数据表如何存储、读取、管理和处理数据的底层机制。换句话说，存储引擎决定了 MySQL 如何在物理层面上存储数据、如何建立索引、如何执行查询，以及支持哪些特性（如事务、锁机制等）。不同的存储引擎适用于不同的应用场景，因此 MySQL 支持多种存储引擎，用户可以根据需求选择合适的存储引擎。 如果没有特别的需求，使用默认的Innodb即可 1、是否支持行级锁 MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。 2、是否支持事务 MyISAM 不提供事务支持。 InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。 3、索引结构 MyISAM是非聚簇索引，而InnoDB有聚簇索引，聚簇索引的查找效率更高 4、是否支持数据库异常崩溃后的安全恢复 MyISAM 不支持，而 InnoDB 支持。 使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。 2.执行一条SQL请求的过程 Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。 存储引擎：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。 MySQL 服务器的连接器开始处理这个请求，主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作 分析器开始对 SQL 语句进行解析，检查语句是否符合 SQL 语法规则，确保引用的数据库、表和列都存在，并处理 SQL 语句中的名称解析和权限验证。 优化器负责确定 SQL 语句的执行计划，这包括选择使用哪些索引，以及决定表之间的连接顺序等。优化器会尝试找出最高效的方式来执行查询。 执行器首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。 ps：如果是一条更新语句，略有一点不同： 执行更新的时候肯定要记录日志啦，这就会引入日志模块了 ，MySQL 自带的日志模块是 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志） 前面的大致都类似 事务：在准备更新记录之前会记录undolog，用于失败回滚和MVCC（支持其它事务读取旧版本） prepare阶段： 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 第三步和第四步也就是“两阶段提交” 3.三大范式 第一范式：要求数据库表的每一列都是不可分割的原子数据项。 第二范式：在 1NF 的基础上，要求数据库表中的每一列都和主键直接相关，而不能只与主键的某一部分相关（主要针对联合主键）。 比如说在一个订单表中，可能会存在订单编号和商品编号，设计出来的表可能是这样的。 这个订单表中就存在冗余数据，比如说商品名称、单位、商品价格等，应该将其拆分为订单表、订单商品关联表、商品表。 这个订单表中就存在冗余数据，比如说商品名称、单位、商品价格等，应该将其拆分为订单表、订单商品关联表、商品表。 第三范式：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖），第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 4.表连接 内连接：返回两个表中有匹配关系的行 。相当于取交集 外连接：仅返回两个表中匹配的行，还返回左表、右表或两者中未匹配的行。 左连接：以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN 右连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN 交叉连接（得到笛卡尔积）：返回第一个表中的每一行与第二个表中的每一行的组合，这种类型的连接通常用于生成笛卡尔积。 5.IN和EXIT的区别IN 和 EXISTS 都是用来处理子查询的关键词， 但它们在功能、性能和使用场景上有各自的特点和区别。 1.基本概念和执行逻辑 IN 用于判断某个字段值是否存在于子查询返回的结果集中，其执行逻辑是先执行子查询，生成一个临时结果集，再与外部查询进行匹配。 EXISTS 则采用半连接（Semi-Join）机制，通过布尔判断检查子查询是否返回至少一行数据，其执行逻辑是逐行遍历外部查询，每次检查子查询是否存在匹配。 2.性能差异和适用场景 当子查询结果集较小时，IN 的性能通常更好，因为临时结果集可以高效缓存（加载内存）。 而当外部查询结果集较小且子查询关联字段有索引时，EXISTS 更具优势，因为它能利用索引快速短路判断（一旦匹配即停止扫描）。 3.NULL 值处理 NULL值处理：IN 能够正确处理子查询中包含NULL值的情况， IN 对 NULL 值的处理遵循三值逻辑（TRUE&#x2F;FALSE&#x2F;UNKNOWN），若子查询结果包含 NULL 且未匹配到非 NULL 值，则返回 UNKNOWN（等效于 FALSE）。 而EXISTS 不受子查询结果中NULL值的影响，因为它关注的是行的存在性，而不是具体值。 6.NULL和&#39;&#39;的区别也可以这样问：为什么 MySQL 不建议使用 NULL 作为列默认值？ NULL的值不确定：NULL 代表一个不确定的值，就算是两个 NULL,它俩也不一定相等。例如，SELECT NULL=NULL的结果为 false，但是在我们使用DISTINCT,GROUP BY,ORDER BY时,NULL又被认为是相等的。 占用空间：&#39;&#39;的长度是 0，是不占用空间的，而NULL 是需要占用空间的。 NULL 会影响聚合函数的结果。例如，SUM、AVG、MIN、MAX 等聚合函数会忽略 NULL 值。 COUNT 的处理方式取决于参数的类型。如果参数是 *(COUNT(*))，则会统计所有的记录数，包括 NULL 值；如果参数是某个字段名(COUNT(列名))，则会忽略 NULL 值，只统计非空值的个数。 查询 NULL 值时，必须使用 IS NULL 或 IS NOT NULLl 来判断，而不能使用 &#x3D;、!&#x3D;、 &lt;、&gt; 之类的比较运算符。而&#39;&#39;是可以使用这些比较运算符的。 7.char和varchar的区别1.存储方式与空间占用 CHAR 是定长字符串，无论实际存储内容长度如何，都会占用定义时的固定空间（不足部分用空格填充）。 VARCHAR 是变长字符串，仅占用实际内容长度 + 1-2 字节的长度标识位，空间利用率更高。 2.性能差异 CHAR 由于长度固定，读写速度通常略快于 VARCHAR，适合存储长度高度一致的数据（如 MD5 哈希值、固定编码等） VARCHAR 在频繁更新且长度变化较大的场景下可能产生碎片，但节省存储空间，适合长度波动大的数据（如用户昵称、地址等）。 3.尾部空格处理 CHAR 在存储时会自动填充尾部空格，读取时移除填充的空格。 VARCHAR 保留原始空格，不会自动填充或截断。例如 &#39;abc &#39; 存入 CHAR(5) 后读取为 &#39;abc&#39;，而存入 VARCHAR(5) 仍为 &#39;abc &#39;。 CHAR 在存储时会在右边填充空格以达到指定的长度，检索时会去掉空格； 8.union和unionAll的区别 如果使用 UNION，会在表链接后筛选掉重复的记录行 如果使用 UNION ALL，不会合并重复的记录行 从效率上说，UNION ALL 要比 UNION 快很多，如果合并没有刻意要删除重复行，那么就使用 UNION All 9.MySQL数据的存储形式MySQL 是以表的形式存储数据的，而表空间的结构则由段、区、页、行组成。 表——段——区——页——行（记录） 10.MySQL查询语句的执行顺序MySQL 在执行查询时，并不是按照编写顺序一步步执行，而是遵循以下逻辑顺序： FROM - 确定数据来源，首先加载主表。 JOIN - 执行表关联操作（如 INNER JOIN、LEFT JOIN 等），生成中间结果集。 WHERE - 根据条件过滤行，缩小结果集。 GROUP BY - 将数据按指定列分组。 HAVING - 对分组后的数据进行过滤。 SELECT - 选择要输出的列或计算表达式。ORDER BY - 对结果集进行排序。 LIMIT - 限制最终输出的行数。 FROM——JOIN——WHERE——GROUP BY——HAVING——SELECT——ORDER BY——LIMIT 2.索引对于这样一张表 它的索引结构如下所示（其中叶子节点是双链表连接） 1.索引的种类 从数据结构角度 B数索引：MySQL 里默认和最常用的索引类型。只有叶子节点存储 value，非叶子节点只有指针和 key。 Hash索引：类似键值对的形式，一次即可定位。 优点是插入很快，缺点是无法做区间查询。适用于只有等值查询的场景 数组：优点是查询效率很快，在等值查询和范围查询场景中的性能就都非常优秀，缺点是插入比较麻烦。只适用于静态存储引擎 ，也就是后续数据基本不会变动 从物理存储角度 聚簇索引和非聚簇索引的区别在于索引和数据行的存储方式。聚簇索引将索引和数据行存储在一起，而非聚簇索引将索引和数据行分开存储。 聚簇索引：聚簇索引是一种索引组织方式，它将索引和数据行存储在一起，即数据行按照索引的顺序存储在磁盘上。聚簇索引的叶子节点保存的是完整的数据行，因此不需要进行额外的查找操作就可以获取到所需的数据。InnoDB 中的主键索引就属于聚簇索引。 非聚簇索引：它将索引和数据行分开存储，即索引保存了指向数据行的指针（通常是行的物理地址或主键值）。非聚簇索引的叶子节点保存的是指向数据行的引用，当查询需要获取数据时，首先根据索引查找到相应的行指针，然后再通过行指针获取数据行。 MyISAM 存储引擎的索引通常是非聚簇索引。 从逻辑角度 主键索引：数据列不允许重复，不允许为NULL，一个表只能有一个主键。 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。关键字UNIQUE 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 普通索引：基本的索引类型，没有唯一性的限制，允许为NULL值。 可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建联合索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一联合索引 在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引： 如果有主键，默认会使用主键作为聚簇索引的索引键（key）； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）； 其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。 主键索引的 B+Tree 和二级索引的 B+Tree 区别如下： 主键索引的 B+Tree 的叶子节点存放的是实际数据， 所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 2.回表查询在使用非聚簇索引查询数据时，如果需要查的数据是主键之外的数据，在查到主键之后然后回到主键索引再查一次，这个就叫回表查询。 对于非聚簇索引，一定会回表查询吗？ 不一定。试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。 这种情况就称之为索引覆盖。 举个例子，这是二级索引的查找过程 将商品表中的 product_no （商品编码）字段设置为二级索引， 那么二级索引的 B+Tree 如下图 其中非叶子的 key 值是 product_no（图中橙色部分）， 叶子节点存储的数据是主键值（图中绿色部分）。 如果我用 product_no 二级索引查询商品，如下查询语句： 1select * from product where product_no = &#x27;0002&#x27;; 会先检二级索引中的 B+Tree 的索引值(商品编码，product no)找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据。 不过，当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到， 这时就不用再查主键索引查，比如下面这条查询语句： 1select id from product where product_no = &#x27;0002&#x27;; 这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」 ，也就是只需要查一个 B+Tree 就能找到数据。 3.索引底层原理MySQL的索引底层结构是 B+树。 B+树是一种平衡多路查找树，具有以下特点: 所有关键字保存在叶子节点，并且叶子节点之间通过链表连接，形成一个有序的叶子节点序列。 非叶子节点只存储索引字段的值和子节点的指针，不保存实际的数据。这样可以使得一个节点可以存储更多的关键字，减少了树的高度，加快搜索速度。 叶子节点包含所有索引字段的值和指向对应数据的指针。 在 B+树索引中，每个节点的大小是固定的，与磁盘页的大小相当。节点的大小通常是数据库页的大小例如16KB或 32KB。每个节点可以存储多个关键字和指针。叶子节点的关键字是有序的，且通过链表连接在一起。 索引查询快的原因有以下几点: 路径长度短:B+树具有平衡性，所有叶子节点的深度相同，因此在查询过程中只需要沿着树的高度进行几次磁盘 &#x2F;&#x2F;O 操作，所以查询速度较快。 顺序访问优势:B+树的叶子节点之间使用链表连接，并且叶子节点的关键字是有序的，因此对于范围查询操作，可以通过顺序扫描叶子节点来获取有序的数据结果，提高查询速度。 最小化磁盘I&#x2F;0 操作:B+树具有较高的填充因子，每个磁盘页上存储的关键字数量较多，能够减少磁盘 I&#x2F;0 操作的次数，提高查询效率。 综上所述，B+树的平衡性、有序的叶子节点、顺序访问以及最小化的磁盘!&#x2F;0 操作是使得索引查询快速的关键因素。通过 B+ 树的数据结构和索引的建立，可以大幅度减少磁盘访问次数，提高数据库查询的效率。 简答：索引底层原理使用了 B+树数据结构，它是一种平衡树，能快速定位和检索数据。B+树的叶子节点存储实际数据，中间节点存储索引，通过减少磁盘I&#x2F;O来提高查询效率;索引按照值的大小顺序排列，使得范围查询效率更高。 4.为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？（TODO要设计一个适合 MySQL 索引的数据结构，至少满足以下要求： 能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作； 要能高效地查询某一个记录，也要能高效地执行范围查找； 1、B+Tree vs B Tree 在B+树中，数据都存储在叶子节点上，而非叶子节点只存储索引信息；而B树的非叶子节点既存储索引信息也存储部分数据。 另外，B+Tree 叶子节点采用的是双链表连接，适合 MSQL 中常见的基于范围的顺序查找，而B树无法做到这一点。 B+树的查找性能更稳定，每次查找都需要查找到叶子节点;而B树的查找可能会在非叶子节点找到数据，性能相对不稳定。 B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B树更「矮胖」，查询底层节点的磁盘 &#x2F;O次数会更少。 B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 &#x2F;0 操作，范围查询效率不如 B+ 树。 2、B+Tree vs 二叉树 普通二叉树存在退化的情况，如果它退化成链表，就相当于全表扫描。 5.最左匹配原则MySQL联合索引遵循最左前缀匹配原则，即最左优先，查询的时候会优先匹配最左边的索引。例如当我们在 (a,b,c)三个字段上创建联合索引时，实际上是创建了三个索引，分别是(a)、(a,b).(a,b,c)。 mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的 建立(a,b,c,d)的索引，可以支持以下前缀索引的查询 (a) (a, b) (a, b, d) (a, b, d, c) 需要注意的是，因为有查询优化器，对于 c &#x3D; ? AND d &#x3D; ? AND b &#x3D; ? AND a &#x3D; ? 会被优化器重新排列为abcd的顺序，也就是仍然可以使用索引。查询条件中的列顺序并不重要，查询优化器会自动优化重新排列 比如，将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name) ，它的B+树示意图如下： 可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product no 字段比较，在 product no 相同的情况下再按 name 字段比较。 也就是说，联合索引查询的 B+Tree 是先按 product no 进行排序，然后再 product no 相同的情况再按name 字段排序。 再比如建立（a，b）的索引，它的索引示意图如下： 可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8）， 而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。 因此，直接执行where b = 2这种查询条件没有办法利用联合索引的， 利用索引的前提是索引里的 key 是有序的。 只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候， b 的值为（7，8），这时就是有序的，这个有序状态是局部的， 因此，执行where a = 2 and b = 7是 a 和 b 字段能用到联合索引的 接下来说几个范围查询的经典例子 1、select * from t_table where a &gt; 1 and b &#x3D; 2 。 由于联合索引(二级索引)是先按照a字段的值排序的，所以符合a&gt;1条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合a&gt;1条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合a&gt;1条件位置，所以a字段可以在联合索引的 B+Tree 中进行索引查询。 但是在符合 a &gt; 1 条件的二级索引记录的范围里，b 字段的值是无序的。 比如前面图的联合索引的 B+ Tree 里， 下面这三条记录的 a 字段的值都符合 a &gt; 1 查询条件， 而 b 字段的值是无序的： a 字段值为 5 的记录，该记录的 b 字段值为 8； a 字段值为 6 的记录，该记录的 b 字段值为 10； a 字段值为 7 的记录，该记录的 b 字段值为 5； 因此，这条查询语句只有 a 字段用到了联合索引进行索引查询，联合索引的最左匹配原则在遇到 a 字段的范围查询（ &gt;）后就停止匹配了 而 b 字段并没有使用到联合索引。 2、select * from t_table where a &gt;&#x3D; 1 and b &#x3D; 2 在符合 a&gt;&#x3D; 1 条件的二级索引记录的范围里，b 字段的值是「无序」的， 但是对于符合 a &#x3D; 1 的二级索引记录的范围里，b 字段的值是「有序」的 （因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下 ，再按照 b 字段的值进行排序）。 当二级索引记录的 a 字段值为 1 时，可以通过 b &#x3D; 2 条件减少需要扫描的二级索引记录范围 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 3、SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b &#x3D; 2 在 MySQL 中，BETWEEN 包含了 value1 和 value2 边界值， 类似于 &gt;&#x3D; and &#x3D;&lt;。 因此 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 4、SELECT * FROM t_user WHERE name like ‘j%’ and age &#x3D; 22 对于符合 name &#x3D; j 的二级索引记录的范围里，age字段的值是「有序」的 ，（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序）。 也就是说，从符合 name = &#39;j&#39; and age = 22 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描 。 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 综上所述，联合索引的最左匹配原则，在遇到范围查询（如 &gt;、&lt;）的时候，就会停止匹配，** **也就是范围查询的字段可以用到联合索引，** **但是在范围查询字段的后面的字段无法用到联合索引。** **注意，对于 &gt;&#x3D;、&lt;&#x3D;、BETWEEN、like 前缀匹配的范围查询， 并不会停止匹配 6.索引下推对于联合索引（a, b） ，在执行 select * from table where a &gt; 1 and b &#x3D; 2只有 a 字段能用到索引 ，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后 ，还需要判断其他条件是否满足（看 b 是否等于 2）， 那是在联合索引里判断？还是回主键索引去判断呢？ MySQL 5.6 引入的索引下推优化，允许存储引擎在索引遍历过程中，执行部分 WHERE字句的判断条件，直接过滤掉不满足条件的记录，从而减少回表次数，提高查询效率。 当你的查询语句的执行计划里，出现了 Extra 为 Using index condition 那么说明使用了索引下推的优化。 7.索引失效有哪些情况 当我们使用左或者左右模糊匹配的时候， 也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 不知道从哪个索引值开始比较，于是就只能通过全表扫描的方式来查询。 当我们在查询条件中对索引列使用函数，就会导致索引失效。因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。因为索引保存的是索引字段的原始值，而不是id +1表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。 当我们在查询条件中对索引列进行隐式类型转换操作 ，背后可能也做了函数运算 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配 ，否则就会导致索引失效。 在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列， 那么索引会失效。 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的， 8.索引创建的原则（了解1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 2）较频繁作为查询条件的字段才去创建索引 3）更新频繁字段不适合创建索引 4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低) 5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 6）定义有外键的数据列一定要建立索引。 7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。 8）对于定义为text、image和bit的数据类型的列不要建立索引。 9.索引的缺点(了解)占用存储空间： 每个索引都会占用额外的磁盘空间，尤其在数据量很大的情况下，存储需求会显著增加。 影响写操作性能： 插入、更新、删除时，MySQL需要维护所有相关索引。这会导致写操作变慢，特别是在频繁更新的表中。 复杂的索引选择： 如果索引过多，优化器在执行查询时需要花费额外时间决定使用哪个索引，这可能导致优化器选择不当。 增加维护成本： 开发和维护人员需要理解和管理这些索引，可能导致复杂性增加。 因此，对于写操作多于读操作的场景，尽量减少索引数量。 10.主键索引为什么最好设置为自增的如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置， 不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。 因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时， 就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入， 甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。 页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。 举个例子，假设某个数据页中的数据是1、3、5、9，且数据页满了，现在准备插入一个数据7，则需要把数据页分割为两个数据页: 出现页分裂时，需要将一个页的记录移动到另外一个页，性能会受到影响， 同时页空间的利用率下降，造成存储空间的浪费。 而如果记录是顺序插入的，例如插入数据11，则只需开辟新的数据页，也就不会发生页分裂： 11.MySQL使用like “%x”，索引一定失效吗？答：不一定。 如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配， 也不会走全表扫描（type&#x3D;all）， 而是走全扫描二级索引树(type&#x3D;index)。 一个表有2个字段，其中name是索引字段，id 拥有自增主键索引。 12select*fromswhere name like&quot;%xxx&#x27;select *froms where name like &quot;%xxx%&#x27; 这两个也会走索引 执行情况如下： 为什么呢？ 首先，这张表的字段没有「非索引」字段， 这个查询的数据都在二级索引的 B+ 树， 因为二级索引的 B+ 树的叶子节点包含「索引值+主键值」，所以查二级索引的 B+ 树就能查到全部结果了，这个就是覆盖索引。 为什么选择全扫描二级索引树，而不扫描聚簇索引树呢？ 因为二级索引树的记录东西很少，就只有「索引列+主键值」，而聚簇索引记录的东西会更多，比如聚簇索引中的叶子节点则记录了主键值、事务 id、用于事务和 MVCC 的回滚指针以及所有的剩余列。 补充ai： 在特定场景下仍可能使用索引： 覆盖索引：当查询的列全部包含在索引中时（即使LIKE &quot;%x&quot;），可能通过全索引扫描避免回表 **索引条件下推(ICP)**：MySQL 5.6+ 可能将条件过滤下推到存储引擎层 3.事务事务是逻辑上的一组操作，要么都执行，要么都不执行。 1.事务的ACID特性以及怎么实现的 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不会丢失。 只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 2.脏读、幻读、不可重复读 脏读（读到其他事务未提交的数据； 如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。 某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读（前后读取的数据不一致； 在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。 在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新了原有的数据。 幻读（前后读取的记录数量不一致 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。 严重性排序：脏读 &gt; 不可重复读 &gt; 幻读 3.事务的隔离级别隔离水平高低排序如下：串行化 &gt; 可重复读 &gt; 读已提交 &gt; 读未提交 各个隔离级别的定义： 读未提交：指一个事务还没提交时，它做的变更就能被其他事务看到； 读已提交：指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； 在各个隔离级别下可能发生的问题： 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象； 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象； 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象； 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。 MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。 各个级别的适用场景： 读未提交：适合对数据一致性要求极低的场景，比如实时日志统计或临时数据分析。 读已提交：适用于大多数业务场景，比如普通的电商订单查询、库存检查等，要求避免脏读但可以容忍一定程度的不一致。 可重复读：适合需要较高一致性的业务场景，比如财务系统、库存管理、银行账户余额查询等。 适用于对数据一致性要求极高的场景，比如关键金融交易、分布式系统中的强一致性需求。 4.隔离级别的实现原理MySQL 的事务隔离级别主要依赖 锁机制 和 MVCC 实现。 读已提交和可重复读通过 MVCC 机制中的 ReadView 来实现。 读已提交：每次读取数据前都生成一个 ReadView，保证每次读操作都是最新的数据。 可重复读：只在第一次读操作时生成一个 ReadView，后续读操作都使用这个 ReadView，保证事务内读取的数据是一致的。 串行化是通过锁来实现的：事务在读操作时，必须先加表级共享锁，直到事务结束才释放；事务在写操作时，必须先加表级排他锁，直到事务结束才释放。 以下了解即可 (1) 锁机制 共享锁（S 锁）：允许多个事务并发读取同一数据，但阻止写入。 排他锁（X 锁）：阻止其他事务读取或写入。 隔离级别越高，锁的粒度和范围越大。 5.MVCC 基本概念 当前读 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如:select .. lockin share mode(共享锁)，select.... for update、update、insert、delete(排他锁)都是一种当前读。 快照读 简单的select(不加锁)就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。 RC读已提交：每次select，都生成一个快照读。 RR可重复读：开启事务后第一个select语句才是快照读的地方 串行化：快照读退化为当前读 MVCC 全称 Multi-Version Concurrency Control，多版本并发控制。MVCC 是数据库管理系统中用于实现事务隔离性和并发控制的一种关键技术。它的核心目标是通过维护数据的多个版本，使得并发执行的事务能够在不相互阻塞的情况下读取和写入数据，从而提高数据库的并发性能，同时保证数据的一致性和隔离性。 基本原理 MVCC 的核心思想是：每次写操作会创建一个新的数据版本，而不是直接覆盖旧数据。 通过这种方式，读操作可以访问与事务开始时一致的旧版本数据，而无需等待写操作完成。这种机制避免了读写之间的锁竞争，从而提升了并发性能。 MVCC的具体实现，还需要依赖于数据库记录中个隐式字段、undolog、readView。 实现过程： 读取时，根据事务的开始时间或快照，访问对应的旧版本数据。 写入时，生成新的版本，旧版本通过 Undo Log 保留。 三个字段 TRX_ID: 最近修改该条数据的事务ID，记录插入这条记录或最后一次修改该记录的事务ID。 ROLL_PTR：回滚指针，指向这条记录的上一个版本，（历史数据存储在undolog中） ROW_ID：隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段。有的话就不用这个了。这个不是很重要 undolog readview ReadView(读视图)主要是用来做可见性判断。是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务(未提交的)id。 四个核心字段： m_ids：所有活跃事务的 ID 列表，活跃事务是指那些已经开始但尚未提交的事务。 min_trx_id：活跃事务中最小的事务id max_trx_id：下一个即将生成的事务ID，也就是即将开始的事务 creator_trx_id:：创建该 Read View 的事务的事务 id。 事务可见性示意图 当一个事务读取某条数据时，InnoDB 会根据 ReadView 中的信息来判断该数据的某个版本是否可见。 如果＜ min_trx_id ，则该数据版本在生成 ReadView 之前就已经提交，因此对当前事务是可见的。 如果＞ max_trx_id ，则表示创建该数据版本的事务在生成 ReadView 之后开始，因此对当前事务是不可见的。 如果在二者之间，需要判断该事务是否在活跃事务列表中 如果不在，表示创建该数据版本的事务在生成 ReadView 之后已经提交，因此对当前事务也是可见的。 在，则表示创建该数据版本的事务仍然活跃，或者在当前事务生成 ReadView 之后开始，因此对当前事务是不可见的。 4.锁(了解)当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。 就像酒店的房间，如果大家随意进出，就会出现多人抢夺同一个房间的情况，而在房间上装上锁，申请到钥匙的人才可以入住并且将房间锁起来，其他人只有等他使用完毕才可以再次使用。 1.表级锁和行级锁二者的区别是锁粒度不同 行级锁 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 2.共享锁和排他锁从锁的类别上来讲，有共享锁和排他锁。 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 5.日志Redo log(重做日志)：是 Innodb 存储引擎层生成的日志，用于保证事务的持久性，它在事务提交前将数据写入磁盘，以防止数据丢失。主要用于掉电等故障恢复； Undo log(回滚日志)：是 Innodb 存储引擎层生成的日志， 用于事务的回滚操作，它记录了事务对数据的修改，以便在事务回滚时进行数据恢复。保证事务的原子性，主要用于事务回滚和 MVCC。 Bin log(二进制日志)：是 Server 层生成的日志， 记录了数据库的所有修改操作，包括对数据的增删改操作，主要用于数据备份和主从复制； 其中redo log是物理日志，记录数据页的物理变化 ，而undo log 和bin log是逻辑日志，分别记录如何撤销事务 和 记录 SQL 或行变更 1.Undo logundo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图: 每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时， 要把回滚时需要的信息都记录到 undo log 里 。在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。 在插入一条记录时，要把这条记录的主键值记下来， 回滚时只需要把这个主键值对应的记录删掉就好了； 在删除一条记录时，要把这条记录中的内容都记下来， 回滚时再把由这些内容组成的记录插入到表中就好了； 在更新一条记录时，要把被更新的列的旧值记下来， 这样之后回滚时再把这些列更新为旧值就好了。 另外，undo log 还有一个作用， 配合ReadView 实现 MVCC（多版本并发控制）。 因此，undo log 两大作用： 实现事务回滚，保障事务的原子性。 实现 MVCC（多版本并发控制）关键因素之一。 当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 undo log 读取之前的版本数据，以此实现快照读（非锁定读） 2.Redo Logredo log（重做日志）是 InnoDB 存储引擎独有的，它让 MySQL 拥有了崩溃恢复能力。是用来实现事务的持久性。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 比如 MySQL 实例挂了或宕机了，重启时，InnoDB 存储引擎会使用 redo log 恢复数据，保证数据的持久性与完整性。 MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。 后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。 更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。 然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log 文件里。 该日志文件由两部分组成：重做日志缓冲(redolog buffer)以及重做日志文件(redolog file)，前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中，用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用。 WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上， 而是先写日志，然后在合适的时间再写到磁盘上。 为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候， InnoDB 引擎就会先更新内存（同时标记为脏页）， 然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。 后续，InnoDB 引擎会在适当的时候， 由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术。 过程如下图： 顺序写vs随机写 redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？ 写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写， 而写入数据需要先找到写入位置，然后才写到磁盘， 所以磁盘操作是随机写。 磁盘的「顺序写 」比「随机写」 高效的多， 因此 redo log 写入磁盘的开销更小。 至此，为什么需要 redo log 这个问题我们有两个答案： 实现事务的持久性，让 MySQL 有 崩溃恢复 的能力， 能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失； 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。 产生的 redo log 是直接写入磁盘的吗？ 不是的。实际上，执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;0操作，而且磁盘的运行速度远慢于内存。所以，redo log也有自己的缓存– redo log buffer，每当产生一条 redo log 时，会先写入到 redo logbuffer，后续在持久化到磁盘如下图: redo log buffer 默认大小 16 MB，可以通过 innodb_log_Buffer_size 参数动态的调整大小， 增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。 redo log和undo log的区别 这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于： redo log 记录了此次事务「修改后」的数据状态，记录的是更新之后的值， 主要用于事务崩溃恢复，保证事务的持久性。 undo log 记录了此次事务「修改前」的数据状态，记录的是更新之前的值， 主要用于事务回滚，保证事务的原子性。 事务提交之前发生了崩溃(这里的崩溃不是宕机崩溃，而是事务执行错误，mysql 还是正常运行的)，重启后会通过 undo log 回滚事务。 事务提交之后发生了崩溃（这里的崩溃是宕机崩溃），重启后会通过 redo log 恢复事务，如下图： redolog刷盘时机（TODO 3.Bin logbinog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT和 SHOW 操作。 作用： 灾难时的数据恢复; MySQ4的主从复制。 binlog 有3种格式类型 分别是 STATEMENT(默认格式)、ROW、 MIXED，区别如下: 指定statement，记录的内容是SQL语句原文，比如执行一条update T set update_time=now() where id=1，记录的内容如下。 同步数据时，会执行记录的SQL语句，但是有个问题，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。 为了解决这种问题，我们需要指定为row，记录的内容不再是简单的SQL语句了，还包含操作的具体数据，记录内容如下。 但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量update 语句，更新多少行数据就会产生多少条记录，使 binog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已; 所以就有了一种折中的方案，指定为mixed，记录的内容是前两者的混合。 MySQL 会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式。 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况， 理论上只要记录在 binlog 上的数据，都可以恢复， 所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。 redo log和binlog的区别 redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 两阶段提交 为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。 redo log（重做日志）让 InnoDB 存储引擎拥有了崩溃恢复能力。 binlog（归档日志）保证了 MySQL 集群架构的数据一致性。 虽然它们都属于持久化的保证，但是侧重点不同。 在执行更新语句过程，会记录 redo log 与 binlog 两块日志，以基本的事务为单位，redo log 在事务执行过程中可以不断写入，而 binlog 只有在提交事务时才写入，所以 redo log 与 binlog 的写入时机不一样。 先写 redo log ，然后写 binlog， 假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据， 但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了， 由于没有 redo log，本机是无法恢复这一条记录的， 但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。 可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态， 就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据， binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。 两阶段提交的过程在一条更新语句的执行过程那里 4.日志写入顺序⭐️ 日志写入顺序 在 MySQL 中，事务的提交过程会严格按照一定的顺序写入日志，以保证数据的一致性和持久性。以下是典型的事务提交过程中三种日志的写入顺序： 步骤 1：写入 undo log 在事务执行过程中，当对数据进行修改时（例如 INSERT、UPDATE、DELETE 操作），InnoDB 首先会将修改前的旧数据记录到 undo log 中。 原因：这是为了支持事务的回滚（Atomicity）和一致性（Consistency）。如果事务失败，undo log 可以用来撤销所有修改。 写入时机：在实际修改数据之前，undo log 必须写入并持久化。 步骤 2：写入 redo log（prepare 阶段） 在事务执行过程中，InnoDB 会将数据修改的物理记录写入 redo log，但此时 redo log 并未真正提交，而是处于 prepare 状态。 原因：这是 WAL 机制的要求，任何数据修改必须先写入 redo log，以保证事务的持久性（Durability）。即使系统崩溃，redo log 可以用来恢复数据。 写入时机：在数据修改后，事务提交（COMMIT）之前，redo log 会被写入并持久化到磁盘（至少写入缓冲区，并根据 innodb_flush_log_at_trx_commit 参数决定是否立即刷盘）。 步骤 3：写入 binlog 当事务提交时，MySQL Server 层会将事务的逻辑操作记录写入 binlog。 原因：binlog 是用于主从复制和数据恢复的日志，必须在事务提交时写入，以保证主从一致性。 写入时机：在 redo log 的 prepare 阶段完成后，binlog 会被写入并持久化到磁盘（根据 sync_binlog 参数决定是否立即刷盘）。 步骤 4：redo log 提交（commit 阶段） 在 binlog 写入成功后，InnoDB 会将 redo log 的状态从 prepare 改为 commit，表示事务正式提交。 原因：这是两阶段提交（Two-Phase Commit, 2PC）机制的一部分，确保 redo log 和 binlog 的一致性。如果 binlog 写入失败，事务会回滚；如果 binlog 写入成功但 redo log 提交失败，MySQL 会根据 binlog 和 redo log 的状态进行恢复。 两阶段提交（2PC）机制 MySQL 使用两阶段提交机制来保证 redo log 和 binlog 的一致性。写入顺序可以总结为： Prepare 阶段：写入 redo log（标记为 prepare 状态）。 Commit 阶段 写入 binlog。 将 redo log 标记为 commit 状态。 这种机制确保了即使在崩溃恢复时，redo log 和 binlog 能够保持一致。 写入顺序总结 综合上述步骤，三种日志的写入顺序如下： undo log：在事务执行过程中，数据修改前写入。 redo log（prepare）：在事务提交前写入，标记为 prepare 状态。 binlog：在事务提交时写入。 redo log（commit）：在 binlog 写入成功后，标记为 commit 状态。 6.SQL优化0.MySQL常见性能优化手段 慢 SQL 定位与分析 监控工具： 介绍常用的慢 SQL 监控工具，如 MySQL 慢查询日志 EXPLAIN 命令： 详细说明 EXPLAIN 命令的使用，分析查询计划、索引使用情况 索引、表结构和 SQL 优化 索引优化： 这是 MySQL 性能优化的重点，可以介绍索引的创建原则、覆盖索引、最左前缀匹配原则等。 表结构优化： 优化表结构设计，包括选择合适的字段类型、避免冗余字段、合理使用范式和反范式设计等等。 SQL语句的优化： 避免使用 SELECT *、尽量使用具体字段、使用连接查询代替子查询、合理使用分页查询、批量操作等，都是 SQL 编写过程中需要注意的细节。 架构优化 读写分离： 将读操作和写操作分离到不同的数据库实例，提升数据库的并发处理能力。 分库分表： 将数据分散到多个数据库实例或数据表中，降低单表数据量，提升查询效率。但要权衡其带来的复杂性和维护成本，谨慎使用。 数据冷热分离：根据数据的访问频率和业务重要性，将数据分为冷数据和热数据，冷数据一般存储在存储在低成本、低性能的介质中，热数据高性能存储介质中。 缓存机制： 使用 Redis 等缓存中间件，将热点数据缓存到内存中，减轻数据库压力。这个非常常用，提升效果非常明显，性价比极高！ 1.MySQL 慢查询的排除与优化 慢查询日志：在 MySQL中，可以启用慢查询日志功能来记录执行时间超过设定阈值的查询。通过分析这些日志，可以找到执行时间较长的SQL语句。 使用 EXPLAIN分析：对慢SQL语句使用 MySQL的EXPLAIN命令，可以分析查询的执行计划。这有助于了解 MySQL是如何处理你的查询的，包括是否使用了索引、是否进行了全表扫描等。 查询了过多不需要的数据：有时候，查询语句可能会返回比实际需要更多的数据，这会导致查询变慢。例如，使用 SELECT*从多个表中进行关联查询时，可能会取出所有列的数据，但实际上可能只需要其中的一部分列。这种情况下，可以优化SQL语句，只选择需要的列。 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。 2.explain执行计划如果一条sql执行很慢的话，我们通常会使用mysql自动的执行计划explain来去查看这条sql的执行情况， 比如在这里面可以通过key和key_len检查是否命中了索引，如果本身已经添加了索引，也可以判断索引是否有失效的情况， 第二个，可以通过type字段查看sq!是否有进一步的优化空间，是否存在全索引扫描或全盘扫描， 第三个可以通过extra建议来判断，是否出现了回表的情况，如果出现了可以尝试添加索引或修改返回字段来修复 最重要的三个字段，key， type，extra key 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。 key_length 索引长度。联合索引的情况下可结合key_len判断实际使用的索引 type(非常重要，可以看到有没有走索引) 查询执行的类型，描述了查询是如何执行的。 性能从最优到最差分别为：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL。 system，表只有一行，一般是系统表，往往不需要进行磁盘 IO，速度非常快 const、eq_ref、ref：这些类型表示 MySQL 可以使用索引来查找单个行，其中 const 是最优的，表示查询最多返回一行。 range：只检索给定范围的行，使用索引来检索。在where语句中使用 bettween...and、&lt;、&gt;、&lt;=、in 等条件查询 type 都是 range。 index：遍历索引树读取。查询遍历了整棵索引树，与 ALL 类似，只不过扫描的是索引，而索引一般在内存中，速度更快。 ALL：全表扫描，效率最低。 extra 的信息非常丰富，常见的有： Using index：表明查询使用了覆盖索引，不用回表，查询效率非常高。 比如SELECT的列都包含在索引中 Using where：表示MySQL服务器在存储引擎检索行后进行了额外的过滤。一般是查询条件不能完全通过索引筛选时会出现这个，优化方法是检查是否可以通过优化索引来避免额外的过滤，也就是检查WHERE条件是否可以利用索引 Using temporary ：表示使用了临时表来存储中间结果。GROUP BY、ORDER BY或DISTINCT操作无法使用索引时。优化建议：优化查询或添加适当的索引 Using index condition：表示查询优化器选择使用了索引条件下推这个特性。 Using filesort：表示需要额外的排序操作。示例场景：ORDER BY无法使用索引排序时。优化建议：为ORDER BY子句创建合适的索引 中性信息：如Using index、Using index condition，通常表示良好优化 警告信息：如Using temporary、Using filesort，优先考虑索引优化 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。说明：1） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2） ref 指的是使用普通的索引（normal index）。3） range 对索引进行范围检索。 3.给你张表，发现查询速度很慢，你有那些解决方案 分析查询语句：使用EXPLAIN命令分析SQL执行计划，找出慢查询的原因 ，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改。 创建或优化索引： 根据查询条件创建合适的索引 避免索引失效： 不符合最左匹配原则 查询优化：避免使用SELECT *，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段； 优化数据库表：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，减轻单个表的查询压力。 使用缓存技术： 引入缓存层 ，如Redis，存储热点数据和频繁查询的结果， 4.主键使用自增ID还是UUID？推荐使用自增ID，不要使用UUID。 因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。 总之，在数据量大一些的情况下，用自增主键性能会好一些。 7.架构1.读写分离读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。 这样的话，就能够小幅提升写性能，大幅提升读性能。 一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。 如何实现读写分离？ 代理方式 我们可以在应用和数据中间加了一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。 提供类似功能的中间件有 MySQL Router（官方， MySQL Proxy 的替代方案）、Atlas（基于 MySQL Proxy）、MaxScale、MyCat。 组件方式 2.主从复制 原理 MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。 流程如下： MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务， 更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。 从库会创建一个专门的 I&#x2F;O 线程，连接主库的 log dump 线程， 来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里， 再返回给主库“复制成功”的响应。 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志， 然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。 在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库， 这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。 3.主从延迟读写分离对于提升数据库的并发非常有效，但是，同时也会引来一个问题：主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 主从同步延迟 。 主从延迟出现的原因 MySQL 主从同步延时是指从库的数据落后于主库的数据，这种情况可能由以下原因造成： 网络延迟 主库和从库之间如果存在网络传输延迟 主库写入压力大 当主库的写入操作（如INSERT、UPDATE、DELETE）非常频繁时，从库可能无法以同样的速度处理这些更新。 从库负载过高 从库可能正在处理其他查询或任务，导致无法及时应用主库传来的更新日志。 如何在主从延迟时保证读到最新数据 强制读主库 对于需要实时一致性的关键业务，可以配置应用程序直接从主库读取数据，避免从库延迟的影响。 延迟监控与切换 实时监控主从延迟（例如通过Seconds_Behind_Master参数），当延迟超过一定阈值时，自动将读请求切换到主库。 5.分库分表读写分离主要应对的是数据库读并发，没有解决数据库存储问题。试想一下：如果 MySQL 一张表的数据量过大怎么办? 换言之，我们该如何解决 MySQL 的存储压力呢？ 答案之一就是 分库分表。 分库 垂直分库：按业务划分，把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。 比如将数据库中的用户表、订单表和商品表分别单独拆分为用户数据库、订单数据库和商品数据库。 水平分库：同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。 举个例子：订单表数据量太大，你对订单表进行了水平切分（水平分表），然后将切分后的 2 张订单表分别放在两个不同的数据库。 分库有个读扩散问题：见B站视频原神那一集（TODO） 分表 垂直分表：是对数据表列的拆分，把一张列比较多的表拆分为多张表。 举个例子：我们可以将用户信息表中的一些列单独抽出来作为一个表。 优点：可以使得行数据变小，在查询时减少读取的Block数，减少I&#x2F;O次数。 水平分表：是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。 举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 常见的分片算法 分片算法主要解决了数据被水平分片之后，数据究竟该存放在哪个表的问题。 常见的分片算法有： 哈希分片：求指定分片键的哈希，然后根据哈希值确定数据应被放置在哪个表中。 范围分片：按照特定的范围区间（比如时间区间、ID 区间）来分配数据，比如 将 id 为 1~299999 的记录分到第一个表， 300000~599999 的分到第二个表。 映射表分片：使用一个单独的表（称为映射表）来存储分片键和分片位置的对应关系。 一致性哈希分片：将哈希空间组织成一个环形结构，将分片键和节点（数据库或表）都映射到这个环上，然后根据顺时针的规则确定数据或请求应该分配到哪个节点上，解决了传统哈希对动态伸缩不友好的问题。 6.冷热分离数据冷热分离是指根据数据的访问频率和业务重要性，将数据分为冷数据和热数据，冷数据一般存储在存储在低成本、低性能的介质中，热数据高性能存储介质中。 冷热分离的思想非常简单，就是对数据进行分类，然后分开存储。 7.深度分页全表查询通常是顺序 IO。数据库在执行全表扫描时，会按存储顺序从头到尾读取表中的所有行，这种读取方式属于顺序 IO，相比随机 IO 更加高效。 但在深度分页场景中，尽管查询仍是全表扫描，由于 OFFSET 值很大，数据库需要跳过大量数据才能到达目标行。虽然跳过数据的操作仍然是顺序读取，但跳过的过程会增加额外的 IO 开销。特别是在数据量很大时，跳过大量数据会显著影响性能，因此深度分页的效率会下降。 查询偏移量过大的场景我们称为深度分页，这会导致查询性能较低，例如： 12# MySQL 在无法利用索引的情况下跳过1000000条记录后，再获取10条记录SELECT * FROM t_order ORDER BY id LIMIT 1000000, 10 当查询偏移量过大时，MySQL 的查询优化器可能会选择全表扫描而不是利用索引来优化查询。这是因为扫描索引和跳过大量记录可能比直接全表扫描更耗费资源。 MySQL 的查询优化器采用基于成本的策略来选择最优的查询执行计划。它会根据 CPU 和 I&#x2F;O 的成本来决定是否使用索引扫描或全表扫描。如果优化器认为全表扫描的成本更低，它就会放弃使用索引。不过，即使偏移量很大，如果查询中使用了覆盖索引（covering index），MySQL 仍然可能会使用索引，避免回表操作。 深度分页解决手段 8.内存1.BufferPool这个缓冲池是存储引擎的缓冲池。MySQL的server也有一个缓存，也就是自带的缓存，那个缓存可以对查询语句做哈希，然后以key-value的形式存储查找结果，当查找语句完全命中（必须一模一样），可以直接返回结果集，不过这个功能比较鸡肋，后面就停止了。 虽然说 MySQL的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的。 要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。 为此，Innodb 存储引擎设计了一个缓冲池(Buffer Pool)来提高数据库的读写性能。 有了缓冲池后: 当读取数据时，如果数据存在于 Bufer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"框架","slug":"八股/框架","date":"2024-10-28T12:14:40.000Z","updated":"2025-06-02T07:30:56.143Z","comments":true,"path":"2024/10/28/八股/框架/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/%E6%A1%86%E6%9E%B6/","excerpt":"这里是有关框架的八股","text":"这里是有关框架的八股 1.基础Spring 是一个轻量级、非入侵式的控制反转 (IoC) 和面向切面 (AOP) 的框架。 1.Spring用到哪些设计模式 工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例； 单例模式：Bean默认为单例模式。 代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术； 模板模式：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。 观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。 2.Spring的基本特性 IoC容器 AOP 事务管理 ：Spring提供了一致的事务管理接口，支持声明式和编程式事务。 开发者可以轻松地进行事务管理，而无需关心具体的事务API。 MVC框架： Spring MVC是一个基于Servlet API构建的Web框架， 采用了模型-视图-控制器（MVC）架构。 3.常用的注解1.Web开发相关注解 @Controller：用于标注控制层组件。 @RestController：是@Controller 和 @ResponseBody 的结合体，返回 JSON 数据时使用。 @RequestMapping：用于映射请求 URL 到具体的方法上，还可以细分为： @GetMapping：只能用于处理 GET 请求 @PostMapping：只能用于处理 POST 请求 @DeleteMapping：只能用于处理 DELETE 请求 @ResponseBody：直接将返回的数据放入 HTTP 响应正文中，一般用于返回 JSON 数据。 @RequestBody：表示一个方法参数应该绑定到 Web 请求体。 @PathVariable：用于接收路径参数，比如 @RequestMapping(“/hello/&#123;name&#125;”)，这里的 name 就是路径参数。 @RequestParam：用于接收请求参数。比如 @RequestParam(name = &quot;key&quot;) String key，这里的 key 就是请求参数。 2.容器相关注解 @Component：标识一个类为 Spring 组件，使其能够被 Spring 容器自动扫描和管理。 @Service：标识一个业务逻辑组件（服务层）。比如 @Service(&quot;userService&quot;)，这里的 userService 就是 Bean 的名称。 @Repository：标识一个数据访问组件（持久层）。 @Autowired：按类型自动注入依赖。 @Configuration：用于定义配置类，可替换 XML 配置文件。 3.AOP相关注解 @After：在方法执行之后执行。 @Before：在方法执行之前执行。 @Around：方法前后均执行。 @PointCut：定义切点，指定需要拦截的方法。 4.事务相关注解 主要就是 @Transactional，用于声明一个方法需要事务支持。 2.IOC1.IOC和DIIOC(lnversion Of Controll，控制反转)是一种设计思想，就是将原本在程序中手动创建对象的控制权，交由给Spring框架来管理。 IOC 负责创建对象，管理对象（通过依赖注入（DI），装配对象，配置对象，并且管理这些对象的整个生命周期。 IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。 Spring 中的 IoC 的实现原理就是工厂模式加反射机制。 依赖注入：依赖注入和控制反转恰恰相反，它是一种具体的编码技巧。我们不通过 new 的方式在类内部创建依赖类的对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递(或注入)给类来使用。 什么是Spring Bean？ 简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。 我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。 以下是牛客一个回答 spring ioc是spring两大核心之一，spring为我们提供了一个ioc容器，也就是beanFactory，同时，ioc有个非常强大的功能，叫做di，也就是依赖注入，我们可以通过配置或者xml文件的方式将bean所依赖的对象通过name（名字）或者type（类别）注入进这个beanFactory中，正因为这个依赖注入，实现类与依赖类之间的解耦，如果在一个复杂的系统中，类之间的依赖关系特别复杂，首先，这非常不利于后期代码的维护，ioc就很好的帮助我们解决了这个问题，它帮助我们维护了类与类之间的依赖关系，降低了耦合性，使我们的类不需要强依赖于某个类，而且，在spring容器启动的时候，spring容器会帮助我们自动的创建好所有的bean，这样，我们程序运行的过程中就不需要花费时间去创建这些bean，速度就快了许多。 2.注入Bean的方式依赖注入 (Dependency Injection, DI) 的常见方式： 构造函数注入：通过类的构造函数来注入依赖项。 Setter 注入：通过类的 Setter 方法来注入依赖项。 Field（字段） 注入：直接在类的字段上使用注解（如 @Autowired 或 @Resource）来注入依赖项。 123456789101112131415161718192021222324252627282930313233343536371、构造函数注入@Servicepublic class UserService &#123; private final UserRepository userRepository; public UserService(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; //...&#125;2、Setter注入@Servicepublic class UserService &#123; private UserRepository userRepository; // 在 Spring 4.3 及以后的版本，特定情况下 @Autowired 可以省略不写 @Autowired public void setUserRepository(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; //...&#125;3、字段注入@Servicepublic class UserService &#123; @Autowired private UserRepository userRepository; //...&#125; 构造器注入：推荐使用的方式，适用于所有必需的依赖项，确保依赖项在对象创建时已被注入。构造函数注入适合处理必需的依赖项 Setter 注入：适用于可选的依赖项，灵活性较高，但不如构造器注入安全。 Setter 注入 则更适合可选的依赖项，这些依赖项可以有默认值或在对象生命周期中动态设置。 字段注入：最简洁的方式，适用于小项目或快速开发，但不推荐用于大规模项目，因其可维护性差。 3.@Resource和@Autowired 的区别这两个都是注入Bean的注解 都是用来自动装配的，都可以放在属性的字段上 @Autowired： 是 Spring 提供的注解， 默认通过 byType（根据类型匹配）的方式注入，而且必须要求这个对象存在! @Resource：是 JDK 提供的注解，默认通过 byName（根据名称进行匹配）的方式实现，如果找不到名字，则通过 byType注入 @Resource 有两个比较重要且日常开发常用的属性：name（名称）、type（类型）。 当一个接口存在多个实现类的情况下，@Autowired 和@Resource都需要通过名称才能正确匹配到对应的Bean。 当容器中存在多个相同类型的 bean，并希望仅使用属性装配其中一个 bean 时， 可以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean 来消除歧义。 或者通过@Resource的 name 属性来显式指定名称。 4.Bean的作用域重点关注前两种 singleton : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。 prototype : 每次获取都会创建一个新的 bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。 request （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。 session （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。 application&#x2F;global-session （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。 websocket （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。 5.Bean是线程安全的吗总结：默认singleton作用域下是单例的，但如果bean是有状态的，可能存在线程安全问题。如果是prototype作用域，不是单例的，每次获取的Bean不同，不会有线程安全问题。 Spring 框架中的 Bean 是否线程安全，取决于其作用域和状态。 我们这里以最常用的两种作用域 prototype 和 singleton 为例介绍。几乎所有场景的 Bean 作用域都是使用默认的 singleton ，重点关注 singleton 作用域即可。 prototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。singleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。 有状态 Bean 示例： 12345678910111213// 定义了一个购物车类，其中包含一个保存用户的购物车里商品的 List@Componentpublic class ShoppingCart &#123; private List&lt;String&gt; items = new ArrayList&lt;&gt;(); public void addItem(String item) &#123; items.add(item); &#125; public List&lt;String&gt; getItems() &#123; return items; &#125;&#125; 不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。 对于有状态单例 Bean 的线程安全问题，常见的三种解决办法是： 避免可变成员变量: 尽量设计 Bean 为无状态。 使用ThreadLocal: 将可变成员变量保存在 ThreadLocal 中，确保线程独立。 使用同步机制: 利用 synchronized 或 ReentrantLock 来进行同步控制，确保线程安全。 ​ 6.bean 的生命周期概括：实例化 —&gt; 属性赋值 —&gt; 初始化 —&gt; 销毁 实例化：实例化一个 bean 对象；Bean 容器首先会找到配置文件中的 Bean 定义，然后使用 Java 反射 API 来创建 Bean 的实例。 属性赋值：为 Bean 设置相关属性和依赖，例如@Autowired 等注解注入的对象、@Value 注入的值、setter方法或构造函数注入依赖和值、@Resource注入的各种资源。 初始化：第 3~7 步，步骤较多，其中第 5、6 步为初始化操作，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，该阶段结束，才能被用户使用； Aware BeanNameAware：注入当前 bean 对应 beanName； BeanClassLoaderAware：注入加载当前 bean 的 ClassLoader； BeanFactoryAware：注入 当前BeanFactory容器 的引用。 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入 Bean 的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果 Bean 实现了 BeanFactoryAware 接口，调用 setBeanFactory()方法，传入 BeanFactory对象的实例。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果 Bean 实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法。 销毁：第 8~10步，第8步不是真正意义上的销毁（还没使用呢），而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 bean 时再执行相应的方法。 如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的 Bean 销毁方法。 如果想在Bean加载&#x2F;销毁前后，实现某些逻辑，可以在Bean中实现init-method和destory-method 记忆： 初始化这一步涉及到的步骤比较多，包含 Aware 接口的依赖注入、BeanPostProcessor 在初始化前后的处理以及 InitializingBean 和 init-method 的初始化操作。 销毁这一步会注册相关销毁回调接口，最后通过DisposableBean 和 destory-method 进行销毁。 7、如果让你设计一个SpringIoc，你觉得会从哪些方面考虑这个设计？ Bean的生命周期管理:需要设计Bean的创建、初始化、销毁等生命周期管理机制，可以考虑使用工厂模式和单例模式来实现。 依赖注入:需要实现依赖注入的功能，包括属性注入、构造函数注入、方法注入等，可以考虑使用反射机制和XML配置文件来实现。 Bean的作用域:需要支持多种Bean作用域，比如单例、原型、会话、请求等，可以考虑使用Map来存诸不同作用域的Bean实例。 AOP功能的支持:需要支持AOP功能，可以考虑使用动态代理机制和切面编程来实现。 异常处理:需要考虑异常处理机制，包括Bean创建异常、依赖注入异常等，可以考虑使用try-catch机制来处理异常。 配置文件加载:需要支持从不同的配置文件中加载Bean的相关信息，可以考虑使用XML、注解或者Java配置类来实现。 7.spring循环依赖循环依赖是指 Bean 对象循环引用，是两个或多个 Bean 之间相互持有对方的引用，例如 CircularDependencyA → CircularDependencyB → CircularDependencyA。 1234567891011@Componentpublic class CircularDependencyA &#123; @Autowired private CircularDependencyB circB;&#125;@Componentpublic class CircularDependencyB &#123; @Autowired private CircularDependencyA circA;&#125; Spring 框架通过使用三级缓存来解决这个问题，确保即使在循环依赖的情况下也能正确创建 Bean。 三级缓存分别是什么 一级缓存（singletonObjects）：存放最终形态的 Bean（已经实例化、属性填充、初始化），单例池，为“Spring 的单例属性”⽽⽣。一般情况我们获取 Bean 都是从这里获取的，但是并不是所有的 Bean 都在单例池里面，例如原型 Bean 就不在里面。 二级缓存（earlySingletonObjects）：存放过渡 Bean（半成品，尚未属性填充），也就是三级缓存中ObjectFactory产生的对象，与三级缓存配合使用的，可以防止 AOP 的情况下，每次调用ObjectFactory#getObject()都是会产生新的代理对象的。 三级缓存（singletonFactories）：存放ObjectFactory，ObjectFactory的getObject()方法（最终调用的是getEarlyBeanReference()方法）可以生成原始 Bean 对象或者代理对象（如果 Bean 被 AOP 切面代理）。三级缓存只会对单例 Bean 生效。 Spring 创建 Bean 的流程 先去 一级缓存 singletonObjects 中获取，存在就返回； 如果不存在或者对象正在创建中，于是去 二级缓存 earlySingletonObjects 中获取； 如果还没有获取到，就去 三级缓存 singletonFactories 中获取，通过执行 ObjectFacotry 的 getObject() 就可以获取该对象，获取成功之后，从三级缓存移除，并将该对象加入到二级缓存中。 举例 12345678class A &#123; // 使用了 B private B b;&#125;class B &#123; // 使用了 A private A a;&#125; 当 Spring 创建 A 之后，发现 A 依赖了 B ，又去创建 B，B 依赖了 A ，又去创建 A； 在 B 创建 A 的时候，那么此时 A 就发生了循环依赖，由于 A 此时还没有初始化完成，因此在 一二级缓存 中肯定没有 A； 那么此时就去三级缓存中调用 getObject() 方法去获取 A 的 前期暴露的对象 ，也就是调用上边加入的 getEarlyBeanReference() 方法，生成一个 A 的 前期暴露对象； 然后就将这个 ObjectFactory 从三级缓存中移除，并且将前期暴露对象放入到二级缓存中，那么 B 就将这个前期暴露对象注入到依赖，来支持循环依赖。 只用两级缓存够吗？ 在没有 AOP 的情况下，确实可以只使用一级和三级缓存来解决循环依赖问题。但是，当涉及到 AOP 时，二级缓存就显得非常重要了，因为它确保了即使在 Bean 的创建过程中有多次对早期引用的请求，也始终只返回同一个代理对象，从而避免了同一个 Bean 有多个代理对象的问题。 总结一下 Spring 如何解决三级缓存： 在三级缓存这一块，主要记一下 Spring 是如何支持循环依赖的即可，也就是如果发生循环依赖的话，就去 三级缓存 singletonFactories 中拿到三级缓存中存储的 ObjectFactory 并调用它的 getObject() 方法来获取这个循环依赖对象的前期暴露对象（虽然还没初始化完成，但是可以拿到该对象在堆中的存储地址了），并且将这个前期暴露对象放到二级缓存中，这样在循环依赖时，就不会重复初始化了！ 不过，这种机制也有一些缺点，比如增加了内存开销（需要维护三级缓存，也就是三个 Map），降低了性能（需要进行多次检查和转换）。并且，还有少部分情况是不支持循环依赖的，比如非单例的 bean 和@Async注解的 bean 无法支持循环依赖。 3.AOP1.基础概念AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 SpringAOP的实现原理： Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理 Spring AOP 和 AspectJ AOP 有什么区别？ Spring AOP 属于运行时增强，而 AspectJ AOP是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单， 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。 术语： 术语 含义 目标(Target) 被通知的对象 代理(Proxy) 向目标对象应用通知之后创建的代理对象 连接点(JoinPoint) 目标对象的所属类中，定义的所有方法均为连接点 切入点(Pointcut) 被切面拦截 &#x2F; 增强的连接点（切入点一定是连接点，连接点不一定是切入点） 通知(Advice) 增强的逻辑 &#x2F; 代码，也即拦截到目标对象的连接点之后要做的事情 切面(Aspect) 切入点(Pointcut)+通知(Advice) Weaving(织入) 将通知应用到目标对象，进而生成代理对象的过程动作 以下为举例说明，帮助理解 由此可见，切入点一定是连接点，连接点不一定是切入点 切面：描述的通知和切入点的关系，差不多是类似绑定的作用，因为可能有多个通知和切入点，切面就是负责绑定的这个作用 黑马程序员SSM框架教程_Spring+SpringMVC+Maven高级+SpringBoot+MyBatisPlus企业实用开发技术 P31-AOP入门案例：介绍了如果去写一个AOP P32-AOP工作流程：介绍了AOP的工作原理流程 2.AOP通知的类型 通知类型： Before（前置通知）：通知方法在目标方法调用之前执行 After （后置通知）：通知方法在目标方法返回或异常后执行 Around （环绕通知）：通知方法会将目标方法封装起来 （重点） AfterReturning（返回通知）：通知方法会在目标方法返回后调用 （了解） AfterThrowing（异常通知）：通知方法会在目标方法抛出异常后调用 （了解） SpringAOP织入时机： 编译期织入 类加载期织入 运行时织入 对比： 织入方式 触发时机 性能影响 适用场景 限制条件 编译期织入 .java → .class ★★★★☆ 性能敏感系统 需要特殊编译器 类加载期织入 ClassLoader加载时 ★★★☆☆ 第三方库增强 需JVM参数支持 运行时织入 Bean初始化完成后 ★★☆☆☆ 常规Spring应用 仅限Spring管理Bean 4.事务Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring 是无法提供事务功能的。Spring 只提供统一事务管理接口，具体实现都是由各数据库自己实现，数据库事务的提交和回滚是通过数据库自己的事务机制实现。 1.Spring中管理事务的方式1.编程式事务：在代码中硬编码(在分布式系统中推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，事务范围过大会出现事务未提交导致超时，因此事务要比锁的粒度更小。实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。 使用TransactionTemplate 进行编程式事务管理的示例代码如下： 12345678910111213141516171819@Autowiredprivate TransactionTemplate transactionTemplate;public void testTransaction() &#123; transactionTemplate.execute(new TransactionCallbackWithoutResult() &#123; @Override protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) &#123; try &#123; // .... 业务代码 &#125; catch (Exception e)&#123; //回滚 transactionStatus.setRollbackOnly(); &#125; &#125; &#125;);&#125; 使用 TransactionManager 进行编程式事务管理的示例代码如下： 12345678910111213@Autowiredprivate PlatformTransactionManager transactionManager;public void testTransaction() &#123; TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition()); try &#123; // .... 业务代码 transactionManager.commit(status); &#125; catch (Exception e) &#123; transactionManager.rollback(status); &#125;&#125; 2.声明式事务：在 XML 配置文件中配置或者直接基于注解（单体应用或者简单业务系统推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 使用 @Transactional注解进行事务管理的示例代码如下： 12345678@Transactional(propagation = Propagation.REQUIRED)public void aMethod &#123; //do something B b = new B(); C c = new C(); b.bMethod(); c.cMethod();&#125; 声明式事务管理更加简洁，适合大多数情况；而编程式事务管理则提供了更高的灵活性，适用于更复杂的场景。选择合适的事务管理方式，可以有效地保证数据的一致性和完整性。 2.Spring事务的传播方式这里简单说一下，因为Spring事务依赖连接的数据库事务支持，所以对于mysql数据库只有innodb引擎是支持事务的，然后Spring事务的隔离级别和对应数据库的事务隔离级别也是一样的。 事务传播行为是为了解决业务层方法之间互相调用的事务问题。 当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。 举个例子：我们在 A 类的aMethod()方法中调用了 B 类的 bMethod() 方法。这个时候就涉及到业务层方法之间互相调用的事务问题。如果我们的 bMethod()如果发生异常需要回滚，如何配置事务传播行为才能让 aMethod()也跟着回滚呢？ 1.REQUIRED 使用的最多的一个事务传播行为，我们平时经常使用的@Transactional注解默认使用就是这个事务传播行为。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。也就是说： 1234567@Transactional(propagation = Propagation.REQUIRED)public void methodA() &#123; methodB(); // 加入methodA的事务&#125;@Transactional(propagation = Propagation.REQUIRED)public void methodB() &#123;...&#125; 2.REQUIRES_NEW 无论当前是否存在事务，都新建一个事务，暂停当前事务（如果存在）。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。 举个例子：如果我们上面的bMethod()使用PROPAGATION_REQUIRES_NEW事务传播行为修饰，aMethod还是用PROPAGATION_REQUIRED修饰的话。如果aMethod()发生异常回滚，bMethod()不会跟着回滚，因为 bMethod()开启了独立的事务。但是，如果 bMethod()抛出了未被捕获的异常并且这个异常满足事务回滚规则的话,aMethod()同样也会回滚，因为这个异常被 aMethod()的事务管理机制检测到了。 123456789101112131415161718@ServiceClass A &#123; @Autowired B b; @Transactional(propagation = Propagation.REQUIRED) public void aMethod &#123; //do something b.bMethod(); &#125;&#125;@ServiceClass B &#123; @Transactional(propagation = Propagation.REQUIRES_NEW) public void bMethod &#123; //do something &#125;&#125; 3.NESTED 如果当前存在事务，则在嵌套事务内执行；如果不存在，则表现同REQUIRED 特点： 嵌套事务是外部事务的子事务 子事务回滚不影响外部事务 外部事务回滚会导致子事务回滚 举个例子： 如果 aMethod() 回滚的话，作为嵌套事务的bMethod()会回滚。 如果 bMethod() 回滚的话，aMethod()是否回滚，要看bMethod()的异常是否被处理： bMethod()的异常没有被处理，即bMethod()内部没有处理异常，且aMethod()也没有处理异常，那么aMethod()将感知异常致使整体回滚。 123456789101112131415161718@ServiceClass A &#123; @Autowired B b; @Transactional(propagation = Propagation.REQUIRED) public void aMethod ()&#123; //do something b.bMethod(); &#125;&#125;@ServiceClass B &#123; @Transactional(propagation = Propagation.NESTED) public void bMethod ()&#123; //do something and throw an exception &#125;&#125; bMethod()处理异常或aMethod()处理异常，aMethod()不会回滚。 12345678910111213141516171819202122@ServiceClass A &#123; @Autowired B b; @Transactional(propagation = Propagation.REQUIRED) public void aMethod ()&#123; //do something try &#123; b.bMethod(); &#125; catch (Exception e) &#123; System.out.println(&quot;方法回滚&quot;); &#125; &#125;&#125;@ServiceClass B &#123; @Transactional(propagation = Propagation.NESTED) public void bMethod &#123; //do something and throw an exception &#125;&#125; 4.MANDATORY 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 这个使用的很少，就不举例子来说了。 若是错误的配置以下 3 种事务传播行为，事务将不会发生回滚，这里不对照案例讲解了，使用的很少。 TransactionDefinition.PROPAGATION_SUPPORTS: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行，如果当前存在事务，则抛出异常。 3.Spring的事务什么情况下会失效1.@Transactional 注解只有作用到 public 方法上事务才生效 如果 Transactional 注解应用在非 public 修饰的方法上，Transactional 将会失效。 是因为在 Spring AOP 代理时，TransactionInterceptor （事务拦截器）在目标方法执行前后进行拦截，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource 的 computeTransactionAttribute方法，获取 Transactional 注解的事务配置信息。 1234567protected TransactionAttribute computeTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; // Don&#x27;t allow no-public methods as required. if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; &#125;&#125; 此方法会检查目标方法的修饰符是否为 public，不是 public 则不会获取 @Transactional 的属性配置信息。 2.未正确的设置 @Transactional 的 rollbackFor 和 propagation 属性 @Transactional的也就是上述三种提到的情况 rollbackFor 用来指定能够触发事务回滚的异常类型。Spring 默认抛出未检查 unchecked 异常（继承自 RuntimeException 的异常）或者 Error 才回滚事务，其他异常不会触发回滚事务。 3.避免同一个类中调用 @Transactional 注解的方法，这样会导致事务失效 当一个方法被标记了@Transactional 注解的时候，Spring 事务管理器只会在被其他类方法调用的时候生效，而不会在一个类中方法调用生效。 这是因为 Spring AOP 工作原理决定的。因为 Spring AOP 使用动态代理来实现事务的管理，它会在运行的时候为带有 @Transactional 注解的方法生成代理对象，并在方法调用的前后应用事物逻辑。如果该方法被其他类调用我们的代理对象就会拦截方法调用并处理事务。但是在一个类中的其他方法内部调用的时候，我们代理对象就无法拦截到这个内部调用，因此事务也就失效了。 TODOSpring中如何配置一个类加载一个类不加载 AOP使用的什么动态代理，AOP动态代理的具体实现过程，详细说明 @Transactional 事务注解原理 5.SpringMVCMVC全名是Model View Controller，是模型(model)一视图(view)一控制器(controller)的缩写，一种软件设计典范，用一种业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑。 1.核心组件 DispatcherServlet：核心的中央处理器，负责接收请求、分发，并给予客户端响应。 HandlerMapping：处理器映射器，根据 URL 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。 HandlerAdapter：处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler； Handler：请求处理器，处理实际请求的处理器。 ViewResolver：视图解析器，根据 Handler 返回的逻辑视图 &#x2F; 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端 2.工作原理 客户端（浏览器）发送请求， DispatcherServlet拦截请求。 DispatcherServlet 根据请求信息调用 HandlerMapping 。HandlerMapping 根据 URL 去匹配查找能处理的 Handler（也就是我们平常说的 Controller 控制器） ，并会将请求涉及到的拦截器和 Handler 一起封装。 DispatcherServlet 调用 HandlerAdapter适配器执行 Handler 。 Handler 完成对用户请求的处理后，会返回一个 ModelAndView 对象给DispatcherServlet，ModelAndView 顾名思义，包含了数据模型以及相应的视图的信息。Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispaterServlet 把返回的 Model 传给 View（视图渲染）。 把 View 返回给请求者（浏览器） 6.SpringBoot1.why springboot 简化开发:Spring Boot通过提供一系列的开箱即用的组件和自动配置，简化了项目的配置和开发过程，开发人员可以更专注于业务逻辑的实现，而不需要花费过多时间在繁琐的配置上。 快速启动:Spring Boot提供了快速的应用程序启动方式，可通过内嵌的Tomcat、Jetty或Undertow等容器快速启动应用程序，无需额外的部署步骤，方便快捷。 自动化配置:Spring Boot通过自动配置功能，根据项目中的依赖关系和约定俗成的规则来配置应用程序，减少了配置的复杂性，使开发者更容易实现应用的最佳实践。 2.spring VS spring boot Spring Boot 提供了自动化配置，大大简化了项目的配置过程。通过约定优于配置的原则，很多常用的配置可以自动完成，开发者可以专注于业务逻辑的实现。 Spring Boot 提供了快速的项目启动器，通过引入不同的 Starter，可以快速集成常用的框架和库(如数据库、消息队列、Web 开发等)，极大地提高了开发效率。 Spring Boot 默认集成了多种内嵌服务器(如Tomcat、Jetty、Undertow)，无需额外配置，即可将应用打包成可执行的 JAR 文件，方便部署和运行。 3.springboot怎么实现约定大于配置的 自动化配置：Spring Boot根据项目的依赖和环境自动配置应用程序， 无需手动配置大量的XML或Java配置文件。 例如，如果项目引入了Spring Web MVC依赖， Spring Boot会自动配置一个基本的Web应用程序上下文。 起步依赖：Spring Boot提供了一系列起步依赖，这些依赖包含了常用的框架和功能， 可以帮助开发者快速搭建项目。 4.自动装配可以从以下几个方面回答： 什么是 SpringBoot 自动装配？ SpringBoot 是如何实现自动装配的？如何实现按需加载？ 如何实现一个 Starter？ 1.什么是自动装配？ 没有 Spring Boot 的情况下，如果我们需要引入第三方依赖，需要手动配置，非常麻烦。但是，Sprimg Boot中，我们直接引入一个 starter 即可。比如你想要在项目中使用redis 的话，直接在项目中引入对应的starter 即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 引入 starter 之后，我们通过少量注解和一些简单的配置就能使用第三方组件提供的功能了。 在我看来，自动装配可以简单理解为：通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。 通俗来讲，自动装配就是通过注解或一些简单的配置就可以在SpringBoot的帮助下开启和配置各种功能，比如数据库访问、Web开发。 2.自动装配的原理 核心注解 12@SpringBootApplication // 等价于：// @Configuration + @EnableAutoConfiguration + @ComponentScan 4.说几个启动器（starter） spring-boot-starter-web：这是最常用的起步依赖之一， 它包含了Spring MVC和Tomcat嵌入式服务器，用于快速构建Web应用程序。 mybatis-spring-boot-starter： 这个Starter是由MyBatis团队提供的，用于简化在Spring Boot应用中集成MyBatis的过程。它自动配置了MyBatis的相关组件， 包括SqlSessionFactory、MapperScannerConfigurer等， 使得开发者能够快速地开始使用MyBatis进行数据库操作。 spring-boot-starter-data-jpa 或 spring-boot-starter-jdbc： 如果使用的是Java Persistence APl (JPA)进行数据库操作，那么应该使用spring-boot-starter-data-jpa。这个Starter包含了Hibernate等JPA实现以及数据库连接池等必要的库，可以让你轻松地与MYSQL数据库进行交互。你需要在application.properties或application.yml中配置MySQL的连接信息。如果倾向于直接使用JDBC而不通过JPA，那么可以使用spring-boot-starter-jdbc，它提供了基本的JDBC支持。 spring-boot-starter-data-redis： 用于集成Redis缓存和数据存储服务。 这个Starter包含了与Redis交互所需的客户端（默认是Jedis客户端， 也可以配置为Lettuce客户端），以及Spring Data Redis的支持， 使得在Spring Boot应用中使用Redis变得非常便捷。 同样地，需要在配置文件中设置Redis服务器的连接详情。 spring-boot-starter-test：包含了单元测试和集成测试所需的库 ，如JUnit, Spring Test, AssertJ等，便于进行测试驱动开发(TDD)。 5.自己实现一个SpringBoot starter6.过滤器和拦截器的区别⭐️小林 过滤器（Filter）和拦截器（Interceptor）是用于处理请求和响应的两种不同机制。 7.Mybatis1.Mybatis里的 # 和 $ 的区别？ Mybatis 在处理 #{} 时，会创建预编译的 SQL 语句，将 SQL 中的 #{} 替换为 ? 号，在执行 SQL 时会为预编译 SQL 中的占位符（?）赋值，预编译的 SQL 语句执行效率高，并且可以防止SQL 注入 Mybatis 在处理 ${} 时，只是创建普通的 SQL 语句，然后在执行 SQL 语句时 MyBatis 将参数直接拼入到 SQL 里，不能防止 SQL 注入 sql注入： 假设有一个简单的登录表单，其后端验证用户名和密码的SQL查询如下： sql 1SELECT * FROM users WHERE username = &#x27;输入的用户名&#x27; AND password = &#x27;输入的密码&#x27; 如果攻击者在用户名字段输入： 1&#x27; OR &#x27;1&#x27;=&#x27;1 那么完整的SQL查询将变为： sql 1SELECT * FROM users WHERE username = &#x27;&#x27; OR &#x27;1&#x27;=&#x27;1&#x27; AND password = &#x27;输入的密码&#x27; 由于&#39;1&#39;=&#39;1&#39;始终为真，这个查询将返回数据库中所有用户的记录，导致数据泄露。 2. MybatisPlus和Mybatis的区别？3.MyBatis运用了哪些常见的设计模式？4.ResultType 和 ResultMap 的区别 如果数据库结果集中的列名和要封装实体的属性名完全一致的话用 resultType 属性。 如果数据库结果集中的列名和要封装实体的属性名有不一致的情况用 resultMap 属 性，通过。resultMap 手动建立对象关系映射，resultMap 要配置一下表和类的–对应关系，所以说就算你的字段名和你的实体类的属性名不一样也没关系，都会给你映射出来 8.SpringCloud了解SpringCloud吗，说一下他和SpringBoot的区别 微服务组件 负载均衡有哪些算法？ 如何实现一直均衡给一个用户？ 熔断降级（了解）","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Spring, SSM","slug":"Spring-SSM","permalink":"http://example.com/tags/Spring-SSM/"}]},{"title":"JUC","slug":"八股/JUC","date":"2024-10-28T12:14:32.000Z","updated":"2025-05-20T12:49:47.912Z","comments":true,"path":"2024/10/28/八股/JUC/","permalink":"http://example.com/2024/10/28/%E5%85%AB%E8%82%A1/JUC/","excerpt":"这里是JAVA并发相关的一些八股","text":"这里是JAVA并发相关的一些八股 1.线程基础补充1：什么是线程安全线程安全 的核心是 避免多线程访问共享资源时的数据竞争和内存可见性问题。 线程安全（Thread Safety）是指 在多线程环境下，某个函数、类或数据结构能够被多个线程同时访问，并且仍然保持正确的行为，不会出现数据竞争（Race Condition）、脏读（Dirty Read）、死锁（Deadlock）等问题。 为什么需要线程安全？ 在 多线程并发 环境下，如果多个线程同时访问 共享资源（如变量、对象、文件等），可能会出现以下问题： 数据不一致：多个线程同时修改数据，导致最终结果不符合预期。 竞态条件（Race Condition）：多个线程竞争同一资源，执行顺序不确定，导致程序行为不可预测。 内存可见性问题：一个线程修改了数据，但其他线程看不到最新值（由于 CPU 缓存、指令重排序等）。 线程安全的典型场景 共享变量被多个线程修改 1234567public class UnsafeCounter &#123; private int count = 0; public void increment() &#123; count++; // 非原子操作，可能导致数据错误 &#125;&#125; 问题：count++ 不是原子操作（分为 读取→修改→写入），多个线程同时执行时可能导致 少加。 解决方案： 使用 synchronized 同步方法： 123public synchronized void increment() &#123; count++;&#125; 使用 AtomicInteger（基于 CAS）： 1234private AtomicInteger count = new AtomicInteger(0);public void increment() &#123; count.incrementAndGet();&#125; 集合类在多线程环境下操作 单例模式（Singleton） 多线程环境下，instance 可能被多次初始化。 解决方案：使用 synchronized或者使用 双重检查锁（DCL） 补充2：线程安全的实现方式 常见的线程安全问题 (1) 竞态条件（Race Condition） 多个线程同时修改共享数据，导致结果不可预测。解决方案：synchronized 或 Atomic 类。 (2) 死锁（Deadlock） 多个线程互相持有对方需要的锁，导致无限等待。解决方案： 避免嵌套锁。 使用 tryLock() 设置超时。 (3) 内存可见性问题 一个线程修改了变量，但其他线程看不到最新值。解决方案：volatile 或 synchronized。 保证线程安全的方式 使用synchronized关键字 ：基于 对象监视器锁（Monitor），可以保证被修饰的方法或代码块在同一时刻只能被一个线程访问 使用Lock接口及其实现类，如ReentrantLock：可以提供更灵活的锁机制，支持可中断锁，公平锁。 使用原子类，如AtomicInteger，AtomicLong：底层基于 CAS（Compare-And-Swap） 实现无锁线程安全，适用于 单个变量的原子操作（如计数、标志位） 使用线程安全的集合，如：ConcurrentHashMap ，CopyOnWriteArrayList ，BlockingQueue线程安全的队列 使用volatile关键字：保证变量的 可见性（一个线程修改后，其他线程立即可见） 使用ThreadLocal类：ThreadLocal 让每个线程拥有自己的变量副本，避免共享变量竞争。 适用于 线程隔离数据（如用户会话、数据库连接）。 Java并发工具类并不直接保证线程安全，而是协调线程之间的执行顺序和资源访问！！这点之前一直理解错了，腾讯s线回答的时候答了这个就❌了！！ 1.线程和进程的区别 进程：进程是程序在操作系统中的执行实例，是系统资源分配的基本单位。每个进程拥有自己的地址空间、数据段、堆栈、程序计数器等，进程间相互独立，通常不能直接共享内存。 特点： 进程之间相互独立，有各自的资源和内存空间。 进程创建、销毁的开销比较大。 进程切换时，操作系统需要保存和恢复上下文，因此开销较大。 线程：线程是进程中的一个执行单元，它是比进程更小的执行单位。一个进程可以包含多个线程， 它们共享进程的内存空间和资源(如堆，全局变量，静态变量，文件等公共资源)，但拥有独立的栈和程序计数器。 特点： 线程之间共享进程的内存空间和资源，因此创建和销毁的开销较小。 线程切换的开销比进程小 由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。 协程：协程是一种用户态的轻量级线程，由程序员在代码中显式控制调度，而非操作系统。 特点： 协程切换的开销极小，比线程更轻量，因为不需要操作系统的干预。 协程通常在同一个线程中执行，因此它们共享线程的所有资源。 协程是非抢占式的调度（即协程必须显式让出控制权），避免了线程的切换和同步的复杂性。 适用场景 高隔离性任务——进程 高并发共享数据任务——线程 高并发 I&#x2F;O 密集型任务——协程 2.并行与并发的区别 并发：两个及两个以上的作业在同一 时间段 内执行。 并行：两个及两个以上的作业在同一 时刻 执行。 3.创建线程的方式(四种） 继承 Thread 类 创建一个类继承Thread类，重写run方法 创建该类的示例 调用实例的star()方法来启动线程 123456789101112public static class myThread_1 extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;第一种方式创建了一个线程....&quot;); &#125; &#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //第一种方式 myThread_1 thread_1 = new myThread_1(); thread_1.start(); &#125; 实现 Runnable 接口 创建一个类实现Runnable接口，并重写run()方法 创建该类的实例，然后用这个实例创建Thread实例 调用Thread实例的start()方法 12345678910111213public static class myRunable implements Runnable&#123; @Override public void run() &#123; System.out.println(&quot;第二种方式创建了一个线程....&quot;); &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //第二种方式 myRunable myRunable = new myRunable(); Thread thread_2 = new Thread(myRunable); thread_2.start(); &#125; 线程类只是实现了Runable接口，还可以继承其他的类。 实现 Callable 接口（需借助FutureTask） 创建实现Callable接口的类myCallable，重写call()方法 以myCallable为参数创建FutureTask对象 将FutureTask实例作为参数创建Thread对象 调用线程对象的start()方法 123456789101112131415public static class myCallable implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; return &quot;第三种方式创建了一个线程....&quot;; &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //第三种方式 myCallable task = new myCallable(); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(task); Thread thread_3 = new Thread(futureTask); thread_3.start(); System.out.println(futureTask.get()); //这个相当于得到重写cll的结果，不能省略 &#125; 和Runnable不同的是，Callable的call()方法可以有返回值并且可以抛出异常。 使用 Executors 工具类创建线程池 Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 主要有newFixedThreadPool，newCachedThreadPool，newSingleThreadExecutor，newScheduledThreadPool，后续详细介绍这四种线程池 这里代码了解即可。前三种大概要会写 123456789101112131415public static class Task implements Runnable&#123; @Override public void run() &#123; System.out.println(&quot;这是一个任务：&quot;); &#125; &#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //第四种方式 ExecutorService executor = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 20; i++) &#123; executor.submit(new Task()); // 提交任务到线程池执行 &#125; executor.shutdown(); &#125; runnable 和 callable 的区别 Runnable 接口run方法没有返回值，Callable接口call方法有返回值，需要FutureTask获取结果 Callable接口的call()方法允许抛出异常; 而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛 4.run()和 start()的区别 start():用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。 start方法只能被调用一次。run():封装了要被线程执行的代码，可以被调用多次。 5.可以直接调用Thread的run方法吗？new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结：调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。 6.线程包括哪些状态，状态之间是如何变化的状态：新建(NEW)、可运行(RUNNABLE)、阻塞(BLOCKED)、等待(WAITING)、时间等待(TIMED_WALTING)、终止(TERMINATED) 变化： 创建线程对象是新建状态 调用了start()方法转变为可执行状态线 程获取到了CPU的执行权，执行结束是终止状态 在可执行状态的过程中，如果没有获取CPU的执行权，可能会切换其他状态 如果没有获取锁(synchronized或lock)进入阻塞状态，获得锁再切换为可执行状态 如果线程调用了wait()方法进入等待状态，其他线程调用notify()唤醒后可切换为可执行状态 如果线程调用了sleep(50)方法，进入计时等待状态，到时间后可切换为可执行状态 7.sleep和wait的区别 两者都可以暂停线程的执行 不同点在于： 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。 sleep() 不释放锁；wait() 释放锁。 会不会自动苏醒：wait() 方法被调用后，线程不会自动苏醒， 需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。 sleep()方法执行完成后，线程会自动苏醒 ，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 用途不同：Wait 通常被用于线程间交互&#x2F;通信，sleep 通常被用于暂停执行。 如何停止一个正在运行的线程（了解） 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止 使用stop方法强行终止(不推荐，方法已作废) 使用interrupt方法中断线程 打断阻塞的线程(sleep，wait，join)的线程，线程会抛出InteruptedException异常 打断正常的线程，可以根据打断状态来标记是否退出线程 8.线程之间的通信方式线程之间的通信由于共享同一个进程的内存空间，可以通过共享数据或同步机制实现。以下是主要的通信方式： 共享变量：多个线程通过共享变量直接读写数据。比如说 volatile 和 synchronized 关键字。 **使用 wait() 和 notify()**，例如，生产者-消费者模式中，生产者生产数据，消费者消费数据，通过 wait() 和 notify() 方法可以实现生产和消费的协调。 CountDownLatch 和 CyclicBarrier ：这两个工具类用于在多个线程之间进行同步，尤其适用于等待多个线程完成任务后再继续执行。 Semaphore（信号量） ：Semaphore 是一个计数信号量，用于控制对共享资源的访问。它通过维护一个信号量计数来决定是否允许线程访问资源。 9.并发编程三要素 原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。 可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（synchronized,volatile） 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 出现线程安全问题的原因： 线程切换带来的原子性问题 缓存导致的可见性问题 编译优化带来的有序性问题 解决办法： JDK Atomic开头的原子类、synchronized、LOCK，可以解决原子性问题 synchronized、volatile、LOCK，可以解决可见性问题 Happens-Before 规则可以解决有序性问题 10.JMM——Java内存模型 是什么 Java 内存模型（JMM）是一个抽象模型，它定义了Java虚拟机（JVM）中线程与内存之间的交互规则。 主要用来定义多线程中变量的内存访问规则，可以解决变量的可见性、有序性和原子性问题，确保在并发环境中安全地访问共享变量。 主内存：所有线程共享的内存区域，存放实例变量、静态变量和数组等数据。 工作内存：每个线程拥有自己的私有工作内存，里面保存了线程所需变量的主内存副本。线程对变量的所有操作（如读取、赋值）都必须在工作内存中进行，不能直接操作主内存。 线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了共享变量的副本，用来进行线程内部的读写操作。 当一个线程更改了本地内存中共享变量的副本后，它需要将这些更改刷新到主内存中，以确保其他线程可以看到这些更改。 当一个线程需要读取共享变量时，它可能首先从本地内存中读取。如果本地内存中的副本是过时的，线程将从主内存中重新加载共享变量的最新值到本地内存中。 本地内存是 JMM 中的一个抽象概念，并不真实存在。 happens-before 指令重排也是有一些限制的，有两个规则happens-before和as-if-serial来约束。 happens-before 的定义：如果A happens-before B，那么A的结果对B可见。同一线程内，按代码顺序，前面的操作happens-before后面的操作 两个操作之间存在 happens-before 关系，并不意味着 Java 平台的具体实现必须要按照 happens-before 关系指定的顺序来执行。如果重排序之后的执行结果，与按 happens-before 关系来执行的结果一致，那么这种重排序并不非法 as-if-serial as-if-serial 语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的 happens-before 关系保证正确同步的多线程程序的执行结果不被重排序改变。 11.虚拟线程虚拟线程（Virtual Thread）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），由 JVM调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。 Java线程和操作系统的线程是一对一的关系，Java线程和虚拟线程是一对多的关系 虚拟线程适用于 I&#x2F;O 密集型任务 优点： 非常轻量级：可以在单个线程中创建成百上千个虚拟线程而不会导致过多的线程创建和上下文切换。 减少资源开销： 由于虚拟线程是由 JVM 实现的，它能够更高效地利用底层资源，例如 CPU 和内存。虚拟线程的上下文切换比平台线程更轻量，因此能够更好地支持高并发场景。 12.join()方法使用示例：线程.jion()：作用，等待调用的这个线程结束才可以继续往下执行 2.锁1.voliatlevolatile 关键字用于修饰变量 ，主要是保证多线程可见性和有序性 保证线程间的可见性 确保一个线程的修改能对其他线程是可见的。如何实现的呢？ 当一个共享变量被 volatile 修饰时，它会保证修改的值会被更新到主存，当有其他线程需要读取时，它会去主存中读取新值。 禁止指令重排序 如果我们将变量声明为 volatile ，在对这个变量进行读写操作的时候，会通过插入特定的 内存屏障 的方式来禁止指令重排序。以下供理解： 简单说就是JVM为了对代码进行优化提高性能会在不影响结果的情况下把代码执行顺序改变，但多线程就可能会出现结果不对的问题然后volatile原理就是加了一些屏障，使屏障后的代码一定不会比屏障前的代码先执行，从而实现有序性 2.乐观锁和悲观锁 悲观锁 悲观锁:认为自己在使用数据的时候一定有别的线程来修改数据，在获取数据的时候会先加锁，确保数据不会被别的线程修改。 锁实现:关键字synchronized、接口Lock的实现类 适用场景:写操作较多，先加锁可以保证写操作时数据正确 乐观锁 乐观锁:认为自己使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据 锁实现1:CAS（比较并交换，Compare-and-Swap）算法，是一种无锁的原子操作。 V：要更新的变量值(Var) E：预期值(Expected) N：新值(New) 当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。 ActomicInteger类的原子自增是通过CAS自选实现。 锁实现 2:版本号控制:数据表中加上版本号字段 version，表示数据被修改的次数。当数据被修改时这个字段值会加1，当更新数据时，同时比较版本号，若当前版本号和更新前获取的版本号一致， 则更新成功，否则失败。 适用场景:读操作较多，不加锁的特点能够使其读操作的性能大幅提升 CAS存在的缺点（问题） ABA问题 ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。 循环时间开销大 自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。 只能保证一个共享变量的原子性 只对一个共享变量操作可以保证原子性，但是多个则不行,多个可以通过AtomicReference来处理或者使用锁synchronized实现。 3.synchronized在 Java 中，关键字 synchronized（翻译过来就是“同步”的意思）用于实现线程同步，保证多个线程对共享资源的操作是互斥的。 synchronized 可用来修饰普通方法、静态方法和代码块 synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁； synchronized 关键字加到普通方法上是给对象实例上锁。 1.synchronized关键字的底层原理 这里要先了解对象的内存布局 synchronize的原理是基于对象内部的一个监视器锁（monitor）来实现的，每个对象都有一个monitor，当一个线程进入synchronize修饰的方法或代码块时，就会获取该对象的monitor，其他线程就无法进入该方法或代码块，直到持有monitor的线程退出并释放monitor。 使用synchronized之后，编译之后在同步的代码块前后加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题, 执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1。此时其他竞争锁的线程则会进入等待队列中。执行monitorexit指令时则会把计数器-1，当计数器值为0时则锁释放，处于等待队列中的线程再继续竞争锁。 synchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态这种转换非常消耗性能。 2.synchronized可重入的原理 重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。 123456789synchronized 之所以支持可重入，是因为 Java 的对象头包含了一个 Mark Word，用于存储对象的状态，包括锁信息。当一个线程获取对象锁时，JVM 会将该线程的 ID 写入 Mark Word，并将锁计数器设为 1。如果一个线程尝试再次获取已经持有的锁，JVM 会检查 Mark Word 中的线程 ID。如果 ID 匹配，表示的是同一个线程，锁计数器递增。当线程退出同步块时，锁计数器递减。如果计数器值为零，JVM 将锁标记为未持有状态，并清除线程 ID 信息。底层是通过 Monitor 对象的 owner 和 count 字段实现的，owner 记录持有锁的线程，count 记录线程获取锁的次数。 3.synchronized 锁升级的原理是什么？ 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁 偏向锁：旨在消除那些 “绝大多数情况下只有一个线程会访问锁” 的场景中的同步开销。 第一次加锁时，JVM 会在对象头（Mark Word）中记录当前线程 ID，并把对象标记为“偏向该线程”，后续该线程再进入同步块时，不做任何原子操作，直接通过检查 Mark Word 中的线程 ID 即可重入。 其他线程尝试获取该锁，偏向锁需要撤销（revoke）并升级到轻量级锁或直接到重量级锁： 当有多个线程竞争锁，但没有锁竞争的强烈迹象时（即线程交替执行同步块），偏向锁会升级为轻量级锁。 轻量级锁：每次都需要CAS操作 加锁： 复制 Mark Word：线程 A 为对象分配一个 Lock Record，并把对象头的 Mark Word 复制到该记录。 CAS 更新对象头：CAS 将对象头改为指向 Lock Record 的指针，并把状态位设置为 “轻量级锁”。 进入临界区：A 继续执行同步块内部代码。 解锁： 恢复 Mark Word：线程 A 将对象头恢复成最初复制的那份 Mark Word（通过 CAS 或直接写回）。 释放 Lock Record：锁记录空间可以复用或丢弃。 synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。 锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。 Java中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被一个线程持有、不同线程交替持有锁、多线程竞争锁三种情况。 重量级锁 底层使用的Monitor实现，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高性能比较低。 轻量级锁 线程加锁的时间是错开的(也就是没有竞争)，可以使用轻量级锁来优化。轻量级修改了对象头的锁标志，相对重量级锁性能提升很多。每次修改都是CAS操作，保证原子性 偏向锁 一段很长的时间内都只被一个线程使用锁，可以使用了偏向锁，在第一次获得锁时会有一个CAS操作，之后该线程再获取锁，只需要判断mark word中是否是自己的线程id即可，而不是开销相对较大的CAS命令 synchronized怎么保证可见性、有序性？ 可见性——JMM。 加锁时，线程必须从主内存读取最新数据。 释放锁时，线程必须将修改的数据刷回主内存，这样其他线程获取锁后，就能看到最新的数据。 有序性：monitorenter 和 monitorexit，来确保加锁代码块内的指令不会被重排。 4.什么是自旋很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 自旋锁有多种实现方式，例如CAS 5.synchronized 和 volatile 的区别​ synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！ 二者的应用场景也不同 volatile 是变量修饰符；synchronized 修饰修饰类、方法。 volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的原子性。 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。 6.ReentrantLockReentrantLock是一个类，其底层实现主要依赖于 AbstractQueuedSynchronizer（AQS）这个抽象类。 ReentrantLock 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。 但提供了比 synchronized 更细粒度的锁控制，支持公平锁、可中断锁、尝试获取锁等功能。 适用场景： 当需要更复杂的锁控制、当线程需要中断时、当锁的获取需要超时限制时， 1.公平锁和非公平锁 公平锁 : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。 非公平锁：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。 2.可中断锁和不可中断锁 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。 不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。 7.synchronized 和 ReentrantLock 的区别 两者都是可重入锁 可重入锁 也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。 synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API synchronized 是JM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。 ReentrantLock比sychronized 增加了一些高级功能 ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。 synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。 3.ThreadLocal 是什么 ThreadLocal是线程本地变量，在多线程并发执行过程中，为保证多个线程对变量的安全访问，可以将变量放到ThreadLocal类型的对象中，使变量在每个线程中都有独立值，线程之间互不影响，相互隔离，提高了线程安全性 底层原理 ThreadLocal底层使用的是当前线程的 ThreadLocalMap 来存储数据，它是一个哈希表，每个线程都有一个相关联的ThreadLocalMap。ThreadLocalMap的key是ThreadLocal实例的弱引用，对应的value是需要存储的值 key：ThreadLocal value：需要存储的值 存在的问题——内存泄露问题 使用线程池时，线程池中的线程会被重复使用。ThreadLocalMap是Thread中的一个属性，因此，ThreadLocalMap的生命周期与Thread一致。map中Entry对象的key被设置成弱引用，会被垃圾回收器回收，但是value不会被回收（ value 是强引用 ），从而造成内存泄漏。解决办法就是使用完之后手动调用remove()释放内存空间。 有关强引用，弱引用参看JVM篇 4.线程池作用：管理和复用线程，提高程序的性能和资源利用率，控制线程数量，避免系统过载 降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度：当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程复用原理：线程池对 Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程循环检查是否还有任务等待被执行，如果有则直接去执行这个任务，也就是调用任务的 run 方法，相当于把每个任务的 run() 方法串联了起来，所以线程数量并不增加。 1.线程池的核心参数（线程池的执行原理） corePoolSize：线程池核心线程数量 maximumPoolSize：线程池中最多可容纳的线程数量。 keepAliveTime ：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间 unit ：keepAliveTime的单位 workQueue：线程池所使用的缓冲队列，被提交但尚未被执行的任务 threadFactory：线程工厂，用于创建线程 handler：拒绝策略，线程池任务队列超过 maxinumPoolSize 之后的拒绝策略 流程 2.线程池的拒绝策略预置的有四种策略 AbortPolicy(默认方式，直接抛出一个任务被线程池拒绝的异常。 CallerRunsPolicy：由线程池的调用者所在的线程去执行被拒绝的任务 DiscardPolicy(不做任何处理，静默拒绝提交的任务。 DiscardOldestPolicy(丢弃最早被添加到队列的任务，然后尝试重新提交新任务) 如果希望快速失败并将异常传递给调用者，则选择AbortPolicy。如果希望尽可能保证任务的执行而不堆积在队列中，则选择CallerRunsPolicy。如果对任务的丢失情况不敏感，则选择 DiscardPolicy。而如果希望尽可能保留最新的任务而不是旧日的任务，则选择DiscardOldestPolicy。 3.线程池如何关闭可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。 shutdown：停止接收外部提交的任务，内部正在跑的任务和队列里等待的任务，会执行完，执行完也就关闭了 shutdownNow：也是先停止接收外部提交的任务，但是这里不同的是会忽略队列里等待的任务，然后尝试去关闭正在执行的任务 4.线程池的大小如何设定N是CPU核心数，设置corePoolSize的大小为： CPU密集型任务：N+1。我的目标是尽量减少线程上下文切换，以优化 CPU 使用率。 比 CPU 核心数多出来的一个线程是为了某些线程因等待系统资源而阻塞 ，一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。 I&#x2F;O密集型任务：2N。由于线程经常处于等待状态（等待 IO 操作完成），可以设置更多的线程来提高并发性（比如说 2 倍），从而增加 CPU 利用率。 5.为什么不推荐使用Executors创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 各个方法的弊端： （加粗的也是创建线程池的四种方式，分别是创建固定大小的线程池，创建一个单线程的线程池，创建可缓存的线程池，创建一个无限大小的线程池） newFixedThreadPool 和 newSingleThreadExecutor: 程池的任务队列使用的是无界队列 LinkedBlockingQueue，可以无限地接受任务。这可能会导致 内存溢出（OOM） 的情况，特别是在任务提交过多且任务处理速度跟不上时。 newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 ThreaPoolExecutor创建线程池方式只有一种，就是走它的构造函数，参数自己指定 四种线程池的执行原理： FixedThreadPool ：固定大小的线程池 如果当前运行的线程数小于 corePoolSize， 如果再来新任务的话，就创建新的线程来执行任务； 当前运行的线程数等于 corePoolSize 后， 如果再来新任务的话，会将任务加入 LinkedBlockingQueue； 线程池中的线程执行完 手头的任务后，会在循环中反复从 LinkedBlockingQueue 中获取任务来执行； SingleThreadExecutor： 是只有一个线程的线程池 如果当前运行的线程数少于1，则创建一个新的线程执行任务； 当前线程池中有一个运行的线程后，将任务加入 LinkedBlockingQueue 线程执行完当前的任务后，会在循环中反复从LinkedBlockingQueue 中获取任务来执行 CachedThreadPool：根据需要创建新线程的线程池 提交任务时，如果线程池没有空闲线程，直接新建线程执行任务；如果有，复用线程执行任务。线程空闲 60 秒后销毁，减少资源占用。缺点是线程数没有上限，在高并发情况下可能导致 OOM。 CachedThreadPool 的corePoolSize 被设置为空（0），maximumPoolSize被设置为 Integer.MAX.VALUE， 即它是无界的，这也就意味着如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时， CachedThreadPool 会不断创建新的线程。极端情况下，这样会导致耗尽 cpu 和内存资源。 ScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 核心线程数固定，但任务队列为无界队列（DelayedWorkQueue）。 6.任务队列的种类无界队列（如 LinkedBlockingQueue 未指定容量、PriorityBlockingQueue）：适合任务量波动大、不限制积压的场景，但需注意内存使用。 有界队列（如 ArrayBlockingQueue、LinkedBlockingQueue 指定容量）：适合需要控制任务积压的场景。 零容量队列（如 SynchronousQueue）：适合任务立即处理、不允许积压的场景。这是一个没有容量的队列。任务不会真正存储在队列中，而是直接交给工作线程处理。如果没有空闲线程，任务会被拒绝或根据拒绝策略处理。 优先级队列（如 PriorityBlockingQueue）：适合需要优先级调度的场景。 延迟队列（如 DelayedWorkQueue）：适合定时或延迟任务。 5.并发工具类⚠️Java 并发工具类（如 Semaphore、CountDownLatch、CyclicBarrier）主要用于 协调多线程之间的执行顺序和资源访问，而不是直接保证线程安全（如 synchronized 或 Atomic 那样）。它们的作用是 控制线程的并发行为，解决特定场景下的同步问题。 1.AQSAQS，全称是 Abstract Queued Synchronizer，中文意思是抽象队列同步器。AQS 就是一个抽象类，主要用来构建锁和同步器。 AQS 的思想是，如果被请求的共享资源空闲，则当前线程能够成功获取资源；否则，它将进入一个等待队列，当有其他线程释放资源时，系统会挑选等待队列中的一个线程，赋予其资源。 原理 是多线程中的队列同步器。是一种锁机制，它是做为一个基础框架使用的，像ReentrantLock、Semaphore都是基于AQS实现的 AQS内部维护了一个先进先出的双向队列，队列中存储的排队的线程在AQS内部还有一个 int 属性state，这个state就相当于是一个资源，默认是0(无锁状态)，如果队列中的有一个线程修改成功了state为1，则当前线程就相等于获取了资源 在对state修改的时候使用的CAS操作，保证多个线程修改的情况下原子性 AQS 支持两种同步方式： 独占模式：这种方式下，每次只能有一个线程持有锁，例如 ReentrantLock。 共享模式：这种方式下，多个线程可以同时获取锁，例如 Semaphore 和 CountDownLatch。 以 ReentrantLock 为例，state 初始值为 0，表示未锁定状态。A 线程 lock() 时，会调用 tryAcquire() 独占该锁并将 state+1 。此后，其他线程再 tryAcquire() 时就会失败，直到 A 线程 unlock() 到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 state 是能回到零态的。 再以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后countDown() 一次，state 会 CAS(Compare and Swap) 减 1。等到所有子线程都执行完后(即 state=0 )，会 unpark() 主调用线程，然后主调用线程就会从 await() 函数返回，继续后余动作。 2.semaphoresynchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，而Semaphore(信号量)可以用来限制同时访问某个资源的线程数量 Semaphore 通常用于那些资源有明确访问数量限制的场景比如限流，也就是流量控制 semaphore的原理 Semaphore 是共享锁的一种实现，它默认构造 AQS 的 state 值为 permits，你可以将 permits 的值理解为许可证的数量，只有拿到许可证的线程才能执行。 调用semaphore.acquire() ，线程尝试获取许可证，如果 state &gt;= 0 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 state 的值 state=state-1。如果 state&lt;0 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程。 调用semaphore.release(); ，线程尝试释放许可证，并使用 CAS 操作去修改 state 的值 state=state+1。释放许可证成功之后，同时会唤醒同步队列中的一个线程。 被唤醒的线程会重新尝试去修改 state 的值 state=state-1 ，如果 state&gt;=0 则获取令牌成功，否则重新进入阻塞队列，挂起线程。 3.CountDownLatch作用：让一个或多个线程等待其他线程完成操作后再继续执行。 CountDownLatch （倒计时器）用于协调多个线程之间的同步。 它允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。 CountDownLatch 的核心方法也不多： CountDownLatch(int count)：创建一个带有给定计数器的 CountDownLatch。 void await()：阻塞当前线程，直到计数器为零。 void countDown()：递减计数器的值，如果计数器值变为零，则释放所有等待的线程。 CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。 CountDownLatch的原理是什么 CountDownLatch 是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。 当线程使用 countDown() 方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state,直至 state 为 0 。 当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。 直到count 个线程调用了countDown()使 state 值被减为 0，或者调用await()的线程被中断，该线程才会从阻塞中被唤醒，await() 方法之后的语句得到执行。 用过CountDownLatch吗？什么场景下用的 测试分布式ID生成速度的时候用过 1234567891011121314151617181920212223242526272829303132333435//测试类@SpringBootTestpublic class RedisIdWorkerTest &#123; @Resource private RedisIdWorker redisIdWorker; private ExecutorService es = Executors.newFixedThreadPool(500); /** * 测试分布式ID生成器的性能，以及可用性 */ @Test public void testNextId() throws InterruptedException &#123; // 使用CountDownLatch让线程同步等待 CountDownLatch latch = new CountDownLatch(300); // 创建线程任务 Runnable task = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; long id = redisIdWorker.nextId(&quot;order&quot;); System.out.println(&quot;id = &quot; + id); &#125; // 等待次数-1 latch.countDown(); &#125;; long begin = System.currentTimeMillis(); // 创建300个线程，每个线程创建100个id，总计生成3w个id for (int i = 0; i &lt; 300; i++) &#123; es.submit(task); &#125; // 线程阻塞，直到计数器归0时才全部唤醒所有线程 latch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;生成3w个id共耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 4.CyclicBarrier作用：让一组线程互相等待，到达屏障点后同时继续执行（可重复使用）。 同步屏障。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。 CyclicBarrier 允许一组线程互相等待，直到到达一个公共的屏障点。 当所有线程都到达这个屏障点后，它们可以继续执行后续操作， 并且这个屏障可以被重置循环使用。 它和 CountDownLatch 类似，都可以协调多线程的结束动作，在它们结束后都可以执行特定动作","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://example.com/tags/JUC/"}]},{"title":"杂谈","slug":"生活/杂谈","date":"2024-10-20T02:25:39.000Z","updated":"2025-06-12T13:21:34.591Z","comments":true,"path":"2024/10/20/生活/杂谈/","permalink":"http://example.com/2024/10/20/%E7%94%9F%E6%B4%BB/%E6%9D%82%E8%B0%88/","excerpt":"","text":"以下内容从网上看到的记录一下 24.10.20 感觉“不舒服”的地方要远离，相信自己的直觉 不要随便说不吉利的话，也不要随便骂人，甚至是诅咒别人，不管在网上还是现实。语言是很有能量的东西，不要给自己制造负能量 家里，尤其是卧室最好不要摆放人形玩偶 勿以善小而不为，勿以恶小而为之 家中的植物尽量避免蕨类和藤曼类的植物，以阔叶类植物为佳 25.6.12 摆烂好多天了，哎，啥也不想干，总觉得没有足够的动力了。。 一直刷抖音，打游戏麻痹自己，明明打游戏打的一点意思也没有，就是麻痹自己，在打游戏的时候起码不那么焦虑，一放松下来就很焦虑。。 但是事后又有一种后悔的感觉。如果真能做到“落子无悔”就好了，起码自己心里不会有什么负担。 一天有很多次做决策的机会，是左还是右，是A还是B，这些决策可能在做之前，自己心里就清楚了答案，但还是不假思索的选择了当下愉悦自己，更轻松的那个抉择。 一天一天的浪费，就虚度了人生中的光阴","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"杂谈记录","slug":"杂谈记录","permalink":"http://example.com/tags/%E6%9D%82%E8%B0%88%E8%AE%B0%E5%BD%95/"}]},{"title":"歌单迁移","slug":"歌单迁移","date":"2024-10-17T14:15:39.000Z","updated":"2024-10-17T14:19:50.382Z","comments":true,"path":"2024/10/17/歌单迁移/","permalink":"http://example.com/2024/10/17/%E6%AD%8C%E5%8D%95%E8%BF%81%E7%A7%BB/","excerpt":"","text":"迁移网易云&#x2F;QQ音乐歌单 至 Apple&#x2F;Youtube&#x2F;Spotify Music一、源音乐文件导出Go-Music官网：https://music.unmeta.cn/ Go-Music 可以把网易云或者QQ音乐平台上面的歌单，以文本的形式导出。 二、迁移Tunemymusic 官网：https://www.tunemymusic.com/zh-CN/transfer 按步骤操作即可，需注意的是免费版一次最多迁移500首歌曲 参考文献：https://coderschool.cn/3791.html","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"http://example.com/tags/%E9%9F%B3%E4%B9%90/"}]},{"title":"前端了解","slug":"技术类/前端了解","date":"2024-10-17T12:29:34.000Z","updated":"2024-10-17T12:33:49.110Z","comments":true,"path":"2024/10/17/技术类/前端了解/","permalink":"http://example.com/2024/10/17/%E6%8A%80%E6%9C%AF%E7%B1%BB/%E5%89%8D%E7%AB%AF%E4%BA%86%E8%A7%A3/","excerpt":"","text":"vscode安装插件HTML css support live server：在浏览器中实时预览页面的变化 auto rename tag：修改HTML标签的时候同步修改另一个标签 一、HTML标签单标签用于没有内容的元素，双标签用于有内容的元素 快速生成HTML初始结构：在vocode中！+tab键 标题标签 h1-6分别对应1-6级标题 文本标签 p段落标签 b字体加粗，i斜体，u下划线，s删除线 ul——li无序标签 ol——li有序列表 1 HTML属性 语法 &lt;开始标签 属性名&#x3D;“属性值”&gt; 属性名不区分大小写，但属性值区分 适用大多数HTML元素的属性 class：为 HTML元素定义一个或多个类名(类名从样式文件引入) id：定义元素唯一的 id style：规定元素的行内样式 二、HTML区块-块元素与行内元素块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。 块级元素通常会从新行开始，并占据整行的宽度，因此它们会在页面上呈现为一块独立的内容块。 可以包含其他块级元素和行内元素。 常见的块级元素包括div&gt;，&lt;p&gt;，&lt;h1&gt;到&lt;h6&gt;,,‘等 行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接强调文本等。 行内元素通常在同一行内呈现，不会独占一行。 它们只占据其内容所需的宽度，而不是整行的宽度。 行内元素不能包含块级元素，但可以包含其他行内元素。 常见的行内元素包括span&gt;，&lt;img&gt;，&lt;br&gt;，&lt;input&gt;等, 三、HTML表单form span标签等于label CSS","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"影视点评","slug":"生活/影视点评","date":"2024-10-10T13:36:25.000Z","updated":"2025-01-17T14:10:11.210Z","comments":true,"path":"2024/10/10/生活/影视点评/","permalink":"http://example.com/2024/10/10/%E7%94%9F%E6%B4%BB/%E5%BD%B1%E8%A7%86%E7%82%B9%E8%AF%84/","excerpt":"","text":"电视剧 人民的名义：9分 都挺好：8.5分 征服：9分 破冰行动：8.5分 狂飙：9分 马大帅1：8.5分 武林外传：10分 富贵：9.5分 我是余欢水：8分（有点高开低走 沉默的真相：9分 隐秘的角落：9分 漫长的季节：9.分 地下交通站-第一季：10分 三国演义：10分 少帅：9分 大宅门：9.5分！ 边水往事：7.5分（高开低走 权力的游戏-综评：9分 黑袍纠察队-综评：8.5分 韦恩：看的时间太长有点忘了，暂给8分 闯关东：9.5分！ 我是大哥大：10分！ 大染坊：9分 电影 让子弹飞：10分！ 异次元骇客：10分！","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"影视","slug":"影视","permalink":"http://example.com/tags/%E5%BD%B1%E8%A7%86/"}]},{"title":"MybatisPlus学习","slug":"技术类/MybatisPlus学习","date":"2024-10-09T14:49:21.000Z","updated":"2025-05-13T03:41:00.317Z","comments":true,"path":"2024/10/09/技术类/MybatisPlus学习/","permalink":"http://example.com/2024/10/09/%E6%8A%80%E6%9C%AF%E7%B1%BB/MybatisPlus%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"一、快速入门1.1、使用1、引入依赖 注意：引入了MP的依赖，就不用引Mybatis的依赖了，这个依赖已经包含了Mybatis的 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt; &lt;/dependency&gt; 2、定义Mapper 自定义的Mapper继承MybatisPlus提供的BaseMapper接口（要制定实体类的类型） 3、在实体类上添加注解声明表信息 4、在application.yml中根据需要添加配置 1.2、常见注解MyBatisPlus通过扫描实体类，并基于反射获取实体类信息作为数据库表信息 约定： 类名驼峰转下划线作为表名 名为id的字段作为主键 变量名驼峰转下划线作为表的字段名 如果实体和表的对应关系不符合以上约定，就要用注解来配置了 @TableName：用来指定表名 @TableId：用来指定表中的主键字段信息 @TableField：用来指定表中的普通字段信息 对于@TableId，IdType枚举可选类型有以下： AUTO:数据库自增长 INPUT:通过set方法自行输入 ASSIGN_ID:分配ID，接口ldentifierGenerator的方法nextld来生成id，默认实现类为雪花算法。这种方式由mp自动生成id 使用@TableField的常见场景： 成员变量名与数据库字段名不一致（如上图name） 成员变量名以is开头，且是布尔值（如上图isMarried） 成员变量名与数据库关键字冲突（如上图order） 成员变量不是数据库字段（如上图address） 二、核心功能2.1、条件构造器MyBatisPlus支持各种复杂的where条件，可以满足日常开发的所有需求。 第一步：构建查询条件 第二步：操作（查询更新等） 推荐还是用lambda的模式 QueryWrapper和LambdaQueryWrapper通常用来构建select、delete、update的where条件部分 UpdateWrapper和LambdaUpdateWrapper通常只有在set语句比较特殊才使用 尽量使用LambdaQueryWrapper和LambdaUpdateWrapper来避免硬编码 2.2、自定义SQLMP擅长where条件的构建，因此我们可以利用MyBatisPlus的Wrapper来构建复杂的Where条件，然后自己定义SQL语句中剩下的部分。 基于Wrapper构建where条件 在mapper方法参数中用Param注解声明wrapper变量名称，必须是ew 自定义SQL，并使用Wrapper条件 2.3、Service接口2.3.1、IService接口的基本使用 MP的Service接口使用流程是怎样的? 自定义Service接口继承IService接口 自定义Service实现类，实现自定义接口并继承Servicelmpl类","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MybatisPlus","slug":"MybatisPlus","permalink":"http://example.com/tags/MybatisPlus/"}]},{"title":"广州南北科技面经","slug":"面经/广州南北科技面经","date":"2024-10-09T13:23:30.000Z","updated":"2024-10-10T04:17:23.667Z","comments":true,"path":"2024/10/09/面经/广州南北科技面经/","permalink":"http://example.com/2024/10/09/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E5%8D%97%E5%8C%97%E7%A7%91%E6%8A%80%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"广州小厂，面试问的问题感觉很奇怪，总共聊了半小时 聊了好长时间本科的毕业设计和现在的研究方向 ArrayList的底层实现，扩容机制； 然后问扩容，Arraylist正在add元素的时候，新数组和旧数组怎么处理（不是往新数组里面拷贝旧数组的元素吗 HashMap链表的扩容机制，链表里面是values，values是怎么存储的； 答：得到在数组中的索引，如果该处节点是链表，会在链表中遍历有没有相同的key，如果有就更新value，没有就在链表末尾插入，最后判断链表长度是否达到阈值（8，这个阈值忘了，直接说的阈值），是的话就转化为红黑树，增加查找效率 问了下平时用什么开发工具 很大的表，用Select count去统计表的条数，发现特别慢，怎么优化 不会，一开始没听清楚瞎答了索引，然后又说什么select count（1），，自己都有点想笑哈哈哈 很大的表，发现不管干啥都慢，有什么办法优化 不会，想到了分库分表，没看这个八股， 然后又问分（区）表策略，没了解 后面就聊到我的本科毕业设计了 然后又问springboot怎么实现‘约定大于配置’的，不会 redis怎么实现分布式锁 setnx命令 又说看我这边是用了lua脚本，直接说的没学过，就是跟着视频用的 最后反问环节","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"广州泰豪软件面经","slug":"面经/广州泰豪软件面经","date":"2024-10-09T13:15:47.000Z","updated":"2024-10-10T04:22:16.023Z","comments":true,"path":"2024/10/09/面经/广州泰豪软件面经/","permalink":"http://example.com/2024/10/09/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E6%B3%B0%E8%B1%AA%E8%BD%AF%E4%BB%B6%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"用时差不多正好半小时，面的是泰豪软件（广州），面试官人感觉不错。第一次面试感觉没有想象中的那么紧张，八股和项目都问了一点。 上来自我介绍 八股： private，default，protected，public的区别； &amp;和&amp;&amp;的区别； final关键字； break，continue，return； 单列集合，List和Set有什么区别； CopyOnWriteArrayList； 多线程同步有哪几种方式（就回答了synchronized和lock）； 常用的线程池有哪几种（一开始想说那个英文方法名，磕巴了半天没说出来还，最后直接用中文说了）； 线程之间是怎么传递数据的（没回答好，没准备这个八股）； 创建线程有几种方式； 项目： 除了MySQL还了解过其它数据库吗（本科的时候学过Oracle，没了）； 设计redis的缓存更新策略的时候，考虑哪些因素（1、过期时间，2、先更新数据库，再删除缓存，更新缓存。不知道 回答的对不对）； 怎么解决缓存击穿和缓存穿透的（介绍了一下这俩是什么，然后回答的，缓存击穿答得不是很详细，有点混乱了）； 后面就是聊天了 问了意向城市， 然后学习和做项目的时候有没有碰到什么问题，是怎么解决的 对前端有了解吗，vue，如果有这方面的学习愿不愿意了解一下 问了下如果通过最快什么时候能到岗 个人职业规划 反问环节，问了几个。最后面试官介绍了一下他们公司业务什么的","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"从设备来理解计算机网络","slug":"技术类/从设备来理解计算机网络","date":"2024-10-03T12:17:15.000Z","updated":"2024-10-10T04:22:43.405Z","comments":true,"path":"2024/10/03/技术类/从设备来理解计算机网络/","permalink":"http://example.com/2024/10/03/%E6%8A%80%E6%9C%AF%E7%B1%BB/%E4%BB%8E%E8%AE%BE%E5%A4%87%E6%9D%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"一、Hub集线器（物理层）广播消息，由设备自己判断该消息是否发送给自己的 但如果两个设备同时发送电平信号，会导致消息杂糅起来，导致想接收的设备解析不了 CSMA&#x2F;CD协议：载波监听在发送消息之前先检测有无设备正在发送消息 缺点： 只能有一个设备同时发送数据 需要广播消息，占用带宽 二、SW交换机（数据链路层）交换机可记录标识：（设备）Mac地址和（交换机）端口的映射 对HUB的改进 所以这种方式不需要将消息广播 而且交换机采用的是全双工，就是可以边发边收，而集线器是半双工的，不能同时收发消息 交换机可以桥接交换机，就是可以通过某个端口向另一个交换机的设备发送消息 缺点： 可以在局域网内使用，在大规模网络中就有点乏力了，要找到设备需要不停的广播（一开始交换机中未记录对应映射的时候），可能会造成泛洪 三、路由器（网关）（网络层）多个网络之间的通信 这里提出IP地址：一是标识网络，二是标识设备。 IP地址是一个抽象的地址，真正传输的时候还是需要mac地址（真实地址） 所以在同一个网络内传输时 先根据目标IP地址得到其mac地址，ARP协议 就可以进行传输了","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"广州亿迅科技面经","slug":"面经/广州亿迅科技面经","date":"2024-09-29T10:43:20.000Z","updated":"2024-10-10T04:31:36.029Z","comments":true,"path":"2024/09/29/面经/广州亿迅科技面经/","permalink":"http://example.com/2024/09/29/%E9%9D%A2%E7%BB%8F/%E5%B9%BF%E5%B7%9E%E4%BA%BF%E8%BF%85%E7%A7%91%E6%8A%80%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"全程大概半小时左右，都不是严格的问答，比较开放式的，感觉跟报菜名似的，全是八股项目几乎没问 聊到一些集合类，把List，Map，Set都介绍了一下，以及对应的使用场景 ArrayList和LinkedList的区别 ArrayList的扩容机制 HashMap简单说了一下，都没涉及到put流程 I&#x2F;O，不熟 项目中怎么用的乐观锁悲观锁 网络编程，Socket，不熟 NIO&#x2F;BIO，不熟 序列化和反序列化，怎么让一部分数据不被序列化，第二个忘了 Spring的IOC和AOP sql的全称，忘了。。-_-|| 然后问的视图，存储过程，都没背。。 索引简单答了一下底层数据结构 表之间的连接 JDBC，没看， String，StringBuffer，StringBulder &#x3D;&#x3D;和equals 后续10.8 OC","categories":[{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"}]},{"title":"Mysql学习","slug":"技术类/Mysql学习","date":"2024-09-11T10:40:44.000Z","updated":"2024-10-10T01:58:25.099Z","comments":true,"path":"2024/09/11/技术类/Mysql学习/","permalink":"http://example.com/2024/09/11/%E6%8A%80%E6%9C%AF%E7%B1%BB/Mysql%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"SQL语句DDL（Data Definition Language）数据定义语言，用来定义数据库对象(数据库，表，字段) 数据库操作12345678910#查询所有数据库SHOW DATABASES; #查询当前数据库SELECT DATABASE; #创建CREATE DATABASE [IF NOT EXISTS] 数据库名 [DEFAULT CHARSET 字符集] [COLLATE 排序规则]; #删除DROP DATABASE[IF EXISTS] 数据库名;#使用USE 数据库名； 表操作123456789101112131415161718192021222324252627282930#查询当前数据库所有表SHOW TABLES;#查询表结构DESC 表名；#查看指定表的建表语句；SHOW CREATE 表名；#创建表CREATE TABLE 表名（ 字段1 字段1类型 [COMMENT 字段1注释(用单引号括起来)]， 字段2 字段2类型 [COMMENT 字段2注释]， 字段3 字段3类型 [COMMENT 字段3注释]， ... 字段n 字段n类型 [COMMENT 字段n注释])[COMMENT 表注释];#添加字段ALTER TABLE 表名 ADD 字段名 类型（长度）[COMMENT 注释][约束];#修改数据类型ALTER TABLE 表名 MODIFY 字段名 新数据类型（长度）;#修改字段名和数据类型ALTER TABLE 表名 CHANGE 旧字段名 新字段名 新类型（长度）[COMMENT 注释][约束];#删除字段ALTER TABLE 表名 DROP 字段名;#删除表DROP TABLE[IF EXISTS] 表名;#删除指定表，并重新创建该表TRUNCATE TABLE 表名； DML（Data Manipulation Language）数据操作语言，用来对数据库表中的数据进行增删改 123456789101112131415161718#添加数据#1、给指定字段添加数据INSERT INTO 表名（字段名1，字段名2，...） VALUES(值1，值2，...);#2、给全部字段添加数据INSERT INTO 表名 VALUES(值1，值2，...);#3、批量添加数据INSERT INTO 表名（字段名1，字段名2，...） VALUES(值1，值2，...),(值1，值2，...),(值1，值2，...);INSERT INTO 表名 VALUES (值1，值2，...),(值1，值2，...),(值1，值2，...);#字符串和日期型数据应该包含在引号中，插入的数据大小应该在字段的规定范围内，括号要加#修改数据UPDATE 表名 SET 字段名1=值1，字段名2=值2,...[WHERE 条件];#修改语句的条件可以有，也可以没有，如果没有，则会修改整张表的所有数据#删除数据DELETE FROM 表名 [WHERE 条件];#条件可以有也可以没有，如果没有则会删除整张表的所有数据#DELETE不能删除某一个字段的值（可以用UPDATE) DQL（Data Query Language）数据查询语言，用来查询数据库中表的记录 基本查询12345678#基本查询#1、查询多个字段SELECT 字段1，字段2，字段3，...FROM 表名；SELECT * FROM 表名；#2、设置别名SELECT 字段1[AS 别名1],字段2[AS 别名2] ...FROM 表名；#3、去掉重复记录SELECT DISTINCT 字段列表 FROM 表名； 条件查询123#条件查询#1、语法SELECT 字段列表 FROM 表名 WHERE 条件列表； 条件查询的条件列表 比较运算符 功能 ＞，＞&#x3D;，&lt;，&lt;&#x3D;，&#x3D;，&lt;&gt;或!&#x3D; 最后一个是不等于 BETWEEND..AND… 在某个范围之内（含最小，最大值）前面可以加一个字段 IN(…) 在in之后的列表中的值，多选一 LIKE 占位符 模糊匹配（_匹配单个字符，%匹配任意个字符），占位符用单引号括起来 IS NULL 是NULL 逻辑运算符 功能 AND 或 &amp;&amp; 并且（同时成立） OR 或 || 或者（任一成立） NOT 或 ！ 非，不是 分组查询聚合函数将一列数据作为整体，进行纵向计算 函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 12#语法SELECT 聚合函数（字段列表） FROM 表名； 分组查询12#语法SELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件]； 这里where和having的区别 执行时机不同：where是分组前进行过滤，having是对分组后的数据进行过滤 判断条件不同：where不能对聚合函数判断（即不能使用聚合函数），having可以 执行顺序：where &gt; 聚合函数 &gt; having 分组之后，查询的字段一般为聚合函数和分组字段，查询其它字段无意义 排序查询12#语法SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2; 排序方式 ASC ：升序（默认） DESC：降序 注意：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段排序 分页查询12#语法SELECT 字段列表 FROM 表名 LIMIT 起始索引，查询记录数； 注意： 起始索引从0开始，起始索引&#x3D;（查询页码-1）*每页记录数 如果查询的是第一页数据，起始索引可以省略，直接简写为limit 10。 DQL的执行顺序编写顺序如下： 1234567891011121314SELECT #----第四步 字段列表FROM #----第一步 表名列表WHERE #----第二步 条件列表GROUP BY #----第三步 分组字段列表HAVING 分组后条件列表ORDER BY #----第五步 排序字段列表LIMIT #----第六步 分页参数 DCL（Data Control Language）数据控制语言，用来创建数据库用户、控制数据库的访问权限 管理用户123456789101112#查询用户USE mysql;SELECT * FROM user;#创建用户CREATE USER &#x27;用户名&#x27;@&#x27;主机名‘ IDENTIFIED BY &#x27;密码&#x27;；#修改用户密码ALTER USER &#x27;用户名&#x27;@&#x27;主机名’ IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;；#删除用户DROP USER &#x27;用户名&#x27;@&#x27;主机名’； 权限控制 权限 说明 ALL,ALL PRIVILEGES 所有权限 SELECT 查询数据 INSERT 插入数据 UPDATE 修改数据 DELETE 删除数据 ALTER 修改表 DROP 删除数据库&#x2F;表&#x2F;视图 CREATE 创建数据库&#x2F;表 12345678#查询权限SHOW GRANTS FOR &#x27;用户名&#x27;@‘主机名’；#授予权限GRANT 权限列表 ON 数据库.表名 TO &#x27;用户名&#x27;@‘主机名’；#撤销权限REVOKE 权限列表 ON 数据库.表名 FROM &#x27;用户名&#x27;@‘主机名’； 多个权限之间，用逗号分隔 授权时，数据库名和表名可以用*进行通配 函数字符串函数 函数 功能 CONCAT(S1,S2,…Sn) 将S1,S2,..SN拼接为一个字符串 LOWER(str) 转小写 UPPER(str) 转大写 LPAD(str,n,pad) 左填充，用pad对str的左边进行填充，达到n个字符串长度 RPAD(str,n,pad) 右填充，用pad对str的右边进行填充，达到n个字符串长度 TRIM(str) 去掉字符串头部和尾部的空格 SUBSTRING(str,start,len) 返回str从start起len个长度的字符串 数值函数 函数 功能 CEIL(x) 向上取整 FLOOR(x) 向下取整 MOD(x,y) 返回x&#x2F;y的模 RAND() 返回0~1的随机数 ROUND(x,y) 求参数x的四舍五入的值，保留y位小数 日期函数 函数 功能 CURDATE() 返回当前日期 CURTIME() 返回当前时间 NOW() 返回当前日期和时间 YEAR(date) 获取指定date的年份 MONTH(date) 获取指定date的月份 DAY(date) 获取指定date的日期 DATE_ADD(date,INTERVAL expr type) 返回一个日期&#x2F;时间值加上一个时间间隔expr后的时间值 DATEDIFF(date1,date2) 返回起始时间date1和结束时间date2之间的天数 流程函数可以在SQL语句中实现条件筛选，从而提高语句的效率 函数 功能 IF(value,t,f) 如果value为true，返回t，否则返回f IFNULL(value1,value2) 如果value不为空，返回value1，否则返回value2 CASE WHEN [val1] THEN [res1]…ELSE [default] END 如果val1为true，返回res1，否则返回默认值 CASE [expr] WHEN [val1] THEN [res1]…ELSE [default] END 如果expr的值等于val1，返回res1，否则返回默认值 约束约束是作用于表中字段上的规则，用于限制存储在表中的数据 约束 功能 关键字 非空约束 NOT NULL 唯一约束 UNIQUE 主键约束 主键是一行数据的唯一标识，要求非空且唯一 PRIMARY KEY 默认约束 保存数据时，如果未指定该字段的值，采用默认值 DEFAULT 检查约束 保证字段值满足某一个条件 CHECK 外键约束 用来让两张表的数据之间建立联系，保持数据的一致性和完整性 FOREIGN KEY 1234567891011#语法一、创建的时候指定外键约束CREATE TABLE 表名（ 字段名 数据类型 ... [CONSTRAINT] [外键名称] FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名));#语法二、对于已创建的表来修改外键约束ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名);#删除外键ALTER TABLE 表名 DROP FOREIGN KEY 外键名称； 删除&#x2F;更新行为 行为 说明 NO ACTION &#x2F; RESTRICT 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新。(默认情况) CASCADE 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有，则也删除&#x2F;更新外键在子表中的记录。 SET NULL 当在父表中删除对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为nu(这就要求该外键允许取nul) 12#语法，只需在后面加上更新和删除的方式ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名) ON UPDATE CASCADE ON DELETE CASCADE; 多表查询多表关系 一对多（多对一） 多对多 一对一 内连接查询两张表的交集部分 12345#隐式内连接SELECT 字段列表 FROM 表1，表2 WHERE 条件...；#显式内连接 （和隐式没有区别，仅是写法的不同而已）[INNER 可有可无SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件...； 外连接左外连接和右外连接左：查询左表的所有数据和左右表交集部分的数据 右：查询右表的所有数据和左右表交集部分的数据 12345#语法------左 [OUTER可有可无SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件...;#语法------右SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件...; 右外可改成左外。左外会写就行 自连接12#语法SELECE 字段列表 FROM 表A 别名A JOIN 表A 表名B ON 条件...; 自连接查询，可以是内连接也可以是外连接 联合查询对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集 1234#语法SELECT 字段列表 FROM 表A ...UNION [ALL] #带ALL不会对查询结果去重SELECT 字段列表 FROM 表B ...; 使用条件：两个语句的字段列表（数量&#x2F;类型）要保持一致 子查询SQL语句中嵌套SELECT语句，称为嵌套查询，又称子查询。子查询要用（）括起来 子查询外部的语句可以是INSERT&#x2F;UPADTE&#x2F;DELETE&#x2F;SELECT 中的任何一个 标量子查询子查询结果为单个值 常用的操作符：&#x3D;，&lt;&gt;,&gt;,&gt;&#x3D;,&lt;,&lt;&#x3D; 列子查询子查询结果是一列 常用的操作符：IN , NOT IN , ANY(满足子查询列表的一个即可) , SOME(与ANY同等) ,ALL(必须全部满足) 行子查询子查询结果是一行 常用的操作符： &#x3D; ，&lt;&gt; , IN , NOT IN 表子查询子查询结果是多行多列 常用的操作符： IN 事务事务 是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 事务操作12345#开启事务START TRANSATION#提交/回滚事务COMMIT / ROLLBACK; *事务四大特性ACID 原子性（Atomicity） ：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency） ：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 *脏读、不可重复读、幻读 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 例子:小明读取到小红提交的100数据.但是小红异常回滚了数据,100变成了90,这个时候小明还是100,但实际是90(脏读) 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 例子:小明多次读取A数据,小红在小明读取数据时,每次读取都修改了数据并提交,小明多次读到的数据不一致 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 例子:小明修改了A,B数据,小红同时又插入了一条C数据,小明会感觉自己明明数据都改了,突然多出来一条,以为出现了幻觉自己漏了一条 *事务的隔离级别 隔离级别 脏读 不可重复读 幻读 Read uncommitted 有 有 有 Read committed 无 有 有 Repeatable Read（Mysql的默认级别） 无 无 有 Serializable 无 无 无 级别越高，安全性越高，执行效率越低 12345#查看事务隔离级别SELECE @@TRANSATION_ISOLATION;#设置事务隔离级别SET [SESSION|GLOBAL] TRANSATION ISOLATION LEVEL &#123;级别&#125; 引擎存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。 MySQL存储引擎MyISAM与InnoDB区别 Innodb引擎：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。 MyIASM引擎(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。 存储引擎选择如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。 索引索引介绍索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。 索引的优缺点优点 使用索引可以大大加快数据的检索速度 缺点 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增&#x2F;改&#x2F;删的执行效率； 空间方面：索引需要占物理空间。 索引结构索引分类从数据结构角度 树索引 Hash索引 从物理存储角度 聚集索引 聚簇索引是一种索引组织方式，它将索引和数据行存储在一起，即数据行按照索引的顺序存储在磁盘上。 聚簇索引的叶子节点保存的是完整的数据行，因此不需要进行额外的查找操作就可以获取到所需的数据。 InnoDB 存储引擎的主键索引就是一个聚簇索引，如果表没有显式地定义主键，InnoDB 会选择一个唯一的非空索引作为聚簇索引。 非聚集索引 非聚簇索引是一种索引组织方式，它将索引和数据行分开存储，即索引保存了指向数据行的指针（通常是行的物理地址或主键值）。 非聚簇索引的叶子节点保存的是指向数据行的引用，当查询需要获取数据时，首先根据索引查找到相应的行指针，然后再通过行指针获取数据行。 在MySQL中，MyISAM 存储引擎的索引通常是非聚簇索引。 总的来说，聚簇索引和非聚簇索引的区别在于索引和数据行的存储方式。聚簇索引将索引和数据行存储在一起，而非聚簇索引将索引和数据行分开存储。 对于非聚簇索引，一定会回表查询吗？ 答：不一定。试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。 这种情况就称之为索引覆盖。 索引覆盖：如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后只写必要的查询字段，以增加索引覆盖的几率。 这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。 从逻辑角度 普通索引：基本的索引类型，没有唯一性的限制，允许为NULL值。 可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引 主键索引：数据列不允许重复，不允许为NULL，一个表只能有一个主键。 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引 索引语法SQL性能分析SQL优化插入数据load指令一次插入大批量数据 主键优化 满足业务需求的情况下，尽量降低主键的长度 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键 尽量不要使用UUID做主键或者是其它自然主键，如身份证号 业务操作时，避免对主键的修改 order by 优化group by优化","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"}]},{"title":"java八股","slug":"八股/java基础","date":"2024-09-11T04:35:44.000Z","updated":"2025-05-22T07:17:46.845Z","comments":true,"path":"2024/09/11/八股/java基础/","permalink":"http://example.com/2024/09/11/%E5%85%AB%E8%82%A1/java%E5%9F%BA%E7%A1%80/","excerpt":"Java基础知识","text":"Java基础知识 1.概述1.Java 语言有哪些特点？ 跨平台 内存管理（垃圾回收） 生态 面向对象（封装，继承，多态）； 2.JVM、JDK 和 JRE的区别 JVM：Java Virtual Machine，Java 虚拟机，Java 程序运行在 Java 虚拟机上。针对不同系统的实现（Windows，Linux，macOS）不同的 JVM，因此 Java 语言可以实现跨平台。 JVM 负责将 Java 字节码转换为特定平台的机器码，并执行。 JRE：Java 运⾏时环境。包含了运行 Java 程序所必需的库，以及 JVM。 它是运⾏已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，Java 命令和其他的⼀些基础构件。但是，它不能⽤于创建新程序。 JDK: Java Development Kit，它是功能⻬全的 Java SDK。它拥有 JRE 所拥有的⼀切，还有编译器（javac）和⼯具（如 javadoc 和 jdb）。它能够创建和编译程序。 3.什么是字节码所谓的字节码，就是 Java 程序经过编译之类产生的.class 文件，字节码能够被虚拟机识别，从而实现 Java 程序的跨平台性。 Java 程序从源代码到运行主要有三步： 编译：将我们的代码（.java）编译成虚拟机可以识别理解的字节码(.class) 解释：虚拟机执行 Java 字节码，将字节码翻译成机器能识别的机器码 执行：对应的机器执行二进制机器码 4.Java 源码从编译到执行，发生了什么 编译：编译器 (javac) 将 .java 文件编译为 .class 字节码文件。 加载：类加载器 (ClassLoader) 在运行时将 .class 文件加载到 JVM 的内存中。 链接：链接器将各类加载的代码整合在一起，为后续运行做准备。 执行：Java 虚拟机 (JVM) 执行字节码。 关键组件： 方法区 (Method Area)： 存储类信息、常量、静态变量等。 堆 (Heap)： 存储对象实例。 栈 (Stack)： 存储方法调用的局部变量和操作数。 程序计数器 (PC)： 跟踪当前执行的字节码指令。 过程： 字节码解释器： 将字节码逐条翻译为机器码并执行。 解释执行速度较慢。 即时编译器 (JIT Compiler)： 热点代码（高频执行的代码）会被编译为机器码，提高性能。 JIT 编译优化包括内联、逃逸分析等。 回收：在程序运行期间，JVM 自动管理内存，通过垃圾回收 (Garbage Collection) 清理不再使用的对象，避免内存泄漏。 1234567891011121314源代码 (.java) ↓ 编译器 (javac) ↓字节码 (.class) ↓ 类加载器 (ClassLoader) ↓ 验证、准备、解析 ↓ JVM 执行字节码 ↓ 垃圾回收与退出 2.基础语法1.Java 有哪些数据类型 数值型 整数类型（byte、short、int、long）(占字节分别是 1、2、4、8) 浮点类型（float、double）(占字节分别是 4、8) 字符型（char）（占字节2） 布尔型（boolean）（占字节1） 注意：浮点数的默认类型为double（如果需要声明一个常量为float型，则必须要在末尾加上f或F），比如float f&#x3D;3.4 就不对，3.4 是双精度数，转为float会有精度损失 2.什么是自动拆箱&#x2F;封箱 装箱：将基本类型用它们对应的引用类型包装起来；引用是 Integer 类型，&#x3D; 右侧是 int 基本类型时，会进行自动装箱，调用的其实是 Integer.valueOf()方法，它会调用 IntegerCache。 拆箱：将包装类型转换为基本数据类型；调用xxValue()方法 Java为什么要引入包装类型呢？ 1.面向对象的需要，基础类型不是对象，不能直接调用方法 2.集合框架的需要，集合只能操作对象 3.包装类型的缓存机制看一个题目 Integer a&#x3D; 127，Integer b &#x3D; 127；Integer c&#x3D; 128，Integer d &#x3D; 128；相等吗? a 和 b 相等，c 和 d 不相等。 这个问题涉及到 Java 的自动装箱机制以及Integer类的缓存机制。 a和b是相等的。这是因为 Java 在自动装箱过程中，会使用Integer.valueOf()方法来创建Integer对象。 Integer.valueOf()方法会针对数值在**-128 到 127** 之间的Integer对象使用缓存。因此，a和b实际上引用了常量池中相同的Integer对象。 c和d不相等。这是因为 128 超出了Integer缓存的范围(-128 到 127)。 因此，自动装箱过程会为c和d创建两个不同的Integer对象，它们有不同的引用地址。 4.成员变量与局部变量的区别有哪些？ 作用域 成员变量：针对整个类有效。 局部变量：只在某个范围内有效。(一般指的就是方法,语句体内) 存储位置 成员变量：随着对象的创建而存在，随着对象的消失而消失，存储在堆内存中。 局部变量：在方法被调用，或者语句被执行的时候存在，存储在栈内存中。当方法调用完，或者语句结束后，就自动释放。 生命周期 成员变量：生命周期和对象一样，随着对象的创建而存在，随着对象的消失而消失 局部变量：当方法调用完，或者语句结束后，就自动释放。 初始值 成员变量：有默认初始值。 局部变量：没有默认初始值，使用前必须赋值。 5.静态变量和实例变量的区别静态变量: 是被 static 修饰符修饰的变量，也称为类变量，它属于类，不属于类的任何一个对象，一个类不管创建多少个对象，静态变量在内存中有且仅有一个副本。 实例变量: 必须依存于某一实例，需要先创建对象然后通过对象才能访问到它。静态变量可以实现让多个对象共享内存。 作用 被 static 修饰的方法称为静态方法，它属于类本身，不依赖于类的实例。 静态方法可以通过类名直接调用，无需创建对象。 作用 被 static 修饰的代码块称为静态代码块，在类加载时执行，且只执行一次。 通常用于初始化静态资源或执行一些类级别的准备工作。 5.&#x3D;&#x3D;和 equals 的区别&#x3D;&#x3D; : 它的作⽤是判断两个对象的地址是不是相等。即，判断两个对象是不是同⼀个对象(基本数据类型 &#x3D;&#x3D; 比较的是值，引⽤数据类型 &#x3D;&#x3D; 比较的是内存地址)。 equals() : 它的作⽤也是判断两个对象是否相等。但是这个“相等”一般也分两种情况： 默认情况：类没有覆盖 equals() ⽅法。则通过 equals() 比较该类的两个对象时，等价于通过“ &#x3D;&#x3D; ”比较这两个对象，还是相当于比较内存地址。 自定义情况：类覆盖了 equals() ⽅法。我们平时覆盖的 equals()方法一般是比较两个对象的内容是否相同，自定义了一个相等的标准，也就是两个对象的值是否相等。 6.为什么重写 equals 时必须重写 hashCode ⽅法根据 Java 规范 ，若两个对象通过 equals() 方法判定为相等，则它们的 hashCode() 必须返回相同的值。反之，若两个对象 hashCode() 相同，它们的 equals() 可以不等。 因此，equals ⽅法被覆盖过，则 hashCode ⽅法也必须被覆盖。如果重写了 equals()方法而没有重写 hashCode()方法，那么被认为相等的对象可能会有不同的哈希码，导致集合无法正确识别重复对象。 为什么两个对象有相同的 hashcode值，它们也不⼀定是相等的？ 因为可能会碰撞，这主要是由于哈希码（hashCode）的本质和目的所决定的。 哈希码是通过哈希函数将对象中映射成一个整数值，其主要目的是在哈希表中快速定位对象的存储位置。 由于哈希函数将一个较大的输入域映射到一个较小的输出域，不同的输入值（即不同的对象）可能会产生相同的输出值（即相同的哈希码）。这种情况被称为哈希冲突。 7.访问修饰符 public、private、protected、以及不写（默认）的区别 default (即默认，什么也不写）: 在同一包内可见，不使用任何修饰符。可以修饰在类、接口、变量、方法。 private : 在同一类内可见。可以修饰变量、方法。注意：不能修饰类（外部类） public : 对所有类可见。可以修饰类、接口、变量、方法 protected : 对同一包内的类和所有子类可见。可以修饰变量、方法。注意：不能修饰类（外部类）。 8.final关键字 被final修饰的类不可以被继承 被final修饰的方法不可以被重写 被final修饰的变量不可以被改变，被final修饰不可变的是变量的引用，而不是引用指向的内容，引用指向的内容是可以改变的 9.final、finally、finalize final 是一个修饰符，可以修饰类、方法和变量。当 final 修饰一个类时，表明这个类不能被继承；当 final 修饰一个方法时，表明这个方法不能被重写；当 final 修饰一个变量时，表明这个变量是个常量，一旦赋值后，就不能再被修改了。 finally 是 Java 中异常处理的一部分，用来创建 try 块后面的 finally 块。无论 try 块中的代码是否抛出异常，finally 块中的代码总是会被执行。通常，finally 块被用来释放资源，如关闭文件、数据库连接等。 finalize 是Object 类的一个方法，用于在垃圾回收器将对象从内存中清除出去之前做一些必要的清理工作。 这个方法在垃圾回收器准备释放对象占用的内存之前被自动调用。我们不能显式地调用 finalize 方法，因为它总是由垃圾回收器在适当的时间自动调用。 10.Object类的方法主要常见的有 protected Object clone()：创建并返回一个对象的拷贝。 boolean equals(Object obj)：比较两个对象是否相等，比较的是值和地址，子类可重写以自定义。 protected void finalize()：当GC(垃圾回收器)确定不存在对该对象的有更多引用时，由对象的垃圾回收器调用此方法。 Class&lt;?&gt; getClass()：获取对象的运行时对象的类。 int hashCode()：获取对象的hash值。 void notify()：唤醒在该对象上等待的某个线程。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。 void notifyAll()：唤醒在该对象上等待的所有线程。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。 String toString()：返回对象的字符串表示形式。如果没有重写，应用对象将打印的是地址值。 void wait()：让当前线程进入等待状态。直到其他线程调用此对象的notify()方法或notifyAll()方法。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。 void wait(long timeout)：让当前线程处于等待(阻塞)状态，直到其他线程调用此对象的notify()方法或notifyAll()方法，或者超过参数设置的timeout超时时间。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。 */public final native Class&lt;?&gt; getClass()/** * native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的HashMap。 */public native int hashCode()/** * 用于比较 2 个对象的内存地址是否相等，String 类对该方法进行了重写以用于比较字符串的值是否相等。 */public boolean equals(Object obj)/** * native 方法，用于创建并返回当前对象的一份拷贝。 */protected native Object clone() throws CloneNotSupportedException/** * 返回类的名字实例的哈希码的 16 进制的字符串。建议 Object 所有的子类都重写这个方法。 */public String toString()/** * native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。 */public final native void notify()/** * native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。 */public final native void notifyAll()/** * native方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁 ，timeout 是等待时间。 */public final native void wait(long timeout) throws InterruptedException/** * 多了 nanos 参数，这个参数表示额外时间（以纳秒为单位，范围是 0-999999）。 所以超时的时间还需要加上 nanos 纳秒。。 */public final void wait(long timeout, int nanos) throws InterruptedException/** * 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念 */public final void wait() throws InterruptedException/** * 实例被垃圾回收器回收的时候触发的操作 */protected void finalize() throws Throwable &#123; &#125; 3.面向对象1.面向对象有哪些特性 封装 封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。 继承 继承是使⽤已存在的类的定义作为基础创建新的类，新类的定义可以增加新的属性或新的方法，也可以继承父类的属性和方法。通过继承可以很方便地进行代码复用。 注意： ⼦类拥有⽗类对象所有的属性和⽅法（包括私有属性和私有⽅法），但是⽗类中的私有属性和⽅法⼦类是⽆法访问，只是拥有。 ⼦类可以拥有自己的属性和⽅法，即⼦类可以对⽗类进⾏扩展。 ⼦类可以⽤⾃⼰的⽅式实现⽗类的⽅法。 多态 多态，顾名思义，就是“多种形态”。在 Java 中，它指的是同一个方法在不同的对象上调用时，可以表现出不同的行为。简单来说，就是“一个接口，多种实现”。 多态的核心思想是：父类引用指向子类对象，调用同一个方法时，实际执行的是子类中重写后的方法。 在代码层面，多态主要依赖于以下几个要素： 继承（或实现接口）：多态的前提是子类要继承父类，或者实现某个接口。 方法重写（Override）：子类要重写父类（或接口）中的方法。 2.重载（overload）和重写（override）的区别？方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载发生在一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同。 重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。 重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。 方法重载的规则： 方法名一致，参数列表中参数的顺序，类型，个数不同。 重载与方法的返回值无关，存在于父类和子类，同类中。 可以抛出不同的异常，可以有不同修饰符。 3.抽象类(abstract class)和接口(interface)有什么区别？共同点： 实例化：接口和抽象类都不能直接实例化，只能被实现（接口）或继承（抽象类）后才能创建具体的对象。 抽象方法：接口和抽象类都可以包含抽象方法。抽象方法没有方法体，必须在子类或实现类中实现。 两者的特点： 抽象类用于描述类的共同特性和行为，可以有成员变量、构造方法和具体方法。适用于有明显继承关系的场景。 接口用于定义行为规范，可以多实现 。适用于定义类的能力或功能。 两者的区别： 特性 抽象类 接口 关键字 abstract class interface ⭐️方法实现 可以有抽象方法和具体方法 Java 8前只能有抽象方法，之后可以有默认&#x2F;静态&#x2F;私有方法 变量 可以有普通成员变量 变量默认是public static final常量 ⭐️构造方法 可以有构造方法 不能有构造方法 ⭐️多继承 一个类只能继承一个抽象类 一个类可以实现多个接口 设计目的 代码复用，提供部分实现 定义行为规范&#x2F;契约 访问修饰符 方法可以有各种访问修饰符 方法默认public，不能是private(除私有方法外) 抽象类和接口都不能直接new 子类实现抽象类要实现所有的方法吗？ 12345AbstractClassA (有抽象方法) ↑AbstractClassB (未实现全部方法，保持抽象) ↑ConcreteClassC (必须实现所有剩余抽象方法) 如果子类是抽象类，可以只实现部分方法，如果子类是具体类，则必须实现全部方法 4.深拷贝和浅拷贝? 浅拷贝：浅拷贝会创建一个新对象，但这个新对象的属性（字段）和原对象的属性完全相同。如果属性是基本数据类型，拷贝的是基本数据类型的值；如果属性是引用类型，拷贝的是引用地址，因此新旧对象共享同一个引用对象。 深拷贝：深拷贝也会创建一个新对象，但会递归地复制所有的引用对象，确保新对象和原对象完全独立。新对象与原对象的任何更改都不会相互影响。 4、StringString不是基本数据类型，是引用数据类型 1.String、StringBuilder、StringBuffer String：操作少量的数据 StringBuilder：单线程操作字符串缓冲区下操作大量数据 StringBuffer：多线程操作字符串缓冲区下操作大量数据 2.String str1 &#x3D; new String(“abc”) 和 String str2 &#x3D; “abc” 的区别直接使用双引号为字符串变量赋值时，Java 首先会检查字符串常量池中是否已经存在相同内容的字符串。 如果存在，Java 就会让新的变量引用池中的那个字符串；如果不存在，它会创建一个新的字符串，放入池中，并让变量引用它。 使用 new String(&quot;abc&quot;) 的方式创建字符串时，实际分为两步： 第一步，先检查字符串字面量 “abc” 是否在字符串常量池中，如果没有则创建一个；如果已经存在，则引用它。 第二步，在堆中再创建一个新的字符串对象，并将其初始化为字符串常量池中 “abc” 的一个副本。 也就是说 123456String s1 = &quot;沉默王二&quot;;String s2 = &quot;沉默王二&quot;;String s3 = new String(&quot;沉默王二&quot;);System.out.println(s1 == s2); // 输出 true，因为 s1 和 s2 引用的是字符串常量池中同一个对象。System.out.println(s1 == s3); // 输出 false，因为 s3 是通过 new 关键字显式创建的，指向堆上不同的对象。 String s &#x3D; new String(“abc”)创建了几个对象？ 一个或两个 字符串常量池中如果之前已经有一个，则不再创建新的，直接引用；如果没有，则创建一个。 堆中肯定会创建一个，因为只要使用了 new 关键字，肯定会在堆中创建一个。即使常量池中已经存在 &quot;abc&quot;，new String(&quot;abc&quot;) 依然会创建一个新的对象，而不会直接使用常量池中的对象。 3.如何保证 String 不可变(为什么String是不可变的)第一，String 类内部使用一个私有的字符数组来存储字符串数据。这个字符数组在创建字符串时被初始化，之后不允许被改变。 第二，String 类没有提供任何可以修改其内容的公共方法， 第三，String 类本身被声明为 final，这意味着它不能被继承。这防止了子类可能通过添加修改方法来改变字符串内容的可能性。 6.异常处理1.异常体系Throwable 是 Java 语言中所有错误和异常的基类。它有两个主要的子类：Error 和 Exception，这两个类分别代表了 Java 异常处理体系中的两个分支。 Error 类代表那些严重的错误，这类错误通常是程序无法处理的。比如，OutOfMemoryError 表示内存不足，StackOverflowError 表示栈溢出。这些错误通常与 JVM 的运行状态有关，一旦发生，应用程序通常无法恢复。 Exception 类代表程序可以处理的异常。它分为两大类：受检异常（Checked Exception）和运行时异常（Runtime Exception）也叫非受检异常（Unchecked Exception ）。 ①、受检异常（Checked Exception）：这类异常在编译时必须被显式处理（捕获或声明抛出）。 如果方法可能抛出某种编译时异常，但没有捕获它（try-catch）或没有在方法声明中用 throws 子句声明它，那么编译将不会通过。例如：IOException、SQLException 等。 ②、运行时异常（Runtime Exception）：这类异常在运行时抛出，它们都是 RuntimeException 的子类。对于运行时异常，Java 编译器不要求必须处理它们（即不需要捕获也不需要声明抛出）。 RuntimeException 及其子类都统称为非受检查异常，通常是由程序逻辑错误导致的，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。 常见的有： NullPointerException(空指针错误) IllegalArgumentException(参数错误比如方法入参类型错误) NumberFormatException（字符串转换为数字格式错误，IllegalArgumentException的子类） ArrayIndexOutOfBoundsException（数组越界错误） ClassCastException（类型转换错误） ArithmeticException（算术错误） 2.异常的处理方式 ①、遇到异常时可以不处理，直接通过throw 和 throws 抛出异常，交给上层调用者处理。 throws 关键字用于声明可能会抛出的异常，而 throw 关键字用于抛出异常。 123public void test() throws Exception &#123; throw new Exception(&quot;抛出异常&quot;);&#125; ②、使用 try-catch 捕获异常，处理异常。 1234567try &#123; //包含可能会出现异常的代码以及声明异常的方法&#125;catch(Exception e) &#123; //捕获异常并进行处理&#125;finally &#123; //可选，必执行的代码&#125; 3.Java中的finally一定会被执行吗？finally 代码块在大多数情况下一定会执行，这是 Java 异常处理机制的核心保证。无论 try 块中是否发生异常、是否被捕获、是否有 return 语句，finally 都会在方法返回前执行。 finally 的执行会覆盖 try&#x2F;catch 中的 return 值： 1234567public int demo() &#123; try &#123; return 1; &#125; finally &#123; return 2; // 实际返回2 &#125;&#125; 但有些情况也不会执行： JVM 非正常退出：调用 System.exit(int) 方法；操作系统强制终止 JVM 进程（如 kill -9）；系统崩溃或断电等硬件故障 无限阻塞：try 块中线程被无限期挂起（如 Thread.sleep() 无超时等待）；死锁导致线程永久阻塞 7.I&#x2F;O1.I&#x2F;O流IO 即 Input/Output，输入和输出。数据输入到计算机内存的过程即输入，反之输出到外部存储（比如数据库，文件，远程主机）的过程即输出。 Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。 InputStream&#x2F;Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream&#x2F;Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 2.I&#x2F;O流为什么要分为字符流和字节流问题本质想问：不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I&#x2F;O 流操作要分为字节流操作和字符流操作呢？ 字符流是由 Java 虚拟机将字节转换得到的，这个过程比较耗时； 如果不知道编码类型的话，使用字节流的过程中很容易出现乱码问题 3.BIO、NIO、AIO的区别BIO（Blocking I&#x2F;O）：采用阻塞式 I&#x2F;O 模型，线程在执行 I&#x2F;O 操作时被阻塞，无法处理其他任务，适用于连接数较少的场景。 NIO（New I&#x2F;O 或 Non-blocking I&#x2F;O）：采用非阻塞 I&#x2F;O 模型，线程在等待 I&#x2F;O 时可执行其他任务，通过 Selector 监控多个 Channel 上的事件，适用于连接数多但连接时间短的场景。 AIO（Asynchronous I&#x2F;O）：使用异步 I&#x2F;O 模型，线程发起 I&#x2F;O 请求后立即返回，当 I&#x2F;O 操作完成时通过回调函数通知线程，适用于连接数多且连接时间长的场景。 8.序列化1.什么是序列化，什么是反序列化序列化（Serialization）是指将对象转换为字节流的过程，以便能够将该对象保存到文件、数据库，或者进行网络传输。 反序列化（Deserialization）就是将字节流转换回对象的过程，以便构建原始对象。 Serializable 接口有什么用？ Serializable接口用于标记一个类可以被序列化。 12345public class Person implements Serializable &#123; private String name; private int age; // 省略 getter 和 setter 方法&#125; serialVersionUID 有什么用？ serialVersionUID 是 Java 序列化机制中用于标识类版本的唯一标识符。它的作用是确保在序列化和反序列化过程中，类的版本是兼容的。 所以serialVersionUlD就是起验证作用 Java 序列化不包含静态变量吗？ 是的，序列化机制只会保存对象的状态，而静态变量属于类的状态，不属于对象的状态。 如果有些变量不想序列化，怎么办？ 可以使用transient关键字修饰不想序列化的变量。 12345public class Person implements Serializable &#123; private String name; private transient int age; // 省略 getter 和 setter 方法&#125; 序列化的过程 Java序列化关键类和接口：ObjectOutputStream 用于序列化，ObjectInputStream用于反序列化。类必须实现Serializable接口才能被序列化。 9.反射1.什么是反射Java 反射机制是在运行状态中，对于任意一个类，都能够知道这个类中的所有属性和方法， 对于任意一个对象，都能够调用它的任意一个方法和属性； 这种动态获取的信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。 反射的原理 Java 程序的执行分为编译和运行两步，编译之后会生成字节码(.class)文件，JVM 进行类加载的时候，会加载字节码文件，将类相关的所有信息加载进方法区，反射就是去获取这些信息，然后进行各种操作。 反射的应用场景 Spring 框架就大量使用了反射来动态加载和管理 Bean。 Java 的动态代理（Dynamic Proxy）机制就使用了反射来创建代理类。代理类可以在运行时动态处理方法调用，这在实现 AOP 和拦截器时非常有用。 注解 的实现也用到了反射。 10.注解1.注解的原理注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。 11.SPISPI 即 Service Provider Interface 专门提供给服务提供者或者扩展框架功能的开发者去使用的一个接口。 SPI 将服务接口和具体的服务实现分离开来，将服务调用方和服务实现者解耦，能够提升程序的扩展性、可维护性。 很多框架都使用了 Java 的 SPI 机制，比如：Spring 框架、数据库加载驱动、日志接口、以及 Dubbo 的扩展实现等等。 SPI和API的区别 当实现方提供了接口和实现，我们可以通过调用实现方的接口从而拥有实现方给我们提供的能力，这就是 API。这种情况下，接口和实现都是放在实现方的包中。调用方通过接口调用实现方的功能，而不需要关心具体的实现细节。 当接口存在于调用方这边时，这就是 SPI 。由接口调用方确定接口规则，然后由不同的厂商根据这个规则对这个接口进行实现，从而提供服务。 简单说，API就是接口实现方做好API，然后调用者只管调用，不用关心底层细节； 而SPI是接口的调用方先确定好规则，然后接口实现方去按照这个规则去实现接口 12.语法糖语法糖（Syntactic sugar） 代指的是编程语言为了方便程序员开发程序而设计的一种特殊语法，这种语法对编程语言的功能并没有影响。实现相同的功能，基于语法糖写出来的代码往往更简单简洁且更易阅读。 简而言之，语法糖让程序更加简洁，有更高的可读性。 Java 中最常用的语法糖主要有泛型、自动拆装箱、变长参数、枚举、内部类、增强 for 循环、try-with-resources 语法、lambda 表达式等。 不过，JVM 其实并不能识别语法糖，Java 语法糖要想被正确执行，需要先通过编译器进行解糖，也就是在程序编译阶段将其转换成 JVM 认识的基本语法。这也侧面说明，Java 中真正支持语法糖的是 Java 编译器而不是 JVM。 13.JDK1.8新特性主要还是Stream API和lambda表达式 1.lambda表达式简单来说，Lambda 表达式就是一个匿名函数，它没有名字，但可以像方法一样被调用、传递给其他函数，或者存储在变量中。它的出现让 Java 的代码更简洁，也支持了函数式编程的风格。 Lambda 表达式的写法很简单，主要由三部分组成： 参数列表：放在括号 () 里，可以是空的，也可以有多个参数，就像普通方法的参数一样。 箭头：用 -&gt; 表示，连接参数和后面的内容。 主体：可以是一个表达式，也可以是一个语句块。 如果是单个表达式，直接写出来，结果会自动返回。 如果是多行代码，用 {} 包起来，里面可以写多条语句。 Stream 是对 Java 集合框架的增强，它提供了一种高效且易于使用的数据处理方式。 14.代理模式Java动态代理是Java中一种非常强大的特性，它允许在运行时动态创建代理对象，以实现对目标对象的代理访问。 这种机制在AOP（面向切面编程）、权限控制、日志记录等领域有着广泛的应用。 代理模式是一种比较好理解的设计模式。简单来说就是 我们使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。 比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。 静态代理就不看了，比较简单而且实用性不大 直接看动态代理 灵活性：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的 1.JDK动态代理在 Java 动态代理机制中 InvocationHandler 接口和 Proxy 类是核心。 Proxy 类中使用频率最高的方法是：newProxyInstance() ，这个方法主要用来生成一个代理对象。 JDK动态代理类使用步骤 定义一个接口及其实现类； 自定义 InvocationHandler 并重写invoke方法，在 invoke 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑； 通过 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 方法创建代理对象； 关键1：newProxyInstance 方法 1234567public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException&#123; ......&#125; 这个方法一共有 3 个参数： loader :类加载器，用于加载代理对象。 interfaces : 被代理类实现的一些接口； h : 实现了 InvocationHandler 接口的对象； 关键2：InvocationHandler 接口 12345678public interface InvocationHandler &#123; /** * 当你使用代理对象调用方法的时候实际会调用到这个方法 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; invoke() 方法有下面三个参数： proxy :动态生成的代理类 method : 与代理类对象调用的方法相对应 args : 当前 method 方法的参数 你通过Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，实际会调用到实现InvocationHandler 接口的类的 invoke()方法。 你可以在 invoke() 方法中自定义处理逻辑，比如在方法执行前后做什么事情。 2.CGLIB动态代理JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。 为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。 CGLIB 允许我们在运行时对字节码进行修改和动态生成。 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。 CGLIB 动态代理类使用步骤 定义一个类； 自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似； 通过 Enhancer 类的 create()创建代理类； 在 CGLIB 动态代理机制中 MethodInterceptor 接口和 Enhancer 类是核心。 你需要自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法。 12345public interface MethodInterceptorextends Callback&#123; // 拦截被代理类中的方法 public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args,MethodProxy proxy) throws Throwable;&#125; obj : 被代理的对象（需要增强的对象） method : 被拦截的方法（需要增强的方法） args : 方法入参 proxy : 用于调用原始方法 你可以通过 Enhancer类来动态获取被代理类，当代理类调用方法的时候，实际调用的是 MethodInterceptor 中的 intercept 方法。 JDK动态代理和CGLIB动态代理对比 JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}],"categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"},{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"面试","slug":"面试","permalink":"http://example.com/categories/%E9%9D%A2%E8%AF%95/"},{"name":"学习","slug":"学习","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"},{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"game","slug":"game","permalink":"http://example.com/tags/game/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"JavaSE","slug":"JavaSE","permalink":"http://example.com/tags/JavaSE/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"},{"name":"刷题","slug":"刷题","permalink":"http://example.com/tags/%E5%88%B7%E9%A2%98/"},{"name":"分布式","slug":"分布式","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"日常实习","slug":"日常实习","permalink":"http://example.com/tags/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"},{"name":"实习","slug":"实习","permalink":"http://example.com/tags/%E5%AE%9E%E4%B9%A0/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"Spring, SSM","slug":"Spring-SSM","permalink":"http://example.com/tags/Spring-SSM/"},{"name":"JUC","slug":"JUC","permalink":"http://example.com/tags/JUC/"},{"name":"杂谈记录","slug":"杂谈记录","permalink":"http://example.com/tags/%E6%9D%82%E8%B0%88%E8%AE%B0%E5%BD%95/"},{"name":"音乐","slug":"音乐","permalink":"http://example.com/tags/%E9%9F%B3%E4%B9%90/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"影视","slug":"影视","permalink":"http://example.com/tags/%E5%BD%B1%E8%A7%86/"},{"name":"MybatisPlus","slug":"MybatisPlus","permalink":"http://example.com/tags/MybatisPlus/"},{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}